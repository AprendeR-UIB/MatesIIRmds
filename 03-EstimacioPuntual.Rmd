# Estimació puntual {#chap:estim}

L'objectiu principal de la **inferència estadística** és obtenir informació sobre tota una població a partir de només una mostra, com quan volem saber si un brou és fat o salat tastant-ne només una cullerada. El primer tipus d'informació que ens sol interessar és què val qualque paràmetre d'alguna variable aleatòria poblacional (una proporció, una mitjana...), per exemple per poder escriure un titular com el següent:

```{r, echo=FALSE, out.width="70%", fig.cap="https://www.efesalud.com/miopia-estudio-universitarios"}
knitr::include_graphics("Bioestadistica-II_files/figure-html/miopia.png")
```

Aquest 60% no s'ha obtingut fent passar a tots els universitaris espanyols un test de miopia, ni tan sols demanant-los a tots si són miops o no, sinó que simplement s'ha pres una mostra d'universitaris, s'hi ha observat un 60% de miops i s'ha extrapolat aquesta proporció a tot el col·lectiu d'universitaris espanyols.

El procés d'intentar endevinar el valor d'un paràmetre d'una població a partir d'una mostra se'n diu **estimació puntual**, i és el que tractarem en aquest tema. 

```{block2,type="rmdimportant"}
En aquest curs, sempre suposarem que empram mostres aleatòries i gairebé sempre que aquestes mostres aleatòries són a més simples. Per tant, si no diem el contrari, d'ara endavant  **quan parlem de mostres sempre suposarem que són mostres aleatòries simples**, encara que no ho diguem explícitament per no carregar massa el text.
```



## Estimadors

Per estimar el valor d'un paràmetre d'una variable aleatòria poblacional, en prenem una mostra (aleatòria simple) i calculam qualque cosa amb els valors que la formen. Què calculam? Doncs un **estimador**: alguna funció adequada aplicada als valors de la mostra, i que dependrà del que volguem estimar. 



Per exemple:

* Si volem estimar l'alçada mitjana dels estudiants de la UIB, prendrem una mostra  d'estudiants de la UIB, els amidarem i calcularem la  **mitjana aritmètica** de les seves alçades.

* Si volem estimar la proporció d'estudiants de la UIB que han passat la COVID-19, prendrem una mostra d'estudiants de la UIB, els farem un test d'anticossos i calcularem la **proporció mostral** de positius en la mostra.

Formalment:

* Tenim una **variable aleatòria poblacional** $X$, definida sobre una **població**.

* Una **mostra aleatòria simple**  de mida $n$ de $X$ és un vector $(X_1,\ldots,X_n)$ format per $n$ còpies *independents*  de $X$. 

    Cada variable $X_i$ és una còpia de "Prenem un subjecte de la població i hi mesuram $X$".

* Una **realització** de la mostra aleatòria simple $(X_1,\ldots,X_n)$ és un vector $(x_1,\ldots,x_n)\in \mathbb{R}^n$ de valors presos per aquestes variables aleatòries. 

    És a dir, amb $(X_1,\ldots,X_n)$ repetim $n$ vegades (independents les unes de les altres) el procés de prendre un subjecte de la població i mesurar-hi $X$. Cada vegada que ho fem, obtenim un vector de números, al que diem una **realització** de la mostra.
    
    A la lliçó anterior a aquestes realitzacions les déiem directament "mostres aleatòries simples de valors de $X$"; no passeu ànsia, en sortir d'aquest "formalment" els ho tornarem a dir.
    
* Un  **estimador**  és una variable aleatòria $f(X_1,\ldots,X_n)$ obtinguda aplicant una funció $f$ a una mostra aleatòria simple $(X_1,\ldots,X_n)$. 

    Aquest estimador s'aplica a les realitzacions de la mostra i dóna nombres reals. 


```{block2,type="rmdimportant"}
Un estimador és una **variable aleatòria**, definida sobre la població formada per les mostres aleatòries simples de la població de partida. Per tant, té funció de densitat, funció de distribució (que genèricament anomenarem **distribució mostral**, per indicar que refereix a la probabilitat que li passi qualque cosa al valor del estimador sobre una mostra), esperança, desviació típica, etc.
```

 
```{block2,type="rmdmercifulgod"}
Com ja us hem dit, i com que no hi ha necessitat de filar tan prim, d'ara endavant cometrem l'abús de llenguatge de dir **mostra** (**aleatòria simple**) tant al vector de variables aleatòries $(X_1,\ldots,X_n)$ com a una realització $(x_1,\ldots,x_n)$ i hi ometrem els parèntesis.

```  

Com ja hem comentat a la Secció \@ref(sec:mostreig), si la mida $N$ de la població és MOLT més gran que la mida $n$ de la mostra (per fixar idees, hem dit que si $N\geqslant 1000n$),  els resultats per a mostres aleatòries simples valen (aproximadament) per a mostres aleatòries sense reposició, perquè les  variables aleatòries que formen la mostra sense reposició són gairebé idèntiques i independents i les repeticions són improbables.



## Mitjana mostral

Quan volem estimar el valor mitjà d'una variable sobre una població, en prenem una mostra de valors i calculam la seva mitjana aritmètica, no és ver? Doncs això és la mitjana mostral. 

Donada una variable aleatòria $X$, la seva **mitjana mostral**  (de mostres aleatòries simples) **de mida $n$** és la variable aleatòria $\overline{X}$ "Prenem una mostra aleatòria simple de mida $n$ de $X$ i calculam la mitjana aritmètica dels seus valors". És a dir, formalment, la **mitjana mostral** de mida $n$ de $X$ és la variable aleatòria obtinguda prenent $n$ còpies independents $X_1,\ldots,X_n$ de la  variable aleatòria $X$ i calculant
$$
\overline{X}=\frac{X_1+\cdots+X_n}{n}
$$

```{block2,type="rmdcaution"}
Fixau-vos que definim la mitjana mostral només per a mostres aleatòries simples. Naturalment, té sentit definir-la per a mostres qualssevol, però llavors la seva distribució mostral deixa de complir les propietats que donarem en aquesta secció. El mateix advertiment val per als estimadors que definim en les pròximes seccions.
```


Com a conseqüència del comportament d'esperances i variàncies de combinacions lineals, tenim el resultat següent:


```{theorem, mitjmostgral}
Siguin $X$ una variable aleatòria d'esperança $\mu_X$ i desviació  típica $\sigma_X$, i $\overline{X}$ la seva mitjana mostral (de mostres aleatòries simples) de mida $n$. Aleshores

a) El valor esperat de $\overline{X}$ és $E(\overline{X})=\mu_X$.

b) La desviació típica de $\overline{X}$ és  $\sigma(\overline{X})={\sigma_X}/{\sqrt{n}}$.

```


```{block2,type="rmdcorbes"}
En efecte, com que
$$
\overline{X}=\frac{1}{n}X_1+\cdots +\frac{1}{n}X_n
$$
i les variables $X_1,\ldots,X_n$ són còpies de $X$, i per tant tenen totes esperança $\mu_X$ i variància $\sigma^2_X$, tenim que
$$
\mu_{\overline{X}}=\overbrace{\frac{1}{n}\mu_X+\cdots +\frac{1}{n}\mu_X}^n=\mu_X
$$
i, si $X_1,\ldots,X_n$ són independents,
$$
\sigma_{\overline{X}}=\sqrt{\overbrace{\frac{1}{n^2}\sigma^2_X+\cdots+ \frac{1}{n^2}\sigma^2_X}^n}=\sqrt{\frac{n}{n^2}\sigma^2_X}=\frac{\sigma_X}{\sqrt{n}}
$$

```

```{block2,type="rmdnote"}
Si us hi fixau, per demostrar que $E(\overline{X})=\mu_X$ no hem fet servir que $X_1,\ldots,X_n$ siguin independents. De fet, **la igualtat $E(\overline{X})=\mu_X$ també és vertadera per a mitjanes mostrals de mostres aleatòries sense reposició**. En canvi, la igualtat $\sigma_{\overline{X}}={\sigma_X}/{\sqrt{n}}$ sí que requereix que les mostres aleatòries siguin simples.
```



Per tant:

* $\overline{X}$ és un estimador puntual de $\mu_X$.


* $E(\overline{X})=\mu_X$, la qual cosa significa que:

    * La mitjana de les mitjanes mostrals de totes les mostres aleatòries de mida $n$ de $X$ torna a ser la mitjana $\mu_X$ de $X$.

    * *Esperam que la mitjana mostral doni $\mu_X$*: si repetíssim moltes vegades el procés de prendre una mostra aleatòria de mida $n$ i calcular-ne la mitjana mostral, molt probablement el valor mitjà d'aquestes mitjanes s'acostaria molt a $\mu_X$.
    


* $\sigma(\overline{X})= \sigma_X/\sqrt{n}$ indica que la dispersió de les mitjanes mostrals creix amb la dispersió de $X$ i decreix amb la mida  $n$ de la mostra, tendint a 0 quan $n\to\infty$.

     L'efecte de la mida de les mostres sobre la variabilitat de $\overline{X}$ és raonable. Quan prenem mostres aleatòries grans d'una variable i en calculam la mitjana, el més normal és que dins cada mostra els valors més petits se compensin amb els més grans, i que com a conseqüència les mitjanes siguin més homogènies que els valors de la variable.
     
     Vaja: si triam una persona a l'atzar, no és molt improbable que faci, jo què sé, 2.10 m. Però si prenem una mostra aleatòria de 50 persones, és molt més difícil que la mitjana de les seves alçades sigui 2.10 m. El que hi esperaríem és que les alçades dels més alts s'hi compensin amb les alçades dels més baixos i tot plegat doni una mitjana més "mitjana".

```{block2,type="rmdimportant"}
A la desviació típica de $\overline{X}$ li diem 
l'**error estàndard**, o **típic**, de $\overline{X}$. Per tant, l'error estàndard de la mitjana mostral de mida $n$ de $X$ és  $\sigma_X/\sqrt{n}$.
```

````{example, experimentTCL1}
El fitxer **tests.txt** que trobareu a l'url https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt conté les notes (sobre 100) de tests dels estudiants de Matemàtiques I de fa uns cursos. El guardam en un vector anomenat `tests`:

````

```{r}
tests=scan("https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt")
```

Considerarem la població dels estudiants de Matemàtiques I d'aquell curs i com a variable aleatòria d'interès $X$ la seva nota de tests sobre 100. Per tant, aquest vector `tests` conté els valors de la variable aleatòria d'interès sobre tots els individus de la població. La seva mida és
```{r}
N=length(tests)
N
```

La seva mitjana, que és la mitjana poblacional $\mu_X$, és
```{r}
mu=mean(tests)
mu
```

```{r,include=FALSE}
set.seed(100)
```


Si en prenem una mostra aleatòria simple, per exemple de mida $n=40$, la seva mitjana mostral no té per què coincidir amb la mitjana poblacional:
```{r}
n=40
MAS=sample(tests,n,replace=TRUE) # Una mostra aleatòria simple
x.barra=mean(MAS) # La seva mitjana mostral
x.barra
```

Però si prenem *moltes* mostres aleatòries simples, la mitjana de les seves mitjanes és molt probable que sí que s'acosti  a la mitjana poblacional. Vegem si tenim sort amb cent mil mostres:
```{r}
mitjanes=replicate(10^5,mean(sample(tests,n,replace=TRUE)))
mean(mitjanes)
```

Vegem ara que la desviació típica d'aquesta mostra de mitjanes s'acosta a l'error típic de la mitjana mostral, no a la desviació típica de la població:

* La desviació típica poblacional:
```{r}
sigma=sd(tests)*sqrt((N-1)/N)
sigma
```

* La desviació típica de la mostra de mitjanes:
```{r}
sd(mitjanes)
```

* L'error típic de la mitjana mostral:
```{r}
sigma/sqrt(n)
```

Veiem que les mitjanes mostrals presenten una dispersió molt més petita que la variable poblacional original. Gràficament, als histogrames de les Figures \@ref(fig:histtests) i \@ref(fig:histmeantests) podeu veure com les mitjanes estan més concentrades al voltant de `r round(mu)` que les notes originals.

Recordau del Teorema \@ref(thm:comblinnormals2)  que una combinació lineal de variables aleatòries normals independents torna a ser normal. Com que la mitjana mostral de mostres aleatòries simples és una combinació lineal de variables aleatòries independents, obtenim el resultat següent:

```{theorem, TCLnorm}
Si $X$ és una variable aleatòria normal $N(\mu_X,\sigma_X)$, la seva mitjana mostral $\overline{X}$ de mostres aleatòries simples de mida $n$ és normal 
$$
N\Big(\mu_X,\frac{\sigma_X}{\sqrt{n}}\Big).
$$

```

El teorema següent diu que la conclusió del teorema anterior és aproximadament vertadera si la mida $n$ de les mostres aleatòries simples és gran:



```{theorem, TCL, name="Teorema Central del Límit"}
Siguin $X$ una variable aleatòria *qualsevol* d'esperança $\mu_X$ i desviació típica $\sigma_X$.  Quan $n\to \infty$, la funció de distribució de la seva mitjana mostral $\overline{X}$ de mostres aleatòries simples de mida $n$  tendeix a la d'una variable normal
$$
N\Big(\mu_X,\frac{\sigma_X}{\sqrt{n}}\Big).
$$

```

```{block2, type='rmdcaution'}
Com us podeu imaginar, quan un resultat l'anomenen **Teorema Central** de qualque cosa és perquè és molt important.
```

Normalment aplicarem el Teorema Central del Límit de la manera següent:

```{block2,type="rmdimportant"}
Siguin $X$ una variable aleatòria *qualsevol* d'esperança $\mu_X$ i desviació típica $\sigma_X$.  Si la mida $n$ de les mostres (aleatòries simples) és gran, la mitjana mostral $\overline{X}$ és aproximadament normal $N(\mu_X,\sigma_X/\sqrt{n})$. 

Per fixar una fita, en aquest curs entendrem que $n$ és prou gran com per poder aplicar aquest "resultat" quan és més gran o igual que 40, potser menys com més se sembli $X$ a una normal i potser més si la $X$ és molt diferent d'una normal.
```

```{block2,type="rmdcaution"}
A partir d'ara, sovint cometrem l'abús de llenguatge d'ometre l'adverbi "aproximadament" de l'expressió anterior, i direm simplement que si $n$ és gran, $\overline{X}$ és normal. Però heu de tenir present que aquest "és normal" en realitat vol dir "la seva distribució és aproximadament la d'una variable normal".
```

```{example} 
Suposem que tenim una variable aleatòria $X$ de mitjana poblacional $\mu_X=3$ i desviació típica poblacional $\sigma_X=0.2$ i que en prenem mostres aleatòries simples de mida 100. Pel Teorema Central del Límit, la distribució de la mitjana mostral $\overline{X}$ és  (aproximadament)
$$
N\Big(3,\frac{0.2}{\sqrt{100}}\Big)=N(3,0.02)
$$
  
```


```{example,experimentTCL2}
Tornem a la situació de l'Exemple \@ref(exm:experimentTCL1). Teníem les notes guardades en un vector anomenat **tests**. Amb l'histograma següent podem veure que aquestes notes no tenen pinta de seguir una distribució normal.


````

```{r,histtests,fig.cap="Histograma de les notes de tests"}
fact.trans=hist(tests,plot=FALSE)$counts[1]/hist(tests,plot=FALSE)$density[1]
hist(tests,col="light blue",xlab="Notes dels tests",
     ylab="Freqüències",main="")
curve(fact.trans*dnorm(x,mean(tests),sd(tests)),col="red",lwd=2,add=TRUE)
```

A l'Exemple \@ref(exm:experimentTCL1) també hem construït un vector anomenat **mitjanes** format per 10^5^ mitjanes mostrals de mostres aleatòries simples de notes de mida 40. Pel Teorema Central del Límit, aquestes mitjanes mostrals haurien de seguir aproximadament una distribució normal, malgrat que la "població original" (les notes dels tests) no sigui normal. Vegem-ho amb un histograma, on hem afegit la densitat de la normal $N(\mu_X,\sigma_X/\sqrt{n})$ predita pel Teorema Central del Límit.

```{r,histmeantests,fig.cap="Histograma de les mitjanes de mostres de notes de tests"}  
fact.trans.m=hist(mitjanes,plot=FALSE)$counts[1]/hist(mitjanes,plot=FALSE)$density[1]
hist(mitjanes,col="light blue",xlab="Mitjanes",
     ylab="Freqüències",main="")
curve(fact.trans.m*dnorm(x,mu,sigma/sqrt(n)),col="red",lwd=2,add=TRUE)
```


L'exemple següent és un tipus de pregunta que més endavant ens preocuparà molt.

```{example}
L'alçada d'una espècie de matolls té valor mitjà  115 cm, amb una desviació típica de 25 cm. Si prenem una mostra aleatòria simple de 100 matolls d'aquesta espècie, quina és la probabilitat que la mitjana mostral de les alçades sigui més petita que 110 cm?

```

Diguem $X$ a la variable aleatòria definida per les alçades d'aquests matolls. Pel Teorema Central del Límit, la mitjana mostral $\overline{X}$ de mostres aleatòries simples de 100 alçades segueix una distribució $N(115,25/\sqrt{100})=N(115,2.5)$. Llavors, la probabilitat que ens demanen és
$$
P(\overline{X}< 110)
$$
que podem calcular amb 
```{r}
round(pnorm(110,115,2.5),4)
```

Un `r 100*round(pnorm(110,115,2.5),4)`% de les mostra aleatòries simples de 100 matolls d'aquesta espècie tenen la mitjana de les alçades més petita que 110 cm.

<!--
Sigui ara $X_1,\ldots, X_n$ una mostra aleatòria **sense reposició** de mida $n$ d'una variable aleatòria $X$ d'esperança $\mu_X$ i desviació típica $\sigma_X$.  Si $n$ és molt petit en relació a la mida $N$ de la població, ja hem explicat que podem suposar que aquesta mostra aleatòria és simple i per tant tot funciona com fins ara; en particular, en aquest cas entendrem que els tres teoremes anteriors són vertaders.


Si $n$ és gran en relació a $N$, aleshores el resultat per l'esperança segueix essent vertader (al Teorema \@ref(thm:mitjmostgral).a no suposàvem que la mostra fos simple), i per tant encara tenim que
$$
\mu_{\overline{X}}=\mu_X.
$$
Però en aquest cas cal modificar la fórmula del Teorema \@ref(thm:mitjmostgral).b per a la desviació típica, que ara és:
$$
\sigma_{\overline{X}}=\frac{\sigma_X}{\sqrt{n}}\cdot\sqrt{\frac{N-n}{N-1}}
$$
A més, en aquest cas les conclusions dels Teoremes \@ref(thm:TCLnorm) i \@ref(thm:TCL) no són certes, ni tan sols amb aquesta correcció de l'error típic.  

Al terme
$$
\sqrt{\frac{N-n}{N-1}}
$$
que apareix a la fórmula anterior li diuen el **factor de població finita**.

```{block2, type='rmdcorbes'}
Si us en recordau, aquest factor de població finita és el factor que passava de la desviació típica d'una distribució binomial a la d'una hipergeomètrica. En efecte:

* Si $X_B\sim B(n,p)$, $\sigma^2_{X_B}=np(1-p)$ i per tant $\sigma_{X_B}=\sqrt{np(1-p)}$

* Si $X_H\sim H(A,B,n)$,  amb $A+B=N$ i $p=A/N$,

$$
\begin{array}{rl}
\sigma^2_{X_H} & \displaystyle =\dfrac{nAB}{(A+B)^2}\cdot\dfrac{A+B-n}{A+B-1}\\ & \displaystyle =n\cdot\frac{A}{N}\cdot\frac{N-A}{N}\cdot\dfrac{N-n}{N-1}\\ & \displaystyle =
np(1-p)\cdot \dfrac{N-n}{N-1}
\end{array}
$$
i per tant
$$
\sigma_{X_H}=\sqrt{np(1-p)}\cdot \sqrt{\dfrac{N-n}{N-1}}=\sigma_{X_B}\cdot \sqrt{\dfrac{N-n}{N-1}}.
$$
  
```

```{example}
Tornem a la situació dels Exemples \@ref(exm:experimentTCL1) i \@ref(exm:experimentTCL2). 
Què passa  si prenem les mostres aleatòries de notes de tests sense reposició?
  
````

Prenguem ara 10^5^ mostres aleatòries sense reposició de 40 notes de tests.
```{r}
mitjanes.norep=replicate(10^5,mean(sample(tests,40)))
```

Un altre cop, la mitjana d'aquest vector de mitjanes hauria de ser propera a la mitjana de la població original, que era `r round(mean(tests),2)`:

```{r}
round(mean(mitjanes.norep),2)
```

Calculem ara la desviació típica d'aquest vector de mitjanes:

```{r}
round(sd(mitjanes.norep),2)
```

Aquesta desviació típica no s'apropa a la desviació típica de la població partida per l'arrel quadrada de la mida de les mostres, que hem calculat abans i era `r round(sd(tests)/sqrt(40),2)`. 

Pel que acabam d'explicar, la desviació típica d'aquest vector de mitjanes de mostres sense reposició hauria de ser molt propera a la desviació típica de la població partida per l'arrel quadrada de la mida de les mostres *i tot multiplicat pel factor de  població finita* $\sqrt{(N-n)/(N-1)}$, on $N$ és la mida de la població, és a dir, la longitud del vector `tests`, i $n$ la mida de les mostres. Vegem si és veritat:

```{r}
round((sd(tests)/sqrt(n))*sqrt((N-n)/(N-1)),2)
```

Això ja s'acosta més a la desviació típica del vector de mitjanes de mostres sense reposició, que ha valgut 3.

-->

## Proporció mostral

Quan volem estimar la proporció d'individus d'una població que tenen una determinada característica, en prenem una mostra i hi calculam la proporció de membres amb aquesta característica. Aquesta serà la **proporció mostral** de subjectes amb aquesta característica en la nostra mostra.

Sigui  $X$ una variable aleatòria poblacional de Bernoulli amb **probabilitat d'èxit** $p_X$. És a dir, $X$ pren els valors 1 (èxit) o 0 (fracàs) i $p_X$ és la proporció de subjectes de la població en els quals val 1. Recordau que $E(X)=p_X$ i $\sigma_X=\sqrt{p_X(1-p_X)}$.


La **proporció mostral** (de mostres aleatòries simples) **de mida $n$** de $X$, $\widehat{p}_X$, és la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida $n$ de $X$ i calcular-ne la proporció d'èxits: és a dir, comptar-hi el nombre total d'èxits i dividir el resultat per $n$.

Formalment, sigui $X_1,\ldots,X_n$ una mostra aleatòria simple de mida $n$ de $X$. Sigui $S_n=\sum_{i=1}^n X_i$, que és la variable aleatòria que compta  el nombre d'èxits en una mostra aleatòria simple de mida $n$. Aleshores, la **proporció mostral** de mida $n$ de $X$ és 
$$
\widehat{p}_X=\frac{S_n}{n}=\frac{X_1+\cdots+X_n}{n}.
$$


```{block2, type="rmdcaution"}
Recordau que si prenem mostres aleatòries simples, **$S_n$ és una variable aleatòria binomial $B(n,p_X)$**. Però és un doi dir que la proporció mostral $\widehat{p}_X$ és una variable aleatòria binomial, ni que només sigui perquè les variables aleatòries binomials prenen valors nombres naturals i els valors que pot prendre $\widehat{p}_X$ són fraccions entre 0 i 1.
```


Fixau-vos que $\widehat{p}_X$ és un cas particular de la mitjana mostral $\overline{X}$, per tant per a les proporcions mostrals val tot el que hem dit per a mitjanes mostrals:

```{theorem, pX}
Sigui $X$ una variable aleatòria de Bernoulli amb probabilitat d'èxit $p_X$. Aleshores, la proporció mostral de mostres aleatòries simples de mida $n$ de $X$, $\widehat{p}_X$, satisfà que:

1. $E(\widehat{p}_X)=p_X$

1. $\sigma(\widehat{p}_X)=\sqrt{\dfrac{p_X(1-p_X)}{n}}$

1. Pel Teorema Central del Límit, si la mida $n$ de la mostra és gran, la distribució de $\widehat{p}_X$ és aproximadament la d'una variable normal
$$
N\left({p}_X,\sqrt{\frac{{p}_X(1-{p}_X)}{n}}\right)
$$
i per tant 
$$
\frac{\widehat{p}_X-p_X}{\sqrt{{p}_X(1-{p}_X)/n}}
$$
és aproximadament $N(0,1)$.


```

```{block2,type="rmdnote"}
Els valors de l'esperança i la desviació típica de $\widehat{p}_X$ es poden deduir dels de $S_n$ sense necessitat d'invocar els de la mitjana mostral. Com que $S_n$ és $B(n,p_X)$, sabem que $E(S_n)=np_X$ i $\sigma(S_n)^2=np_X(1-p_X)$ i per tant
$$
\begin{array}{l}
\displaystyle E(\widehat{p}_X)=E\Big(\frac{S_n}{n}\Big)=\frac{E(S_n)}{n}=\frac{np_X}{n}=p_X\\
\displaystyle \sigma(\widehat{p}_X)=\sigma\Big(\frac{S_n}{n}\Big)=\frac{\sigma(S_n)}{n}=\frac{\sqrt{np_X(1-p_X)}}{n}=\sqrt{\frac{p_X(1-p_X)}{n}}
\end{array}
$$
  
```



Alguns comentaris:

* $E(\widehat{p}_X)=p_X$: Esperam que la proporció mostral sigui igual a la proporció poblacional d'èxits (si hi ha, diguem, un 20% d'èxits a la població, quin percentatge d'èxits "esperau" trobar a la mostra? Un 20%, no?). 

    És a dir,  si repetíssim moltes vegades el procés de prendre una mostra aleatòria simple de mida $n$ d'una variable aleatòria de Bernoulli $X$ i calcular-ne la proporció mostral d'èxits, molt probablement la mitjana d'aquestes proporcions mostrals s'acostaria molt a $p_X$.

* En particular, $\widehat{p}_X$ serveix per estimar $p_X$, naturalment.

* $\sigma(\widehat{p}_X)= \sqrt{{p_X(1-p_X)}/{n}}$: la variabilitat dels resultats de $\widehat{p}_X$ decreix amb $n$ i tendeix a 0 quan $n\to \infty$. 

    Pel que fa a la dependència de $\sigma(\widehat{p}_X)$ respecte de $p_X$ si la $n$ és fixada, observau a la Figura \@ref(fig:sqrtp) que $\sqrt{p_X(1-p_X)}$ creix entre 0 i 0.5 i decreix entre 0.5 i 1, assolint el valor màxim a $p_X=0.5$.

```{r sqrtp, echo=FALSE, fig.cap="Gràfica de $\\sqrt{p(1-p)}$"}
curve(sqrt(x*(1-x)),xlab="p",ylab="",lwd=2)
```


* $\sqrt{{p_X(1-p_X)}/{n}}$ és l'**error estándard**, o **típic**, de $\widehat{p}_X$. L'estimam amb l'**error estándard**, o **típic**, **de la mostra** $\sqrt{{\widehat{p}_X(1-\widehat{p}_X)}/{n}}$.

* Sovint cometrem l'abús de llenguatge d'ometre l'adverbi "aproximadament" de l'apartat (3) del teorema anterior, i direm simplement que si $n$ és gran, $\widehat{p}_X$ és normal. Però, repetim, hem de recordar que aquest "és normal" en realitat vol dir "la seva distribució és aproximadament la d'una variable normal".



```{example,experimentTCLprop}
Tornem  una altra vegada a la situació dels Exemples \@ref(exm:experimentTCL1) i \@ref(exm:experimentTCL2). Traduïm el fitxer de notes de tests en un vector binari: 0 per suspens (haver tret menys de 50) i 1 per aprovat (haver tret 50 o més):
  

```

```{r}
# Iniciam totes les notes a 1
aprovs=rep(1,length(tests))
# Posam 0 on la nota del test és suspesa
aprovs[which(tests<50)]=0
```
Aquest vector `aprovs` el podem entendre com els valors sobre la nostra població d'estudiants de la variable poblacional de Bernoulli $Y$ que ens diu si un estudiant aprovà o suspengué els tests. La seva probabilitat poblacional d'èxit (aprovat) $p_Y$ serà la proporció d'estudiants aprovats:
```{r}
p_Y=sum(aprovs)/N
round(p_Y,4)
```

Ara n'extreurem 10^5^ mostres aleatòries simples de mida $n=40$, en calcularem les proporcions mostrals d'aprovats i comprovarem si es confirmen les conclusions del teorema anterior.

```{r}
n=40
props.mostrals=replicate(10^5,mean(sample(aprovs,n,rep=TRUE)))
```

La mitjana d'aquest vector de proporcions hauria de ser propera a la proporció poblacional d'aprovats $p_Y=`r round(p_Y,4)`$.

```{r}  
round(mean(props.mostrals),4)
```

Vegem ara la seva desviació típica:

```{r}
round(sd(props.mostrals),4)
```

Pel Teorema \@ref(thm:pX), sabem que això hauria de ser proper a $\sqrt{p_Y(1-p_Y)/n}$

```{r}
round(sqrt(p_Y*(1-p_Y)/n),4)
```

I pel Teorema Central del Límit, aquestes proporcions mostrals haurien de seguir aproximadament una distribució normal $N(p_Y,\sqrt{p_Y(1-p_Y)/n})$. Vegem-ho amb un histograma:

```{r}
fact.trans.p=hist(props.mostrals,plot=FALSE)$counts[1]/hist(props.mostrals,plot=FALSE)$density[1]
hist(props.mostrals,col="light blue",xlab="Proporcions mostrals",
     ylab="Freqüències",main="Histograma de la mostra de proporcions")
curve(fact.trans.p*dnorm(x,p_Y,sqrt(p_Y*(1-p_Y)/n)),
      col="red",lwd=2,add=TRUE)
```

I això que la mida de les mostres, 40, no és especialment gran.

```{example}
Un  59.1% dels estudiants de la UIB són dones. Hem pres una mostra més o menys aleatòria de 60 estudiants de la UIB i hi hem trobat 40 dones, dos terços. Ens demanam si 40 de 60 és una quantitat raonable de dones en una mostra aleatòria simple d'estudiants de la UIB, o si són moltes (atès que hi esperaríem al voltant d'un 59% de dones).  

 
```

Aquesta pregunta, que serà molt típica d'aquí a pocs temes, la traduïm en la  pregunta següent: 
  
> Si prenem una mostra aleatòria simple de 60 estudiants, quina és la probabilitat que la proporció mostral de dones sigui més gran o igual que 2/3?

La manera més correcta de respondre aquesta qüestió és emprar que el nombre $S_{60}$ de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix de manera exacta una distribució binomial $B(60,0.591)$. Com que el 2/3 de la pregunta en realitat representa 40 dones, la probabilitat demanada és exactament
```{r}
round(1-pbinom(39,60,0.591),4)
```


```{block2,type="rmdcaution"}
Recordau que si $X$ és una variable aleatòria discreta que pren valors enters, com ara la binomial, $P(X\geqslant 40)=1-P(X\leqslant 39)$.
```

Això ens diu que, de mitjana, 1 de cada 7 mostres aleatòries simples de 60 estudiants de la UIB conté almenys 40 dones.  Naturalment, això només és exacte si la proporció poblacional "59.1%" és exacta.

Una altra opció seria  aprofitar el Teorema Central del Límit, segons el qual la proporció mostral $\widehat{p}_X$ de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix una distribució aproximadament normal amb $\mu=0.591$ i
$$
\sigma=\sqrt{\dfrac{0.591(1-0.591)}{60}}=0.0635
$$
Per tant, la probabilitat que $\widehat{p}_X\geqslant 2/3$ és (ara, aproximadament)
```{r}
round(1-pnorm(2/3,0.591,sqrt(0.591*(1-0.591)/60)),4)
```

L'aproximació seria més bona si haguéssim efectuat la correcció de continuïtat. Diguem $Y$ a la normal $N(0.591,0.0635)$. Com que $\widehat{p}_X=S_{60}/60$, seria millor aproximar
$$
P(S_{60}\geqslant 40)=1-P(S_{60}\leqslant 39)
$$ 
per 
$$
1-P(Y\leqslant 39.5/60)
$$
```{r}
round(1-pnorm(39.5/60,0.591,sqrt(0.591*(1-0.591)/60)),4)
```

En el cas de la proporció mostral, de vegades considerarem que s'han pres **mostres aleatòries sense reposició**. En aquest cas, la distribució del nombre d'èxits $S_n$ en una mostra segueix una distribució hipergeomètrica. D'aquí deduïm, exactament igual que en el cas de mostres aleatòries simples, que seguim tenint que $E(\widehat{p}_X)=p_X$, però ara, si $N$ és la mida de la població, 
$$
\sigma({\widehat{p}_X})=\sqrt{\frac{p_X(1-p_X)}{n}}\cdot
\sqrt{\frac{\vphantom{(p_X}N-n}{N-1}}.
$$
Recordau que al factor
$$
\sqrt{\frac{N-n}{N-1}}
$$ 
que transforma $\sigma({\widehat{p}_X})$ per a mostres aleatòries simples en la desviació típica de ${\widehat{p}_X}$ per a mostres aleatòries sense reposició li diem el **factor de població finita**, i és el que transformava la desviació típica d'una variable binomial (que compta èxits en mostres aleatòries simples) en la desviació típica d'una variable hipergeomètrica (que compta èxits en mostres aleatòries sense reposició).


```{block2,type="rmdrecordau"}
Però recordau que si la mida de la població $N$ és molt gran comparat amb $n$, podem suposar que una mostra aleatòria sense reposició és simple.
```


```{example}
Tornem a la situació de l'Exemple \@ref(exm:experimentTCLprop). 
Què passa  si prenem les mostres aleatòries de notes de tests sense reposició?

  
```

Prenguem ara 10^5^ mostres aleatòries sense reposició de 40 notes de tests.
```{r}
props.norep=replicate(10^5,mean(sample(aprovs,n)))
```

Un altre cop, la mitjana d'aquest vector de proporcions mostrals hauria de ser propera a la proporció poblacional d'aprovats $p_Y=`r round(p_Y,4)`$.


```{r}
round(mean(props.norep),4)
```

Calculem ara la desviació típica d'aquest vector:

```{r}
round(sd(props.norep),4)
```

Pel que acabam d'explicar, la desviació típica d'aquest vector de proporcions mostrals de mostres sense reposició hauria de ser molt propera a
$$
\sqrt{\frac{p_Y(1-p_Y)}{n}}\cdot\sqrt{\frac{\vphantom{(p_Y}N-n}{N-1}}
$$
on $N$ és la mida de la població, és a dir, la longitud del vector `aprovs`, i $n$ la mida de les mostres. Vegem si és veritat:

```{r}
round(sqrt(p_Y*(1-p_Y)/n)*sqrt((N-n)/(N-1)),4)
```

```{block2,type="rmdcaution"}
Però si prenem mostres aleatòries sense reposició i la població no és molt més gran que les mostres, ja no es pot aplicar el Teorema Central del Límit: encara que les mostres siguin grans, la proporció mostral no té per què ser aproximadament normal.
```


## Variància mostral

Donada una variable aleatòria $X$, direm:

* La **variància mostral** (de mostres aleatòries simples) **de mida $n$**, $\widetilde{S}_{X}^2$, a la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida $n$ de $X$ i calcular la variància mostral dels seus valors.

* **Desviació típica mostral** (de mostres aleatòries simples) **de mida $n$**, $\widetilde{S}_{X}$, a la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida $n$ de $X$ i calcular la desviació típica mostral dels seus valors.

Formalment, sigui $X_1,\ldots, X_n$ una mostra aleatòria simple de mida $n$ d'una variable aleatòria $X$. Aleshores
$$
\widetilde{S}_{X}^2=\frac{\sum_{i=1}^n (X_{i}-\overline{X})^2}{n-1},\quad 
\widetilde{S}_{X}=+\sqrt{\widetilde{S}_{X}^2}
$$
A més, de tant en tant també farem servir la variància i la desviació típica "a seques":

* La **variància** (de mostres aleatòries simples) **de mida $n$**, $S_{X}^2$, és la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida $n$ de $X$ i calcular la variància dels seus valors:
$$
S^2_{X}=\frac{\sum_{i=1}^n (X_{i}-\overline{X})^2}{n}=\frac{(n-1)}{n}\widetilde{S}^2_{X}
$$

* La **desviació típica** (de mostres aleatòries simples) **de mida $n$**, ${S}_{X}$, és la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida $n$ de $X$ i calcular la desviació típica dels seus valors:
$$
S_X=+\sqrt{S_X^2}
$$

La variància (a seques) admet la  expressió senzilla següent:
$$
S^2_X=\frac{\sum_{i=1}^n X_{i}^2}{n}-\overline{X}^2
$$

```{block2, type='rmdcorbes'}
En efecte:
$$
\begin{array}{l}
\displaystyle \frac{\sum_{i=1}^n (X_{i}-\overline{X})^2}{n}=\frac{1}{n}\sum_{i=1}^n (X_{i}^2-2\overline{X}X_i+\overline{X}^2)\\
\displaystyle\qquad = \frac{1}{n}\Big(\sum_{i=1}^n X_{i}^2-2\overline{X}\sum_{i=1}^n X_{i}+n\overline{X}^2\Big)\\
\displaystyle\qquad =\frac{\sum_{i=1}^n X_{i}^2}{n}-2\overline{X}\frac{\sum_{i=1}^n X_{i}}{n}+\frac{n\overline{X}^2}{n}\\
\displaystyle\qquad =\frac{\sum_{i=1}^n X_{i}^2}{n}-2\overline{X}\cdot\overline{X} + \overline{X}^2=\frac{\sum_{i=1}^n X_{i}^2}{n}- \overline{X}^2
\end{array}
$$

  
```


Tenim els dos resultats següents. El primer ens diu que **esperam** que la variància mostral d'una mostra aleatòria simple de $X$ valgui la variància $\sigma_{X}^2$ de $X$, en el sentit usual que si prenem mostres aleatòries simples de $X$ de mida $n$ gran i calculam les seves variàncies mostrals, molt probablement obtenim de mitjana un valor molt proper a $\sigma_{X}^2$.

```{theorem}
Si $X$ és una variable aleatòria de desviació típica $\sigma_X$ i $\widetilde{S}_{X}$ és la seva variància mostral de mida $n$,
$$
E(\widetilde{S}_{X}^2)=\sigma_{X}^2
$$
per a qualsevol $n$.

```
  

```{block2,type="rmdcaution"}
I per tant **no esperam** que la variància "a seques" d'una mostra aleatòria simple valgui $\sigma_{X}^2$. Això ho podeu comprovar fàcilment, perquè $S_X^2$ s'obté a partir de $\widetilde{S}_{X}^2$ canviant el denominador,
$$
S_X^2=\frac{n-1}{n} \widetilde{S}_{X}^2
$$
i per tant
$$
E(S_X^2)=\frac{n-1}{n}E(\widetilde{S}_{X}^2)=\frac{n-1}{n}\sigma^2_{X}
$$
```


El segon resultat ens diu que **si la variable $X$ és normal**, un múltiple adequat de $\widetilde{S}_{X}^2$ té distribució mostral coneguda, la qual cosa ens permetrà calcular probabilitats d'esdeveniments relatius a $\widetilde{S}_{X}^2$.



```{theorem,khi2}
Si $X$ es $N(\mu_X,\sigma_X)$ i $\widetilde{S}_{X}$ és la seva variància mostral de mida $n$, la variable aleatòria
$$
\frac{(n-1)\widetilde{S}_{X}^2}{\sigma_{X}^2}
$$
té distribució coneguda: $\chi_{n-1}^2$ (es llegeix **khi quadrat amb $n-1$ graus de llibertat**).

```


```{block2,type="rmdcaution"}
La lletra $\chi$  en català es llegeix *khi*; en castellà, *ji*; i en anglès, *chi*, pronunciat *xai*.
```




```{r, echo=FALSE, out.width="40%"}
knitr::include_graphics("Bioestadistica-II_files/figure-html/chihogar.png")
```


De la distribució $\chi_\nu^2$, on $\nu$ són els **graus de llibertat**, heu de saber que:

* Per definició, és la distribució de la suma dels quadrats de $\nu$ variables aleatòries normals estàndard independents. És a dir, si $Z_{1},Z_{2},\ldots, Z_{\nu}$ són variables $N(0,1)$ independents, la variable
$$
Z_{1}^{2}+Z_{2}^{2}+\cdots +Z_{\nu}^{2}
$$ 
té distribució $\chi_\nu^2$.

* Per tant, és una distribució contínua

* El nombre de graus de llibertat $\nu$ és el paràmetre del que depèn la seva densitat

* Amb R és `chisq`

* Si $X_\nu$ és una variable aleatòria amb distribució  $\chi_\nu^2$, aleshores $\mu_{X_\nu}=\nu$ i $\sigma_{X_\nu}^2=2 \nu$


* Per a $\nu$ petits, la distribució d'una $\chi_{\nu}^2$ és asimètrica amb una cua a la dreta.


```{r, echo=FALSE, fig.cap="Algunes densitats de variables $\\chi^2$"}
curve(dchisq(x,1),col=1,lwd=2,xlim=c(0,20),xlab="",ylab="",ylim=c(0,0.3))
curve(dchisq(x,2),col=2,lwd=2,add=TRUE)
curve(dchisq(x,3),col=3,lwd=2,add=TRUE)
curve(dchisq(x,4),col=4,lwd=2,add=TRUE)
curve(dchisq(x,5),col=5,lwd=2,add=TRUE)
curve(dchisq(x,10),col=6,lwd=2,add=TRUE)
legend("topright",col=1:6,lty=c(1,1),
       lwd=c(2,2),legend=paste("n=",c(1:5,10),sep=""),cex=0.8)
```


* A mida que $\nu$ creix, i atès que és la distribució d'una suma de $\nu$ variables aleatòries independents, pel Teorema Central del Límit es va aproximant a una distribució normal $N(n,\sqrt{2n})$.


```{r,echo=FALSE, fig.cap="$\\chi^2$ vs normal"}
curve(dchisq(x,300),xlim=c(150,450),lwd=2,xlab="",ylab="")
curve(dnorm(x,300,sqrt(600)),lwd=2,col="red",add=TRUE)
legend("topleft",col=c("black","red"),lty=c(1,1),
       lwd=c(2,2),legend=c("Khi quadrat amb n=300","Normal"),cex=0.6)
```


Tornem un instant a això dels *graus de llibertat*. Per què diem que la variància (mostral o a seques) té $n-1$ graus de llibertat? 

Doncs perquè si volem construir un conjunt de $n$ nombres $x_1,\ldots,x_n$ que tenguin variància un valor donat, posem $y_0$, en principi podem escollir com volguem $n-1$ d'ells, $x_1,\ldots,x_{n-1}$,  i aleshores el darrer, $x_n$, queda bastant fixat. En matemàtiques això se sol expressar dient que "tenim $n-1$ graus de llibertat a l'hora d'escollir $x_1,\ldots,x_n$ amb variància fixada $y_0$".

```{block2, type='rmdcorbes'}
En efecte, si fixam el valor $y_0\geqslant 0$ de la variància i volem trobar $x_1,\ldots,x_{n}$ 
tals que
$$
y_0=\frac{\sum_{i=1}^n (x_i-\overline{x})^2}{n}=\frac{\sum_{i=1}^n x_i^2}{n}-\overline{x}^2
$$
vegem que per a qualssevol valors de $x_1,\ldots,x_{n-1}$, el valor de $x_n$ queda fixat per una equació quadràtica:
$$
\begin{array}{l}
n y_0 & =\displaystyle \sum_{i=1}^n x_i^2-n\overline{x}^2= \sum_{i=1}^n x_i^2-n\Big(\frac{\sum_{i=1}^n x_i}{n}\Big)^2\\
& =\displaystyle \sum_{i=1}^n x_i^2-\frac{(\sum_{i=1}^n x_i)^2}{n}\\
& \displaystyle =\frac{1}{n}\left(n\sum_{i=1}^n x_i^2-\Big(\sum_{i=1}^{n} x_i\Big)^2\right)\\
& =\displaystyle \frac{1}{n}\left(n\sum_{i=1}^{n-1} x_i^2+n\mathbf{x_n}^2-\Big(\sum_{i=1}^{n-1} x_i\Big)^2\right.\\
& \displaystyle\qquad\qquad \left. -2\Big(\sum_{i=1}^{n-1} x_i\Big)\mathbf{x_n}-\mathbf{x_n}^2\right)\\
& =\displaystyle \frac{1}{n}\left((n-1)\mathbf{x_n}^2-2\Big(\sum_{i=1}^{n-1} x_i\Big)\mathbf{x_n}\right.\\
& \displaystyle\qquad\qquad \left.+n\sum_{i=1}^{n-1} x_i^2-\Big(\sum_{i=1}^{n-1} x_i\Big)^2 \right)
\end{array}
$$
d'on (multiplicant els dos costats de la igualtat per $n$ i dividint-los per $n-1$) obtenim, finalment, l'equació de segon grau en $\mathbf{x_n}$
$$
\mathbf{x_n}^2-\frac{2\sum_{i=1}^{n-1} x_i}{n-1}\mathbf{x_n}+\frac{n\sum_{i=1}^{n-1} x_i^2-\Big(\sum_{i=1}^{n-1} x_i\Big)^2-n^2y_0^2}{n-1}=0
$$
Per tant, fixat $y_0$ i un cop escollits $x_1,\ldots,x_{n-1}$, el darrer valor $x_n$ ha de ser per força una solució d'aquesta equació de segon grau. 

Fixau-vos que aquesta equació no sempre té solució real, perquè pot tenir el discriminant negatiu. Per tant exageràvem un poc dient que podíem triar $x_1,\ldots,x_{n-1}$ "com volguem".  Per exemple, si voleu que la variància sigui 0 i preneu $x_1,\ldots,x_{n-1}$ no tots iguals, podeu estar ben segurs que no trobareu cap $x_n$ que satisfaci aquesta equació: per tenir variància 0, $x_1,\ldots,x_n$ han de ser tots iguals. Però el que ha de quedar clar és que un cop escollits $x_1,\ldots,x_{n-1}$, el valor de $x_n$ ja no pot ser qualsevol, pot prendre com a màxim dos valors diferents.

  
```

```{block2,type="rmdcaution"}
Anau alerta:

* Si la variable poblacional $X$ no és normal, la conclusió del Teorema \@ref(thm:khi2) no és vertadera.

* Encara que $X$ sigui normal, $E(\widetilde{S}_{X})\neq \sigma_{X}$. 

* Ja ho hem comentat abans, però ho repetim: si $S^2_{X}$ és la variància "a seques" (dividint per $n$ en comptes de per $n-1$), $E(S^2_{X})\neq \sigma^2_{X}$. 


```

```{example,pesosnadonsSIDA}
Suposem que el pes en néixer dels nadons segueix una distribució normal, i s'estima que la seva desviació típica (en g) és 800. Hem anotat els pesos de tots els recent nats amb SIDA d'una ciutat durant 2 anys. El teniu al vector `pesos.SIDA` següent:
  
```

```{r}
pesos.SIDA=c(2466,3941,2807,3118,2098,3175,3515,3317,3742,3062,
             3033,2353,2013,3515,3260,2892,1616,4423,3572,2750,
             2807,2807,3005,3374,2722,2495,3459,3374,1984,2495,
             3062,3005,2608,2353,4394,3232,2013,2551,2977,3118,
             2637,1503,2438,2722,2863,2013,3232,2863)
```

Quina és la probabilitat que una mostra (aleatòria simple) de pesos de recent nats de la mateixa mida que aquesta tengui una desviació típica mostral més petita que la d'aquesta mostra? 

La variable d'interès és $X$: "Prenem un recent nat i pesam el seu pes en g". Ens diuen que és normal amb $\sigma=800$. Pel que fa a la nostra mostra de pesos, la seva mida $n$ és

```{r}
n=length(pesos.SIDA)
n
```
i la seva desviació típica mostral és
```{r}
s.tilda=round(sd(pesos.SIDA),1)
s.tilda
```

Sigui $\widetilde{S}_X$ la desviació típica mostral de mida 48 de la variable $X$. Ens demanen $P(\widetilde{S}_X <`r s.tilda`)$. Això tal qual no ho sabem calcular, perquè no sabem la funció de distribució de $\widetilde{S}_X$. Però sí que sabem la de 
$$
\frac{(n-1)\widetilde{S}_{X}^2}{\sigma_{X}^2}=
\frac{`r n-1`\widetilde{S}_{X}^2}{800^2}
$$
Aquesta variable té distribució $\chi_{47}^2$. Per tant el que hem de fer és traduir la probabilitat que volem calcular en termes d'aquesta variable:
$$
P(\widetilde{S}_X<`r s.tilda`)=P\Big(\frac{47\widetilde{S}_{X}^2}{800^2}<\frac{`r n-1`\cdot `r s.tilda`^2}{800^2}\Big)=P(\chi_{`r n-1`}^2<`r round((n-1)*s.tilda^2/800^2,2)`)
$$
i això val
```{r}
round(pchisq(round((n-1)*s.tilda^2/800^2,2),n-1),4)
```

Per tant, només un 1.5\% de les mostres aleatòries simples de `r n-1` recent nats tenen una desviació típica mostral més petita que la de la nostra mostra de recent nats amb SIDA. 




## La distribució t de Student

Recordau que si la variable poblacional $X$ és $N(\mu_X,\sigma_X)$ i prenem mostres aleatòries simples de mida $n$,  la variable
$$
\frac{\overline{X}-\mu_X}{\sigma_{X}/\sqrt{n}}
$$
és normal estàndard. Des del punt de vista teòric això és útil per obtenir fórmules, però normalment no ens serveix per calcular la probabilitat que a $\overline{X}$ li passi qualque cosa, perquè gairebé mai sabrem la desviació típica poblacional $\sigma_{X}$. Què passa si l'estimam per mitjà de $\widetilde{S}_{X}$ amb la mateixa mostra amb la qual calculam $\overline{X}$? Doncs que el resultat següent ens salva el dia, perquè la variable que obtenim té distribució coneguda.


```{theorem}
Sigui $X$ una variable $N(\mu_X, \sigma_X)$. Siguin $\overline{X}$ i  $\widetilde{S}_{X}$ les seves mitjana mostral i desviació típica mostral de mostres aleatòries simples de mida $n$, respectivament. Aleshores, la variable aleatòria
$$
T=\frac{\overline{X}-\mu_X}{\widetilde{S}_{X}/\sqrt{n}}
$$
segueix una distribució coneguda, anomenada **t de Student amb $n-1$ graus de llibertat**, $t_{n-1}$.
  

```

```{block2,type="rmdimportant"}
Al denominador $\widetilde{S}_{X}/\sqrt{n}$ li diem l'**error estàndard**, o **típic**, **de la mostra**: estima l'error estàndard $\sigma_X/\sqrt{n}$ de $\overline{X}$.
```



De la distribució t de Student amb $\nu$ graus de llibertat, $t_{\nu}$, heu de saber que:

* És contínua

* Amb R és `t`

* El nombre de graus de llibertat $\nu$ és el paràmetre del que depèn la seva densitat

* Si $T_{\nu}$ és una variable amb distribució $t_{\nu}$, aleshores  $\mu_{T_{\nu}}=0$  i $\sigma_{T_{\nu}}^2=\nu/(\nu-2)$ (en realitat aquestes dues igualtats només són  veritat si $\nu\geqslant 3$, però no fa falta recordar-ho).

* La funció de densitat d'una variable $T_{\nu}$ és simètrica al voltant de 0 (com la d'una $N(0,1)$):
$$
P(T_{\nu}\leqslant -x)=P(T_{\nu}\geqslant x)=1-P(T_{\nu}\leqslant x)
$$
Per tant 0 també és la seva mediana.

```{r,echo=FALSE,fig.cap="Densitats d'algunes t de Student"}
curve(dnorm(x),col=1,lwd=2,xlim=c(-4,4),xlab="",ylab="",ylim=c(0,0.4))
curve(dt(x,2),col=2,lwd=2,add=TRUE)
curve(dt(x,3),col=3,lwd=2,add=TRUE)
curve(dt(x,4),col=4,lwd=2,add=TRUE)
curve(dt(x,5),col=5,lwd=2,add=TRUE)
curve(dt(x,10),col=6,lwd=2,add=TRUE)
legend("topleft",col=1:6,lty=rep(1,6), lwd=rep(2,6),
legend=c("N(0,1)", paste("t amb g.l.=",c(2:5,10),sep="")),cex=0.7)
```

* Si $\nu$ és gran, la distribució d'una variable $T_{\nu}$ és aproximadament la d'una $N(0,1)$ però amb més variància (perquè $\nu/(\nu-2)>1$) i per tant un poc més aplatada. 

```{r,echo=FALSE,fig.cap="t amb molts graus de llibertat vs Normal estàndard"}
curve(dnorm(x),col=1,lwd=2,xlim=c(-4,4),xlab="",ylab="",ylim=c(0,0.4))
curve(dt(x,50),col=2,lwd=2,add=TRUE)
legend("topleft",col=1:2,lty=rep(1,2), lwd=rep(2,2),
       legend=c("N(0,1)", "t amb g.l.=50"),cex=0.7)
```

El fet que una t de Student sigui més aplatada que una normal estàndard $Z$ implica que les cues de la t tenen major probabilitat que les de $Z$ (fixau-vos que als gràfics anteriors els extrems de les densitats de les t estan per damunt dels de la de $Z$), la qual cosa es tradueix en el fet que és més probable obtenir valors lluny del 0 amb una t de Student que amb una $N(0,1)$.


Indicarem amb $t_{\nu,q}$ el  $q$-quantil d'una  variable aleatòria  $T_{\nu}$ que segueix una distribució   $t_\nu$. És a dir, $t_{\nu,q}$ és el valor tal que
$$
P(T_{\nu}\leqslant t_{\nu,q})=q
$$
Per la simetria de la distribució $t_\nu$,
$$
t_{\nu,q}=-t_{\nu,1-q}.
$$


```{r, echo=FALSE}
x <- seq(-4,4,.1)

plot(x,dt(x,5),type="l",xlab="",ylab="",xaxs="i",yaxs="i",ylim=c(0,.4),bty="l",xaxt="n",yaxt="n",lwd=2)
polysection <- function(a,b,col="light blue",n=11){
    dx <- seq(a,b,length.out=n)
    polygon(c(a,dx,b),c(0,dt(dx,5),0),border=NA,col=col)
}

for(i in -4:-2){
    polysection(i,i+1,col="light blue")
  #  polysection(-i-1,-i,col="grey")
}
for(i in 1:4){
    polysection(i,i+1,col="light blue")
  #  polysection(-i-1,-i,col="grey")
}


axis(1,at=c(-1,0,1), labels=c(expression(t["n,q"]),0,expression(t["n,1-q"])))
abline(v=0,lty=2)
text(-1.5,dt(-1.5,5)/2,labels="q")
text(1.5,dt(1.5,5)/2,labels="q")
```

Hi ha algunes propietats dels quantils de la t de Student que heu de saber, per poder aplicar-les quan no tengueu a l'abast R o una apli per calcular quantils:

* $t_{\nu ,q}\approx z_{q}$ si $\nu$ és molt gran, posem $\nu \geqslant 200$. Per exemple
```{r}
qt(0.975,200) # t_{200,0.975}
qnorm(0.975)  # z_0.975
```

* $t_{\nu,0.95}$ (per a $10\leqslant \nu\leqslant 200$) està entre 1.65 i 1.8; ho podeu aproximar $t_{n,0.95}\approx 1.7$

* $t_{n,0.975}$  (per a $10\leqslant n\leqslant 200$) està entre 1.97 i 2.2; ho podeu aproximar $t_{n,0.975}\approx 2$

```{block2,type="rmdexercici"}
Comprovau amb R les afirmacions sobr els quantils de la t de Student dels darrers dos punts.
```

```{block2, type='rmdcaution'}
Abans de tancar aquesta secció, recordau que, donada una variable aleatòria $X$,  no heu de confondre:

* **Desviació típica** (o **estàndard**) *de la variable aleatòria*, $\sigma_X$: El paràmetre poblacional, normalment desconegut

* **Desviació típica** (o **estàndard**) (sigui mostral, $\widetilde{S}_X$, o a seques, $S_X$) *d'una mostra*: L'estadístic que calculam sobre la mostra i que quantifica la dispersió de la mostra

* **Error típic** (o **estàndard**) *d'un estimador*: La desviació típica de la variable aleatòria que defineix l'estimador, normalment desconeguda

* **Error típic** (o **estàndard**) *d'una mostra*: Estimació de l'error típic de la mitjana mostral (o de la proporció mostral) a partir d'una mostra; servirà per calcular intervals de confiança. És $\widetilde{S}_X/\sqrt{n}$.

```

## Biaix i precisió

En una primera aproximació, la bondat d'un estimador es descriu en termes de dues propietats: la seva exactitud i la seva precisió.

* L'**exactitud** d'un estimador refereix al fet que el seu valor esperat sigui el valor real del paràmetre que es vol estimar.

* La **precisió** d'un estimador refereix al fet que els seus valors estiguin molt concentrats.

Per tant, un estimador serà **exacte** i **precís** quan els seus valors es concentrin molt al voltant del valor real del paràmetre. La combinació d'exactitud i precisió disminueix la probabilitat que una estimació caigui enfora del valor real que volem estimar.

Aquests dos conceptes se solen il·lustrar amb una diana, així que nosaltres també ho farem:


```{r, echo=FALSE, out.width="80%"}
knitr::include_graphics("Bioestadistica-II_files/figure-html/exactprecis.png")
```



### Estimadors no esbiaixats

Un estimador puntual $\widehat{\theta}$ d'un paràmetre poblacional $\theta$ és **exacte**, o **no esbiaixat** (**insesgado**, en castellà), quan el seu valor esperat és precisament el valor poblacional del paràmetre, és a dir, quan
$$
E(\widehat{\theta})=\theta
$$ 
El  **biaix** d'un estimador $\widehat{\theta}$ d'un paràmetre $\theta$ és la diferència $E(\widehat{\theta})-\theta$. L'**exactitud** de l'estimador també es mesura amb aquesta diferència $E(\widehat{\theta})-\theta$, però hem de tenir en compte a l'hora d'expressar-nos que, com més petit sigui el valor absolut d'aquesta diferència, $|E(\widehat{\theta})-\theta|$, **menys esbiaixat** i **més exacte** és l'estimador. Per tant, "augmentar l'exactitud" és reduir el valor absolut del biaix.

**Exemples:** Ja hem vist a les seccions anteriors que

* $E(\overline{X})=\mu_X$. Per tant, $\overline{X}$ és  un estimador no esbiaixat de $\mu_X$.


* $E(\widehat{p}_X)=p_X$. Per tant, $\widehat{p}_X$ és   un estimador no esbiaixat de $p_X$.


* $E(\widetilde{S}_{X}^2)=\sigma_X^2$. Per tant, $\widetilde{S}_{X}^2$ és un estimador no esbiaixat de $\sigma_X^2$.


* Com que ${S}_{X}^2=\dfrac{n-1}{n}\widetilde{S}_{X}^2$, tenim que $E({S}_{X}^2)=\dfrac{n-1}{n}\sigma_X^2$. Per tant, en aquest cas, 
${S}_{X}^2$ és un **estimador esbiaixat** de $\sigma_X^2$, amb biaix
$$
\mu_{{S}_{X}^2}-\sigma_X^2=\dfrac{n-1}{n}\sigma_X^2-\sigma_X^2=-\dfrac{\sigma_X^2}{n}\ \mathop{\longrightarrow}_{\scriptscriptstyle
n\to\infty}\ 0
$$
    En aquest cas diem que el seu **biaix tendeix a 0**.


* $E(\widetilde{S}_{X}), E({S}_{X})\neq \sigma_X$ ni tan sols quan $X$ és normal. Per tant,  $\widetilde{S}_{X}$ i ${S}_{X}$ són estimadors  **esbiaixats** de $\sigma_X$. Quan $X$ és normal, el seu biaix tendeix a 0.

```{block2,type="rmdcaution"}
Recordau que, en general, $E(X^2)\neq E(X)^2$. Per tant, no hauríem d'esperar que $E(\widetilde{S}_{X})=\sqrt{E(\widetilde{S}_{X}^2)}$.
```


```{block2,type="rmdcorbes"}
Per si qualque dia us cal saber-ho, si $X$ és normal
$$
E(\widetilde{S}_X)=\left\{\begin{array}{ll}
\sigma_X\sqrt{\dfrac{2}{(n-1)\pi}}\cdot \dfrac{2^{n-2}(\frac{n}{2}-1)!^2}{(n-2)!} & \text{ si $n$ és parell}\\ 
\sigma_X\sqrt{\dfrac{2\pi}{n-1}}\cdot \dfrac{(n-2)!}{2^{n-2}(\frac{n-1}{2}-1)!^2} & \text{ si $n$ és imparell}
\end{array}\right.
$$
Per tant, per obtenir un estimador no esbiaixat per a $\sigma_X$ només heu de dividir $\widetilde{S}_X$ pel factor que acompanyi la $\sigma_X$ a la dreta d'aquesta fórmula.
```



### Estimadors precisos

Donats dos estimadors $\widehat{\theta}_1$, $\widehat{\theta}_2$ del mateix paràmetre $\theta$, direm que  $\widehat{\theta}_1$ és **més eficient**, o **més precís**, que $\widehat{\theta}_2$ quan la desviació típica de $\widehat{\theta}_1$ és més petita que la de $\widehat{\theta}_2$:
$$
\sigma(\widehat{\theta}_1)< \sigma(\widehat{\theta}_2).
$$  
Quan $\widehat{\theta}_1$ i $\widehat{\theta}_2$ són no esbiaixats, que $\widehat{\theta}_1$ sigui més eficient que $\widehat{\theta}_2$ significa que els seus valors es concentren més al voltant del paràmetre $\theta$ que volem estimar.



Normalment, només comparam l'eficiència de dos estimadors quan són no esbiaixats o amb el biaix que tendeixi a 0. De res ens serveix tenir un estimador molt precís però que sistemàticament dóna un valor llunyà del valor real del paràmetre.


**Exemples:**

* Si $X$ és normal, $\overline{X}$ és l'estimador no esbiaixat més eficient de la mitjana poblacional $\mu_X$.


* Si $X$ és Bernoulli, $\widehat{p}_X$ és l'estimador
no esbiaixat més eficient de la proporció poblacional $p_X$.


* Si $X$ és normal, $\widetilde{S}_X^2$ és l'estimador
no esbiaixat  més eficient de la variància poblacional $\sigma_X^2$.


```{example}
Sigui $X$ una variable aleatòria normal $N(\mu_X,\sigma_X)$.
Considerem la mediana $\mathit{Me}=Q_{0.5}$ d'una mostra aleatòria simple de $X$ com a estimador puntual de $\mu_X$, que coincideix amb la mediana de $X$ per la simetria de les variables normals.


```

Resulta que $E(\mathit{Me})=\mu_X$ però
$$
\sigma^2(\mathit{Me})\approx \dfrac{\pi}{2}\cdot
     \dfrac{\sigma_{X}^2}{n}\approx 1.57 \cdot \frac{\sigma_{X}^2}{n}=1.57\sigma^2_{\overline{X}}
$$

Per tant, si $X$ és normal, la mediana $\mathit{Me}$ també és un estimador no esbiaixat de $\mu_X$, però és menys eficient que $\overline{X}$. Per això preferim emprar la mitjana mostral per estimar $\mu_X$.



```{block2, type='rmdnote'}
Hem dit que si la població és normal, $\widetilde{S}_X^2$ és l'estimador no esbiaixat  més eficient de la variància poblacional $\sigma_X^2$. La variància a seques
$$
S_X^2=\frac{(n-1)}{n} \widetilde{S}_X^2
$$   
és més eficient, perquè
$$
\sigma(S_X^2)=\sqrt{\frac{(n-1)}{n}}\sigma(\widetilde{S}_X^2)<\sigma(\widetilde{S}_X^2),
$$   
però és un estimador esbiaixat de $\sigma_X^2$, amb biaix que tendeix a 0.

Si $n$ és petit, és millor fer servir la variància mostral $\widetilde{S}_X^2$ per estimar la variància, ja que el biaix pot desplaçar substancialment l'estimació, però si $n$ és gran, el biaix de $S_X^2$ ja és petit i es pot fer servir $S_X^2$. De totes formes, si $n$ és molt gran, dividir per $n$ o per $n-1$ no varia gaire el resultat i per tant $\widetilde{S}_X^2$ i $S_X^2$ donen valors molt semblants.

```

## Estimadors màxim versemblants

Un estimador d'un paràmetre és **màxim versemblant**  quan, aplicat a una mostra aleatòria simple,  dóna el valor del paràmetre que fa màxima la probabilitat d'obtenir aquesta mostra.

```{block2,type="rmdcorbes"}
En realitat, l'estimació màxim versemblant d'un paràmetre el que fa màxim  és el producte dels valors de la funció densitat de la variable aleatòria poblacional aplicada als elements de la mostra. Quan la variable aleatòria és discreta, això coincideix amb el que hem dit, perquè la probabilitat d'obtenir un valor concret és la funció densitat aplicada a aquest valor. Però quan la variable aleatòria poblacional és contínua, la probabilitat d'obtenir una mostra concreta és sempre 0 i no té sentit parlar de maximitzar aquest 0. Per això es pren la funció densitat.

Aquí no ens complicarem la vida i entendrem que el que maximitzam és la probabilitat d'obtenir la mostra.
```


```{example}
Suposem que tenim una variable aleatòria Bernoulli $X$ de probabilitat d'èxit $p_X$ desconeguda. Donada una mostra aleatòria simple $x_1,\ldots,x_n$ de $X$, siguin $\widehat{p}_x$ la seva proporció mostral i  
$$
P(x_1,\ldots,x_n\mid p_X=p)
$$ 
la probabilitat d'obtenir la mostra quan la probabilitat poblacional $p_X$ és igual $p$. Un estimador  per a $p_X$ és màxim versemblant quan, aplicat a cada mostra aleatòria simple $x_1,\ldots,x_n$ de $X$, ens dóna el valor de $p$ que fa que 
$$
P(x_1,\ldots,x_n\mid p_X=p)
$$ 
sigui el màxim possible. 


```

Quin creieu que és l'estimador màxim versemblant de $p_X$? Un exemple concret. Suposau en 20 llançaments d'una moneda obtenim 5 cares. Quina creieu que és la probabilitat d'obtenir cara amb aquesta moneda que fa màxima la probabilitat que en 20 llançaments obtinguem 5 cares? La intuïció ens diu que hauria de ser la proporció mostral $\widehat{p}_X=5/20=0.25$, no? Confirmem-ho amb el gràfic  de la probabilitat que una binomial $B(20,p)$ doni 5 en funció de $p$:

```{r,fig.cap="Probabilitat que una B(20,p) valgui 5"}
plot((0:200)/200,dbinom(5,20,(0:200)/200),type="h",xlab="p",ylab="",xaxp=c(0,1,20))
points(0.25,dbinom(5,20,0.25),type="h",col="red")
```

El resultat següent mostra que això sempre és així.


```{theorem}
El valor de $p$ per al qual $P(x_1,\ldots,x_n\mid p_X=p)$ és màxim és $\widehat{p}_x$.

```


```{block2,type="rmdcorbes"}
La demostració és senzilla. Suposau que dins $x_1,\ldots,x_n$ hi ha $m$ 1s i $n-m$ 0s, de manera que $\widehat{p}_X=m/n$. Aleshores, la probabilitat d'obtenir $x_1,\ldots,x_n$ és
$$
P(x_1,\ldots,x_n\mid p_X=p)=p^m(1-p)^{n-m}
$$
Per trobar el valor de $p$ que fa aquest probabilitat màxima, derivau respecte de $p$ i estudiau el signe de la derivada, i concloureu que el màxim es dóna efectivament a $p=m/n$.
```


```{block2,type="rmdimportant"}
La proporció $\widehat{p}_x$ és el valor que fa màxima la probabilitat d'obtenir la nostra mostra, no a l'enrevés: **No és el valor més probable de $p_X$ condicionat a la nostra mostra**. Vaja, no confongueu
$$
P(x_1,\ldots,x_n\mid p_X=p)\text{ amb }P(p_X=p\mid x_1,\ldots,x_n).
$$ 
D'això darrer no en sabem trobar el màxim sense alguna hipòtesi sobre la distribució de probabilitat dels valors possibles de $p_X$.
```


Alguns altres estimadors màxim versemblants:

* $\overline{X}$  és l'estimador màxim versemblant del paràmetre $\lambda$ d'una variable aleatòria Poisson

* $\overline{X}$  és l'estimador màxim versemblant de la mitjana $\mu_X$ d'una variable aleatòria normal


* $S_X^2$ i $S_X$ (la variància i desviació típica **a seques**, no les mostrals!) són els estimadors màxim versemblants de la variància $\sigma_X^2$ i la desviació típica $\sigma_X$ d'una variable aleatòria normal


## Estimació de poblacions {#sec:pobl}

### Estimació de poblacions numerades

```{example, taxi1}
Un dia vaig voler estimar quants taxis hi havia a Palma.
Per fer-ho, assegut en un bar del Passeig Marítim vaig apuntar les llicències dels 40 primers taxis que passaren. Els entraré directament en un vector de R.

```

```{r}
taxis=c(1217,600,883,1026,150,715,297,137,508,134,38,961,538,1154,
        314,1121,823,158,940,99,977,286,1006,1207,264,1183,1120,
        498,606,566,1239,860,114,701,381,836,561,494,858,187)
sort(taxis)
```

Puc estimar quants taxis hi ha a Palma a partir d'aquesta mostra? Us pot semblar una beneitura de pregunta, però aquest és un problema de rellevància històrica, com podeu consultar en [aquest article](https://www.investigacionyciencia.es/files/14469.pdf).

La solució d'aquest problema és donada pel resultat següent:

```{theorem}
Sigui $X$ una variable aleatòria **uniforme** sobre $\{1,2,\ldots,N\}$ (és a dir, $X$ pot prendre tots els valors entre 1 i N, tots amb la mateixa probabilitat 1/N), i sigui $x_1,\ldots,x_n$ una mostra aleatòria sense reposició de $X$. Sigui $m=\max(x_1,\ldots,x_n)$. Aleshores, l'estimador no esbiaixat més eficient de $N$ és
$$
\widehat{N}=m+\frac{m-n}{n}
$$

```


```{block2, type='rmdcorbes'}
Vegem la idea intuïtiva que hi ha al darrere d'aquesta fórmula. Suposau que teniu $x_1,\ldots,x_n$ ordenats en ordre creixent, $x_1<\cdots<x_n$, de manera que $x_n=m$. Calculem la longitud mitjana dels "forats" a l'esquerra de cada valor $x_i$.

* A l'esquerra de $x_1$ hi "falten" els nombres $1,2,\ldots,x_1-1$, per tant hi ha un forat de $x_1-1$ nombres.
* Entre $x_1$ i $x_2$ hi "falten" els nombres $x_1+1,\ldots,x_2-1$, per tant hi ha un forat de $x_2-x_1-1$ nombres.
* En general, entre cada $x_{i-1}$ i $x_{i}$ hi ha un forat de $x_{i}-x_{i-1}-1$ nombres (hi "falten" els nombres $x_{i-1}+1,\ldots,x_i-1$).


Per tant, la mitjana de les longituds d'aquests "forats" és
$$
\begin{array}{l}
\displaystyle \frac{(x_1-1)+(x_2-x_1-1)+\cdots+(x_{n}-x_{n-1}-1)}{n}\\
\displaystyle \qquad\quad =\frac{x_n-n}{n}=\frac{m-n}{n}
\end{array}
$$

El que fa l'estimador $\widehat{N}$ és sumar al màxim de la mostra, $m$, aquesta longitud mitjana dels forats entre membres de la mostra. És a dir, estimam que la mida de la població és tal que a la dreta del màxim de la nostra mostra hi ha un "forat" de mida la mitjana dels forats de la mostra.

```

```{example}
Continuem amb l'Exemple \@ref(exm:taxi1). Emprant la fórmula anterior, obtenim

```

```{r}
max(taxis)+(max(taxis)-length(taxis))/length(taxis)
```

la qual cosa em permeté estimar que hi havia `r round(max(taxis)+(max(taxis)-length(taxis))/length(taxis))` taxis a Palma. 
En realitat, consultant la web de l'Ajuntament, després vaig saber que en aquell moment n'hi havia 1246.

```{example,simultancs}
Fem un experiment. Generarem a l'atzar una mida N d'una població  grandeta, i suposarem que els individus de la població estan numerats de l'1 al N. A continuació, prendrem 100 mostres aleaòries sense reposició de la nostra població i amb cada una d'aquestes mostres estimarem la N emprant la fórmula que hem donat. Al final, calcularem la mitjana d'aquestes estimacions i la compararem amb el valor real de N, que no descobrirem fins el final. 


```

Perquè l'experiment sigui reproduïble, fixarem la llavor d'aleatorietat, però perquè no cregueu que fem trampes amb aquesta llavor, el que farem serà generar a l'atzar la llavor d'aleatorietat amb la funció `sample`.

```{r}
Llavor=sample(1000,1)
Llavor
set.seed(Llavor)
```

Ara generam la mida N de la població com un nombre a l'atzar entre 5000 i 10000.

```{r}
N=sample(5000:10000,1)
```

Suposarem per tant que hi ha N individus a la nostra població, numerats de l'1 al N. Ara generarem 100 mostres aleatòries sense reposició d'aquesta població, i ens quedarem amb la mida i el valor màxim de cada una d'elles, que és l'únic que necessitam saber. Les mides les generarem a l'atzar entre, posem, 25 i 75:

```{r}
Mostra=function(a,b,P){
  # a i b: mides màxima i mínima de la mostra; P: mida de la població
  n=sample(a:b,1)  # Mida de la mostra
  X=sample(P,n)  # Mostra aleatòria de mida n
  c(n,max(X)) # Parell (mida, màxim)
}
Mostres=replicate(100,Mostra(25,75,N))
Mostres
```

En aquesta matriu `Mostres`, cada columna correspon a una mostra aleatòria: la primera filera és la seva mida $n$ i la segona filera el màxim $m$. Ara, amb cada una d'aquestes mostres, podem estimar la mida N de la població per mitjà de la fórmula $m+(m-n)/n$. Dibuixarem un histograma d'aquestes estimacions, per veure què ens ha sortit.

```{r}
Estimacions=Mostres[2,]+(Mostres[2,]-Mostres[1,])/Mostres[1,]
round(range(Estimacions),1) # Estimacions mínima i màxima
hist(Estimacions, breaks=20,col="light blue",
     xlab="Estimacions de N",ylab="Freqüències",main="")
```
Com veieu, obtenim estimacions que van de `r round(min(Estimacions),1)`  a `r round(max(Estimacions),1)`. La mitjana d'aquestes estimacions és
```{r}
round(mean(Estimacions),1)
```

És hora de descobrir el valor de N, per veure si hi hem fet a prop:

```{r}
N
```

No hem fet molt enfora, com veieu.

### Marca-recaptura

Suposem que en una població hi ha $N$ individus, en capturam $K$ (tots diferents), els marcam i els tornam a amollar.  Al cap de poc temps, en capturam $n$, dels quals resulta que $k$ estan marcats. A partir d'aquestes dades, volem estimar el valor de $N$.


Si suposam que $N$ i $K$ no han canviat de la primera a la segona captura (cap individu no ha abandonat la població ni se n'hi ha incorporat cap de nou), aleshores la variable aleatòria
$X$ definida per "Capturam un individu i miram si està marcat" és Bernoulli $Be(p)$ amb $p=K/N$, on coneixem la $K$ i volem estimar la $N$.

Sigui ara $x_1,\ldots,x_n$ la mostra capturada en segon lloc. La seva proporció mostral d'individus marcats és  $\widehat{p}_X=k/n$. Com que $\widehat{p}_X$ és l'estimador màxim versemblant de $p$, estimam que
$$
\dfrac{K}{N}=\dfrac{k}{n}
$$
d'on, aïllant la $N$, estimam que
$$
N=\frac{n\cdot K}{k}.
$$

En resum, l'estimador
$$
\widehat{N}=\frac{n\cdot K}{k}
$$
maximitza la probabilitat d'obtenir $k$ individus marcats en una mostra aleatòria de $n$ individus. És l'**estimador màxim versemblant** de $N$ a partir de $K$, $k$ i $n$; també se li diu **estimador de Lincoln-Petersen**. Fixau-vos que aquest estimador no fa res més que traduir la proporció "Si he trobat $k$ individus marcats en un conjunt de $n$ individus, què ha de valer el nombre total $N$ de individus perquè hi hagi en total $K$ individus marcats?"



```{example, MR}
Suposem que hem marcat 15 peixos d'un llac, i que en una captura posterior de 10 peixos, n'hi ha 4 de marcats. Quants peixos conté el llac?
  
  
```

Ho estimarem amb l'estimador de Lincoln-Petersen:
$$
\widehat{N}=\frac{15\cdot 10}{4}=37.5
$$
Per tant, estimam que hi haurà entre 37 i 38 peixos al llac.

En aquest cas podem comprovar la màxima versemblança d'aquesta estimació, calculant la probabilitat d'obtenir 4 individus marcats en una mostra aleatòria de 10 individus d'una població de $N$ individus on n'hi ha 15 de marcats i trobant la $N$ que maximitza aquesta probabilitat. Per fer-ho, recordem que si una població està formada per $K$ subjectes marcats i $N-K$ subjectes no marcats, el nombre de subjectes marcats en mostres aleatòries sense reposició de mida $n$ segueix una distribució hipergeomètrica $H(K, N-K,n)$. Per tant, per a cada possible $N$, la probabilitat que en una mostra de 10 peixos del nostre llac n'hi hagi 4 de marcats serà `dhyper(4,15,N-15,10)`.


```{r}
N=15:1000  # Rang de possibles valors de N
p=dhyper(4,15,N-15,10)  # Probabilitats de 4 marcats en 10
Nmax=N[which(p==max(p))] # N que maximitza la probabilitat
Nmax
```

Aquest `Nmax` és la $N$ que fa màxima la probabilitat que en una mostra de 10 peixos del nostre llac n'hi hagi 4 de marcats. Vegem-ho amb un gràfic:

```{r}
plot(N[1:86],p[1:86],type="h",xaxp=c(15,100,17),xlab="N",ylab="p")
points(Nmax,dhyper(4,15,Nmax-15,10),type="h",col="red",lwd=1.5)
```

```{block2,type="rmdromans"}
I què hagués passat si no haguéssim trobat cap peix marcat a la mostra?
```

Quan la mida de la mostra és petita, és més convenient emprar  l'**estimador de Chapman**:
$$
\widehat{N}=\frac{(n+1)\cdot (K+1)}{k+1}-1
$$

La idea és que afegim a la població un individu extra i marcat, que suposam que també capturam a la segona mostra. Llavors, aplicam l'estimador de Lincoln-Petersen i finalment restam 1, per descomptar l'individu marcat extra que realment no pertany a la població que volem estimar. D'aquesta manera ja no tenim el problema de dividir per 0 si $k$ ens dóna 0.


En la situació de l'Exemple \@ref(exm:MR), aquest estimador dóna
$$
\widehat{N}=\frac{16\cdot 11}{5}-1=34.2
$$
i ens fa estimar una població total d'uns 34 peixos. Abans hem obtingut entre 37 i 38 peixos. 

```{block2,type="rmdnote"}
Quina de les dues estimacions s'acosta més a la realitat? Ni idea, no ho podem saber. Amb una altra recaptura segurament haguéssim obtingut resultats diferents.
```

L'estimador de Lincoln-Petersen
$$
\widehat{N}=\frac{n\cdot K}{k}
$$
és esbiaixat, amb biaix que tendeix a 0. L'estimador de Chapman és menys esbiaixat però no és màxim versemblant. 

```{example,simulpeixos}
Fem un experiment similar al de l'Exemple \@ref(exm:simultancs). Generarem a l'atzar una mida N d'una població grandeta i en marcarem una certa quantitat K. A continuació, prendrem 50 mostres aleaòries sense reposició de la nostra població i amb cada una d'aquestes mostres estimarem la N emprant els dos estimadors que hem explicat en aquesta subsecció. Al final, calcularem les mitjanes d'aquestes estimacions i les compararem amb el valor real de N, que no descobrirem fins el final. Com a l'Exemple \@ref(exm:simultancs), fixarem la llavor d'aleatorietat a l'atzar.


```



```{r}
Llavor2=sample(1000,1)
Llavor2
set.seed(Llavor2)
```


Ara generam la mida N de la població com un nombre a l'atzar entre 5000 i 10000.

```{r}
N=sample(5000:10000,1)
```

Ara en capturam i marcam K; per fixar idees, prendrem K=200. 

```{r}
K=200
```

Per simplificar, suposarem que els N individus de la nostra població estan numerats de l'1 a l'N i que els marcats són els K primers. Ara generarem 100 mostres aleatòries sense reposició d'aquesta població, i ens quedarem amb la mida de la mostra i el nombre d'individus marcats (és a dir, el nombre de valors $\leq K=200$ en la mostra). Les mides les generarem a l'atzar entre, posem, 100 i 150:

```{r}
Mostra=function(a,b,P,M){
  # a i b: mides màxima i mínima de la mostra; P: mida de la població;
  # M: nombre de marcats
  n=sample(a:b,1)  # Mida de la mostra
  X=sample(P,n,rep=FALSE)  # Mostra aleatòria 
  c(n,length(which(X<=M))) # Parell (mida, nombre de marcats)
}
Mostres=replicate(100, Mostra(100,150,N,K))
Mostres
```

En aquesta matriu `Mostres`, cada columna correspon a una mostra aleatòria: la primera filera és la seva mida $n$ i la segona filera el nombre d'individus marcats a la mostra. Ara, amb cada una d'aquestes mostres, podem estimar la mida N de la població per mitjà de l'estimador de Lincoln-Petersen.

```{r}
EstimacionsLP=Mostres[1,]*K/Mostres[2,]
round(range(EstimacionsLP),1)
hist(EstimacionsLP, breaks=20,col="light blue",
     xlab="Estimacions de N",ylab="Freqüències",
     main="Estimador de Lincoln-Petersen")
```
Com veieu, obtenim estimacions que van de `r round(min(EstimacionsLP),1)`  a 30000. La mitjana de les estimacions  és
```{r}
round(mean(EstimacionsLP),1)
```

També podem emprar l'estimador de Chapman:
```{r}
EstimacionsCh=(Mostres[1,]+1)*(K+1)/(Mostres[2,]+1)-1
round(range(EstimacionsCh),1)
hist(EstimacionsCh, breaks=20,col="light blue",xlab="Estimacions de N",ylab="Freqüències",main="Estimador de Chapman")
```
Com veieu, obtenim estimacions que van de `r round(min(EstimacionsCh),1)`  a `r as.integer(round(max(EstimacionsCh),1))`. La mitjana d'aquestes estimacions   és
```{r}
round(mean(EstimacionsCh),1)
```


És hora de descobrir el valor de N, per veure si hi hem fet a prop:

```{r}
N
```

Com veieu, amb l'estimador de Chapman ens hem fet més a prop del valor real de $N$ que amb el màxim versemblant. Però amb cap d'ells ens hi hem fet molt a prop. 


## Test de la lliçó 3


**(1)** Tenim una variable aleatòria $X$ normal de mitjana $\mu$ i desviació típica $\sigma$. Prenem mostres aleatòries simples de mida $n$, i indicam amb  $\widetilde{S}_X$ la seva desviació típica mostral. Quina o quines de les afirmacions següents són vertaderes?

1.  $E(\widetilde{S}_X^2)=\sigma^2$.
1.  $E(\widetilde{S}_X)=\sigma$.
1.  $\widetilde{S}_X^2$ segueix una distribució $\chi^2$ amb $n-1$ graus de llibertat.
1.  $(n-1)\widetilde{S}_X^2/\sigma^2$ segueix una distribució $\chi^2$ amb $n-1$ graus de llibertat.
1.  Totes les altres respostes són falses.




**(2)** Quina o quines de les  afirmacions següents sobre la mitjana mostral són vertaderes? 

1.  Si la distribució poblacional és normal, sempre coincideix amb la mediana de la mostra.
1.  Sempre serveix per estimar la mitjana poblacional. 
1.  Sempre serveix per estimar la mediana poblacional. 
1.  Si la distribució poblacional és normal, serveix per estimar la mediana poblacional. 
1.  Cap de les altres respostes és correcta.



**(3)** L'error estàndard de la mitjana mostral de mida $n\geq 2$ (marca  totes les continuacions correctes): 

1.  Mesura la variabilitat de les observacions que formen la mostra.
1.  És l'exactitud amb què es mesura cada observació de la mostra.
1.  Mesura la variabilitat de les mitjanes mostrals de mostres aleatòries simples. 
1.  Mesura la precisió amb què les mitjanes mostrals de mostres aleatòries simples estimen la mitjana poblacional. 
1.  És proporcional a la mitjana mostral.
1.  És més gran que la desviació típica de la població. 
1.  Sobre cada mostra val la desviació típica de la mostra.
1.  Cap de les altres respostes és correcta.


**(4)** La proporció d'afectats per una determinada malaltia en una població és del 10%. Si estimam aquesta proporció poblacional repetidament a partir de mostres de mida 1000, aquestes estimacions segueixen una distribució que (marca totes les afirmacions correctes): 

1.  És una distribució mostral. 
1.  És aproximadament normal. 
1.  Té mitjana 0.1. 
1.  Té variància 90. 
1.  És binomial. 
1.  Cap de les altres respostes és correcta.



**(5)** Què hem de fer per disminuir a la meitat l'error estàndard d'una proporció? 

1.  Hem d'augmentar en un 50% la mida de la mostra
1.  Hem de doblar la mida de la mostra.
1.  Hem de quadruplicar la mida de la mostra.  
1.  Hem de dividir per 2 la mida de la mostra.
1.  Hem de dividir per 4 la mida de la mostra.
1.  Cap de les altres respostes és correcta.

**(6)** La probabilitat que els individus d'una determinada població tenguin una determinada característica $C$ és $p$. Prenem mostres aleatòries simples de mida $n$ d'aquesta població, i indicam amb   $\widehat{p}_X$ la seva proporció mostral. Quina o quines de les afirmacions següents són vertaderes?   

1.  $\widehat{p}_X$ té sempre distribució binomial $B(n,p)$.
1.  $\widehat{p}_X$ té sempre distribució  normal.
1.  Si $n$ és gran, $\widehat{p}_X$ té distribució aproximadament binomial  $B(n,p)$.
1.  Si $n$ és gran, $\widehat{p}_X$ té distribució aproximadament normal.
1.  L'error estàndard de $\widehat{p}_X$ és  $\sqrt{p(1-p)/n}$.


**(7)** Sigui $X$ una variable aleatòria que no és constant. Si en prenem mostres aleatòries simples més grans (marca totes les continuacions correctes):

1.  La mitjana mostral sempre disminueix. 
1.  L'error estàndard de la mitjana sempre disminueix. 
1.  L'error estàndard de la mitjana sempre augmenta.  
1.  La variància mostral sempre augmenta. 
1.  El nombre de graus de llibertat de l'estimador $\chi^2$ associat a la variància mostral sempre augmenta. 
1.  Cap de les altres respostes és correcta.


**(8)** La longitud d'una determinada espècie d'animalons  té un valor mitjà de $\mu$ cm.  Si prenem mostres aleatòries simples de 20 exemplars, calculam la seva mitjana mostral $\overline{X}$ i la seva desviació típica mostral $\widetilde{S}_X$ (marca la continuació més correcta):


1.  L'estadístic $\frac{\overline{X}-\mu}{\widetilde{S}_X/\sqrt{20}}$ segueix sempre una llei normal.
1.  L'estadístic $\frac{\overline{X}-\mu}{\widetilde{S}_X/\sqrt{20}}$ segueix sempre una llei t de Student.
1.  L'estadístic $\frac{\overline{X}-\mu}{\widetilde{S}_X/\sqrt{20}}$ segueix una llei normal si la longitud segueix una llei normal.
1.  L'estadístic $\frac{\overline{X}-\mu}{\widetilde{S}_X/\sqrt{20}}$ segueix una llei t de Student si la longitud segueix una llei normal. 
1.  L'estadístic $\frac{\overline{X}-\mu}{\widetilde{S}_X/\sqrt{20}}$ no segueix mai ni una llei normal ni una llei t de Student, perquè les mostres no són prou grans.


**(9)** En una mostra de 100 dones es va obtenir una concentració mitjana d'hemoglobina en sang de 10 amb una desviació típica de 2. Quin és l'error típic de la mostra?

1. 0.02
1. 0.04
1. 0.2
1. 0.4
1. 1
1. Cap dels valors anteriors




**(10)** Què significa que un estimador d'un paràmetre d'una variable aleatòria sigui no esbiaixat?  

1.  Que la distribució mostral de l'estimador és normal.
1.  Que aplicat a una mostra aleatòria simple sempre dóna el valor poblacional del paràmetre.
1.  Que el seu valor esperat és igual al valor poblacional del paràmetre. 
1.  Que aplicat a una mostra aleatòria simple sempre dóna el valor esperat del  paràmetre.
1.  Que el seu error típic és petit.


**(11)** La concentració en sang a les persones d'un determinat metabolit (en mg/ml) té una distribució $N(23,3)$. Quina de les afirmacions següents és vertadera?


1.  Aproximadament un 90% de les mostres aleatòries de 100 individus tendran la seva mitjana entre 22.4 i 23.6 mg/ml.
1.  Aproximadament un 95% de les mostres aleatòries de 100 individus tendran la seva mitjana entre 22.4 i 23.6 mg/ml. 
1.  Aproximadament un 99% de les mostres aleatòries de 100 individus tendran la seva mitjana entre 22.4 i 23.6 mg/ml.
1.  Més d'un 99% de les mostres aleatòries de 100 individus tendran mitjana igual a 23.
1.  Cap de les afirmacions anteriors és vertadera.




**(12)** Sigui $X$ una variable aleatòria $N(\mu_X,2)$ i sigui $\overline{X}$ la mitjana mostral de mida $10$ de $X$. Quina de les  afirmacions següents és vertadera? 

1.  La desviació típica de $\overline{X}$ és igual a 2. 
1.  La desviació típica de $\overline{X}$ és menor que 2. 
1.  La desviació típica de $\overline{X}$ és major que 2. 
1.  Que la desviació típica de $\overline{X}$ sigui major, menor o 
igual que 2 depèn de $\mu_X$.
1.  Cap de les afirmacions anteriors és vertadera.

