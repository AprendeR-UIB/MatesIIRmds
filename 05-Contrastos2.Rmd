# Contrastos d'hipòtesis d'un i dos paràmetres

## Test t per a una mitjana

Si estam en una de les dues situacions següents: 

* $X$ una variable aleatòria normal de mitjana $\mu$ i prenem una mostra aleatòria simple de mida $n$ qualsevol

* $X$ una variable aleatòria qualsevol de mitjana $\mu$ i prenem una mostra aleatòria simple de mida $n$ gran (diguem  de com a mínim 30, o millor 40, subjectes)

i volem realitzar un contrast
$$
\left\{\begin{array}{l}
H_{0}:\mu=\mu_0\\ 
H_{1}:\mu \neq\mu_0\text{ o }\mu >\mu_0\text{ o }\mu<\mu_0
\end{array}
\right.
$$
podem emprar el **test t** que ja hem explicat a la Secció \@ref(sec:exttest), basat en l'estadístic de contrast
$$
T= \frac{\overline{X}-\mu_{0}}{{\widetilde{S}_X}/{\sqrt{n}}}
$$
que, en les condicions donades i si $\mu=\mu_0$, té una distribució (aproximadament, quan $X$ no és normal però $n$ és gran) $t_{n-1}$.

```{example, ttest1}
Una organització ecologista afirma que el pes  mitjà dels individus adults d'una espècie  ha disminuït dràsticament.
Se sap per les dades històriques que el pes mitjà poblacional era de 460 g.

```

Una mostra aleatòria de 50 individus d'aquesta espècie ha donat una mitjana mostral de 428 g i una desviació típica mostral de 119 g. Amb aquestes dades, podem afirmar  amb un nivell de significació del 5%  que el pes mitjà és inferior a 460 g?


* *Variable aleatòria d'interès*: $X$: "Prenem un animaló d'aquests i mesuram el seu pes, en grams",  de mitjana $\mu$

* *Contrast*:
$$
\left\{\begin{array}{l}
H_{0}:\mu=460\\
H_{1}:\mu<460
\end{array}
\right.
$$

* *Nivell de significació*: $\alpha=0.05$

* *Estadístic*: Com que $n=50$ és  gran, podem usar
$$
T=\frac{\overline{X}-\mu_0}{{\widetilde{S}_X}/{\sqrt{n}}}
$$
que sí $H_0$ és vertadera serà (aproximadament) t de Student amb $n-1=49$ graus de llibertat

* *Valor de l'estadístic*:
$$
\dfrac{428-460}{{119}/{\sqrt{50}}}=-1.9
$$

* *p-valor*:
$$
P(T\leq -1.9)=\texttt{pt(-1.9,49)}=0.032
$$

* *Interval de confiança del 95%*:
$$
\left(-\infty, \overline{X}-t_{n-1,\alpha}\cdot \frac{\widetilde{S}_X}{\sqrt{n}}\right]=(-\infty, 456.2]
$$


* *Decisió*: Com que el p-valor és més petit que 0.05,  concloem (amb $\alpha=0.05$) que el pes mitjà actual és més petit que 460 g. Amb un 95% de confiança podem afirmar que el pes mitjà actual és inferior a 456.2 g.

Ho resumiríem dient:

> Hi ha evidència estadísticament significativa que el pes mitjà actual és menor que 460 g (p=0.03, IC 95% $-\infty$ a 456.2) i que per tant ha minvat en els darrers anys


## Test t per a dues mitjanes

Si estam en una de les situacions següents:


* $X_1,X_2$ dues variables aleatòries normals de mitjanes $\mu_1$, $\mu_2$ i en prenem mostres aleatòries simples de mides $n_1$, $n_2$ qualssevol

* $X_1,X_2$ dues variables aleatòries qualssevol de mitjanes $\mu_1$, $\mu_2$ i i en prenem mostres aleatòries simples de mides $n_1$, $n_2$ grans (diguem de com a mínim 30, o millor 40, subjectes cadascuna)

i volem realitzar un contrast
$$
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2\\ 
H_{1}:\mu_1 \neq\mu_2\text{ o }\mu_1 >\mu_2\text{ o }\mu_1<\mu_2
\end{array}
\right.
$$
podem usar un **test t**, basat en un estadístic de contrast $T$ adequat que segueix una llei t de Student.

L'estadístic de contrast concret i els graus de llibertat de la seva distribució t de Student depenen:


* De si les dues mostres són **independents** (hem mesurat $X_1$ i $X_2$ sobre dues mostres obtingudes de manera independent una de l'altra) o **aparellades** (hem mesurat $X_1$ i $X_2$ sobre els subjectes d'una mateixa mostra o hi ha un aparellament natural entre els subjectes de les dues mostres)

* Quan les mostres són independents, també depenen de si $X_1$ i $X_2$ tenen la *mateixa variància* o no (que s'ha de decidir amb un altre contrast); per a mostres de la mateixa mida de variables normals, la conclusió sol ser la mateixa

Quan les mostres són aparellades, podem entendre que tenim una sola mostra, formada per les parelles. En aquest cas, traduïm
$$
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2\\ 
H_{1}:\mu_1 \neq\mu_2\text{ o }\mu_1 >\mu_2\text{ o }\mu_1<\mu_2
\end{array}
\right.
$$
en
$$
\left\{\begin{array}{l}
H_{0}:\mu_1=\mu_2\\ 
H_{1}:\mu_1-\mu_2 \neq0\text{ o }\mu_1-\mu_2 >0\text{ o }\mu_1-\mu_2<0
\end{array}
\right.
$$
on $\mu_1-\mu_2$ és la mitjana de $X_1-X_2$, i el consideram un contrast d'una sola mitjana, emprant com a mostra les diferències $X_1-X_2$ a les parelles.

Per tant, quan les mostres són aparellades, si diem $\overline{D}$ a la mitjana mostral de $X_1-X_2$ i $\widetilde{S}_D$ a la desviació típica mostral de $X_1-X_2$ sobre la mostra de parelles i diem $n$ a la mida de la mostra de parelles,  l'estadístic de contrast és
$$
T=\frac{\overline{D}}{\widetilde{S}_D/\sqrt{n}}
$$
que quan $\mu_1-\mu_2=0$ té (aproximadament, en el cas que $X_1,X_2$ no siguin normals però la $n$ sigui gran) distribució $t_{n-1}$.


Quan les mostres són independents, siguin $\overline{X}_1$ i $\widetilde{S}^2_1$ la mitjana mostral i la variància mostral de la mostra de $X_1$ i $\overline{X}_2$ i $\widetilde{S}^2_2$ la mitjana mostral i la variància mostral de la mostra de $X_2$. Diguem, a més, $\sigma_1^2$ i $\sigma_2^2$ a les variàncies (poblacionals) de $X_1$ i $X_2$. Aleshores:


* Si $\sigma_1^2=\sigma_2^2$, l'estadístic de contrast és
$$
T=\frac{\overline{X}_1-\overline{X}_2}{\sqrt{(\frac{1}{n_1}+\frac{1}{n_2})\cdot 
\frac{(n_1-1)\widetilde{S}_1^2+(n_2-1)\widetilde{S}_2^2}{n_1+n_2-2}}}
$$
que, quan $\mu_1=\mu_2$, té distribució (aproximadament, en el cas que $X_1,X_2$ no siguin normals però $n_1$ i $n_2$ siguin grans) $t_{n_1+n_2-2}$


* Si $\sigma_1^2\neq \sigma_2^2$, l'estadístic de contrast és
$$
T=\frac{\overline{X}_1-\overline{X}_2}{\sqrt{\frac{\widetilde{S}_1^2}{n_1}+\frac{\widetilde{S}_2^2}{n_2}}}
$$
que, quan $\mu_1=\mu_2$, té distribució (aproximadament, en el cas que $X_1,X_2$ no siguin normals però $n_1$ i $n_2$ siguin grans) $t_{\nu}$ amb
$$
\nu=\frac{\displaystyle \left( \frac{\widetilde{S}_1^2}{n_1}+\frac{\widetilde{S}_2^2}{n_2}\right)^2}
{\displaystyle \frac{1}{n_1-1}\left(\frac{\widetilde{S}_1^2}{n_1}\right)^2+\frac{1}{n_2-1}\left(\frac{\widetilde{S}_2^2}{n_2}\right)^2}
$$

```{block2,type="rmdnote"}
No cal que sapigueu aquestes fórmules per a mostres independents, només que l'estadístic de contrast i la seva distribució depenen de si les variàncies poblacionals són iguals o diferents.
```

El nombre de graus de llibertat de la distribució t de Student usada en un contrast sobre dues mostres de mida $n$:

* Si les mostres són aparellades, és $n-1$

* Si les mostres són independents, és aproximadament $2(n-1)$

Això fa que la probabilitat d'error de Tipus I del contrast amb mostres aparellades (a igualtat de la resta de valors) sigui més petita. Per exemple, suposem que volem realitzar el contrast
$$
\left\{
\begin{array}{l}
H_0: \mu_1=\mu_2\\
H_1: \mu_1>\mu_2
\end{array}
\right.
$$
i que l'estadístic de contrast $T$ sobre dues mostres de mides $n_1=n_2=20$ dóna 1.7. Aleshores

* Si les mostres són independents,
$$
\text{p-valor}=P(T>1.7)\approx \texttt{1-pt(1.7,38)}=0.0487
$$

* Si les mostres són aparellades,
$$
\text{p-valor}=P(T>1.7)=\texttt{1-pt(1.7,19)}=0.0527
$$

Per tant, amb nivell de significació $\alpha=0.05$, rebutjaríem la hipòtesi nul·la amb les mostres independents i l'acceptaríem amb les mostres aparellades.

Tots aquests tests t estan implementats en la funció de R
```{r,eval=FALSE}
t.test(x, y, mu=..., alternative=..., conf.level=..., paired=..., var.equal=...)
```

on:

* Entram com a `x` una mostra i a `mu` el valor amb el qual volem contrastar $\mu$, o entram com a `x` i `y` les
mostres de $X_1$ i  de $X_2$

* A `alternative` hi hem d'indicar el tipus de contrast segons la hipòtesi alternativa:

    * `alternative="two.sided"` ($\neq$, el valor per defecte)
    * `alternative="less"` ($<$)
    * `alternative="greater"` ($>$)

* En el cas d'un contrast de dues mitjanes, a `paired` hi hem d'indicar si les mostres són independents, amb `paired=FALSE` (el valor per defecte), o aparellades, amb `paired=TRUE`

* En el cas d'un contrast de dues mitjanes amb mostres independents, a `var.equal`  hi hem d'indicar si les variàncies són iguals,  amb `var.equal=TRUE`, o diferents, amb `var.equal=FALSE` (el valor per defecte)

* A `conf.level` hi hem d'especificar el nivell de confiança $1-\alpha$: el seu valor per defecte és 0.95, que correspon al nivell de significació $\alpha=0.05$ usual 

```{example, temphomes1}
La temperatura mitjana del cos humà, és el valor usualment acceptat de 98.6^o^ F (37^o^ C)?

```

Per contrastar-ho, emprarem la taula de dades **Body_Temperature.txt**, construïda per P.A. Mackowiak, S. S. Wasserman i M.M. Levine en 1992 precisament per realitzar aquest contrast i que trobareu a l'Aula Digital. 

* *Variable aleatòria d'interès*: $X$: "Prenem una persona i li miram la temperatura, en graus F", de mitjana $\mu$

* *Contrast*:
$$
\left\{\begin{array}{l}
H_{0}:\mu=98.6\\
H_{1}:\mu \neq 98.6
\end{array}
\right.
$$


Realitzarem aquest contrast amb R. Carregam la taula de temperatures, que prèviament hem guardat en el directori de treball de R, en un dataframe que anomenarem `BT`.

```{r}
BT=read.table("Body_Temperature.txt")
head(BT)
str(BT)
```

Veiem que la taula `BT` consta de 230 individus i 3 variables mesurades sobre cadascun d'ells: el sexe (variable `Gender`, amb valors `F` per a dona i `M` per a home), les pulsacions per minut (variable `HeartRate`) i la temperatura en graus F (variable `Temperature`).

Com que la mostra és gran, $n=230$, podem emprar un test t. Emprarem la funció `t.test`, aplicant-la al vector de temperatures i al valor que contrastam, 98.6, entrat amb el parametre `mu`. El paràmetre `alternative="two.sided"` indica que el test serà bilateral.

```{r}
t.test(BT$Temperature, mu=98.6, alternative="two.sided")
```

Del resultat cal destacar:

* El p-valor, `p-value`, en el nostre cas $`r round(t.test(BT$Temperature, mu=98.6, alternative="two.sided")$p.value,11)`$ (R l'ha escrit en notació científica: `r sprintf("%.3e", t.test(BT$Temperature, mu=98.6, alternative="two.sided")$p.value)`).

* L'IC 95%, `95 percent confidence interval`, per al valor que contrastam (aquí, la temperatura mitjana poblacional), en el nostre cas [`r round(t.test(BT$Temperature, mu=98.6, alternative="two.sided")$conf.int,5)`].

* La mitjana mostral de la mostra, `sample of x`, en el nostre cas `r round(t.test(BT$Temperature, mu=98.6, alternative="two.sided")$estimate,5)`.

La conclusió és:
 
* El p-valor és $3\times 10^{-8}$, per la qual cosa obtenim evidència estadísticament significativa que la temperatura mitjana del cos humà no és de 98.6^o^ F (37^o^ C)

* A més, com com que l'IC 95% per a la temperatura mitjana del cos humà que hem obtingut  va de 98.2 a 98.4 (36.78 a 36.89^o^ C), hem trobat evidència a aquest nivell de confiança que aquesta temperatura mitjana és (lleugerament) inferior 98.6^o^ F

Ho resumiríem dient que hi ha evidència estadísticament significativa que la temperatura mitjana del cos humà no és de 98.6^o^ F (p=3·10^-8^, IC 95% 98.2 a 98.4).



```{example, temphomesdones}
La temperatura mitjana dels homes, és més alta que la de les dones?
  

```

Per resoldre aquesta qüestió, emprarem la mateixa taula de dades que abans. 

* *Variables aleatòries d'interès*:

    * $X_h$: temperatura d'un home en graus F, de mitjana $\mu_h$
    * $X_d$: temperatura d'una dona en graus F, de mitjana $\mu_d$


* *Contrast*:
$$
\left\{\begin{array}{l}
H_{0}:\mu_h=\mu_d\\
H_{1}:\mu_h> \mu_d
\end{array}
\right.
$$

Per poder emprar un t test, primer ens cal saber si hi ha nombres suficientment grans d'homes i dones a la nostra mostra per emprar-lo. Per això calcularem la taula de freqüències dels sexes, aplicant la funció `table` al vector `BT$Gender` dels sexes:

```{r}
table(BT$Gender)
```

Són prou grans.

Anam a crear uns vectors amb les temperatures d'homes i de dones. Recordau que per extreure d'un dataframe el vector de valors d'una variable `V1` per als individus que prenen un valor concret `X` en una altra variable `V2` s'empra la construcció `dataframe[V2==X,V1]`. Així, les temperatures dels homes (individus on la variable `Gender` és igual a `M`) són

```{r}
BT[BT$Gender=="M","Temperature"]
```

Bé, cream els vectors $X_h$ (homes) y $X_d$ (dones)

```{r}
X_h=BT[BT$Gender=="M","Temperature"]  #temperatures d'homes
X_d=BT[BT$Gender=="F","Temperature"]  #temperatures de dones
```

Per portar a terme un test t per comparar dues mitjanes, aplicam la funció `t.test` als vectors `X_h`i `X_d` amb paràmetre `alternative="greater"` per indicar que el test és unilateral: la hipòtesi alternativa és que la mitjana de la primera població (homes) és més gran que la de la segona (dones). En aquest exemple, a més, especificarem que les mostres són independents amb `paired=FALSE` (no caldria, ja que és el valor per defecte) i a més hem d'especificar si les variàncies poblacionals són iguals (`var.equal=TRUE`) o diferents (`var.equal=FALSE`). El que farem serà provar quan les variàncies són iguals i quan són diferents: si les dues conclusions són la mateixa, aquesta serà la conclusió que prendrem. 


```{r}
t.test(X_h, X_d, alternative="greater",paired=FALSE, var.equal=TRUE)
t.test(X_h, X_d, alternative="greater",paired=FALSE, var.equal=FALSE)
```

En tots dos casos obtenim un p-valor (`p-value`) gran i un IC 95 % (`95 percent confidence interval`) per a la diferència de les mitjanes que conté el 0, per la qual cosa no podem descartar que les dues mitjanes siguin iguals.  

Ho resumiríem dient que no hi ha evidència estadísticament significativa que la temperatura mitjana de les dones sigui més baixa que la dels homes  (p=0.99, IC 95% -0.46 a $\infty$).


```{block2,"rmdnote"}
Vegem, si $\overline{X_h}=98.14$ i $\overline{X_d}=98.42$, com volíeu que obtinguéssim evidència que $\mu_h>\mu_d$? *Mirau sempre les dades primer!*
```

**Exercici**: Emprant les mateixes dades, trobau evidència que $\mu_h<\mu_d$? I que $\mu_h\neq \mu_d$?

```{r, echo=FALSE, label=base,fig.cap="Spoiler",out.width="50%"}
knitr::include_graphics("Bioestadistica-II_files/figure-html/tempcorp3.png")
```



```{example,oatbran}
Desdijunar segó de civada (*oat bran*) en lloc de flocs de blat de moro (*corn flakes*), ajuda a reduir el nivell de colesterol?


```

Per resoldre aquesta qüestió, emprarem la taula de dades **oatbran.txt**, que trobareu a l'Aula Digital. Aquestes dades es recolliren en un assaig creuat sobre 14 individus. A cada un d'ells se li assignà un dels dos desdijunis i el prengueren durant  15 dies. Al final d'aquest període, se'ls analitzà el nivell de colesterol en sang. Passat un mes de descans, cada participant va desdijunar durant 15 l'altra dieta, i al final se'ls tornà a analitzar el nivell de colesterol en sang.

<!-- (J. Anderson \textsl{et a el}, ``Oat-bran cereal lowers serum total and LDL cholesterol in hypercholesterolemic men.'' \textsl{The American journal of clinical nutrition} 52 (1990), 495--499)
-->

* *Variables aleatòries d'interès*:

    * $X_{ob}$: Nivell de colesterol en sang d'una persona que consumeix  *oat bran*, de mitjana $\mu_{ob}$
    * $X_{cf}$: nivell de colesterol en sang d'una persona que consumeix  *corn flakes*, de mitjana $\mu_{cf}$

* *Contrast*:
$$
\left\{\begin{array}{l}
H_{0}:\mu_{ob}=\mu_{cf}\\
H_{1}:\mu_{ob}< \mu_{cf}
\end{array}
\right.
$$


Carregam la taula de dades, que prèviament hem guardat en el directori de treball de R, en un dataframe al que anomenam `OBR` i consultam la seva estructura:

```{r}
OBR=read.table("oatbran.txt",header=TRUE)
head(OBR)
str(OBR)
```

N'extraiem les dues variables en forma de vectors:

```{r}
OAT=OBR$OATBRAN
CFL=OBR$CORNFLK
```

14 dades són poques, si volem aplicar un test t necessitam que provinguin d'una distribució normal. Per decidir si és veritat o no, més endavant explicarem contrastos de bondat d'ajustament, amb hipòtesi nul·la "Aquesta mostra prové d'una variable aleatòria amb tal distribució" i hipòtesi alternativa "No és veritat que aquesta mostra provengui d'una variable aleatòria amb tal distribució". Per ara ens conformarem amb contrastar-ho a partir d'un gràfic.

A Matemàtiques I us explicàvem que podeu dibuixar un histograma de les dades amb la densitat estimada de la distribució que les ha generades i la densitat de la normal de la seva mitjana i desviació típica, i mirar si sembla que les dades segueixen aquesta darrera densitat. Però amb poques dades això és mal de veure:

```{r}
hist(OAT,freq=FALSE, breaks=4,col="light blue",xlab="Colesterol",ylab="Densitat", main="Histograma de OATBRAN")
lines(density(OAT),lty=2,lwd=2)
curve(dnorm(x,mean(OAT),sd(OAT)),col="red",lwd=2,add=TRUE)
legend("topright",legend=c("Densitat estimada","Normal"),col=c("black","red"),lty=c(2,1),cex=0.5)

hist(CFL,freq=FALSE, breaks=4,col="light blue",xlab="Colesterol",ylab="Densitat", main="Histograma de CORNFLK",ylim=c(0,0.5))
curve(dnorm(x,mean(CFL),sd(CFL)),col="red",lwd=2,add=TRUE)
lines(density(CFL),lty=2,lwd=2)
legend("topright",legend=c("Densitat estimada","Normal"),col=c("black","red"),lty=c(2,1),cex=0.5)
```


En aquest cas, una opció millor és dibuixar un *q-q-plot*.  Un **q-q-plot** d'una mostra i una distribució teòrica és el gràfic dels  **q-q-punts**: els punts de la forma  (q-quantil de la distribució, q-quantil de la mostra), per a tots els valors de q que tengui sentit donada la mida de la mostra.  Quan la distribució amb la que comparam la mostra és una normal, se'n diu un **normal-plot**.

Si la mostra prové de la distribució emprada en el q-q-plot, és d'esperar que el q-quantil de la mostra sigui aproximadament igual al q-quantil de la distribució i per tant que aquests q-q-punts estiguin prop de la diagonal principal $y=x$.

La funció `qqPlot` del paquet **car** produeix uns *normal-plots* que contenen una regió de confiança del 95% que especifica què vol dir això que "els q-q-punts estiguin prop de la diagonal principal $y=x$", amb el significat usual de nivell de confiança. Ja l'explicarem en detall a la lliçó de R sobre contrastos de bondat d'ajustament. 


```{r}
library(car)
qqPlot(OAT,mean=mean(OAT),sd=sd(OAT),
        ylab="Quantils de OATBRAN",xlab="Quantils de normal",pch=20,id=FALSE)
qqPlot(CFL,mean=mean(CFL),sd=sd(CFL),
       ylab="Quantils de CORNFLK",xlab="Quantils de normal",pch=20,id=FALSE)
```

Aceptarem per tant que les nostres dades provenen de dues distribucions normals: podem fer servir la funció `t.test`.

En aquest cas, el test t és de mostres aparellades (hem mesurat les dues variable aleatòries sobre els mateixos individus), per la qual cosa hem d'especificar `paired=TRUE` i no hem  d'especificar el paràmetre `var.equal`. Emprarem el paràmetre `alternative="less"` per indicas que el test és unilateral: la mitjana de la primera població és més petita que la de la segona


```{r}
t.test(OAT,CFL,alternative="less", paired=TRUE)
```

Com abans, el resultat inclou el p-valor, l'IC 95% per a la mitjana de les diferències (que és igual a la diferència de les mitjanes: recordau que $E(X-Y)=E(X)-E(Y)$) i ara, com a novetat, la mitjana de les diferències (`mean of the differences`) en comptes de les dues mitjanes, ja que el que ens interessa és contrastar si la mitjana de les diferències és menor que 0.

La conclusió és que hi ha evidència estadísticament significativa que desdijunar *oatbran* redueix el colesterol respecte dels *corn flakes* (p=0.003, IC 95% $-\infty$ a -0.163).

```{example}
Volem contrastar si el nivell mitjà de triglicèrids als nadons de 2 setmanes és més alt que el del seu cordó umbilical. Es prengué una mostra de 25 nadons i es mesuraren els nivells de triglicèrids en plasma a la sang del seu cordó umbilical i en la seva sang al cap de 2 setmanes de néixer. Tenim les dades a la taula **trignadons.txt** que trobareu a l'Aula Digital. Les seves variables són `CU`, les mesures del cordó umbilical, `DS`, les mesures al cap de dues setmanes, i `Nin`, que identifica el nadó.

```


* *Variables aleatòries d'interès*:

    * $X_{cu}$: Nivell de triglicèrids en plasma a la sang del cordó umbilical d'un nadó, de mitjana $\mu_{cu}$
    * $X_{ds}$: Nivell de triglicèrids en plasma d'un nadó de 2 setmanes, de mitjana $\mu_{cf}$

* *Contrast*:
$$
\left\{\begin{array}{l}
H_{0}:\mu_{cu}=\mu_{ds}\\
H_{1}:\mu_{cu}< \mu_{ds}
\end{array}
\right.
$$

Carregam la taula de dades, que prèviament hem guardat en el directori de treball de R, en un dataframe al que anomenam `TGN` i consultam la seva estructura:

```{r}
TGN=read.table("trignadons.txt",header=TRUE)
head(TGN)
str(TGN)
```

Com que 25 dades són poques, miram si segueixen distribucions normals amb els seus normal-plots:


```{r}
qqPlot(TGN$CU,mean=mean(TGN$CU),sd=sd(TGN$CU),
        ylab="Quantils de la mostra",xlab="Quantils de normal",pch=20,id=FALSE)
qqPlot(TGN$DS,mean=mean(TGN$DS),sd=sd(TGN$DS),
       ylab="Quantils de la mostra",xlab="Quantils de normal",pch=20,id=FALSE)
```

Vaja, no sembla que segueixin una distribució normal. Vegem els seus histogrames


```{r}
hist(TGN$CU, freq=FALSE, main="Histograma de TGN$CU", 
     xlab="",ylab="",col="light blue")
lines(density(TGN$CU),lty=2,lwd=2)
curve(dnorm(x,mean(TGN$CU),sd(TGN$CU)),col="red",lwd=2,add=TRUE)
legend("topright",legend=c("Densitat estimada","Normal"),col=c("black","red"),lty=c(2,1),cex=0.5)

hist(TGN$DS, freq=FALSE, main="Histograma de TGN$DS", 
     xlab="",ylab="",col="light blue")
lines(density(TGN$DS),lty=2,lwd=2)
curve(dnorm(x,mean(TGN$DS),sd(TGN$DS)),col="red",lwd=2,add=TRUE)
legend("topright",legend=c("Densitat estimada","Normal"),col=c("black","red"),lty=c(2,1),cex=0.5)
```

Les dues mostres presenten una cua a la dreta. En casos així, de vegades els logaritmes seguexen aproximadament una distribució normal:

```{r}
LogCU=log(TGN$CU)
qqPlot(LogCU,mean=mean(LogCU),sd=sd(LogCU),
        ylab="Quantils dels logaritmes",xlab="Quantils de normal",pch=20,id=FALSE)

LogDS=log(TGN$DS)
qqPlot(LogDS,mean=mean(LogDS),sd=sd(LogCU),
        ylab="Quantils dels logaritmes",xlab="Quantils de normal",pch=20,id=FALSE)
```


<!--
## Tests no paramètrics per a una o dues mitjanes 

Si les variables aleatòries d'interès no són (aproximadament) normals i alguna mostra és petita, no podem usar un test t. En aquest cas, una possibilitat és provar de transformar les dades per veure si la transformació esdevé normal.

Es pot provar de transformar les dades per veure si esdevenen normals

O usar un \red{test no paramètric} (que no pressuposi que les vv.aa. siguin normals)





\frametitle{Transformacions logarítmiques}\vspace*{-2ex}

Sovint el logaritme d'una variable amb cua a la dreta és aproximadament normal

\only<1>{\blue{Exemple}: 280 mesuraments de triglicèrids en sang de cordó umbilical

\begin{center}
\hspace*{-1ex}\includegraphics[width=0.5\linewidth]{Trigl1}\
\includegraphics[width=0.5\linewidth]{qqTrig1}

\end{center}}
\only<2>{\blue{Exemple}: 280 \red{logaritmes} de mesuraments de triglicèrids en sang de cordó umbilical

\begin{center}
\hspace*{-1ex}\includegraphics[width=0.5\linewidth]{Trigl2}\
\includegraphics[width=0.5\linewidth]{qqTrig2}
\end{center}
}






\frametitle{Tests no paramètrics} 

Els tests no paramètrics més populars per comparar mitjanes en realitat comparen \red{medianes} (i per tant mitjanes si les variables aleatòries són simètriques). Són:


*\red{Test de Wilcoxon} per a una mitjana o dues mitjanes usant mostres aparellades

*\red{Test de Mann-Whitney} per a dues mitjanes usant  mostres independents



Es calculen amb \red{\texttt{wilcox.test}}: per a dues mostres, el primer amb  \blue{\texttt{paired=TRUE}}  i el segon amb \blue{\texttt{paired=FALSE}}
 






\frametitle{Test de Wilcoxon d'una mitjana}\vspace*{-2ex}

$X$ una variable aleatòria contínua simètrica al voltant de la mitjana $\mu$ desconeguda

\red{Contrast}:
$$
\left\{\begin{array}{l}
H_{0}:\mu=\mu_0\\ 
H_{1}:\mu \neq \mu_0 \text{ o }\mu >\mu_0\text{ o }\mu<\mu_0
\end{array}
\right.
$$

Tenim una m.a.s.\ de $X$: $x_1,\ldots, x_n$






\frametitle{Test de Wilcoxon d'una mitjana}\vspace*{-2ex}

\red{Procediment}:
\begin{enumerate}
*Per a cada $i=1,\ldots,n$, sigui $d_i=x_i-\mu_0$; s'eliminen els 0

*Enumeram els valors $d_i$ de menor a major valor absolut; en cas d'empats, a cada un li assignam la mitjana de les posicions (\red{rangs}) que ocuparien

*$T_+$: suma dels rangs dels $d_i>0$; $T_{-}$: suma dels rangs dels $d_i<0$

*Si $H_0$ vertadera, per la simetria esperam $T_+\approx T_-$:

*Si $T_+$ és molt petit, és evidència que $\mu <\mu_0$
*Si $T_+$ és molt gran,  és evidència que $\mu >\mu_0$
*Si $T_+$ és molt petit o gran,  és evidència que $\mu\neq \mu_0$

La distribució de $T_+$ per a cada $n$ quan $X$ és simètrica i $H_0$ vertadera és coneguda, es pot calcular el p-valor


\end{enumerate}






\frametitle{Exemple}\vspace*{-2ex}

Alimentam amb una dieta especial 13 ratolins des del naixement fins a la setmana 12. Els augments de pes (en grams) varen ser:
$$
69,66,69,65,70,68,69,67,72,67,71,69,72
$$
Podem conclure que l'augment mitjà de pes en aquestes condicions és de menys de 70 g?

\red{Contrast:}
$$
\left\{\begin{array}{l}
H_{0}:\mu=70\\ 
H_{1}:\mu <70
\end{array}
\right.
$$

\begin{center}\footnotesize
\hspace*{-0.6cm}\begin{tabular}{l|cccccccccccccc}
\hline
$x_i$\hspace*{-0.75ex} & \hspace*{-0.75ex}    69\hspace*{-0.5ex} & \hspace*{-0.5ex}  66\hspace*{-0.5ex} & \hspace*{-0.5ex}  69\hspace*{-0.5ex} & \hspace*{-0.5ex}  65\hspace*{-0.5ex} & \hspace*{-0.5ex}  70\hspace*{-0.5ex} & \hspace*{-0.5ex}  68\hspace*{-0.5ex} & \hspace*{-0.5ex}  69\hspace*{-0.5ex} & \hspace*{-0.5ex}  67\hspace*{-0.5ex} & \hspace*{-0.5ex}  72\hspace*{-0.5ex} & \hspace*{-0.5ex}  67\hspace*{-0.5ex} & \hspace*{-0.5ex}  71\hspace*{-0.5ex} & \hspace*{-0.5ex}  69\hspace*{-0.5ex} & \hspace*{-0.5ex}  72\\
$d_i$       \hspace*{-0.75ex} & \hspace*{-0.75ex}   -1\hspace*{-0.5ex} & \hspace*{-0.5ex}  -4\hspace*{-0.5ex} & \hspace*{-0.5ex}  -1\hspace*{-0.5ex} & \hspace*{-0.5ex}  -5   \hspace*{-0.75ex} & \hspace*{-0.75ex}    0\hspace*{-0.5ex} & \hspace*{-0.5ex}  -2\hspace*{-0.5ex} & \hspace*{-0.5ex}  -1\hspace*{-0.5ex} & \hspace*{-0.5ex}  -3\hspace*{-0.5ex} & \hspace*{-0.5ex}   2\hspace*{-0.5ex} & \hspace*{-0.5ex}  -3  \hspace*{-0.75ex} & \hspace*{-0.75ex}      1\hspace*{-0.5ex} & \hspace*{-0.5ex}  -1\hspace*{-0.5ex} & \hspace*{-0.5ex}   2\\
Rk       \hspace*{-0.75ex} & \hspace*{-0.75ex}   1\hspace*{-0.75ex} & \hspace*{-0.75ex}    11\hspace*{-0.5ex} & \hspace*{-0.5ex}  2\hspace*{-0.75ex} & \hspace*{-0.75ex}   12 \hspace*{-0.75ex} & \hspace*{-0.75ex}     \hspace*{-0.75ex} & \hspace*{-0.75ex}   6\hspace*{-0.75ex} & \hspace*{-0.75ex}    3\hspace*{-0.75ex} & \hspace*{-0.75ex}  9 \hspace*{-0.75ex} & \hspace*{-0.75ex}   7\hspace*{-0.75ex} & \hspace*{-0.75ex}   10\hspace*{-0.75ex} & \hspace*{-0.75ex}      4\hspace*{-0.75ex} & \hspace*{-0.75ex}     5\hspace*{-0.75ex} & \hspace*{-0.75ex}   8  \\
Rk  bo     \hspace*{-0.75ex} & \hspace*{-0.75ex}   3\hspace*{-0.75ex} & \hspace*{-0.75ex}    11\hspace*{-0.75ex} & \hspace*{-0.75ex}    3\hspace*{-0.75ex} & \hspace*{-0.75ex}   12 \hspace*{-0.75ex} & \hspace*{-0.75ex}     \hspace*{-0.75ex} & \hspace*{-0.75ex}    7\hspace*{-0.75ex} & \hspace*{-0.75ex}    3\hspace*{-0.75ex} & \hspace*{-0.75ex}  9.5\hspace*{-0.75ex} & \hspace*{-0.75ex}   7\hspace*{-0.75ex} & \hspace*{-0.75ex}    9.5\hspace*{-0.75ex} & \hspace*{-0.75ex}    3\hspace*{-0.75ex} & \hspace*{-0.75ex}   3\hspace*{-0.75ex} & \hspace*{-0.75ex}  7 \\
S     \hspace*{-0.75ex} & \hspace*{-0.75ex}    -\hspace*{-0.5ex} & \hspace*{-0.5ex}  -\hspace*{-0.5ex} & \hspace*{-0.5ex}  -\hspace*{-0.5ex} & \hspace*{-0.5ex}  -\hspace*{-0.5ex} & \hspace*{-0.5ex}  \hspace*{-0.75ex} & \hspace*{-0.75ex}   -\hspace*{-0.5ex} & \hspace*{-0.5ex}  -\hspace*{-0.5ex} & \hspace*{-0.5ex}  -\hspace*{-0.5ex} & \hspace*{-0.5ex}   +\hspace*{-0.5ex} & \hspace*{-0.5ex}  -  \hspace*{-0.75ex} & \hspace*{-0.75ex}     +\hspace*{-0.5ex} & \hspace*{-0.5ex}  -\hspace*{-0.5ex} & \hspace*{-0.5ex}   +\\ \hline
\end{tabular}
\end{center}
$T_+=7+3+7=17$ d'un total de $T_++T_-=78$
%
%
%
%
%
%
%\begin{center}
%\includegraphics[width=0.45\linewidth]{histwilk}
%\end{center}



\frametitle{Exemple}\vspace*{-2ex}

\begin{lstlisting}
> x=c(69,66,69,65,70,68,69,67,72,67,71,
   69,72)
> wilcox.test(x,mu=70,alternative="less")

      Wilcoxon signed rank test with 
      continuity correction
data:  x
V = 17, p-value = 0.04428
alternative hypothesis: true location is less than 70
\end{lstlisting}\vspace{-1.4ex}

\begin{lstlisting}[style=warning]
Warning messages:
1: In wilcox.test.default(x, mu = 70, alternative = "less") :
  cannot compute exact p-value with ties
2: In wilcox.test.default(x, mu = 70, alternative = "less") :
  cannot compute exact p-value with zeroes
\end{lstlisting}









\frametitle{Tests no paramètrics}

\red{Atenció!}

*Els millors tests no paramètrics solen tenir potència inferior als millors tests paramètrics

*Els tests no paramètrics no solen produir IC fiables (es necessita una distribució)

*Però, per exemple, emprar un test t quan no és adequat pot portar a conclusions equivocades


\red{\bf Emprau tests paramètrics sempre que pogueu, però només quan pogueu} 





\frametitle{Exemple 3 (cont.)}\vspace{-2ex}

Si no volguéssim suposar que les mostres provenen de distribucions normals?


\begin{lstlisting}
> wilcox.test(OATBRAN,OBR$CORNFLK, 
alternative="less",paired=TRUE)

Wilcoxon signed rank test with continuity correction

data: OBR$OATBRAN and OBR$CORNFLK
V = 12, p-value = 0.006008
alternative hypothesis: true location shift is less than 0
\end{lstlisting}\vspace{-1.4ex}

\begin{lstlisting}[style=warning]
Warning message:
In wilcox.test.default(OBR$OATBRAN, OBR$CORNFLK, alternative = "less", :
cannot compute exact p-value with ties
\end{lstlisting}

Obtenim p-valor=0.006, mateixa conclusió





\section{Variàncies}
\subsection{Test $\chi^2$ d'1 variància}



\frametitle{Test $\chi^2$ d'una variància}\vspace*{-2ex}

Siguin $X\sim N(\mu,\sigma)$ i $X_1,\ldots,X_n$ una m.a.s.\ de $X$ de mida $n$ (arbitrària)

Volem realitzar un contrast
$$
\left\{\begin{array}{l}
H_{0}:\sigma=\sigma_0\\ 
H_{1}:\sigma \neq\sigma_0\text{ o }\sigma >\sigma_0\text{ o }\sigma<\sigma_0
\end{array}
\right.
$$
o equivalentment
$$
\left\{\begin{array}{l}
H_{0}:\sigma^2=\sigma_0^2\\ 
H_{1}:\sigma^2 \neq\sigma_0^2\text{ o }\sigma^2 >\sigma_0^2\text{ o }\sigma^2<\sigma_0^2
\end{array}
\right.
$$


Si $H_0$ és vertadera, l'\red{estadístic de contrast}
 $$
\chi^2=\frac{(n-1) \widetilde{S}_X^2}{\sigma_{0}^2}
$$
té  una distribució $\chi_{n-1}^2$: el podem emprar per calcular p-valors etc.






\frametitle{Test $\chi^2$ d'una variància}\vspace*{-2ex}

Empram l'estadístic de contrast
$$
 \chi^2=\frac{(n-1)\widetilde{S}_X^2}{\sigma_0^2}
$$
Calculam el seu valor $\chi^2_0$ sobre la mostra

p-valors:

*Si $H_{1}:\sigma>\sigma_{0}$,
{p-valor:} $P(\chi^2_{n-1}\geq \chi^2_0)$

*Si $H_{1}:\sigma<\sigma_{0}$,
{p-valor:} $P(\chi^2_{n-1}\leq \chi^2_0)$

*Si $H_{1}:\sigma\neq \sigma_{0}$,\\
{p-valor:}  \blue{$2\text{min}\big\{P(\chi_{n-1}^2\geq \chi^2_0), P(\chi_{n-1}^2\leq\chi^2_0)\big\}$}


Implementat en la funció \red{\texttt{sigma.test}} del paquet \red{\texttt{TeachingDemos}}; sintaxi similar a \texttt{t.test}




 
\frametitle{Test $\chi^2$ d'una variància}
\vspace*{-2ex}

\red{\textbf{Alerta amb els p-valors dels C.H. bilaterals quan la distribució de l'estadístic no és simètrica}}

Suposem tenim una m.a.s. de $X$ normal de mida 25, i ha donat 
$\widetilde{S}_X^2=1.25$. Volem contrastar $\sigma_X^2=0.8$. Llavors
$$
 \chi_0^2={(25-1)\cdot 1.25}/{0.8}=37.5
$$

\only<1>{Amb el contrast
$$\left\{\begin{array}{l}
H_{0}:\sigma_X^2=0.8 \\
H_{1}:\sigma_X^2\ \red{>}\ 0.8
\end{array}
\right.
$$
El p-valor és
$$
P(\chi^2_{24} \geq 37.5)=\texttt{1-pchisq(37.5,24)}=0.039
$$
Rebutjam $H_0$}

\only<2>{Amb el contrast $\left\{\begin{array}{l}
H_{0}:\sigma_X^2=0.8 \\
H_{1}:\sigma_X^2\ \red{\neq}\ 0.8
\end{array}
\right.$

El p-valor és $2\min\{P(\chi^2_{24}\geq 37.5),P(\chi^2_{24}\leq 37.5)\}$:
$$
\begin{array}{rl}
2\cdot P(\chi^2_{24}\geq 37.5)& =2\cdot 0.039=0.078\\[1ex]
2\cdot P(\chi^2_{24}\leq 37.5) &=2\cdot 0.961=1.922
\end{array}
$$
Prenem com a p-valor el més petit (\red{l'únic $\leq 1$}): 0.078. No podem rebutjar $H_0$.}









\frametitle{Exemple 4}

S'ha analitzat el líquid amniòtic d'una mostra aleatòria de 15 embarassades de 3er trimestre, i s'han obtingut les mesures següents de proteïnes totals (en grams per 100 ml)
\begin{quote}
\sf 0.69, 1.04, 0.39, 0.37, 0.64, 0.73, 0.69, 1.04, 0.83, 1.01, 0.19, 0.61, 0.42, 0.25, 0.79
\end{quote}

Podem concloure a partir d'aquestes dades, amb un nivell de significació del 5%, que la variància poblacional (és a dir, la variància de la quantitat de proteïna total en el líquid amniòtic de les embarassades de 3er trimestre expressada en grams per 100 ml) és diferent de 0.05?



\frametitle{Exemple 4}\vspace*{-2ex}

* *Variable aleatòria d'interès:} $X$: Quantitat de proteïna\ldots

\red{Contrast:}
$$
\left\{\begin{array}{l}
H_{0}:\sigma^2=0.05 \\
H_{1}:\sigma^2\neq 0.05
\end{array}
\right.
$$
amb $\alpha=0.05$\pause

Per poder aplicar el test $\chi^2$, cal que $X$ sigui normal
\vspace*{-1ex}

\begin{center}
\includegraphics[width=0.45\linewidth]{qqplotamni}
\end{center}
\vspace*{-1ex}

Acceptarem que $X$ és normal







\frametitle{Exemple 4}\vspace*{-2ex}

\red{Estadístic de contrast:} 
$$
\chi^2=\frac{(n-1) \widetilde{S}_X^2}{\sigma_{0}^2}
$$
que segueix una llei $\chi^2_{n-1}$ si $H_0$ és certa

\red{Valor:}
\begin{lstlisting}
> x=c(0.69,1.04,0.39,0.37,0.64,0.73,0.69,
  1.04,0.83,1.01,0.19,0.61,0.42,0.25,0.79)
> var(x)
[1] 0.07624
\end{lstlisting}

$$
\chi_0^2=\frac{14\cdot  0.07624}{0.05}=21.3472
$$






\frametitle{Exemple 4}

\red{p-valor} $=2\text{min}\big\{P(\chi_{n-1}^2\geq \chi^2_0), P(\chi_{n-1}^2\leq \chi^2_0)\big\}$


*$P(\chi_{14}^2 \geq 21.3472)=\texttt{1-pchisq(21.3472,14)}=0.093$
*$P(\chi_{14}^2\leq 21.3472)=\texttt{pchisq(21.3472,14)}=0.907$


\red{p-valor} $=2\cdot\min\{0.093,0.907\}=0.186$


No podem rebutjar la hipòtesi que la variància sigui 0.05 amb un nivell
de significació del 5%





\frametitle{Exemple 4}


Com que el contrast és bilateral, l'IC 95% seria el del tema anterior (amb $q=1-\alpha=0.95$)
$$
\begin{array}{l}
\displaystyle \left[ \frac{(n-1)\widetilde{S}_{X}^2}{\chi_{n-1,0.975}^2},
\frac{(n-1)\widetilde{S}_{X}^2}{\chi_{n-1,0.025}^2}
\right]=\left[ \frac{14\cdot 0.07624}{26.119},
\frac{14\cdot 0.07624}{5.6287}\right]\\[3ex]
\qquad\qquad=[0.0409,0.1896]
\end{array}
$$

Conté el valor 0.05 contrastat.




\frametitle{Exemple 4}\vspace*{-2ex}

\begin{lstlisting}
> #Instal·lam i carregam el paquet TeachingDemos
...
> sigma.test(x,sigmasq=0.05,
   alternative="two.sided")

One sample Chi-squared test for variance

data:  x
X-squared = 21.347, df = 14, p-value = 0.1861
alternative hypothesis: true variance is not equal to 0.05
95 percent confidence interval:
 0.04086535 0.18962728
sample estimates:
var of x 
 0.07624
\end{lstlisting}





\frametitle{Exemple 4}\vspace*{-3ex}

\begin{lstlisting}
> sqrt(0.05)
[1] 0.2236068
> sigma.test(x,sigma=0.2236068,
   alternative="two.sided")

One sample Chi-squared test for variance

data:  x
X-squared = 21.347, df = 14, p-value = 0.1861
alternative hypothesis: true variance is not equal to 0.05
95 percent confidence interval:
 0.04086535 0.18962728
sample estimates:
var of x 
 0.07624
\end{lstlisting}

\red{Alerta!} L'interval de confiança és el de la variància






\subsection{Test F de 2 variàncies}


\frametitle{Test F per a dues variàncies}

Siguin $X_1,X_2$ dues variables aleatòries normals de desviacions típiques $\sigma_1$, $\sigma_2$

En prenem dues m.a.s.\ independents de mides $n_1$ i $n_2$ i desviacions típiques mostrals $\widetilde{S}_1$ i  $\widetilde{S}_2$


Volem realitzar el contrast
$$
\left\{\begin{array}{l}
H_{0}:\sigma_1^2=\sigma_2^2\\[1ex]
H_{1}:\sigma_1^2\neq \sigma_2^2\text{ o }\sigma_1^2> \sigma_2^2\text{ \blue  o }\sigma_1^2< \sigma_2^2
\end{array}
\right.
$$

L'interpretarem
$$
\left\{\begin{array}{l}
H_{0}:\sigma_1^2/\sigma_2^2=1\\[1ex]
H_{1}:\sigma_1^2/\sigma_2^2\neq 1\text{ \blue  o }\sigma_1^2/\sigma_2^2>1 \text{ \blue  o }\sigma_1^2/\sigma_2^2< 1
\end{array}
\right.
$$





\frametitle{Test F per a variàncies}

S'hi empra l'estadístic de contrast
$$
F={\widetilde{S}_1^2}/{\widetilde{S}_2^2}
$$
que, si les dues poblacions són normals i 
$$
H_0: \sigma_1=\sigma_2
$$
 és vertadera, té distribució coneguda: la \emph{$F$ de Fisher-Snedecor} $F_{n_1-1,n_2-1}$ amb $n_1-1$ i $n_2-1$ graus de llibertat 
 
Per això se li diu el \red{test F} 



\frametitle{Test F per a variàncies}

La distribució \red{$F_{n,m}$}, on $n,m$ són els seus \emph{graus de llibertat}:

*És la del quocient d'una variable aleatòria $\chi^2_n$ per una variable aleatòria $\chi^2_m$

*$n,m$ són els paràmetres dels qual depèn la funció de distribució

*Amb R és \texttt{f}  

*No és simètrica. \blue{Els p-valors es calculen com en el cas de la $\chi^2$.} \emph{Alerta en el cas bilateral!}


Implementat en la funció \red{\texttt{var.test}} de R: s'aplica a les dues mostres, amb sintaxi similar a \texttt{t.test}






\frametitle{Exemple 3 (cont.)}\vspace{-2ex}

\blue{Les variables $X_h$ i $X_d$ de l'Exemple 3, tenen la mateixa variància?}

Suposarem que totes dues són normals (les temperatures ho solen ser) i aplicarem un test F al contrast

$$
\left\{\begin{array}{l}
H_{0}:\sigma_h^2=\sigma_d^2\\[1ex]
H_{1}:\sigma_h^2\neq \sigma_d^2
\end{array}
\right.
$$
Calculam l'estadístic de contrast $F_0=\widetilde{S}_h^2/\widetilde{S}_d^2$

\begin{lstlisting}
> F0=var(X_h)/var(X_d)
> F0
[1] 1.201637
\end{lstlisting}






\frametitle{Exemple 3 (cont.)}\vspace{-2ex}

El p-valor serà
$$
\blue{2\text{min}\big\{P(F_{n_1-1,n_2-1} \geq F_0), P(F_{n_1-1,n_2-1}\leq F_0)\big\}}
$$
on $n$ és el nombre d'homes i $m$ el nombre de dones

\begin{lstlisting}
> n=length(X_h)
> m=length(X_d)
> 1-pf(F0,n-1,m-1)
[1] 0.1639021
> pf(F0,n-1,m-1)
[1] 0.8360979
\end{lstlisting}

El p-valor és $2\times 0.164=0.328$. No podem rebutjar que $X_h$ i $X_d$ tenguin la mateixa variància: acceptarem que tenen la mateixa variància.











\frametitle{Exemple 3 (cont.)}\vspace{-2ex}

Amb R:

\begin{lstlisting}
> var.test(X_h, X_d)

F test to compare two variances

data:  X_h and X_d
F = 1.2016, num df = 113, denom df = 115, p-value = 0.3278
alternative hypothesis: true ratio of variances is not equal to 1
95 percent confidence interval:
 0.8311002 1.7384230
sample estimates:
ratio of variances 
          1.201637
\end{lstlisting}




 
\frametitle{Exemple 3 (cont.)}\vspace{-2ex}

\red{Conclusió}: 

*Com  que \blue{p-valor $=0.328$}, no podem rebutjar que $X_h$ i $X_d$ tenguin la mateixa variància: acceptarem que tenen la mateixa variància

*L'\blue{IC 95%} \red{per al quocient de les variàncies} \blue{va de 0.83 a 1.74}: com que conté l'1, també ens diu que, amb aquest nivell de confiança, no podem rebutjar que $X_h$ i $X_d$ tenguin la mateixa variància (encara que també podria ser que $\sigma^2_{X_h}$ fos un 70% més gran que $\sigma^2_{X_d}$)


Per tant, si els tests t amb \texttt{var.equal=TRUE} i \texttt{var.equal=FALSE} haguessin donat conclusions diferents, prendríem la corresponent a variàncies iguals





 
\frametitle{Exemple 3 (cont.)}\vspace{-2ex}

\blue{Les variables $X_h$ i $X_d$ de l'Exemple 2, tenen la mateixa variància?}

Era adequat suposar que provenen de distribucions normals?\vspace{-2ex}

\begin{center}
\hspace{-0.5cm}
\includegraphics[width=0.5\linewidth]{histTM}\
\includegraphics[width=0.5\linewidth]{histTF}
\end{center} 



 
\frametitle{Exemple 3 (cont.)}\vspace{-2ex}

\blue{Les variables $X_m$ i $X_d$ de l'Exemple 2, tenen la mateixa variància?}

Era adequat suposar que provenen de distribucions normals?\vspace{-2ex}

\begin{center}
\hspace{-0.5cm}
\includegraphics[width=0.5\linewidth]{qqplotTM}\
\includegraphics[width=0.5\linewidth]{qqplotTF}
\end{center}\vspace{-3ex}

Millor usar un test no paramètric, per més seguretat







\frametitle{Tests no paramètrics}

El test F no serveix per poc que les variables difereixin de normals

En aquest cas, és necessari usar un test no paramètric

Us recomanam emprar el \red{test de Fligner-Killeen}, implementat en R en la funció \red{\texttt{fligner.test}}, que en la pràctica ha mostrat ser més exacte  per a variables aleatòries molt diferents de normals


Només serveix per a tests bilaterals, que en realitat són els únics interessants







\frametitle{Exemple 3 (cont.)}

\begin{lstlisting}
> fligner.test(list(X_h,X_d))

Fligner-Killeen test of homogeneity of variances

data: list(X_h, X_m)
Fligner-Killeen:med chi-squared = 1.7736, 
df = 1, p-value = 0.1829
\end{lstlisting}

Acceptam que $X_h$ i $X_d$ tenen la mateixa variància






\section{Proporcions}
\subsection{1 proporció}


\frametitle{Contrastos per a una $p$}

Sigui $X$ una variable aleatòria Bernoulli  $Be(p)$

Volem realitzar un contrast 
$$
\left\{\begin{array}{l}
H_{0}:p=p_{0}\\
H_{1}:p\neq p_{0}\text{ o }  p>p_0 \text{ o } p<p_0
\end{array}
\right.
$$




\frametitle{Test binomial exacte}




\red{\bf Situació 1:} Prenem una m.a.s. de mida $n$ arbitrària


Obtenim $x_0$ èxits, de manera que $\widehat{p}_X=x_0/n$

Si $H_0$ és vertadera, el nombre d'èxits segueix una distribució $B(n,p_0)$. Ho podem usar per calcular p-valors de la manera usual. En diuen el \red{test binomial exacte}:


*$H_{1}:p>p_{0}$: p-valor = $P(B(n,p_0)\geq x_0)$
*$H_{1}:p<p_{0}$: p-valor = $P(B(n,p_0)\leq x_0)$
*$H_{1}:p\neq p_{0}$: p-valor = $2\min\{P(B(n,p_0)\leq x_0),P(B(n,p_0)\geq x_0)\}$






\frametitle{Test aproximat}\vspace*{-2ex}

\red{\bf Situació 2:} Prenem una m.a.s. de mida $n$ \red{gran}


En aquest cas, si  $H_{0}:p=p_{0}$ és vertadera,
$$
Z=\frac{\widehat{p}_X-p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}\approx N(0,1)
$$
Ho empram per calcular p-valors: si pren el valor $z_0$,

*$H_{1}:p>p_{0}$: p-valor = $P(Z\geq z_0)$
*$H_{1}:p<p_{0}$: p-valor = $P(Z\leq z_0)$
*$H_{1}:p\neq p_{0}$: p-valor = $2P(Z\geq |z_0|)$ (recordau que $Z$ és simètrica)



En cas de dubte, refiau-vos d'ell només si estau en les condicions de la fórmula de l'IC de Laplace (que és quan l'aproximació $Z\approx N(0,1)$ és millor)






\frametitle{Exemple 5}
\blue{La proporció d'estudiants esquerrans a la UIB, és diferent de la de l'estat espanyol?}

El percentatge d'esquerrans a Espanya és del 10%. 

De 30 estudiants de la UIB enquestats a l'atzar, 1 ha estat esquerrà.

\red{V. a. d'interès:} $X$: Que un estudiant de la UIB,  sigui esquerrà, de probabilitat poblacional $p$

\red{Contrast:}
$$
\left\{\begin{array}{l}
H_{0}:p=0.1\\
H_{1}:p\neq 0.1
\end{array}
\right.
$$






\frametitle{Exemple 5}

Empram el test binomial exacte: Si $H_0$ és vertadera, el nombre d'èxits en una mostra de 30 és $B(30,0.1)$

\red{p-valor} = $2\min\{P(B(30,0.1)\geq 1), P(B(30,0.1)\leq 1)\}$


*$P(B(30,0.1)\geq 1)= \texttt{1-pbinom(0,30,0.1)}=0.96$

*$P(B(30,0.1)\leq 1)= \texttt{pbinom(1,30,0.1)}=0.18$



Per tant p-valor = 0.36: no podem rebutjar que $p=0.1$





\frametitle{Exemple 5}\vspace*{-2ex}

El test binomial exacte està implementat en R en la funció \texttt{binom.test}. 

\begin{lstlisting}
> binom.test(1, 30, p=0.1)

     Exact binomial test
data:  1 and 30
number of successes = 1, number of trials = 30, p-value = 0.3592
alternative hypothesis: true probability of success is not equal to 0.1
95 percent confidence interval:
 0.0008435709 0.1721694556
sample estimates:
probability of success 
            0.03333333 
\end{lstlisting}

L'IC bilateral és el de Clopper-Pearson





\frametitle{Exemple 5}

Ara emprarem el test aproximat (tot i que no és lo seu): Si $H_0$ és vertadera, 
$$
Z=\frac{\widehat{p}_X-p_0}{\sqrt{\frac{p_0(1-p_0)}{n}}}\approx N(0,1)
$$

L'estadístic de contrast sobre la nostra mostra val
$$
\frac{\frac{1}{30}-0.1}{\sqrt{\frac{0.1(1-0.1)}{30}}}=-1.22
$$

\red{p-valor} = $2P(Z\geq 1.22)=\texttt{2*(1-pnorm(1.22))}=0.22$


No podem rebutjar que $p=0.1$






\frametitle{Exemple 5}\vspace*{-2ex}

El test aproximat està (millor) implementat en R en la funció \texttt{prop.test}. 

\begin{lstlisting}
> prop.test(1, 30, p=0.1)

	1-sample proportions test with continuity correction
data:  1 out of 30, null probability 0.1
X-squared = 0.8333, df = 1, p-value = 0.3613
alternative hypothesis: true p is not equal to 0.1
95 percent confidence interval:
 0.001742467 0.190530216
sample estimates:
         p 
0.03333333 
\end{lstlisting}\vspace{-1.4ex}

\begin{lstlisting}[style=warning]
Warning message:
In prop.test(1, 30, p = 0.1) : Chi-squared approximation may be incorrect
\end{lstlisting}





\frametitle{Exemple 5}\vspace*{-2ex}

El nostre test aproximat  s'obté amb el paràmetre \texttt{correct=FALSE}

\begin{lstlisting}
> prop.test(1, 30, p=0.1,correct = FALSE)

	1-sample proportions test without continuity correction
data:  1 out of 30, null probability 0.1
X-squared = 1.4815, df = 1, p-value = 0.2235
alternative hypothesis: true p is not equal to 0.1
95 percent confidence interval:
 0.00590859 0.16670391
sample estimates:
         p 
0.03333333 
\end{lstlisting}\vspace{-1.4ex}

\begin{lstlisting}[style=warning]
Warning message:
In prop.test(1, 30, p = 0.1,correct = FALSE) : Chi-squared approximation may be incorrect
\end{lstlisting}








\frametitle{Exemple 5}\vspace*{-2ex}

Potència d'aquest contrast?

\begin{lstlisting}
> library(pwr)
> ES.h(0.1,0.03)  #La mida de l'efecte observat
[1] 0.2953351
> cohen.ES(test="p",size="small") #Per determinar-la a priori

...
    effect.size = 0.2

> pwr.p.test(h=0.3, n=30, sig.level=0.05, 
   alternative="two.sided")

...
          power = 0.3758563
\end{lstlisting}






\frametitle{Exemple 5}\vspace*{-2ex}

Què hagués passat amb una mostra de 150 estudiants amb 5 esquerrans?

\begin{lstlisting}
> prop.test(5,150,p=0.1)

1-sample proportions test with continuity correction

data:  5 out of 150, null probability 0.1
X-squared = 6.6852, df = 1, p-value = 0.009722
alternative hypothesis: true p is not equal to 0.1
95 percent confidence interval:
 0.01233588 0.08010876
sample estimates:
         p 
0.03333333 
\end{lstlisting}








\frametitle{Exemple 5}\vspace*{-2ex}

Què hagués passat amb una mostra de 150 estudiants, 5 esquerrans?

\begin{lstlisting}
> pwr.p.test(h=0.3,n=150,sig.level=0.05,
    alternative="two.sided")

proportion power calculation for binomial distribution (arcsine transformation) 

              h = 0.3
              n = 150
      sig.level = 0.05
          power = 0.9567605
    alternative = two.sided
\end{lstlisting}







\frametitle{Exemple 5}\vspace*{-2ex}

De quina mida hauríem d'haver pres la mostra per obtenir una potència del 90% amb $\alpha=0.05$ i esperant un efecte petit?


\begin{lstlisting}
> cohen.ES(test="p",size="small")
...
    effect.size = 0.2
> pwr.p.test(h=0.2, power=0.9, 
  sig.level=0.05, alternative="two.sided")

proportion power calculation for binomial distribution (arcsine transformation) 

              h = 0.2
              n = 262.6855
      sig.level = 0.05
          power = 0.9
    alternative = two.sided
\end{lstlisting}






%%%%%%%%%


\subsection{2 props., mostres indep.}


\frametitle{Tests per a 2 proporcions, mostres independents}

Siguin $X_1$ i $X_2$ dues vv.aa. Bernoulli de paràmetres $p_1$ i $p_2$


Volem realitzar un contrast
$$
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\ 
H_{1}:p_1\neq p_2\text{ o }p_1> p_2\text{ o }p_1< p_2
\end{array}
\right.
$$


En prenem dues mostres independents, una de cada variable. Obtenim la taula següent
\begin{center}
\begin{tabular}{c|cc|c }
  & $X_1$ & $X_2$ & Total  \\\hline
Èxits & $n_{11}$ & $n_{12}$ & $E$  \\
Fracassos & $n_{21}$ & $n_{22}$ & $F$   \\\hline 
Total & $n_{1}$ & $n_{2}$ 
\end{tabular}
\end{center}




\frametitle{Test $\chi^2$}\vspace*{-2ex}

Suposem que les mostres són \emph{grans} ($n_1,n_2\geq 50$) i que els nombres d'èxits i de fracasos a cada mostra són $\geq 5$

Siguin $\widehat{p}_1$ i $\widehat{p}_2$  les proporcions mostrals de les mostres

Si la hipòtesi nu\l.la $H_0: p_1=p_2$ és vertadera,
$$
Z=\frac{\widehat{p}_1 -\widehat{p}_2}{
\sqrt{\frac{n_1 \widehat{p}_1 +n_2 \widehat{p}_2}{n_1
+n_2}\cdot \Big(1-\frac{n_1 \widehat{p}_1 +n_2 \widehat{p}_2}{n_1
+n_2}\Big)\cdot \Big(\frac{1}{n_1}+\frac{1}{n_2}
\Big)}}\approx N(0,1)
$$
(fixau-vos que $n_1 \widehat{p}_1 +n_2 \widehat{p}_2=E$).

S'empra com sempre per calcular p-valors

(Se'n diu \red{test $\chi^2$} perquè és un cas particular d'un test   $\chi^2$ que veurem més endavant, i  en realitat s'hi empra $Z^2$, que és  $\approx\chi^2_1$)













\frametitle{Exemple 6}\vspace*{-2ex}

Es vol saber si un determinat al·lel d'un gen és present o no amb la mateixa proporció entre els mallorquins i els menorquins

Es prenen una mostra d'ADN de 100 individus amb almenys tres generacions
familiars a l'illa de Mallorca, i una altra de 50 individus amb almenys tres generacions
familiars a l'illa de  Menorca


A la mostra mallorquina, 20 individus el tenen, i a la mostra menorquina, 12

\begin{center}
\begin{tabular}{c|cc }
  & Mall. & Men.  \\\hline
Present & 20 & 12 \\
Absent & 80 & 38   \\\hline 
Total & 100 & 50   
\end{tabular}
\end{center}







\frametitle{Exemple 6}

\red{Variables}: $X_1$ i $X_2$, que un mallorquí o un menorquí, respectivament, tengui aquest al·lel, de proporcions poblacionals $p_1$ i $p_2$


\emph{Contrast}:
$$
\left\{\begin{array}{l}
H_0:p_1=p_2\\
H_1:p_1\neq p_2
\end{array}\right.
$$

Estam les condicions d'emprar el test $\chi^2$

\emph{Estadístic de contrast}: 
$$
Z=\frac{\widehat{p}_1 -\widehat{p}_2}{
\sqrt{\frac{n_1 \widehat{p}_1 +n_2 \widehat{p}_2}{n_1
+n_2}\cdot \Big(1-\frac{n_1 \widehat{p}_1 +n_2 \widehat{p}_2}{n_1
+n_2}\Big)\cdot\Big(\frac{1}{n_1}+\frac{1}{n_2}
\Big)}}$$
que és aprox. $N(0,1)$ si $H_0$ és vertadera





\frametitle{Exemple 6}

\emph{Valor de l'estadístic}: $\widehat{p}_1=0.2$, $\widehat{p}_2=0.24$, $n_1=100$, $n_2=50$, $E=32$
$$
z_0=\frac{0.2 -0.24}{
\sqrt{\frac{32}{150}\Big(1-\frac{32}{150}\Big)\Big(\frac{1}{100}+\frac{1}{50}
\Big)}}
=-0.5637$$

\emph{p-valor}: $2\cdot P(Z\geq 0.5637)=0.573$


\emph{Decisió}: Com que el p-valor és més gran que $\alpha=0.05$, acceptam la hipòtesi nul·la que les dues proporcions són iguals




\frametitle{Test  $\chi^2$ amb R}\vspace*{-2ex}

Amb R, es fa amb la funció \texttt{prop.test} aplicada al vector de nombres d'èxits i al vector de mides de mostres

\begin{lstlisting}
> prop.test(c(20,12),c(100,50),
   alternative="two.sided")

2-sample test for equality of proportions with continuity correction

data:  c(20, 12) out of c(100, 50)
X-squared = 0.12414, df = 1, p-value = 0.7246
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.1969858  0.1169858
sample estimates:
prop 1 prop 2 
  0.20   0.24 
\end{lstlisting}







\frametitle{Test $\chi^2$ amb R}\vspace*{-2ex}

Com al cas d'una proporció, el test que hem explicat en realitat correspon a l'opció \texttt{correct=FALSE}

\begin{lstlisting}
> prop.test(c(20,12),c(100,50),
   alternative="two.sided",correct=FALSE)

2-sample test for equality of proportions without continuity correction

data:  c(20, 12) out of c(100, 50)
X-squared = 0.3178, df = 1, p-value = 0.5729
alternative hypothesis: two.sided
95 percent confidence interval:
 -0.1819858  0.1019858
sample estimates:
prop 1 prop 2 
  0.20   0.24 
\end{lstlisting}







\frametitle{Test exacte de Fisher}\vspace*{-2ex}

Si no se satisfan les condicions pel test $\chi^2$, sempre es pot aplicar el \red{test exacte de Fisher}

\begin{center}
\begin{tabular}{c|cc|c}
  & $X_1$ & $X_2$ &  Total\\\hline
Èxits & $n_{11}$ & $n_{12}$ &  $E$\\
Fracassos & $n_{21}$ & $n_{22}$ &  $F$ \\\hline 
Total & $n_{1}$ & $n_{2}$ & 
\end{tabular}
\end{center}

Si $p_1=p_2$, la probabilitat d'obtenir $n_{11}$ èxits dins $X_1$ és la de:
\begin{quote}
\red{En una bossa hi tenim $E$ bolles Èxit i $F$ bolles Fracàs. Probabilitat d'obtenir $n_{11}$ bolles Èxit si en triam $n_{1}$ de cop.}
\end{quote}
Per tant, la distribució de $n_{11}$ és hipergeomètrica $H(E,F,n_{1})$. S'empra com a estadístic de contrast.






\frametitle{Exemple 7}
\vspace*{-1ex}

Per determinar si la Síndrome de Mort Sobtada del Nadó (SIDS) té component genètic, es consideren els casos de SIDS en parelles de bessons monozigòtics i dizigòtics. Diguem: 

*$p_1$: proporció de parelles de bessons monozigòtics amb algun cas de SIDS on només un germà la sofrí

*$p_2$: proporció de parelles de bessons dizigòtics amb algun cas de SIDS on només un germà la sofrí


Si la SIDS té component genètic, és d'esperar que $p_1<p_2$


Volem realitzar el contrast
$$
\left\{\begin{array}{l}
H_0:p_1=p_2\\
H_1:p_1< p_2
\end{array}\right.
$$



\frametitle{Exemple 7}

En un estudi s'obtingueren les dades següents:
\begin{center}
\begin{tabular}{ll|cc|c}
\multicolumn{2}{c}{} & \multicolumn{2}{c}{\bf Tipus de bessons} & \\  
 & & Monozig. & Dizig. & Total \\ \hline
 \textbf{Casos} & Un  & 23 & 35 & 58\\
 \textbf{de SIDS} & Dos & 1 & 2 & 3\\\hline
 & Total  & 24 & 37 & 
\end{tabular}
\end{center}

\red{p-valor:}
$$
P(H(58,3,24)\leq 23) =\text{\texttt{phyper(23,58,3,24)}}=0.7841
$$

No podem rebutjar la hipòtesi nu\l.la




\frametitle{Test exacte de Fisher}\vspace*{-2ex}

Amb R es porta a terme amb la funció \texttt{fisher.test} aplicada a la taula de freqüències com l'hem donada

\begin{lstlisting}
> Dades=matrix(c(23,35,1,2), nrow=2,
   byrow=TRUE)
> fisher.test(Dades,alternative="less")

  Fisher's Exact Test for Count Data
data:  Dades
p-value = 0.7841
alternative hypothesis: true odds ratio is less than 1
95 percent confidence interval:
  0.00000 39.73954
sample estimates:
odds ratio 
  1.308589 
\end{lstlisting}





\frametitle{Alerta amb \texttt{fisher.test}}

La funció \texttt{fisher.test} no compara $p_1$ i $p_2$, sinó les seves \red{\sl odds} (\red{oportunitats}; en castellà, també \textsl{momios})
$$
\frac{p_1}{1-p_1}\text{ i }\frac{p_2}{1-p_2}
$$
i l'interval de confiança que dóna és per al quocient d'aquestes \textsl{odds}: la \red{\sl odds ratio} (\red{OR}, \red{raó d'oportunitats}; en castellà també \textsl{razón de momios})





\frametitle{\textsl{Odds}}

Les \red{\textsl{odds}} d'un esdeveniment $A$ són
$$
\red{\text{Odds}(A)}=\frac{P(A)}{P(A^c)}=\frac{P(A)}{1-P(A)}
$$
Indiquen quantes vegades és més probable $A$ que <<no $A$>>

\blue{Exemples}: 

*Si $P(A)=0.3$, $\text{Odds}(A)=0.3/0.7=0.43$
*Si $P(A)=0$, $\text{Odds}(A)=0$
*Si $P(A)=0.5$, $\text{Odds}(A)=1$
*Si $P(A)=1$, $\text{Odds}(A)=\infty$







\frametitle{\textsl{Odds}}

\blue{Exemple}: Si $\text{Odds}(A)=0.6$ (o són \red{6 a 10})
$$
\begin{array}{l}
0.6=\dfrac{P(A)}{1-P(A)}\Rightarrow 0.6-0.6P(A)=P(A)\\[2ex]
\qquad \Rightarrow 0.6=1.6P(A)\Rightarrow P(A)=\dfrac{0.6}{1.6}=0.375
\end{array}
$$
En general
$$
P(A)=\dfrac{\text{Odds}(A)}{1+\text{Odds}(A)}
$$

Per tant 
$$
\begin{array}{c}
\text{Odds}(A)<\text{Odds}(B)\Longleftrightarrow P(A)<P(B)\\[1ex]
\text{Odds}(A)=\text{Odds}(B)\Longleftrightarrow P(A)=P(B)
\end{array}
$$




\frametitle{Exemple 6  (cont.)}

El contrast dels al·lels amb el test $\chi^2$:

\begin{lstlisting}
> prop.test(c(20,12),c(100,50),
   alternative="two.sided",correct=FALSE)
...
p-value = 0.5729
95 percent confidence interval:
 -0.1819858  0.1019858
sample estimates:
prop 1 prop 2 
  0.20   0.24 
\end{lstlisting}




 
\frametitle{Exemple 6  (cont.)}


*El \blue{p-valor $0.5729$} no ens permet rebutjar que les proporcions de mallorquins i menorquins amb l'al·lel objecte d'estudi siguin diferents

*El \blue{IC 95%} per a la diferència de proporcions \blue{va de $-0.18$ a 0.1}: com que conté el 0, no podem rebutjar amb aquest nivell de confiança que les proporcions siguin iguals

*La \blue{diferència de proporcions mostrals $p_1-p_2$} ha estat $0.2-0.24=-0.04$: la proporció de menorquins amb l'al·lel a la nostra mostra ha estat 4 punts percentuals més gran que la dels mallorquins




\frametitle{Exemple 6  (cont.)}

El contrast dels al·lels amb el test de Fisher:

\begin{lstlisting}
> Dades.G=matrix(c(20,12,80,38), nrow=2,
   byrow=T)
> fisher.test(Dades.G)
...
p-value = 0.673
95 percent confidence interval:
 0.3287521 1.9742955
sample estimates:
odds ratio 
 0.7929466 
\end{lstlisting}





\frametitle{Exemple 6  (cont.)}


*El \blue{p-valor $0.673$} no ens permet rebutjar que les \textsl{odds} (i per tant les probabilitats) de tenir aquest al·lel entre els mallorquins i els menorquins siguin la mateixa

*El \blue{IC 95%} per a la \red{\textsl{odds ratio}}  (per al quocient d'\textsl{odds}) \blue{va de 0.33 a 1.97}: com que conté el 1, no podem rebutjar amb aquest nivell de confiança que les odds (i per tant les proporcions) siguin iguals (que correspondria a quocient igual a 1)

*El \blue{quocient d'odds mostrals} (la \textsl{odds ratio} a la mostra) ha estat $0.79$: a la nostra mostra, les \textsl{odds} que un mallorquí tengués l'al·lel han estat 0.79 vegades (un 21% més petites que) les d'un menorquí




\subsection{2 props, mostres aparellades}

\frametitle{2 props., mostres aparellades}\vspace*{-2ex}

Siguin $X_1$ i $X_2$ dues vv.aa. Bernoulli de paràmetres $p_1$ i $p_2$


Volem realitzar un contrast
$$
\left\{\begin{array}{l}
H_{0}:p_1=p_2\\ 
H_{1}:p_1\neq p_2\text{ o }p_1> p_2\text{ o }p_1< p_2
\end{array}
\right.
$$
Les mesuram sobre els subjectes d'una mateixa mostra, o sobre els subjectes de dues mostres  aparellades, de mida $n$


Resultats:\vspace*{-3ex}

\begin{center}
\begin{tabular}{l|l|c|c|}
\multicolumn{2}{c}{\ } & \multicolumn{2}{c}{Variable $X_2$}\\ \cline{3-4}
\multicolumn{2}{c|}{\ } &Èxit & Fracàs \\ \cline{2-4}
Variable & Èxit & $a$ & $b$ \\\cline{2-4}
$X_1$ & Fracàs & $c$ & $d$\\ \cline{2-4}
\end{tabular}
\end{center}






\frametitle{2 props., mostres aparellades}

Quan el test és \red{bilateral}, si  $n$ és prou gran ($\geq 100$) i si el nombre de \emph{casos discordants} ($b+c$ en la taula anterior) és grandet ($\geq 20$), es pot emprar el \emph{test de McNemar}, que empra l'estadístic
$$
Z^2=\frac{(b-c)^2}{b+c}
$$
que és aproximadament $\chi^2_1$ si $H_0$ és vertadera

Està implementat en la funció \red{\texttt{mcnemar.test}}: s'aplica a la taula de freqüències absolutes anterior




\frametitle{Exemple 8}\vspace*{-2ex}

Es volgué comparar l'efectivitat d'un fàrmac nou contra la migranya amb la d'un placebo

Es prengué una mostra de $500$ persones afectades per migranya. A cada una, a l'atzar, se li administrà el fàrmac o el placebo. Se'ls demanà si havien notat alleujament en el dolor.


Al cap d'un temps, als mateixos individus se'ls subministrà l'altre tractament (fàrmac als que havien rebut placebo, 
placebo als que havien rebut fàrmac) i se'ls tornà a demanar si havien notat o no milloria

Els resultats varen ser:
$$
\begin{tabular}{c|c|cc|}
\multicolumn{2}{c}{}& \multicolumn{2}{c} {Placebo}\\\cline{3-4}
\multicolumn{2}{c|}{} & Sí & No \\\hline
Fàrmac & Sí & 150 & 41 \\
& No & 19 & 285
\\\hline
\end{tabular}
$$





\frametitle{Exemple 8} 

\red{Variables d'interès:}

*$X_1$: Trobar  milloria amb el fàrmac, de proporció poblacional $p_1$

*$X_2$: Trobar  milloria amb el placebo, de proporció poblacional $p_2$



\red{Contrast}: Volem emprar el test de McNemar, per tant ha de ser bilateral
$$
\left\{\begin{array}{l}
H_0:p_1=p_2\\
H_1:p_1\neq  p_2
\end{array}\right.
$$





\frametitle{Exemple 8} 

\begin{lstlisting}
> Dades.M=matrix(c(150,41,19,285), nrow=2,
     byrow=T)
> mcnemar.test(Dades.M)

McNemar's Chi-squared test with continuity correction

data:  Dades.M
McNemar's chi-squared = 7.35, df = 1, p-value = 0.006706
\end{lstlisting}

Podem rebutjar que tenen la mateixa taxa d'efectivitat, i com que la taxa d'efectivitat del fàrmac ha estat superior a la del placebo 
($191/500$ contra $169/500$) concloem que la diferència és perquè el fàrmac es més efectiu






\frametitle{Test binomial exacte}\vspace*{-2ex}

Si no podeu emprar el test de McNemar, sempre podeu emprar un \emph{test binomial exacte}

Considerau la taula de probabilitats
\begin{center}
\begin{tabular}{l|l|c|c|}
\multicolumn{2}{c}{\ } & \multicolumn{2}{c}{Variable $X_2$}\\ \cline{3-4}
\multicolumn{2}{c|}{\ } &Èxit & Fracàs \\ \cline{2-4}
Variable & Èxit & $p_{11}$ & $p_{10}$ \\
$X_1$ & Fracàs & $p_{01}$ & $p_{00}$\\ \cline{2-4}
\end{tabular}
\end{center}
Llavors
$$
p_1=p_{11}+p_{01},\ p_2=p_{11}+p_{10}
$$
i per tant
$$
\begin{array}{l}
p_1=p_2\Longleftrightarrow   p_{10}=p_{01}\\
p_1\neq p_2\Longleftrightarrow   p_{10}\neq p_{01}\\
p_1< p_2\Longleftrightarrow   p_{10}< p_{01}\\
p_1> p_2\Longleftrightarrow   p_{10}> p_{01}
\end{array}
$$






\frametitle{Test binomial exacte}

Això permet traduir un contrast sobre $p_1$ i $p_2$ en el mateix  contrast sobre $p_{01}$ i $p_{10}$ i al final en un contrast d'una proporció

Per exemple:
$$
\begin{array}{rl}
\left\{\begin{array}{l}
H_0: p_1=p_2\\
H_1: p_1> p_2
\end{array}\right. & 
\Longleftrightarrow
\left\{\begin{array}{l}
H_0: p_{10}=p_{01}\\
H_1: p_{10}>p_{01}
\end{array}\right.\\[3ex]
 & \Longleftrightarrow
\left\{\begin{array}{l}
H_0: \dfrac{p_{10}}{p_{10}+p_{01}}=0.5\\[2ex]
H_1:  \dfrac{p_{10}}{p_{10}+p_{01}}>0.5
\end{array}\right.
\end{array}
$$



\frametitle{Test binomial exacte}\vspace*{-2ex}
$$
\left\{\begin{array}{l}
H_0:  p_{10}/(p_{10}+p_{01})=0.5\\
H_1:   p_{10}/(p_{10}+p_{01})>0.5
\end{array}\right.
$$

\red{$p_{10}/(p_{10}+p_{01})$} és la proporció poblacional de (Èxit,Fracàs) dins la població de casos discordants

Aquest darrer contrast el podem efectuar amb un test binomial exacte amb:


*\blue{Mostra}: Casos discordants, de mida $b+c$
*\blue{Èxits}: Èxit a $X_1$ i Fracàs a $X_2$, de mida  $b$
*\blue{Proporció a contrastar}:  $p=0.5$


Mirau només el p-valor (l'IC serà per a $p_{10}/(p_{10}+p_{01})$, no té res a veure amb $p_1-p_2$ o $p_1/p_2$)






\frametitle{Exemple 8}\vspace{-6ex}
{\small $$
\begin{tabular}{c|c|cc|}
\multicolumn{2}{c}{}& \multicolumn{2}{c} {Placebo}\\\cline{3-4}
\multicolumn{2}{c|}{} & Sí & No \\\hline
Fàrmac & Sí & 150 & 41 \\
& No & 19 & 285
\\\hline
\end{tabular}
$$

}
\begin{lstlisting}
> binom.test(41, 60, p=0.5, alt="greater")

	Exact one-sided binomial test

data:  41 and 60
number of successes = 41, number of trials = 60, p-value = 0.003109
alternative hypothesis: true probability of success is greater than 0.5
95 percent confidence interval:
 0.5708296 1.0000000
sample estimates:
probability of success 
             0.6833333 
\end{lstlisting}


\end{document}



\frametitle{Contrastos una mica més generals}

Fins ara hem pres $H_0:\mu_1=\mu_2$. Un tipus de contrastos lleugerament més generals serien
$$
\left\{\begin{array}{l}
H_0:\mu_1-\mu_2=\Delta\\
H_1:\mu_1-\mu_2<\Delta\text{ o }\mu_1-\mu_2>\Delta\text{ o }\mu_1-\mu_2\neq\Delta
\end{array}\right.
$$
amb $\Delta\in \RR$.


Es fan igual, modificant lleugerament l'estadístic: substituïm als numeradors
\begin{center}
$\overline{X}_1-\overline{X}_2$ per
\red{$\overline{X}_1-\overline{X}_2-\Delta$}
\end{center}





\frametitle{Exemple}
Tenim dos tractaments, A i B, d'una malaltia. Tractam 50 malalts amb A i 100 amb B. 20 malalts  tractats amb A i 25 tractats amb B manifesten haver sentit malestar general durant els 7 dies posteriors a iniciar el tractament.


Podem concloure, a un nivell de significació del 5%, que A produeix malestar general en una proporció dels malalts que és 5 punts percentuals superior  a la proporció dels malalts en què el produeix B?



%%%%%%%%%


\frametitle{Exemple}

$p_1$: Fracció de malalts en què A produeix malestar general\\
$p_2$: Fracció de malalts en què B produeix malestar general


\emph{Contrast}:
$$
\left\{\begin{array}{l}
H_0:p_1\leq p_2+0.05\\
H_1:p_1>p_2+0.05
\end{array}\right.
$$

\emph{Estadístic de contrast}:
$$
Z=\frac{\widehat{p}_1 -\widehat{p}_2-\Delta}{
\sqrt{\Big(\frac{n_1 \widehat{p}_1 +n_2 \widehat{p}_2}{n_1
+n_2}\Big)\Big(1-\frac{n_1 \widehat{p}_1 +n_2 \widehat{p}_2}{n_1
+n_2}\Big)\Big(\frac{1}{n_1}+\frac{1}{n_2}
\Big)}}\sim N(0,1)
$$




\frametitle{Exemple}


\emph{Valor que pren}: $\widehat{p}_1=0.4$, $\widehat{p}_2=0.25$, $n_1=50$, $n_2=100$, $\Delta=0.05$
$$
z_0=\frac{0.4 -0.25-0.05}{
\sqrt{\Big(\frac{20+25}{50+100}\Big)\Big(1-\frac{20+25}{50+100}\Big)\Big(\frac{1}{50}+\frac{1}{100}
\Big)}}
=1.26
$$


\emph{p-valor}: $P(Z\geq 1.26)= 0.104$


\emph{Decisió}: Com que el p-valor és més gran que $\alpha=0.05$, no podem rebutjar la hipòtesi que $p_1-p_2$ és inferior a un $5%$



\frametitle{Exemple}

L'\emph{interval de confiança} per a  $p_1-p_2$
al nivell de confiança $(1-\alpha)\cdot 100%$ en aquest contrast és

{\footnotesize $$
\left[\widehat{p}_1-\widehat{p}_2+z_{\alpha}\sqrt{\Big(\frac{n_1 \widehat{p}_1 +n_2 \widehat{p}_2}{n_1
+n_2}\Big)\Big(1-\frac{n_1 \widehat{p}_1 +n_2 \widehat{p}_2}{n_1
+n_2}\Big)\Big(\frac{1}{n_1}+\frac{1}{n_2}
\Big)},\infty
\right[
$$
}
Operant:
$$
[(0.4-0.25)-1.645\cdot 0.0794,\infty [=[0.0194,\infty[
$$
Conté $0.05$, per tant no podem rebutjar que $p_1\leq p_2+ 0.05$ (però en canvi, no conté 0 i per tant podríem rebutjar que $p_1=p_2$)





-->