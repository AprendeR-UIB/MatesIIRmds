<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<meta property="og:title" content="1.2 Regressió lineal múltiple | Matemàtiques II v.2021" />
<meta property="og:type" content="book" />


<meta property="og:description" content="Apunts Matemàtiques II bookdown::gitbook." />
<meta name="github-repo" content="cescrossello/MatesII" />


<meta name="date" content="2021-09-17" />

<script type="text/x-mathjax-config">
MathJax.Hub.Config({
  TeX: { equationNumbers: { autoNumber: "AMS" } }
});
</script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<meta name="description" content="Apunts Matemàtiques II bookdown::gitbook.">

<title>1.2 Regressió lineal múltiple | Matemàtiques II v.2021</title>

<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="libs/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="libs/navigation-1.1/tabsets.js"></script>
p.caption {
  color: #777;
  margin-top: 10px;
}
p code {
  white-space: inherit;
}
pre {
  word-break: normal;
  word-wrap: normal;
}
pre code {
  white-space: inherit;
}
.rmdcaution, .rmdimportant, .rmdnote, .rmdrecordau {
  padding: 1em 1em 1em 4em;
  margin-bottom: 10px;
  background: #f5f5f5 5px center/3em no-repeat;
}
.rmdmercifulgod {
  padding: 1em 1em 1em 6em;
  margin-bottom: 10px;
  background: #f5f5f5 5px center/5em no-repeat;
}
.rmdromans {
  padding: 1em 1em 2em 6em;
  margin-bottom: 10px;
  background: #f5f5f5 5px center/5em no-repeat;
}
.rmdexercici {
  padding: 1em 1em 1em 4em;
  margin-bottom: 10px;
  background: #f9f9f9 5px center/3em no-repeat;
}
.rmderror {
  padding: 1em 1em 2em 7em;
  margin-bottom: 10px;
  background: #f5f5f5 5px center/6em no-repeat;
}
.rmderrorpetit {
  padding: 1em 1em 2em 4em;
  margin-bottom: 10px;
  background: #f5f5f5 5px center/3em no-repeat;
}
.rmdcorbes {
  padding: 1em 1em 1em 4em;
  margin-bottom: 10px;
  background: #f9f9f9  5px center/3em  no-repeat;
}
.rmdcaution {
  background-image: url("Bioestadistica-II_files/figure-html/caution.png");
}
.rmdimportant {
  background-image: url("Bioestadistica-II_files/figure-html/important.png");
}
.rmdnote {
  background-image: url("Bioestadistica-II_files/figure-html/note.png");
}
.rmdcorbes {
  background-image: url("Bioestadistica-II_files/figure-html/corbes.png");
}
.rmdrecordau {
  background-image: url("Bioestadistica-II_files/figure-html/recordau.png");
}
.rmderror {
  background-image: url("Bioestadistica-II_files/figure-html/error.png");
}
.rmderrorpetit{
  background-image: url("Bioestadistica-II_files/figure-html/error.png");
}
.rmdmercifulgod {
  background-image: url("Bioestadistica-II_files/figure-html/mercifulgod.png");
}
.rmdromans {
  background-image: url("Bioestadistica-II_files/figure-html/romanos.png");
}
.rmdexercici {
  background-image: url("Bioestadistica-II_files/figure-html/exercici.png");
}


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
  height: auto;
}
/* show arrow before summary tag as in bootstrap
TODO: remove if boostrap in updated in html_document (rmarkdown#1485) */
details > summary {
  display: list-item;
  cursor: pointer;
}
</style>
</head>

<body>

<div class="container-fluid main-container">


<div class="row">
<div class="col-sm-12">
<div id="TOC">
<ul>
<li><a href="index.html#presentació">Presentació</a></li>
<li><a href="1-regressió-lineal.html#regressió-lineal"><span class="toc-section-number">1</span> Regressió lineal</a>
<ul>
<li><a href="1.1-regressió-lineal-simple.html#regressió-lineal-simple"><span class="toc-section-number">1.1</span> Regressió lineal simple</a>
<ul>
<li><a href="1.1-regressió-lineal-simple.html#el-model"><span class="toc-section-number">1.1.1</span> El model</a></li>
<li><a href="1.1-regressió-lineal-simple.html#mínims-quadrats"><span class="toc-section-number">1.1.2</span> Mínims quadrats</a></li>
<li><a href="1.1-regressió-lineal-simple.html#coeficient-de-determinació"><span class="toc-section-number">1.1.3</span> Coeficient de determinació</a></li>
<li><a href="1.1-regressió-lineal-simple.html#intervals-de-confiança-dels-coeficients"><span class="toc-section-number">1.1.4</span> Intervals de confiança dels coeficients</a></li>
<li><a href="1.1-regressió-lineal-simple.html#intervals-de-confiança-per-a-les-estimacions-de-la-variable-dependent"><span class="toc-section-number">1.1.5</span> Intervals de confiança per a les estimacions de la variable dependent</a></li>
<li><a href="1.1-regressió-lineal-simple.html#té-sentit-una-regressió-lineal"><span class="toc-section-number">1.1.6</span> Té sentit una regressió lineal?</a></li>
</ul></li>
<li><a href="1.2-regressió-lineal-múltiple.html#regressió-lineal-múltiple"><span class="toc-section-number">1.2</span> Regressió lineal múltiple</a>
<ul>
<li><a href="1.2-regressió-lineal-múltiple.html#mínims-quadrats-1"><span class="toc-section-number">1.2.1</span> Mínims quadrats</a></li>
<li><a href="1.2-regressió-lineal-múltiple.html#coeficient-de-determinació-múltiple"><span class="toc-section-number">1.2.2</span> Coeficient de determinació múltiple</a></li>
<li><a href="1.2-regressió-lineal-múltiple.html#coeficient-de-determinació-ajustat"><span class="toc-section-number">1.2.3</span> Coeficient de determinació ajustat</a></li>
<li><a href="1.2-regressió-lineal-múltiple.html#intervals-de-confiança-per-als-coeficients"><span class="toc-section-number">1.2.4</span> Intervals de confiança per als coeficients</a></li>
<li><a href="1.2-regressió-lineal-múltiple.html#intervals-de-confiança-per-a-les-estimacions-de-la-variable-resposta"><span class="toc-section-number">1.2.5</span> Intervals de confiança per a les estimacions de la variable resposta</a></li>
<li><a href="1.2-regressió-lineal-múltiple.html#lanova-de-la-regressió-lineal-múltiple"><span class="toc-section-number">1.2.6</span> L’ANOVA de la regressió lineal múltiple</a></li>
</ul></li>
<li><a href="1.3-test-de-la-lliçó-11.html#test-de-la-lliçó-11"><span class="toc-section-number">1.3</span> Test de la lliçó 11</a></li>
</ul></li>
</ul>
</div>
</div>
</div>
<div class="row">
<div class="col-sm-12">
<div id="regressió-lineal-múltiple" class="section level2" number="1.2">
<h2><span class="header-section-number">1.2</span> Regressió lineal múltiple</h2>
<p>Comencem amb un exemple.</p>

<div class="example">
<p><span id="exm:mult" class="example"><strong>Exemple 1.13  </strong></span>Es postula que l’alçada esperada d’un nadó en cm (<span class="math inline">\(Y\)</span>) té una relació lineal amb la seva edat en dies (<span class="math inline">\(X_1\)</span>), la seva alçada en néixer en cm (<span class="math inline">\(X_2\)</span>), el seu pes en kg en néixer (<span class="math inline">\(X_3\)</span>) i l’augment en tant per cent del seu pes actual respecte del seu pes en néixer (<span class="math inline">\(X_4\)</span>). És a dir, es creu que existeixen coeficients <span class="math inline">\(\beta_0,\ldots,\beta_4\in \mathbb{R}\)</span> tals que el model
<span class="math display">\[
\mu_{Y|x_1,x_2,x_3,x_4}=\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3+\beta_4x_4
\]</span>
és correcte, on <span class="math inline">\(\mu_{Y|x_1,x_2,x_3,x_4}\)</span> és l’alçada esperada, en cm, d’un nadó de <span class="math inline">\(x_1\)</span> dies que en néixer va fer <span class="math inline">\(x_2\)</span> cm i <span class="math inline">\(x_3\)</span> kg i des de llavors el seu pes ha augmentat un <span class="math inline">\(x_4\)</span>%. En una mostra de <span class="math inline">\(n=9\)</span> nins, els resultats varen ser els de la taula següent:</p>
</div>
<table>
<thead>
<tr>
<th style="text-align:right;">
Alçada (en cm)
</th>
<th style="text-align:right;">
Edat (en dies)
</th>
<th style="text-align:right;">
Alçada en néixer (en cm)
</th>
<th style="text-align:right;">
Pes en néixer (en kg)
</th>
<th style="text-align:right;">
% d’increment de pes
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
57.5
</td>
<td style="text-align:right;">
78
</td>
<td style="text-align:right;">
8.2
</td>
<td style="text-align:right;">
2.75
</td>
<td style="text-align:right;">
29.5
</td>
</tr>
<tr>
<td style="text-align:right;">
52.8
</td>
<td style="text-align:right;">
69
</td>
<td style="text-align:right;">
45.5
</td>
<td style="text-align:right;">
2.15
</td>
<td style="text-align:right;">
26.3
</td>
</tr>
<tr>
<td style="text-align:right;">
61.3
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
46.3
</td>
<td style="text-align:right;">
4.41
</td>
<td style="text-align:right;">
32.2
</td>
</tr>
<tr>
<td style="text-align:right;">
67.0
</td>
<td style="text-align:right;">
88
</td>
<td style="text-align:right;">
49.0
</td>
<td style="text-align:right;">
5.52
</td>
<td style="text-align:right;">
36.5
</td>
</tr>
<tr>
<td style="text-align:right;">
53.5
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:right;">
43.0
</td>
<td style="text-align:right;">
3.21
</td>
<td style="text-align:right;">
27.2
</td>
</tr>
<tr>
<td style="text-align:right;">
62.7
</td>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
4.32
</td>
<td style="text-align:right;">
27.7
</td>
</tr>
<tr>
<td style="text-align:right;">
56.2
</td>
<td style="text-align:right;">
74
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
2.31
</td>
<td style="text-align:right;">
28.3
</td>
</tr>
<tr>
<td style="text-align:right;">
68.5
</td>
<td style="text-align:right;">
94
</td>
<td style="text-align:right;">
53.0
</td>
<td style="text-align:right;">
4.30
</td>
<td style="text-align:right;">
30.3
</td>
</tr>
<tr>
<td style="text-align:right;">
79.2
</td>
<td style="text-align:right;">
102
</td>
<td style="text-align:right;">
58.0
</td>
<td style="text-align:right;">
3.71
</td>
<td style="text-align:right;">
28.7
</td>
</tr>
</tbody>
</table>
<p>A partir d’aquesta mostra, volem estimar els coeficients <span class="math inline">\(\beta_0,\ldots,\beta_4\in \mathbb{R}\)</span> de la relació lineal predita.</p>
<p>Aquest és un problema de <strong>regressió lineal múltiple</strong>. Ara tenim <span class="math inline">\(k\)</span> variables <strong>independents</strong>, o <strong>de control</strong> <span class="math inline">\(X_1,\ldots, X_k\)</span> (com al cas simple, no necessàriament aleatòries) i una
variable aleatòria <strong>dependent</strong>, o <strong>de resposta</strong>, <span class="math inline">\(Y\)</span>. Suposam que el model
<span class="math display">\[
\mu_{Y|x_1,\ldots,x_k}= \beta_0+\beta_1 x_1+\cdots+\beta_k x_k
\]</span>
o, equivalentment,
<span class="math display">\[
Y|x_1,\ldots,x_k=\beta_0+\beta_1 x_{1}+\cdots+\beta_{k} x_k+E_{x_1,\ldots,x_k}
\]</span>
és correcte, on:</p>
<ul>
<li><p><span class="math inline">\(Y|x_1,\ldots,x_k\)</span> és la variable aleatòria que dóna el valor de <span class="math inline">\(Y\)</span> sobre individus en els quals <span class="math inline">\(X_i=x_i\)</span> per a cada <span class="math inline">\(i=1,\ldots,k\)</span></p></li>
<li><p><span class="math inline">\(\mu_{Y|x_1,\ldots,x_k}\)</span> és el valor esperat de <span class="math inline">\(Y|x_1,\ldots,x_k\)</span>, és a dir, la mitjana dels valors de <span class="math inline">\(Y\)</span> sobre tots els individus de la població en els quals <span class="math inline">\(X_i=x_i\)</span> per a cada <span class="math inline">\(i=1,\ldots,k\)</span></p></li>
<li><p>Les <span class="math inline">\(E_{x_1,\ldots,x_k}\)</span> són les variables aleatòries <strong>error</strong>, o <strong>residu</strong>, i representen l’error aleatori de la variable <span class="math inline">\(Y\)</span> sobre un individu en el qual <span class="math inline">\((X_1,\ldots,X_k)=(x_1,\ldots,x_k)\)</span></p></li>
<li><p><span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_{k}\in \mathbb{R}\)</span>:</p>
<ul>
<li><p><span class="math inline">\(\beta_0\)</span> és el valor esperat de <span class="math inline">\(Y\)</span> quan <span class="math inline">\(X_1=\cdots=X_k=0\)</span></p></li>
<li><p>Cada <span class="math inline">\(\beta_i\)</span> és la variació del valor esperat de <span class="math inline">\(Y\)</span> quan <span class="math inline">\(X_i\)</span> augmenta una unitat i les altres variables <span class="math inline">\(X_j\)</span> no varien</p></li>
</ul></li>
</ul>
<p>Els paràmetres <span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_{k}\)</span> són desconeguts, i els volem estimar a partir d’una mostra
<span class="math display">\[
(x_{1i},x_{2i},\ldots,x_{ki},y_i)_{i=1,\ldots,n}
\]</span>
d’observacions del vector aleatori <span class="math inline">\((X_1,\ldots,X_k,Y)\)</span> sobre <span class="math inline">\(n\)</span> individus. Requerirem que
<span class="math inline">\(n&gt;k\)</span> (el nombre d’observacions ha de ser més gran que el nombre de variables) a fi que el sistema d’equacions lineals amb incògnites els coeficients <span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_{k}\)</span>
<span class="math display">\[
\left\{
\begin{array}{l}
y_1=\beta_0+\beta_1x_{11}+\cdots +\beta_kx_{k1}\\
\quad\vdots\\
y_n=\beta_0+\beta_1x_{1n}+\cdots +\beta_kx_{kn}
\end{array}
\right.
\]</span>
no sigui indeterminat. Direm <span class="math inline">\(b_0,b_1,\ldots,b_k\)</span> a les estimacions dels paràmetres <span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_k\)</span> a partir d’una mostra, i per escurçar escriurem <span class="math inline">\(\underline{x}_i\)</span> per indicar <span class="math inline">\((x_{1i},x_{2i},\ldots,x_{ki})\)</span>.</p>
<p>Per a cada <span class="math inline">\(i=1,\ldots,n\)</span>, diguem
<span class="math display">\[
\begin{array}{l}
\widehat{y}_i= b_0+b_1 x_{1i}+\cdots+b_{k} x_{ki}\\
e_i=y_i-\widehat{y}_i=y_i-(b_0+b_1 x_{1i}+\cdots+b_{k} x_{ki})
\end{array}
\]</span>
Amb aquestes notacions:</p>
<ul>
<li><p><span class="math inline">\(\widehat{y}_i\)</span> és el <strong>valor predit</strong> de <span class="math inline">\(Y\)</span> sobre l’individu <span class="math inline">\(i\)</span>-èsim de la mostra a partir del seu vector de valors <span class="math inline">\(\underline{x}_{i}\)</span> i de les estimacions <span class="math inline">\(b_0,b_1,\ldots,b_k\)</span> dels paràmetres</p></li>
<li><p><span class="math inline">\(e_i\)</span> és l’<strong>error</strong> que es comet amb aquesta estimació sobre aquest individu</p></li>
</ul>
<p>Direm la <strong>Suma de Quadrats dels Errors</strong> a:
<span class="math display">\[
\begin{array}{rl}
SS_E= &amp;\displaystyle\sum\limits_{i=1}^n
e^2_i=\sum\limits_{i=1}^n (y_i-\widehat{y}_i)^2 \\
= &amp;\displaystyle\sum\limits_{i=1}^n (y_i-b_0-b_1 x_{1i}-\cdots -b_{k} x_{ki})^2.
\end{array}
\]</span></p>
<div id="mínims-quadrats-1" class="section level3" number="1.2.1">
<h3><span class="header-section-number">1.2.1</span> Mínims quadrats</h3>
<p>Els estimadors de <span class="math inline">\(\beta_0,\beta_1,\ldots, \beta_k\)</span> pel <strong>mètode de mínims quadrats</strong> són els
valors <span class="math inline">\(b_0,b_1,\ldots, b_k\)</span> que minimitzen <span class="math inline">\(SS_E\)</span> sobre la nostra mostra. Per calcular-los, calculam les derivades parcials de <span class="math inline">\(SS_E\)</span> respecte de cada <span class="math inline">\(b_i\)</span>, les igualam a 0, resolem el sistema resultant, comprovam que la solució <span class="math inline">\((b_0,\ldots,b_k)\)</span> trobada dóna un mínim… Tot plegat, al final s’obté el resultat següent:</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-79" class="theorem"><strong>Teorema 1.5  </strong></span>Siguin
<span class="math display">\[
\mathbf{y}=
\left(
\begin{array}{l}
y_1\\ y_2\\ \vdots\\ y_n
\end{array}
\right),\ \mathbf{X}=\left(
\begin{array}{lllll}
1&amp;x_{11}&amp;x_{21}&amp;\ldots&amp;x_{k1}\\
1&amp;x_{12}&amp;x_{22}&amp;\ldots&amp;x_{k2}\\
\vdots&amp;\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
1&amp;x_{1n}&amp;x_{2n}&amp;\ldots&amp;x_{kn}
\end{array}
\right)
\]</span></p>
<p>Aleshores, els estimadors per mínims quadrats <span class="math inline">\(\mathbf{b}=(b_0,b_1,\ldots,b_k)^t\)</span> de <span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_k\)</span> a partir de la mostra <span class="math inline">\((\underline{x}_{i},y_i)_{i=1,2,\ldots,n}\)</span> són donats per l’equació següent:
<span class="math display">\[
\mathbf{b}=\left(\mathbf{X}^t\cdot \mathbf{X}\right)^{-1}\cdot \left(\mathbf{X}^t \cdot \mathbf{y}\right).
\]</span></p>
</div>

<div class="rmdcorbes">
Amb una mica de paciència podeu comprovar que si <span class="math inline">\(k=1\)</span>, aquesta fórmula dóna la de <span class="math inline">\((b_0,b_1)^t\)</span> a la regressió lineal simple.
</div>
<p>Com al cas simple, la funció resultant l’escriurem
<span class="math display">\[
\widehat{Y}=b_0+b_1X_1+\cdots +b_kX_k
\]</span>
i en direm la <strong>funció de regressió lineal per mínims quadrats</strong> de <span class="math inline">\(Y\)</span> en funció de <span class="math inline">\(X_1,\ldots,X_k\)</span>.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-81" class="example"><strong>Exemple 1.14  </strong></span>Tornem a l’Exemple <a href="1.2-regressió-lineal-múltiple.html#exm:mult">1.13</a>. Recordau les dades:</p>
</div>
<table>
<thead>
<tr>
<th style="text-align:right;">
Alçada (en cm)
</th>
<th style="text-align:right;">
Edat (en dies)
</th>
<th style="text-align:right;">
Alçada en néixer (en cm)
</th>
<th style="text-align:right;">
Pes en néixer (en kg)
</th>
<th style="text-align:right;">
% d’increment de pes
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
57.5
</td>
<td style="text-align:right;">
78
</td>
<td style="text-align:right;">
8.2
</td>
<td style="text-align:right;">
2.75
</td>
<td style="text-align:right;">
29.5
</td>
</tr>
<tr>
<td style="text-align:right;">
52.8
</td>
<td style="text-align:right;">
69
</td>
<td style="text-align:right;">
45.5
</td>
<td style="text-align:right;">
2.15
</td>
<td style="text-align:right;">
26.3
</td>
</tr>
<tr>
<td style="text-align:right;">
61.3
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
46.3
</td>
<td style="text-align:right;">
4.41
</td>
<td style="text-align:right;">
32.2
</td>
</tr>
<tr>
<td style="text-align:right;">
67.0
</td>
<td style="text-align:right;">
88
</td>
<td style="text-align:right;">
49.0
</td>
<td style="text-align:right;">
5.52
</td>
<td style="text-align:right;">
36.5
</td>
</tr>
<tr>
<td style="text-align:right;">
53.5
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:right;">
43.0
</td>
<td style="text-align:right;">
3.21
</td>
<td style="text-align:right;">
27.2
</td>
</tr>
<tr>
<td style="text-align:right;">
62.7
</td>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
4.32
</td>
<td style="text-align:right;">
27.7
</td>
</tr>
<tr>
<td style="text-align:right;">
56.2
</td>
<td style="text-align:right;">
74
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
2.31
</td>
<td style="text-align:right;">
28.3
</td>
</tr>
<tr>
<td style="text-align:right;">
68.5
</td>
<td style="text-align:right;">
94
</td>
<td style="text-align:right;">
53.0
</td>
<td style="text-align:right;">
4.30
</td>
<td style="text-align:right;">
30.3
</td>
</tr>
<tr>
<td style="text-align:right;">
79.2
</td>
<td style="text-align:right;">
102
</td>
<td style="text-align:right;">
58.0
</td>
<td style="text-align:right;">
3.71
</td>
<td style="text-align:right;">
28.7
</td>
</tr>
</tbody>
</table>
<p>Calculem la funció lineal de regressió per mínims quadrats de l’alçada en funció de les altres variables. Pel teorema anterior, si diem
<span class="math display">\[
\mathbf{X}=\left(
\begin{array}{ccccc}
1&amp;78&amp;48.2&amp;2.75&amp;29.5\\
1&amp;69&amp;45.5&amp;2.15&amp;26.3\\
1&amp;77&amp;46.3&amp;4.41&amp;32.2\\
1&amp;88&amp;49&amp;5.52&amp;36.5\\
1&amp;67&amp;43&amp;3.21&amp;27.2\\
1&amp;80&amp;48&amp;4.32&amp;27.7\\
1&amp;74&amp;48&amp;2.31&amp;28.3\\
1&amp;94&amp;53&amp;4.3&amp;30.3\\
1&amp;102&amp;58&amp;3.71&amp;28.7
\end{array}
\right),\
\mathbf{y}=\left(
\begin{array}{c}
57.5\\ 52.8\\ 61.3\\ 67\\ 53.5\\ 62.7\\ 56.2\\ 68.5\\ 79.2
\end{array}
\right)
\]</span></p>
<p>aleshores <span class="math inline">\((b_0,b_1,b_2,b_3,b_4)\)</span> s’obté mitjançant
<span class="math display">\[
\left(\begin{array}{c} b_0 \\ \vdots \\ b_4\end{array}\right)=\left(\mathbf{X}^t\cdot \mathbf{X} \right)^{-1}\cdot \left(\mathbf{X}^t \cdot \mathbf{y}\right)
\]</span></p>
<p>Per calcular aquest vector, primer entram les dades i definim aquestes matrius</p>
<div class="sourceCode" id="cb108"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb108-1"><a href="1.2-regressió-lineal-múltiple.html#cb108-1" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">c</span>(<span class="fl">57.5</span>,<span class="fl">52.8</span>,<span class="fl">61.3</span>,<span class="dv">67</span>,<span class="fl">53.5</span>,<span class="fl">62.7</span>,<span class="fl">56.2</span>,<span class="fl">68.5</span>,<span class="fl">79.2</span>)</span>
<span id="cb108-2"><a href="1.2-regressió-lineal-múltiple.html#cb108-2" aria-hidden="true" tabindex="-1"></a>x1<span class="ot">=</span><span class="fu">c</span>(<span class="dv">78</span>,<span class="dv">69</span>,<span class="dv">77</span>,<span class="dv">88</span>,<span class="dv">67</span>,<span class="dv">80</span>,<span class="dv">74</span>,<span class="fl">94.0</span>,<span class="dv">102</span>)</span>
<span id="cb108-3"><a href="1.2-regressió-lineal-múltiple.html#cb108-3" aria-hidden="true" tabindex="-1"></a>x2<span class="ot">=</span><span class="fu">c</span>(<span class="fl">8.2</span>,<span class="fl">45.5</span>,<span class="fl">46.3</span>,<span class="dv">49</span>,<span class="dv">43</span>,<span class="dv">48</span>,<span class="dv">48</span>,<span class="dv">53</span>,<span class="dv">58</span>)</span>
<span id="cb108-4"><a href="1.2-regressió-lineal-múltiple.html#cb108-4" aria-hidden="true" tabindex="-1"></a>x3<span class="ot">=</span><span class="fu">c</span>(<span class="fl">2.75</span>,<span class="fl">2.15</span>,<span class="fl">4.41</span>,<span class="fl">5.52</span>,<span class="fl">3.21</span>,<span class="fl">4.32</span>,<span class="fl">2.31</span>,<span class="fl">4.3</span>,<span class="fl">3.71</span>)</span>
<span id="cb108-5"><a href="1.2-regressió-lineal-múltiple.html#cb108-5" aria-hidden="true" tabindex="-1"></a>x4<span class="ot">=</span><span class="fu">c</span>(<span class="fl">29.5</span>,<span class="fl">26.3</span>,<span class="fl">32.2</span>,<span class="fl">36.5</span>,<span class="fl">27.2</span>,<span class="fl">27.7</span>,<span class="fl">28.3</span>,<span class="fl">30.3</span>,<span class="fl">28.7</span>)</span>
<span id="cb108-6"><a href="1.2-regressió-lineal-múltiple.html#cb108-6" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">cbind</span>(<span class="dv">1</span>,x1,x2,x3,x4)</span>
<span id="cb108-7"><a href="1.2-regressió-lineal-múltiple.html#cb108-7" aria-hidden="true" tabindex="-1"></a>X</span></code></pre></div>
<pre><code>##          x1   x2   x3   x4
##  [1,] 1  78  8.2 2.75 29.5
##  [2,] 1  69 45.5 2.15 26.3
##  [3,] 1  77 46.3 4.41 32.2
##  [4,] 1  88 49.0 5.52 36.5
##  [5,] 1  67 43.0 3.21 27.2
##  [6,] 1  80 48.0 4.32 27.7
##  [7,] 1  74 48.0 2.31 28.3
##  [8,] 1  94 53.0 4.30 30.3
##  [9,] 1 102 58.0 3.71 28.7</code></pre>
<p>Ara ja podem estimar els coeficients de la funció de regressió lineal:</p>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="1.2-regressió-lineal-múltiple.html#cb110-1" aria-hidden="true" tabindex="-1"></a>B<span class="ot">=</span><span class="fu">solve</span>(<span class="fu">t</span>(X)<span class="sc">%*%</span>X)<span class="sc">%*%</span>(<span class="fu">t</span>(X)<span class="sc">%*%</span>y)</span>
<span id="cb110-2"><a href="1.2-regressió-lineal-múltiple.html#cb110-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(B,<span class="dv">4</span>)</span></code></pre></div>
<pre><code>##       [,1]
##     9.9464
## x1  0.6626
## x2  0.0483
## x3  1.0618
## x4 -0.2543</code></pre>
<p>Obtenim
<span class="math display">\[
\begin{array}{ccccc}
b_0 &amp; b_1 &amp; b_2 &amp; b_3&amp; b_4\\ \hline
9.9464 &amp; 0.6626 &amp; 0.0483 &amp; 1.0618 &amp; -0.2543
\end{array}
\]</span>
i per tant la funció de regressió lineal per mínims quadrats
<span class="math display">\[
\widehat{Y}=9.9464+0.6626X_1+0.0483X_2+1.0618X_3-0.2543X_4
\]</span></p>
<p>Fixau-vos que les igualtats
<span class="math display">\[
\widehat{y}_i=b_0+b_1x_{1i}+b_2x_{2i}+\cdots +b_nx_{ni}
\]</span>
es tradueixen en la igualtat matricial
<span class="math display">\[
\left(
\begin{array}{l}
\widehat{y}_1\\ \widehat{y}_2\\ \vdots\\ \widehat{y}_n
\end{array}
\right)=\left(
\begin{array}{lllll}
1&amp;x_{11}&amp;x_{21}&amp;\ldots&amp;x_{k1}\\
1&amp;x_{12}&amp;x_{22}&amp;\ldots&amp;x_{k2}\\
\vdots&amp;\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
1&amp;x_{1n}&amp;x_{2n}&amp;\ldots&amp;x_{kn}
\end{array}
\right)\cdot
\left(
\begin{array}{l}
b_0 \\ b_1\\ b_2\\ \vdots\\ b_k
\end{array}
\right)
\]</span></p>
<p>En el nostre exemple, els valors estimats de <span class="math inline">\(Y\)</span> sobre els nins de la nostra mostra serien</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="1.2-regressió-lineal-múltiple.html#cb112-1" aria-hidden="true" tabindex="-1"></a>Y.cap<span class="ot">=</span>X<span class="sc">%*%</span>B</span>
<span id="cb112-2"><a href="1.2-regressió-lineal-múltiple.html#cb112-2" aria-hidden="true" tabindex="-1"></a><span class="fu">t</span>(<span class="fu">round</span>(Y.cap,<span class="dv">1</span>))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
## [1,] 57.4 53.5 59.7 67.2 52.9 62.8 56.6 71.7   77</code></pre>
<p>i per tant els errors <span class="math inline">\(e_i=y_i-\widehat{y}_i\)</span> són</p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="1.2-regressió-lineal-múltiple.html#cb114-1" aria-hidden="true" tabindex="-1"></a>e.i<span class="ot">=</span>y<span class="sc">-</span>Y.cap</span>
<span id="cb114-2"><a href="1.2-regressió-lineal-múltiple.html#cb114-2" aria-hidden="true" tabindex="-1"></a><span class="fu">t</span>(e.i)</span></code></pre></div>
<pre><code>##            [,1]       [,2]     [,3]       [,4]   [,5]       [,6]       [,7]
## [1,] 0.05698925 -0.6579705 1.603446 -0.2006111 0.5914 -0.1154555 -0.3529814
##           [,8]    [,9]
## [1,] -3.150977 2.22616</code></pre>
<p>Amb R, la regressió lineal múltiple per mínims quadrats també es fa amb la funció <code>lm</code>, aplicada a la fórmula que agrupa la variable resposta en funció de <strong>la suma</strong> de les variables de control. Al nostre exemple <a href="1.2-regressió-lineal-múltiple.html#exm:mult">1.13</a> seria</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="1.2-regressió-lineal-múltiple.html#cb116-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Coefficients:
## (Intercept)           x1           x2           x3           x4  
##      9.9464       0.6626       0.0483       1.0618      -0.2543</code></pre>
<p>Obtenim la mateixa funció lineal de regressió que abans:
<span class="math display">\[
\widehat{Y}=9.9464+0.6626X_1+0.0483X_2+1.0618X_3-0.2543X_4
\]</span></p>
<p>A més, com al cas simple, aquesta funció també calcula els errors <span class="math inline">\(e_i\)</span>:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="1.2-regressió-lineal-múltiple.html#cb118-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>residuals</span></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
##  0.05698925 -0.65797046  1.60344630 -0.20061111  0.59140004 -0.11545548 
##           7           8           9 
## -0.35298144 -3.15097741  2.22616031</code></pre>
<p>La regressió lineal múltiple per mínims quadrats satisfà les mateixes propietats que la simple:</p>
<ul>
<li><p>La recta de regressió passa pel vector mitjà <span class="math inline">\((\overline{x}_1,\overline{x}_2,\ldots,\overline{x}_k,\overline{y})\)</span>:
<span class="math display">\[
\overline{y}=b_0+b_1 \overline{x}_1+\cdots+b_k \overline{x}_k
\]</span></p></li>
<li><p>La mitjana dels valors estimats és igual a la mitjana dels observats:
<span class="math display">\[
\overline{\widehat{y}}=\overline{y}
\]</span></p></li>
<li><p>Els errors <span class="math inline">\((e_i)_{i=1,\ldots,n}\)</span> tenen mitjana 0 i variància
<span class="math display">\[
s_e^2=\frac{SS_E}{n}
\]</span></p></li>
<li><p>Si les variables aleatòries error <span class="math inline">\(E_{\underline{x}_i}\)</span> tenen totes mitjana 0 i la mateixa variància <span class="math inline">\(\sigma^2_E\)</span> i són, dues a dues, incorrelades, aleshores els <span class="math inline">\(b_i\)</span> són els estimadors lineals no esbiaixats òptims dels <span class="math inline">\(\beta_i\)</span> i
<span class="math display">\[
S^2=\frac{SS_E}{n-k-1}
\]</span>
és un estimador no esbiaixat de <span class="math inline">\(\sigma_E^2\)</span></p></li>
<li><p>Si <strong>a més</strong> les variables aleatòries error <span class="math inline">\(E_{\underline{x}_i}\)</span> són totes normals, aleshores
els <span class="math inline">\(b_i\)</span> són els estimadors màxim versemblants dels <span class="math inline">\(\beta_i\)</span></p></li>
<li><p>Se satisfà la mateixa <strong>identitat de les sumes de quadrats</strong>
<span class="math display">\[
SS_{Tot}=SS_R+SS_E
\]</span>
o, equivalentment,
<span class="math display">\[
s^2_y=s^2_{\widehat{y}}+s^2_e
\]</span>
on:</p>
<ul>
<li><p><span class="math inline">\(SS_{Tot}=\sum_{i=1}^n (y_i-\overline{y})^2\)</span> és la <strong>Suma de Quadrats Total</strong>, que mesura la variabilitat dels valors observats <span class="math inline">\(y_i\)</span> de la <span class="math inline">\(Y\)</span> i satisfà que <span class="math inline">\(SS_{Tot}=n\cdot s_y^2\)</span>, on <span class="math inline">\(s_y^2\)</span> és la variància de les <span class="math inline">\(y_i\)</span>.</p></li>
<li><p><span class="math inline">\(SS_R=\sum_{i=1}^n(\widehat{y}_i-\overline{y})^2\)</span> és la <strong>Suma de Quadrats de la Regressió</strong>, que mesura la variabilitat de les estimacions <span class="math inline">\(\widehat{y}_i\)</span> de la <span class="math inline">\(Y\)</span> sobre la nostra mostra i satisfà que <span class="math inline">\(SS_R=n\cdot s_{\widehat{y}}^2\)</span>, on <span class="math inline">\(s_{\widehat{y}}^2\)</span> és la variància de les <span class="math inline">\(\widehat{y}_i\)</span>.</p></li>
<li><p><span class="math inline">\(SS_E=\sum_{i=1}^n (y_i-\widehat{y}_i)^2\)</span> és la de <strong>Suma de Quadrats dels Errors</strong> que ja hem definit i satisfà que <span class="math inline">\(SS_E=n\cdot s_{e}^2\)</span>, on <span class="math inline">\(s_{e}^2\)</span> és la variància dels errors <span class="math inline">\(e_i\)</span>.</p></li>
</ul></li>
</ul>
<p>Com al cas simple, quan R calcula una funció de regressió lineal per mínims quadrats també calcula un munt de coses més:</p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="1.2-regressió-lineal-múltiple.html#cb120-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>
<p>D’aquesta caterva d’informació, ja sabem algunes coses que són: els coeficients de la funció (la columna <code>Estimate</code> de la matriu <code>Coefficients</code>), els residus (<code>Residuals</code>), l’arrel quadrada de la <span class="math inline">\(S^2\)</span> (<code>Residual standard error</code>). I algunes tenen el mateix significat que a la regressió lineal simple: la resta d’entrades de la matriu <code>Coefficients</code> o el <code>Multiple R-squared</code>. Els tres darrers valors que dóna R (<code>Adjusted R-squared</code>, <code>F-statistic</code> i <code>p-value</code>) tendran només interès a la regressió múltiple, com veurem.</p>
</div>
<div id="coeficient-de-determinació-múltiple" class="section level3" number="1.2.2">
<h3><span class="header-section-number">1.2.2</span> Coeficient de determinació múltiple</h3>
<p>Com al cas simple, consideram que la funció lineal de regressió
<span class="math display">\[
\widehat{Y}=b_0+b_1X_1+\cdots+b_kX_k
\]</span>
és una bona aproximació de <span class="math inline">\(Y\)</span> com a funció lineal de <span class="math inline">\(X_1,\ldots,X_k\)</span> sobre la nostra mostra quan la variabilitat dels valors estimats <span class="math inline">\(\widehat{y}_i\)</span> representa una fracció molt gran de la variabilitat dels valors observats <span class="math inline">\(y_i\)</span>. Això es quantifica amb el <strong>coeficient de determinació</strong> (<strong>múltiple</strong>) <span class="math inline">\(R^2\)</span>, que es defineix exactament igual que al cas simple i es calcula igual:
<span class="math display">\[
R^2=\frac{SS_R}{SS_{Tot}}=\frac{s^2_{\widehat{y}}}{s^2_y}
\]</span></p>

<div class="example">
<p><span id="exm:unnamed-chunk-91" class="example"><strong>Exemple 1.15  </strong></span>Al nostre Exemple <a href="1.2-regressió-lineal-múltiple.html#exm:mult">1.13</a>, el coeficient de determinació és</p>
</div>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="1.2-regressió-lineal-múltiple.html#cb122-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.9679545</code></pre>

<div class="rmdnote">
Suposam que encara recordau que, en el cas simple, el coeficient de determinació era el quadrat del coeficient de correlació de Pearson. En el cas múltiple, el que es fa és <strong>definir</strong> el
<strong>coeficient de correlació múltiple</strong> d’un vector <span class="math inline">\(y\)</span> respecte d’uns vectors <span class="math inline">\(x_1,\ldots, x_k\)</span> (tots ells mesures de diferents variables aleatòries sobre els mateixos individus) com
<span class="math display">\[
R= \sqrt{R^2}
\]</span>
i així també se té que <strong>el coeficient de determinació múltiple és el quadrat del coeficient de correlació múltiple</strong>.
</div>
</div>
<div id="coeficient-de-determinació-ajustat" class="section level3" number="1.2.3">
<h3><span class="header-section-number">1.2.3</span> Coeficient de determinació ajustat</h3>
<p><span class="math inline">\(R^2\)</span> tendeix a créixer si afegim variables independents al model, fins i tot quan les variables que afegim són irrellevants. Vegem-ne un exemple.</p>

<div class="example">
<p><span id="exm:multfake" class="example"><strong>Exemple 1.16  </strong></span>Imaginau que a la taula de dades de l’Exemple <a href="1.2-regressió-lineal-múltiple.html#exm:mult">1.13</a> li afegim una nova variable <span class="math inline">\(X_5\)</span> que mesura la distància (en km) a vol d’ocell de la llibreria on la mare sol comprar els llibres a la consulta del pediatra que ha mesurat l’alçada <span class="math inline">\(Y\)</span>. Ens inventarem els valors d’aquesta nova variable, generant-los amb distribució normal <span class="math inline">\(N(2000,1000)\)</span></p>
</div>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="1.2-regressió-lineal-múltiple.html#cb124-1" aria-hidden="true" tabindex="-1"></a>x5<span class="ot">=</span><span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">9</span>,<span class="dv">2000</span>,<span class="dv">1000</span>))</span>
<span id="cb124-2"><a href="1.2-regressió-lineal-múltiple.html#cb124-2" aria-hidden="true" tabindex="-1"></a>x5</span></code></pre></div>
<pre><code>## [1] 2085 2226 2433 2558 2060 1885  979 1703 2168</code></pre>
<p>Per tant, les dades ara són</p>
<pre><code>## [1] 2085 2226 2433 2558 2060 1885  979 1703 2168</code></pre>
<table>
<thead>
<tr>
<th style="text-align:right;">
Alçada (en cm)
</th>
<th style="text-align:right;">
Edat (en dies)
</th>
<th style="text-align:right;">
Alçada en néixer (en cm)
</th>
<th style="text-align:right;">
Pes en néixer (en kg)
</th>
<th style="text-align:right;">
% d’increment de pes
</th>
<th style="text-align:right;">
Distància llibreria-pediatra (en m)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
57.5
</td>
<td style="text-align:right;">
78
</td>
<td style="text-align:right;">
8.2
</td>
<td style="text-align:right;">
2.75
</td>
<td style="text-align:right;">
29.5
</td>
<td style="text-align:right;">
2085
</td>
</tr>
<tr>
<td style="text-align:right;">
52.8
</td>
<td style="text-align:right;">
69
</td>
<td style="text-align:right;">
45.5
</td>
<td style="text-align:right;">
2.15
</td>
<td style="text-align:right;">
26.3
</td>
<td style="text-align:right;">
2226
</td>
</tr>
<tr>
<td style="text-align:right;">
61.3
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
46.3
</td>
<td style="text-align:right;">
4.41
</td>
<td style="text-align:right;">
32.2
</td>
<td style="text-align:right;">
2433
</td>
</tr>
<tr>
<td style="text-align:right;">
67.0
</td>
<td style="text-align:right;">
88
</td>
<td style="text-align:right;">
49.0
</td>
<td style="text-align:right;">
5.52
</td>
<td style="text-align:right;">
36.5
</td>
<td style="text-align:right;">
2558
</td>
</tr>
<tr>
<td style="text-align:right;">
53.5
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:right;">
43.0
</td>
<td style="text-align:right;">
3.21
</td>
<td style="text-align:right;">
27.2
</td>
<td style="text-align:right;">
2060
</td>
</tr>
<tr>
<td style="text-align:right;">
62.7
</td>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
4.32
</td>
<td style="text-align:right;">
27.7
</td>
<td style="text-align:right;">
1885
</td>
</tr>
<tr>
<td style="text-align:right;">
56.2
</td>
<td style="text-align:right;">
74
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
2.31
</td>
<td style="text-align:right;">
28.3
</td>
<td style="text-align:right;">
979
</td>
</tr>
<tr>
<td style="text-align:right;">
68.5
</td>
<td style="text-align:right;">
94
</td>
<td style="text-align:right;">
53.0
</td>
<td style="text-align:right;">
4.30
</td>
<td style="text-align:right;">
30.3
</td>
<td style="text-align:right;">
1703
</td>
</tr>
<tr>
<td style="text-align:right;">
79.2
</td>
<td style="text-align:right;">
102
</td>
<td style="text-align:right;">
58.0
</td>
<td style="text-align:right;">
3.71
</td>
<td style="text-align:right;">
28.7
</td>
<td style="text-align:right;">
2168
</td>
</tr>
</tbody>
</table>
<p>Ara calculem el <span class="math inline">\(R^2\)</span> de la regressió de <span class="math inline">\(Y\)</span> en funció de <span class="math inline">\(X_1,\ldots,X_5\)</span> i comparem-lo amb l’obtingut amb <span class="math inline">\(X_1,\ldots,X_4\)</span>:</p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="1.2-regressió-lineal-múltiple.html#cb127-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4<span class="sc">+</span>x5))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.974853</code></pre>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="1.2-regressió-lineal-múltiple.html#cb129-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.9679545</code></pre>
<p>Com veieu, la regressió tenint en compte la distància de ca’l llibreter a ca’l pediatra té coeficient de determinació més gran que sense tenir-lo en compte. Però imaginam que teniu clar que aquesta variable és irrellevant a l’hora d’explicar l’alçada d’un nin.</p>
<p>Per tenir en compte aquest fet i compensar el nombre de variables emprat en la regressió, en lloc d’emprar el coeficient de determinació
<span class="math display">\[
R^2=\frac{SS_R}{SS_{Tot}}=\frac{SS_{Tot}-SS_E}{SS_{Tot}}
\]</span>
s’empra el <strong>coeficient de determinació ajustat</strong>
<span class="math display">\[
R^2_{adj}=\frac{MS_{Total}-MS_E}{MS_{Total}}
\]</span>
on
<span class="math display">\[
MS_{Total}=\frac{SS_{Tot}}{n-1}\text{ i } MS_E=\frac{SS_E}{n-k-1}.
\]</span></p>

<div class="rmdcaution">
Fixau-vos que <span class="math inline">\(MS_{Total}\)</span> no és res més que <span class="math inline">\(\widetilde{s}_y^2\)</span> i que fa una estona a <span class="math inline">\(MS_E\)</span> li hem dit <span class="math inline">\(S^2\)</span>: l’estimador no esbiaixat de la variància comuna de les variables error <span class="math inline">\(E_{\underline{x}_i}\)</span> quan totes aquestes variables tenen la mateixa variància.
</div>
<p>Operant, queda
<span class="math display">\[
R^2_{adj}=\frac{(n-1)R^2-k}{n-k-1}
\]</span></p>
<p>A la sortida del <code>summary(lm( ))</code> és el <code>Adjusted R-squared</code> de la penúltima línia:</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="1.2-regressió-lineal-múltiple.html#cb131-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>
<p>Es considera que una regressió lineal múltiple per mínims quadrats és “millor” que una altra quan té el coeficient de determinació ajustat més gran. Això només té interès per a regressions amb diferents nombres de variables independents i la mateixa mostra d’individus, perquè fixats <span class="math inline">\(n\)</span> i <span class="math inline">\(k\)</span>, la funció
<span class="math display">\[
R^2\mapsto R^2_{adj}=\frac{(n-1)R^2-k}{n-k-1}
\]</span>
és creixent, i per tant si fixam els valors de <span class="math inline">\(n\)</span> i de <span class="math inline">\(k\)</span>, comparar <span class="math inline">\(R^2\)</span> és equivalent a comparar <span class="math inline">\(R^2_{adj}\)</span>.</p>
<p>Amb R es calcula amb el sufix <code>$adj.r.squared</code>. Calculem els del nostre exemple, amb i sense la variable “falsa”, a veure què passa:</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="1.2-regressió-lineal-múltiple.html#cb133-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.9359091</code></pre>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="1.2-regressió-lineal-múltiple.html#cb135-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4<span class="sc">+</span>x5))<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.9329412</code></pre>
<p>Com veieu, sense tenir en compte la distància de la llibreria de capçalera de la mare a la consulta del pediatra obtenim un valor més gran de <span class="math inline">\(R^2_{adj}\)</span> i per tant consideram que és una regressió millor que tenint-la en compte. Ja que hi som, comprovem l’equació
<span class="math display">\[
R^2_{adj}=\frac{(n-1)R^2-k}{n-k-1}
\]</span>
per al model amb 4 variables independents:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="1.2-regressió-lineal-múltiple.html#cb137-1" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">9</span></span>
<span id="cb137-2"><a href="1.2-regressió-lineal-múltiple.html#cb137-2" aria-hidden="true" tabindex="-1"></a>k<span class="ot">=</span><span class="dv">4</span></span>
<span id="cb137-3"><a href="1.2-regressió-lineal-múltiple.html#cb137-3" aria-hidden="true" tabindex="-1"></a>R2<span class="ot">=</span><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>r.squared</span>
<span id="cb137-4"><a href="1.2-regressió-lineal-múltiple.html#cb137-4" aria-hidden="true" tabindex="-1"></a>((n<span class="dv">-1</span>)<span class="sc">*</span>R2<span class="sc">-</span>k)<span class="sc">/</span>(n<span class="sc">-</span>k<span class="dv">-1</span>)</span></code></pre></div>
<pre><code>## [1] 0.9359091</code></pre>
</div>
<div id="intervals-de-confiança-per-als-coeficients" class="section level3" number="1.2.4">
<h3><span class="header-section-number">1.2.4</span> Intervals de confiança per als coeficients</h3>
<p>Suposarem en el que queda de tema que les variables aleatòries error <span class="math inline">\(E_i=E_{\underline{x}_{i}}\)</span> són totes normals de mitjana 0 i la mateixa variància, <span class="math inline">\(\sigma_E^2\)</span>, i dues a dues incorrelades. Recordem que, sota aquestes hipòtesis:</p>
<ul>
<li><p>Els estimadors <span class="math inline">\(b_0,\ldots, b_k\)</span> de <span class="math inline">\(\beta_0,\ldots,\beta_k\)</span> són màxim versemblants i a més no esbiaixats òptims.</p></li>
<li><p>Un estimador no esbiaixat de <span class="math inline">\(\sigma_E^2\)</span> és
<span class="math display">\[
S^2(=MS_E)=\frac{SS_E}{n-k-1}
\]</span></p></li>
</ul>
<p>A l’Exemple <a href="1.2-regressió-lineal-múltiple.html#exm:mult">1.13</a>, aquesta estimació de la variància comuna dels errors <span class="math inline">\(\sigma_E^2\)</span> és</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="1.2-regressió-lineal-múltiple.html#cb139-1" aria-hidden="true" tabindex="-1"></a>S2<span class="ot">=</span><span class="fu">sum</span>(e.i<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(n<span class="sc">-</span>k<span class="dv">-1</span>)</span>
<span id="cb139-2"><a href="1.2-regressió-lineal-múltiple.html#cb139-2" aria-hidden="true" tabindex="-1"></a>S2</span></code></pre></div>
<pre><code>## [1] 4.604896</code></pre>
<p>Com al cas simple, la sortida de <code>summary(lm( ))</code> dóna el valor de la <span class="math inline">\(S\)</span> (és a dir, l’arrel quadrada de <span class="math inline">\(S^2\)</span>, que per tant estima la desviació típica comuna de les variables error) com a <code>Residual standard error</code>
i s’obté amb el sufix <code>$sigma</code>:</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="1.2-regressió-lineal-múltiple.html#cb141-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="1.2-regressió-lineal-múltiple.html#cb143-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>sigma</span></code></pre></div>
<pre><code>## [1] 2.145902</code></pre>
<div class="sourceCode" id="cb145"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb145-1"><a href="1.2-regressió-lineal-múltiple.html#cb145-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>sigma)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 4.604896</code></pre>
<p>Resulta que sota les condicions imposades al principi d’aquesta secció sobre les variables <span class="math inline">\(E_i\)</span>, podem calcular intervals de confiança per als coeficients <span class="math inline">\(\beta_i\)</span> de la funció de regressió lineal.</p>

<div class="rmdmercifulgod">
Donam les fórmules per pura completesa, no esperam que calculeu aquests intervals a mà mai.
</div>
<ul>
<li>L’error típic de cada estimador <span class="math inline">\(b_i\)</span> és l’arrel quadrada de la <span class="math inline">\(i\)</span>-èsima entrada de la diagonal de la matriu <span class="math inline">\(\sigma_E^2\cdot (\mathbf{X}^t \mathbf{X})^{-1}\)</span>, començant a comptar amb <span class="math inline">\(i=0\)</span>:
<span class="math display">\[
\sqrt{(\sigma_E^2\cdot (X^t X)^{-1})_{ii}}
\]</span>
L’estimam sobre una mostra substituint-hi <span class="math inline">\(\sigma_E^2\)</span> per <span class="math inline">\(S^2\)</span>. R ens dóna aquestes estimacions a la columna <code>Std. Error</code> de la matriu <code>Coefficients</code> a la sortida de <code>summary(lm( ))</code>:</li>
</ul>
<div class="sourceCode" id="cb147"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb147-1"><a href="1.2-regressió-lineal-múltiple.html#cb147-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>
<div class="sourceCode" id="cb149"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb149-1"><a href="1.2-regressió-lineal-múltiple.html#cb149-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>coefficients[,<span class="dv">2</span>]</span></code></pre></div>
<pre><code>## (Intercept)          x1          x2          x3          x4 
## 11.06339306  0.07996131  0.06346116  1.30586646  0.42423970</code></pre>
<ul>
<li><p>Cada fracció
<span class="math display">\[
T_i=\frac{b_i-\beta_i}{\sqrt{(S^2\cdot (X^t X)^{-1})_{ii}}}
\]</span>
segueix un llei t de Student amb <span class="math inline">\(n-k-1\)</span> graus de llibertat</p></li>
<li><p>Un interval de confiança de nivell de confiança <span class="math inline">\(q\)</span> per a <span class="math inline">\(\beta_i\)</span> és
<span class="math display">\[
b_i\pm t_{n-k-1,(1+q)/2}\cdot \sqrt{(S^2\cdot (X^t X)^{-1})_{ii}}
\]</span></p></li>
</ul>
<p>Amb R, aquests intervals de confiança s’obtenen com al cas simple, aplicant la funció <code>confint</code> al resultat de la <code>lm</code>:</p>
<div class="sourceCode" id="cb151"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb151-1"><a href="1.2-regressió-lineal-múltiple.html#cb151-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>##                   2.5 %     97.5 %
## (Intercept) -20.7704551 40.6633520
## x1            0.4406012  0.8846176
## x2           -0.1278951  0.2244978
## x3           -2.5638682  4.6874649
## x4           -1.4322167  0.9235397</code></pre>
<p>Els podem calcular “a mà” a partir de les estimacions dels errors típics que dóna <code>summary(lm( ))</code> amb la fórmula genèrica “estimació <span class="math inline">\(\pm\)</span> quantil per error típic”. Per exemple, l’IC 95% per a <span class="math inline">\(\beta_1\)</span> seria</p>
<div class="sourceCode" id="cb153"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb153-1"><a href="1.2-regressió-lineal-múltiple.html#cb153-1" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">9</span></span>
<span id="cb153-2"><a href="1.2-regressió-lineal-múltiple.html#cb153-2" aria-hidden="true" tabindex="-1"></a>k<span class="ot">=</span><span class="dv">4</span></span>
<span id="cb153-3"><a href="1.2-regressió-lineal-múltiple.html#cb153-3" aria-hidden="true" tabindex="-1"></a>b1<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4)<span class="sc">$</span>coefficients[<span class="dv">2</span>]</span>
<span id="cb153-4"><a href="1.2-regressió-lineal-múltiple.html#cb153-4" aria-hidden="true" tabindex="-1"></a>Error.Tip.b1<span class="ot">=</span><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">2</span>]</span>
<span id="cb153-5"><a href="1.2-regressió-lineal-múltiple.html#cb153-5" aria-hidden="true" tabindex="-1"></a>IC<span class="ot">=</span>b1<span class="sc">+</span><span class="fu">qt</span>(<span class="fl">0.975</span>,n<span class="sc">-</span>k<span class="dv">-1</span>)<span class="sc">*</span>Error.Tip.b1<span class="sc">*</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb153-6"><a href="1.2-regressió-lineal-múltiple.html#cb153-6" aria-hidden="true" tabindex="-1"></a>IC</span></code></pre></div>
<pre><code>## [1] 0.4406012 0.8846176</code></pre>
</div>
<div id="intervals-de-confiança-per-a-les-estimacions-de-la-variable-resposta" class="section level3" number="1.2.5">
<h3><span class="header-section-number">1.2.5</span> Intervals de confiança per a les estimacions de la variable resposta</h3>
<p>Si les variables error <span class="math inline">\(E_i\)</span> satisfan les condicions imposades al principi de la secció anterior, també podem calcular intervals de confiança per al valor estimat de la <span class="math inline">\(Y\)</span> sobre els individus amb valors de <span class="math inline">\((X_1,\ldots,X_k)\)</span> donats. Com al cas simple, tenim dos intervals:</p>
<ul>
<li><p>L’interval per al <strong>valor esperat</strong> <span class="math inline">\(\mu_{Y|x_{10},\ldots,x_{k0}}\)</span> de <span class="math inline">\(Y\)</span> sobre els individus en els que <span class="math inline">\((X_1,\ldots,X_k)\)</span> val <span class="math inline">\((x_{10},\ldots,x_{k0})\)</span>, és a dir, per al valor mitjà de la <span class="math inline">\(Y\)</span> sobre tots els individus de la població en els que <span class="math inline">\((X_1,\ldots,X_k)\)</span> valgui <span class="math inline">\((x_{10},\ldots,x_{k0})\)</span></p></li>
<li><p>L’interval per al <strong>valor predit</strong> <span class="math inline">\(y_0\)</span> de <span class="math inline">\(Y\)</span> sobre un individu concret en el que <span class="math inline">\((X_1,\ldots,X_k)\)</span> valgui <span class="math inline">\((x_{10},\ldots,x_{k0})\)</span>.</p></li>
</ul>
<p>La discussió sobre les diferències entre una i altra estimació i per què el segon interval és més ample que el primer són les mateixes que al cas simple, no la repetirem aquí. I, contràriament, al cas simple, us estalviarem les fórmules. Simplement heu de saber que aquests intervals també es calculen amb R amb la funció <code>predict.lm</code> aplicada a:</p>
<ul>
<li>un data frame amb els valors de les variables independents sobre l’individu, o els individus, per al que volem estimar la <span class="math inline">\(Y\)</span></li>
<li>el resultat de la <code>lm</code></li>
<li>el paràmetre <code>interval</code> igualat al tipus d’interval que volem: <code>"prediction"</code> si és per al valor en un individu, <code>"confidence"</code> si és per al valor esperat</li>
</ul>

<div class="example">
<p><span id="exm:unnamed-chunk-108" class="example"><strong>Exemple 1.17  </strong></span>Suposem que volem estimar amb un 95% de confiança l’alçada d’un infant de <span class="math inline">\(X_1=69\)</span> dies que en néixer va fer <span class="math inline">\(X_2=45.5\)</span> cm i va pesar <span class="math inline">\(X_3=2.55\)</span> kg i des de llavors el seu pes ha augmentat un <span class="math inline">\(X_4=26.3\)</span>%.</p>
</div>
<p>Primer definim un data frame que reculli les dades d’aquest infant:</p>
<div class="sourceCode" id="cb155"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb155-1"><a href="1.2-regressió-lineal-múltiple.html#cb155-1" aria-hidden="true" tabindex="-1"></a>infant<span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">x1=</span><span class="dv">69</span>,<span class="at">x2=</span><span class="fl">45.5</span>,<span class="at">x3=</span><span class="fl">2.55</span>,<span class="at">x4=</span><span class="fl">26.3</span>)</span></code></pre></div>
<p>Aleshores:</p>
<ul>
<li>Un interval de confiança del 95% per al valor estimat de l’alçada d’aquest infant és</li>
</ul>
<div class="sourceCode" id="cb156"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb156-1"><a href="1.2-regressió-lineal-múltiple.html#cb156-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.lm</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4), infant, <span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 53.88269 46.99166 60.77372</code></pre>
<ul>
<li>Un interval de confiança del 95% per al valor estimat de l’alçada mitjana de tots els infants amb els mateixos valors de <span class="math inline">\(X_1,\ldots,X_4\)</span> que aquest infant és</li>
</ul>
<div class="sourceCode" id="cb158"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb158-1"><a href="1.2-regressió-lineal-múltiple.html#cb158-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.lm</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4), infant, <span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>)</span></code></pre></div>
<pre><code>##        fit     lwr      upr
## 1 53.88269 50.4202 57.34518</code></pre>
<p>Obtenim que:</p>
<ul>
<li><p>Estimam que l’alçada d’aquest infant és 53.9 cm.</p></li>
<li><p>Estimam amb un 95% de confiança que l’alçada d’aquest infant està entre els 47 i els 60.8 cm.</p></li>
<li><p>Estimam amb un 95% de confiança que l’alçada mitjana dels infants amb les mateixes característiques que aquest està entre els 50.4 i els 57.3 cm. És a dir que, de mitjana, els infants com aquest fan entre 50.4 i els 57.3 cm.</p></li>
</ul>
</div>
<div id="lanova-de-la-regressió-lineal-múltiple" class="section level3" number="1.2.6">
<h3><span class="header-section-number">1.2.6</span> L’ANOVA de la regressió lineal múltiple</h3>
<p>Com en el cas simple, en una regressió lineal múltiple ens interessa realitzar el contrast
<span class="math display">\[
\left\{\begin{array}{l} H_0: \beta_1=\beta_2=\cdots=\beta_k=0 \\
H_1: \text{hi ha qualque }\beta_i\not= 0 \end{array}
\right.
\]</span>
perquè si <span class="math inline">\(\beta_1=\beta_2=\cdots=\beta_k=0\)</span>, el model esdevé
<span class="math display">\[
Y|{x_1,\ldots,x_k}=\beta_0+E_{x_1,\ldots,x_k}
\]</span>
i la <span class="math inline">\(Y\)</span> no depèn de les <span class="math inline">\(X_i\)</span>, de manera que el model lineal no és adequat.</p>
<p>Això es pot fer amb <span class="math inline">\(k\)</span> contrastos
<span class="math display">\[
\left\{\begin{array}{l} H_0: \beta_i=0 \\
H_1: \beta_i\neq 0 \end{array}
\right.
\]</span>
emprant els estadístics <span class="math inline">\(T_i\)</span> que hem definit fa una estona, que segueixen lleis t de Student amb <span class="math inline">\(n-k-1\)</span> graus de llibertat. Els p-valors d’aquests contrastos són els de la columna <code>Pr(&gt;|t|)</code> a la matriu de <code>Coefficients</code> de la sortida de <code>summary(lm( ))</code>. No cal ajustar-los, el nombre <span class="math inline">\(n-k-1\)</span> de graus de llibertat ja té en compte que fem <span class="math inline">\(k+1\)</span> contrastos.</p>
<div class="sourceCode" id="cb160"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb160-1"><a href="1.2-regressió-lineal-múltiple.html#cb160-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>
<p>Només obtenim evidència estadística que <span class="math inline">\(\beta_1\neq 0\)</span>.</p>
<p>Una altra possibilitat és emprar una ANOVA. Fixau-vos que si
<span class="math display">\[
\beta_1=\beta_2=\cdots=\beta_k=0,
\]</span>
aleshores
<span class="math display">\[
\mu_{Y|x_{11},\ldots,x_{k1}}=\cdots=\mu_{Y|x_{1n},\ldots,x_{kn}}=\beta_0
\]</span>
Per tant, si al contrast
<span class="math display">\[
\left\{\begin{array}{l}
H_0:\mu_{Y|x_{11},\ldots,x_{1k}}=\cdots=\mu_{Y|x_{n1},\ldots,x_{nk}}\\
H_1:\text{no és veritat que }\mu_{Y|x_{11},\ldots,x_{1k}}=\cdots=\mu_{Y|x_{n1},\ldots,x_{nk}}
\end{array}
\right.
\]</span>
rebutjam la hipòtesi nul·la, això implicarà que podem rebutjar que <span class="math inline">\(\beta_1=\beta_2=\cdots=\beta_k=0\)</span> i podrem concloure que el model lineal té sentit.</p>
<p>La <strong>taula</strong> d’aquesta ANOVA és
<span class="math display">\[
\begin{array}{llllll}\hline
\text{Font de} &amp; \text{Graus de} &amp; \text{Suma de} &amp; \text{Quadrats} &amp; \text{Estadístic} &amp; \text{p-valor}\\
\text{variació} &amp; \text{llibertat} &amp;  \text{quadrats} &amp; \text{mitjans}      &amp;\text{de contrast}  &amp; \\\hline
\text{Regressió} &amp; k &amp; SS_R  &amp; MS_R &amp; F &amp;  p\\
\text{Error} &amp; n-k-1 &amp; SS_E  &amp; MS_E &amp; &amp;\\
\hline 
\end{array}
\]</span>
on
<span class="math display">\[
MS_R=\frac{SS_R}{k},\quad MS_E=\frac{SS_E}{n-k-1}
\]</span>
Com a les altres ANOVA, l’estadístic de contrast <span class="math inline">\(F\)</span> és
<span class="math display">\[
F=\frac{MS_R}{MS_E}
\]</span>
Si la hipòtesi nul·la és vertadera (i els errors satisfan les condicions establertes al començament de la secció anterior), aquest estadístic de contrast segueix una llei F de Fisher amb <span class="math inline">\(k\)</span> i <span class="math inline">\(n-k-1\)</span> graus de llibertat i té valor proper a 1, de manera que se pren com a p-valor
<span class="math display">\[
\text{p-valor}=P(F_{k,n-k-1}\geqslant F).
\]</span></p>
<p>Calculem la taula ANOVA de l’Exemple <a href="1.2-regressió-lineal-múltiple.html#exm:mult">1.13</a></p>
<div class="sourceCode" id="cb162"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb162-1"><a href="1.2-regressió-lineal-múltiple.html#cb162-1" aria-hidden="true" tabindex="-1"></a>SS.R<span class="ot">=</span><span class="fu">sum</span>((Y.cap<span class="sc">-</span><span class="fu">mean</span>(y))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb162-2"><a href="1.2-regressió-lineal-múltiple.html#cb162-2" aria-hidden="true" tabindex="-1"></a>SS.R</span></code></pre></div>
<pre><code>## [1] 556.376</code></pre>
<div class="sourceCode" id="cb164"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb164-1"><a href="1.2-regressió-lineal-múltiple.html#cb164-1" aria-hidden="true" tabindex="-1"></a>SS.E<span class="ot">=</span><span class="fu">sum</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4)<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb164-2"><a href="1.2-regressió-lineal-múltiple.html#cb164-2" aria-hidden="true" tabindex="-1"></a>SS.E</span></code></pre></div>
<pre><code>## [1] 18.41959</code></pre>
<div class="sourceCode" id="cb166"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb166-1"><a href="1.2-regressió-lineal-múltiple.html#cb166-1" aria-hidden="true" tabindex="-1"></a>MS.R<span class="ot">=</span>SS.R<span class="sc">/</span>k</span>
<span id="cb166-2"><a href="1.2-regressió-lineal-múltiple.html#cb166-2" aria-hidden="true" tabindex="-1"></a>MS.R</span></code></pre></div>
<pre><code>## [1] 139.094</code></pre>
<div class="sourceCode" id="cb168"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb168-1"><a href="1.2-regressió-lineal-múltiple.html#cb168-1" aria-hidden="true" tabindex="-1"></a>MS.E<span class="ot">=</span>SS.E<span class="sc">/</span>(n<span class="sc">-</span>k<span class="dv">-1</span>)</span>
<span id="cb168-2"><a href="1.2-regressió-lineal-múltiple.html#cb168-2" aria-hidden="true" tabindex="-1"></a>MS.E</span></code></pre></div>
<pre><code>## [1] 4.604896</code></pre>
<div class="sourceCode" id="cb170"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb170-1"><a href="1.2-regressió-lineal-múltiple.html#cb170-1" aria-hidden="true" tabindex="-1"></a>F<span class="ot">=</span>MS.R<span class="sc">/</span>MS.E</span>
<span id="cb170-2"><a href="1.2-regressió-lineal-múltiple.html#cb170-2" aria-hidden="true" tabindex="-1"></a>F</span></code></pre></div>
<pre><code>## [1] 30.20567</code></pre>
<div class="sourceCode" id="cb172"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb172-1"><a href="1.2-regressió-lineal-múltiple.html#cb172-1" aria-hidden="true" tabindex="-1"></a>p.val<span class="ot">=</span><span class="dv">1</span><span class="sc">-</span><span class="fu">pf</span>(F,k,n<span class="sc">-</span>k<span class="dv">-1</span>)</span>
<span id="cb172-2"><a href="1.2-regressió-lineal-múltiple.html#cb172-2" aria-hidden="true" tabindex="-1"></a>p.val</span></code></pre></div>
<pre><code>## [1] 0.003014918</code></pre>
<p><span class="math display">\[
\begin{array}{llllll}\hline
\text{Font de} &amp; \text{Graus de} &amp; \text{Suma de} &amp; \text{Quadrats} &amp; \text{Estadístic} &amp; \text{p-valor}\\
\text{variació} &amp; \text{llibertat} &amp;  \text{quadrats} &amp; \text{mitjans}      &amp;\text{de contrast}  &amp; \\\hline
\text{Regressió} &amp; 4 &amp; 556.376  &amp; 139.094 &amp;  30.21 &amp;  0.003\\
\text{Error} &amp; 4 &amp; 18.42  &amp; 4.605 &amp; &amp;\\
\hline 
\end{array}
\]</span></p>
<p>Hem trobat evidència estadística que el model lineal és adequat.</p>

<div class="rmdromans">
Podeu creure que no hi ha cap funció de cap paquet de R que calculi aquesta taula per a la regressió lineal múltiple?
</div>
<p>L’estadístic de contrast i el p-valor d’aquesta ANOVA els podeu trobar a la darrera línia de la sortida <code>summary(lm( ))</code>; són el <code>F-statistic</code> (i a més us diu els graus de llibertat, <code>DF</code>, de la seva distribució) i el <code>p-value</code>:</p>
<div class="sourceCode" id="cb174"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb174-1"><a href="1.2-regressió-lineal-múltiple.html#cb174-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>

<div class="rmdromans">
Podeu creure que no podem extreure el p-valor del <code>summary(lm(y~x1+x2+x3+x4))</code> amb un sufix, sinó que l’hem de calcular? Per sort és fàcil, emprant el contingut de <code>summary(lm( ))$fstatistic</code>, que és un vector de 3 entrades: el valor de l’estadístic <span class="math inline">\(F\)</span> i els seus dos graus de llibertat. Per tant, per calcular el p-valor, podem fer el següent:
</div>
<div class="sourceCode" id="cb176"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb176-1"><a href="1.2-regressió-lineal-múltiple.html#cb176-1" aria-hidden="true" tabindex="-1"></a>FF<span class="ot">=</span><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>fstatistic</span>
<span id="cb176-2"><a href="1.2-regressió-lineal-múltiple.html#cb176-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pf</span>(FF[<span class="dv">1</span>],FF[<span class="dv">2</span>],FF[<span class="dv">3</span>])</span></code></pre></div>
<pre><code>##       value 
## 0.003014918</code></pre>

<div class="rmdnote">
Una altra opció és emprar la funció <code>glance</code> del paquet <strong>broom</strong>, que aplicada a un objecte dóna un <em>dataframe</em> (de fet, una adaptació del concepte de <em>dataframe</em> a l’anàlisi de dades massives, un <strong>tibble</strong>) amb els seus continguts més importants; vaja, que us permet “donar una ullada” a l’objecte.
</div>
<div class="sourceCode" id="cb178"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb178-1"><a href="1.2-regressió-lineal-múltiple.html#cb178-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb178-2"><a href="1.2-regressió-lineal-múltiple.html#cb178-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.968         0.936  2.15      30.2 0.00301     4  -16.0  44.0  45.2
## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb180"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb180-1"><a href="1.2-regressió-lineal-múltiple.html#cb180-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>p.value</span></code></pre></div>
<pre><code>##       value 
## 0.003014918</code></pre>
</div>
</div>
<p style="text-align: center;">
<a href="1.1-regressió-lineal-simple.html"><button class="btn btn-default">Previous</button></a>
<a href="1.3-test-de-la-lliçó-11.html"><button class="btn btn-default">Next</button></a>
</p>
</div>
</div>


</div>

<script>

// add bootstrap table styles to pandoc tables
$(document).ready(function () {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
});

</script>

</body>
</html>
