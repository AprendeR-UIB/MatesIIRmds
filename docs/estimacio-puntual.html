<!DOCTYPE html>
<html >

<head>

  <meta charset="UTF-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <title>Tema 2 Estimació puntual | Matemàtiques II</title>
  <meta name="description" content="Apunts Matemàtiques II bookdown::gitbook.">
  <meta name="generator" content="bookdown  and GitBook 2.6.7">

  <meta property="og:title" content="Tema 2 Estimació puntual | Matemàtiques II" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Apunts Matemàtiques II bookdown::gitbook." />
  <meta name="github-repo" content="cescrossello/MatesII" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Tema 2 Estimació puntual | Matemàtiques II" />
  
  <meta name="twitter:description" content="Apunts Matemàtiques II bookdown::gitbook." />
  



<meta name="date" content="2020-04-15">

  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="apple-mobile-web-app-capable" content="yes">
  <meta name="apple-mobile-web-app-status-bar-style" content="black">
  
  
<link rel="prev" href="repas-de-la-distribucio-normal.html">
<link rel="next" href="intervals-de-confianca.html">
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />









<style type="text/css">
a.sourceLine { display: inline-block; line-height: 1.25; }
a.sourceLine { pointer-events: none; color: inherit; text-decoration: inherit; }
a.sourceLine:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
a.sourceLine { text-indent: -1em; padding-left: 1em; }
}
pre.numberSource a.sourceLine
  { position: relative; left: -4em; }
pre.numberSource a.sourceLine::before
  { content: attr(data-line-number);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; pointer-events: all; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {  }
@media screen {
a.sourceLine::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bioestadística II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentació</a></li>
<li class="part"><span><b>Part II: Estadística inferencial</b></span></li>
<li class="chapter" data-level="1" data-path="repas-de-la-distribucio-normal.html"><a href="repas-de-la-distribucio-normal.html"><i class="fa fa-check"></i><b>1</b> Repàs de la distribució normal</a><ul>
<li class="chapter" data-level="1.1" data-path="repas-de-la-distribucio-normal.html"><a href="repas-de-la-distribucio-normal.html#propietats-de-la-distribucio-normal"><i class="fa fa-check"></i><b>1.1</b> Propietats de la distribució normal</a></li>
<li class="chapter" data-level="1.2" data-path="repas-de-la-distribucio-normal.html"><a href="repas-de-la-distribucio-normal.html#amb-r"><i class="fa fa-check"></i><b>1.2</b> Amb R</a></li>
<li class="chapter" data-level="1.3" data-path="repas-de-la-distribucio-normal.html"><a href="repas-de-la-distribucio-normal.html#combinacions-lineals"><i class="fa fa-check"></i><b>1.3</b> Combinacions lineals</a></li>
<li class="chapter" data-level="1.4" data-path="repas-de-la-distribucio-normal.html"><a href="repas-de-la-distribucio-normal.html#intervals-de-referencia"><i class="fa fa-check"></i><b>1.4</b> Intervals de referència</a></li>
<li class="chapter" data-level="1.5" data-path="repas-de-la-distribucio-normal.html"><a href="repas-de-la-distribucio-normal.html#el-z-score"><i class="fa fa-check"></i><b>1.5</b> El z-score</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html"><i class="fa fa-check"></i><b>2</b> Estimació puntual</a><ul>
<li class="chapter" data-level="2.1" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#definicions-basiques"><i class="fa fa-check"></i><b>2.1</b> Definicions bàsiques</a></li>
<li class="chapter" data-level="2.2" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#mitjana-mostral"><i class="fa fa-check"></i><b>2.2</b> Mitjana mostral</a></li>
<li class="chapter" data-level="2.3" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#proporcio-mostral"><i class="fa fa-check"></i><b>2.3</b> Proporció mostral</a></li>
<li class="chapter" data-level="2.4" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#variancia-mostral"><i class="fa fa-check"></i><b>2.4</b> Variància mostral</a></li>
<li class="chapter" data-level="2.5" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#la-t-de-student"><i class="fa fa-check"></i><b>2.5</b> La t de Student</a></li>
<li class="chapter" data-level="2.6" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#bons-estimadors"><i class="fa fa-check"></i><b>2.6</b> “Bons” estimadors</a><ul>
<li class="chapter" data-level="2.6.1" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#estimadors-no-esbiaixats"><i class="fa fa-check"></i><b>2.6.1</b> Estimadors no esbiaixats</a></li>
<li class="chapter" data-level="2.6.2" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#estimadors-eficients"><i class="fa fa-check"></i><b>2.6.2</b> Estimadors eficients</a></li>
<li class="chapter" data-level="2.6.3" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#estimadors-maxim-versemblants"><i class="fa fa-check"></i><b>2.6.3</b> Estimadors màxim versemblants</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#sec:pobl"><i class="fa fa-check"></i><b>2.7</b> Estimació de poblacions</a><ul>
<li class="chapter" data-level="2.7.1" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#estimacio-de-poblacions-numerades"><i class="fa fa-check"></i><b>2.7.1</b> Estimació de poblacions numerades</a></li>
<li class="chapter" data-level="2.7.2" data-path="estimacio-puntual.html"><a href="estimacio-puntual.html#marca-recaptura"><i class="fa fa-check"></i><b>2.7.2</b> Marca-recaptura</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="3" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html"><i class="fa fa-check"></i><b>3</b> Intervals de confiança</a><ul>
<li class="chapter" data-level="3.1" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#definicions-basiques-1"><i class="fa fa-check"></i><b>3.1</b> Definicions bàsiques</a></li>
<li class="chapter" data-level="3.2" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#exemple-interval-de-confianca-del-95-per-a-la-mitjana-duna-variable-aleatoria-normal"><i class="fa fa-check"></i><b>3.2</b> Exemple: Interval de confiança del 95% per a la mitjana d’una variable aleatòria normal</a></li>
<li class="chapter" data-level="3.3" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#interval-de-confianca-per-a-la-mitjana-basat-en-la-t-de-student"><i class="fa fa-check"></i><b>3.3</b> Interval de confiança per a la mitjana basat en la t de Student</a><ul>
<li class="chapter" data-level="" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#la-formula"><i class="fa fa-check"></i>La fórmula</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#algunes-consideracions"><i class="fa fa-check"></i>Algunes consideracions</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#amb-r-1"><i class="fa fa-check"></i>Amb R</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#calcul-de-la-mida-de-la-mostra-per-fixar-lerror"><i class="fa fa-check"></i>Càlcul de la mida de la mostra per fixar l’error</a></li>
</ul></li>
<li class="chapter" data-level="3.4" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#intervals-de-confianca-per-a-proporcions"><i class="fa fa-check"></i><b>3.4</b> Intervals de confiança per a proporcions</a><ul>
<li class="chapter" data-level="" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#metode-exacte-de-clopper-pearson"><i class="fa fa-check"></i>Mètode “exacte” de Clopper-Pearson</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#metode-de-wilson"><i class="fa fa-check"></i>Mètode de Wilson</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#metode-de-laplace"><i class="fa fa-check"></i>Mètode de Laplace</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#mes-exemples"><i class="fa fa-check"></i>Més exemples</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#calcul-de-la-mida-de-la-mostra-per-a-fixar-lerror"><i class="fa fa-check"></i>Càlcul de la mida de la mostra per a fixar l’error</a></li>
</ul></li>
<li class="chapter" data-level="3.5" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#intervals-de-confianca-per-a-la-variancia-duna-variable-normal"><i class="fa fa-check"></i><b>3.5</b> Intervals de confiança per a la variància d’una variable normal</a></li>
<li class="chapter" data-level="3.6" data-path="intervals-de-confianca.html"><a href="intervals-de-confianca.html#poblacions-finites"><i class="fa fa-check"></i><b>3.6</b> “Poblacions finites”</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="contrastos-dhipotesis-generalitats.html"><a href="contrastos-dhipotesis-generalitats.html"><i class="fa fa-check"></i><b>4</b> Contrastos d’hipòtesis: Generalitats</a><ul>
<li class="chapter" data-level="4.1" data-path="contrastos-dhipotesis-generalitats.html"><a href="contrastos-dhipotesis-generalitats.html#hipotesis-nulla-i-alternativa"><i class="fa fa-check"></i><b>4.1</b> Hipòtesis nul·la i alternativa</a></li>
<li class="chapter" data-level="4.2" data-path="contrastos-dhipotesis-generalitats.html"><a href="contrastos-dhipotesis-generalitats.html#sec:moneda"><i class="fa fa-check"></i><b>4.2</b> Un exemple</a></li>
<li class="chapter" data-level="4.3" data-path="contrastos-dhipotesis-generalitats.html"><a href="contrastos-dhipotesis-generalitats.html#sec:pval"><i class="fa fa-check"></i><b>4.3</b> El p-valor</a></li>
<li class="chapter" data-level="4.4" data-path="contrastos-dhipotesis-generalitats.html"><a href="contrastos-dhipotesis-generalitats.html#tipus-derrors"><i class="fa fa-check"></i><b>4.4</b> Tipus d’errors</a></li>
<li class="chapter" data-level="4.5" data-path="contrastos-dhipotesis-generalitats.html"><a href="contrastos-dhipotesis-generalitats.html#sec:exttest"><i class="fa fa-check"></i><b>4.5</b> Exemple: El test t</a></li>
<li class="chapter" data-level="4.6" data-path="contrastos-dhipotesis-generalitats.html"><a href="contrastos-dhipotesis-generalitats.html#recapitulacio"><i class="fa fa-check"></i><b>4.6</b> Recapitulació</a><ul>
<li class="chapter" data-level="" data-path="contrastos-dhipotesis-generalitats.html"><a href="contrastos-dhipotesis-generalitats.html#interval-de-confianca-dun-contrast"><i class="fa fa-check"></i>Interval de confiança d’un contrast</a></li>
<li class="chapter" data-level="" data-path="contrastos-dhipotesis-generalitats.html"><a href="contrastos-dhipotesis-generalitats.html#la-potencia"><i class="fa fa-check"></i>La potència</a></li>
<li class="chapter" data-level="" data-path="contrastos-dhipotesis-generalitats.html"><a href="contrastos-dhipotesis-generalitats.html#el-risc-de-positiu-fals-opcional"><i class="fa fa-check"></i>El risc de positiu fals (Opcional)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="5" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html"><i class="fa fa-check"></i><b>5</b> Contrastos d’hipòtesis d’un i dos paràmetres</a><ul>
<li class="chapter" data-level="5.1" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#contrastos-de-mitjanes"><i class="fa fa-check"></i><b>5.1</b> Contrastos de mitjanes</a><ul>
<li class="chapter" data-level="5.1.1" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#test-t-per-a-una-mitjana"><i class="fa fa-check"></i><b>5.1.1</b> Test t per a una mitjana</a></li>
<li class="chapter" data-level="5.1.2" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#test-t-per-a-dues-mitjanes"><i class="fa fa-check"></i><b>5.1.2</b> Test t per a dues mitjanes</a></li>
<li class="chapter" data-level="5.1.3" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#tests-t-amb-r"><i class="fa fa-check"></i><b>5.1.3</b> Tests t amb R</a></li>
<li class="chapter" data-level="5.1.4" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#exemples"><i class="fa fa-check"></i><b>5.1.4</b> Exemples</a></li>
<li class="chapter" data-level="5.1.5" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#tests-no-parametrics"><i class="fa fa-check"></i><b>5.1.5</b> Tests no paramètrics</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#sec:contrvar"><i class="fa fa-check"></i><b>5.2</b> Contrastos de variàncies</a><ul>
<li class="chapter" data-level="5.2.1" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#test-chi2-duna-variancia"><i class="fa fa-check"></i><b>5.2.1</b> Test <span class="math inline">\(\chi^2\)</span> d’una variància</a></li>
<li class="chapter" data-level="5.2.2" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#test-f-per-a-dues-variancies"><i class="fa fa-check"></i><b>5.2.2</b> Test F per a dues variàncies</a></li>
<li class="chapter" data-level="5.2.3" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#tests-no-parametrics-1"><i class="fa fa-check"></i><b>5.2.3</b> Tests no paramètrics</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#contrastos-per-a-proporcions"><i class="fa fa-check"></i><b>5.3</b> Contrastos per a proporcions</a><ul>
<li class="chapter" data-level="5.3.1" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#contrastos-per-a-una-proporcio"><i class="fa fa-check"></i><b>5.3.1</b> Contrastos per a una proporció</a></li>
<li class="chapter" data-level="5.3.2" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#contrastos-per-a-2-proporcions-emprant-mostres-independents"><i class="fa fa-check"></i><b>5.3.2</b> Contrastos per a 2 proporcions emprant mostres independents</a></li>
<li class="chapter" data-level="5.3.3" data-path="contrastos-dhipotesis-dun-i-dos-parametres.html"><a href="contrastos-dhipotesis-dun-i-dos-parametres.html#contrastos-per-a-2-proporcions-emprant-mostres-aparellades"><i class="fa fa-check"></i><b>5.3.3</b> Contrastos per a 2 proporcions emprant mostres aparellades</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html"><i class="fa fa-check"></i><b>6</b> Contrastos de bondat d’ajust</a><ul>
<li class="chapter" data-level="6.1" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#bondat-dajust"><i class="fa fa-check"></i><b>6.1</b> Bondat d’ajust</a></li>
<li class="chapter" data-level="6.2" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#test-chi2-de-pearson"><i class="fa fa-check"></i><b>6.2</b> Test <span class="math inline">\(\chi^2\)</span> de Pearson</a><ul>
<li class="chapter" data-level="6.2.1" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#el-test-basic"><i class="fa fa-check"></i><b>6.2.1</b> El test bàsic</a></li>
<li class="chapter" data-level="6.2.2" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#metode-de-montecarlo"><i class="fa fa-check"></i><b>6.2.2</b> Mètode de Montecarlo</a></li>
<li class="chapter" data-level="6.2.3" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#test-chi2-amb-parametres-poblacionals-desconeguts"><i class="fa fa-check"></i><b>6.2.3</b> Test <span class="math inline">\(\chi^2\)</span> amb paràmetres poblacionals desconeguts</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#test-de-kolmogorov-smirnov"><i class="fa fa-check"></i><b>6.3</b> Test de Kolmogorov-Smirnov</a></li>
<li class="chapter" data-level="6.4" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#test-de-kolmogorov-smirnov-lilliefors"><i class="fa fa-check"></i><b>6.4</b> Test de Kolmogorov-Smirnov-Lilliefors</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="contrastos-dindependencia-i-homogeneitat.html"><a href="contrastos-dindependencia-i-homogeneitat.html"><i class="fa fa-check"></i><b>7</b> Contrastos d’independència i homogeneïtat</a><ul>
<li class="chapter" data-level="7.1" data-path="contrastos-dindependencia-i-homogeneitat.html"><a href="contrastos-dindependencia-i-homogeneitat.html#test-chi2-dindependencia"><i class="fa fa-check"></i><b>7.1</b> Test <span class="math inline">\(\chi^2\)</span> d’independència</a></li>
<li class="chapter" data-level="7.2" data-path="contrastos-dindependencia-i-homogeneitat.html"><a href="contrastos-dindependencia-i-homogeneitat.html#test-chi2-dhomogeneitat"><i class="fa fa-check"></i><b>7.2</b> Test <span class="math inline">\(\chi^2\)</span> d’homogeneïtat</a></li>
<li class="chapter" data-level="7.3" data-path="contrastos-dindependencia-i-homogeneitat.html"><a href="contrastos-dindependencia-i-homogeneitat.html#test-chi2-de-tendencia-opcional"><i class="fa fa-check"></i><b>7.3</b> Test <span class="math inline">\(\chi^2\)</span> de tendència (Opcional)</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="introduccio-a-lestadistica-multidimensional.html"><a href="introduccio-a-lestadistica-multidimensional.html"><i class="fa fa-check"></i><b>8</b> Introducció a l’estadística multidimensional</a><ul>
<li class="chapter" data-level="8.1" data-path="introduccio-a-lestadistica-multidimensional.html"><a href="introduccio-a-lestadistica-multidimensional.html#poblacions-vectors-aleatoris"><i class="fa fa-check"></i><b>8.1</b> Poblacions: vectors aleatoris</a><ul>
<li class="chapter" data-level="8.1.1" data-path="introduccio-a-lestadistica-multidimensional.html"><a href="introduccio-a-lestadistica-multidimensional.html#covariancia"><i class="fa fa-check"></i><b>8.1.1</b> Covariància</a></li>
<li class="chapter" data-level="8.1.2" data-path="introduccio-a-lestadistica-multidimensional.html"><a href="introduccio-a-lestadistica-multidimensional.html#correlacio"><i class="fa fa-check"></i><b>8.1.2</b> Correlació</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="introduccio-a-lestadistica-multidimensional.html"><a href="introduccio-a-lestadistica-multidimensional.html#estadistica-descriptiva-mostres"><i class="fa fa-check"></i><b>8.2</b> Estadística descriptiva: Mostres</a><ul>
<li class="chapter" data-level="8.2.1" data-path="introduccio-a-lestadistica-multidimensional.html"><a href="introduccio-a-lestadistica-multidimensional.html#covariancies"><i class="fa fa-check"></i><b>8.2.1</b> Covariàncies</a></li>
<li class="chapter" data-level="8.2.2" data-path="introduccio-a-lestadistica-multidimensional.html"><a href="introduccio-a-lestadistica-multidimensional.html#correlacio-de-pearson"><i class="fa fa-check"></i><b>8.2.2</b> Correlació de Pearson</a></li>
<li class="chapter" data-level="8.2.3" data-path="introduccio-a-lestadistica-multidimensional.html"><a href="introduccio-a-lestadistica-multidimensional.html#correlacio-de-spearman"><i class="fa fa-check"></i><b>8.2.3</b> Correlació de Spearman</a></li>
<li class="chapter" data-level="8.2.4" data-path="introduccio-a-lestadistica-multidimensional.html"><a href="introduccio-a-lestadistica-multidimensional.html#contrastos-de-correlacio"><i class="fa fa-check"></i><b>8.2.4</b> Contrastos de correlació</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="anova.html"><a href="anova.html"><i class="fa fa-check"></i><b>9</b> ANOVA</a><ul>
<li class="chapter" data-level="9.1" data-path="anova.html"><a href="anova.html#nocions-basiques"><i class="fa fa-check"></i><b>9.1</b> Nocions bàsiques</a></li>
<li class="chapter" data-level="9.2" data-path="anova.html"><a href="anova.html#anova-d1-via"><i class="fa fa-check"></i><b>9.2</b> ANOVA d’1 via</a><ul>
<li class="chapter" data-level="9.2.1" data-path="anova.html"><a href="anova.html#contrast-basic"><i class="fa fa-check"></i><b>9.2.1</b> Contrast bàsic</a></li>
<li class="chapter" data-level="9.2.2" data-path="anova.html"><a href="anova.html#amb-r-2"><i class="fa fa-check"></i><b>9.2.2</b> Amb R</a></li>
<li class="chapter" data-level="9.2.3" data-path="anova.html"><a href="anova.html#comparacions-posteriors-per-parelles"><i class="fa fa-check"></i><b>9.2.3</b> Comparacions posteriors per parelles</a></li>
<li class="chapter" data-level="9.2.4" data-path="anova.html"><a href="anova.html#verificacio-de-les-condicions"><i class="fa fa-check"></i><b>9.2.4</b> Verificació de les condicions</a></li>
<li class="chapter" data-level="9.2.5" data-path="anova.html"><a href="anova.html#test-no-parametric"><i class="fa fa-check"></i><b>9.2.5</b> Test no paramètric</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="anova.html"><a href="anova.html#anova-de-blocs"><i class="fa fa-check"></i><b>9.3</b> ANOVA de blocs</a><ul>
<li class="chapter" data-level="9.3.1" data-path="anova.html"><a href="anova.html#contrast-basic-1"><i class="fa fa-check"></i><b>9.3.1</b> Contrast bàsic</a></li>
<li class="chapter" data-level="9.3.2" data-path="anova.html"><a href="anova.html#amb-r-3"><i class="fa fa-check"></i><b>9.3.2</b> Amb R</a></li>
<li class="chapter" data-level="9.3.3" data-path="anova.html"><a href="anova.html#comparacions-posteriors-per-parelles-1"><i class="fa fa-check"></i><b>9.3.3</b> Comparacions posteriors per parelles</a></li>
<li class="chapter" data-level="9.3.4" data-path="anova.html"><a href="anova.html#contrast-no-parametric"><i class="fa fa-check"></i><b>9.3.4</b> Contrast no paramètric</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="anova.html"><a href="anova.html#anova-de-2-vies"><i class="fa fa-check"></i><b>9.4</b> ANOVA de 2 vies</a><ul>
<li class="chapter" data-level="9.4.1" data-path="anova.html"><a href="anova.html#contrast-basic-2"><i class="fa fa-check"></i><b>9.4.1</b> Contrast bàsic</a></li>
<li class="chapter" data-level="9.4.2" data-path="anova.html"><a href="anova.html#amb-r-4"><i class="fa fa-check"></i><b>9.4.2</b> Amb R</a></li>
</ul></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Matemàtiques II</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="estimacio-puntual" class="section level1">
<h1><span class="header-section-number">Tema 2</span> Estimació puntual</h1>
<p>L’objectiu principal de la <strong>inferència estadística</strong> és intentar obtenir informació sobre tota una població a partir de només una mostra, com quan volem saber si un brou és fat o salat tastant-ne només una culleradeta. El primer tipus d’informació que ens sol interessar és el valor concret d’alguna característica numèrica (una proporció, una mitjana…) d’una població, per exemple per poder escriure un titular com el següent:</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-49"></span>
<img src="Bioestadistica-II_files/figure-html/miopia.png" alt="https://www.efesalud.com/miopia-estudio-universitarios" width="70%" />
<p class="caption">
Figura 2.1: <a href="https://www.efesalud.com/miopia-estudio-universitarios" class="uri">https://www.efesalud.com/miopia-estudio-universitarios</a>
</p>
</div>
<p>Aquest 60% no s’ha obtingut fent passar a tots els universitaris espanyols un test de miopia, ni tan sols demanant-los a tots si són miops o no, sinó que simplement s’ha pres una mostra d’universitaris, s’hi ha observat un 60% de miops i s’ha extrapolat aquesta proporció a tot el col·lectiu d’universitaris espanyols.</p>
<p>El procés d’intentar endevinar el valor d’un paràmetre d’una població a partir d’una mostra se’n diu <strong>estimació puntual</strong>, i és el que tractarem en aquest tema. Al tema següent ens centrarem en intentar endevinar el valor d’un paràmetre amb un cert marge d’error i de seguretat.</p>
<div id="definicions-basiques" class="section level2">
<h2><span class="header-section-number">2.1</span> Definicions bàsiques</h2>
<p>Una <strong>població</strong> és un conjunt d’individus o objectes sobre el que volem obtenir informació.</p>
<p>Una <strong>mostra de mida</strong> <span class="math inline">\(n\)</span> d’una població és simplement un conjunt de <span class="math inline">\(n\)</span> individus (possiblement repetits) de la població.</p>

<div class="rmdcaution">
Una <strong>població</strong> inclou <em>tots</em> els membres d’un grup específic d’individus sobre els que volem saber qualque cosa, mentre que una <strong>mostra</strong> està formada per <em>alguns</em> membres de la població, els que mesuram al nostre estudi.
</div>

<p>Una <strong>mostra aleatòria simple</strong> de mida <span class="math inline">\(n\)</span> d’una població s’obté repetint <span class="math inline">\(n\)</span> vegades, cada una de manera independent de les altres, el procés d’escollir equiprobablement un individu de la població; els individus triats es poden repetir. D’aquesta manera, totes les mostres possibles de <span class="math inline">\(n\)</span> individus (possiblement repetits: en diem <strong>multiconjunts</strong>) tenen la mateixa probabilitat d’obtenir-se.</p>
<p>Un <strong>estimador</strong> (<strong>puntual</strong>) o <strong>estadístic</strong> és una funció que aplicada a una mostra d’una població dóna un valor que ens permet <strong>estimar</strong> alguna cosa que vulguem saber de tota la població.</p>
<div class="figure" style="text-align: center"><span id="fig:unnamed-chunk-51"></span>
<img src="Bioestadistica-II_files/figure-html/poblaciomostra.png" alt="Població *versus* mostra" width="60%" />
<p class="caption">
Figura 2.2: Població <em>versus</em> mostra
</p>
</div>

<div class="example">
<p><span id="exm:uib1" class="example"><strong>Exemple 2.1  </strong></span>Si escollim 30 estudiants de la UIB a l’atzar (mitjançant una sorteig a partir d’un llistat de tots els estudiants de la UIB), un rere l’altre i permetent que es repeteixin, i mesuram les seves alçades, obtenim una <em>mostra aleatòria simple</em> de mida 30 d’alçades de la <em>població</em> formada pels estudiants de la UIB. Si llavors calculam la mitjana aritmètica d’aquestes alçades amb l’objectiu d’estimar la mitjana de les alçades de tots els estudiants de la UIB, aquesta mitjana és el valor sobre aquesta mostra de l’<em>estimador</em> que anomenarem “mitjana mostral”.</p>
</div>


<div class="rmdnote">
<p>Per què prenem una mostra, en lloc d’estudiar directament la població? Doncs perquè sovint és impossible accedir a tota la població:</p>
<ul>
<li><p>La població pot ser massa gran: per exemple, si volem calcular l’alçada mitjana dels europeus que avui tenen 18 anys, és pràcticament impossible midar-los tots.</p></li>
<li><p>La població pot ser <em>virtual</em> en el sentit que pot contenir membres que en aquest moment ni existeixin: per exemple, si volem saber qualque cosa sobre els diabètics, això hauria d’incloure els passats, que ja són morts, els presents, que n’hi haurà molts que ni saben que ho són, i els futurs, que encara no ho són o per ventura no hagin ni nascut.</p></li>
<li><p>Simplement, pot ser difícil accedir a tota la població: per exemple, els estudiants de la UIB són relativament pocs, uns 12000, però seria molt difícil aconseguir midar-los tots.</p></li>
<li><p>I tanmateix, per provar si el brou ha quedat fat, en provau una cullerada (una mostra), no us bebeu tota l’olla (la població), no? Si basta una mostra per als nostres propòsits, no cal esforçar-se en accedir a tota la població.</p></li>
</ul>
</div>

<p>Formalment:</p>
<ul>
<li><p>Una <strong>població</strong> és un conjunt on està definida una variable aleatòria (<strong>poblacional</strong>) <span class="math inline">\(X\)</span>.</p></li>
<li><p>Una <strong>mostra aleatòria simple</strong> de mida <span class="math inline">\(n\)</span> de la variable aleatòria <span class="math inline">\(X\)</span> és un vector <span class="math inline">\((X_1,\ldots,X_n)\)</span> format per <span class="math inline">\(n\)</span> còpies <em>independents</em> de <span class="math inline">\(X\)</span>.</p></li>
<li><p>Una <strong>realització</strong> de la mostra aleatòria simple <span class="math inline">\((X_1,\ldots,X_n)\)</span> és un vector <span class="math inline">\((x_1,\ldots,x_n)\)</span> de valors presos per aquestes variables aleatòries.</p></li>
<li><p>Un <strong>estimador</strong> és una variable aleatòria <span class="math inline">\(f(X_1,\ldots,X_n)\)</span> obtinguda aplicant una funció <span class="math inline">\(f\)</span> a una mostra aleatòria simple <span class="math inline">\(X_1,\ldots,X_n\)</span>.</p>
<p>Aquest estimador s’aplica a les realitzacions de la mostra i dóna nombres reals. Com que és una variable aleatòria, té distribució (en diem la <strong>distribució mostral</strong> de l’estimador), esperança, desviació típica (en diem l’<strong>error estàndard</strong>, o <strong>típic</strong>, de l’estimador), etc.</p></li>
</ul>

<div class="example">
<p><span id="exm:unnamed-chunk-53" class="example"><strong>Exemple 2.2  </strong></span>Podem formalitzar l’Exemple <a href="estimacio-puntual.html#exm:uib1">2.1</a> de la manera següent:</p>
</div>

<ul>
<li><p><em>Població</em>: El conjunt dels estudiants de la UIB</p></li>
<li><p><em>Variable aleatòria poblacional</em> <span class="math inline">\(X\)</span>: Prenem un estudiant de la UIB i midam la seva alçada</p></li>
<li><p><em>Mostra aleatòria simple de mida 30</em>: Un vector <span class="math inline">\((X_1,\ldots,X_{30})\)</span> format per 30 còpies independents de <span class="math inline">\(X\)</span></p></li>
<li><p>Una <em>realització</em> d’aquesta mostra aleatòria simple: Un vector <span class="math inline">\((x_1,\ldots,x_{30})\)</span> obtingut repetint 30 vegades, de manera independent cada una de les altres, el procés d’escollir un estudiant de la UIB i midar-li l’alçada</p></li>
<li><p><em>Estimador</em>: La mitjana aritmètica que farem servir sobre aquesta mostra és
<span class="math display">\[
\overline{X}=\frac{X_1+\cdots+X_{30}}{30}
\]</span>
Això és una variable aleatòria. Sobre la realització concreta obtinguda pren el valor
<span class="math display">\[
\overline{x}=\frac{x_1+\cdots+x_{30}}{30}
\]</span></p></li>
</ul>

<div class="rmdnote">
<p>A partir d’ara, quan no hi hagi necessitat de filar prim, cometrem l’abús de llenguatge de dir <em>mostra aleatòria simple</em> tant al vector de variables aleatòries <span class="math inline">\((X_1,\ldots,X_n)\)</span> com a una realització <span class="math inline">\((x_1,\ldots,x_n)\in \mathbb{R}^n\)</span>; i hi ometrem els parèntesis.</p>
</div>

<p>A la vida real, les mostres aleatòries se solen prendre prohibint les repeticions (<strong>sense reposició</strong>). No són mostres aleatòries simples, però la situació encara pot tenir salvació.</p>
<p>Si la mida <span class="math inline">\(N\)</span> de la població és MOLT més gran que la mida <span class="math inline">\(n\)</span> de la mostra, els resultats per a mostres aleatòries simples valen (aproximadament) per a mostres aleatòries sense reposició, perquè les variables aleatòries que formen la mostra sense reposició són gairebé idèntiques i independents i les repeticions són improbables.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-55" class="example"><strong>Exemple 2.3  </strong></span>Imaginau que teniu una població de 10<sup>6</sup> individus i en voleu extreure una mostra aleatòria de 10. Si la treieu escollint els individus un a un a l’atzar sense repeticions, la probabilitat a cada moment d’escollir un individu concret dels que quedin és gairebé la mateixa que si permetéssiu repeticions. Per exemple, quan ja portau 9 individus escollits, la probabilitat de triar un individu concret dels que queden és 1/999991=10<sup>-6</sup>+9·10<sup>-12</sup>, mentre que si permeteu que surti qualcun dels ja escollits és 1/10<sup>6</sup>=10<sup>-6</sup>.</p>
<p>Observau també que si prenem una mostra aleatòria de 10 individus sense reposició de la nostra població de 10<sup>6</sup> individus, gairebé és com si hagués estat presa permetent repeticions, perquè per molt que les permetéssim, seria molt improbable que s’hi donàs alguna repetició. Recordau que si una població té <span class="math inline">\(N\)</span> individus, la probabilitat que una mostra aleatòria simple de mida <span class="math inline">\(n\)</span> tingui tots els seus membres diferents és
<span class="math display">\[
\frac{N(N-1)\cdots (N-n+1)}{N^n}.
\]</span>
Per tant, la probabilitat que una mostra aleatòria simple de mida 10 d’una població de mida 10<sup>6</sup> tengui algun membre repetit és
<span class="math display">\[
1-\frac{10^6(10^6-1)\cdots (10^6-9)}{(10^6)^{10}}=0.000045.
\]</span>
Molt petita. Per tant, si ens trobam al davant d’una mostra aleatòria de 10 individus d’aquesta població escollida sense permetre repeticions, ens podem creure perfectament que l’hem obtinguda permetent repeticions i que simplement no n’hi ha hagut cap per pur atzar.</p>
</div>

<p>Ara bé, quan <span class="math inline">\(n\)</span> és relativament gran per comparació amb <span class="math inline">\(N\)</span>, ja és mal de creure que una mostra sense repeticions hagi estat escollida permetent-les. Per exemple, si prenem una mostra aleatòria simple (permetent repeticions) de 10 individus d’una població de 100 individus, la probabilitat que escollim qualque individu més d’una vegada és
<span class="math display">\[
1-\frac{100\cdot 99\cdots 91}{100^{10}}=0.37.
\]</span>
Més d’una de cada 3 mostres aleatòries simples de 10 individus d’una població de 100 individus contenen qualque repetició, per tant no podem acceptar amb els ulls clucs que si no tenim cap repetició, les hàgim permeses.</p>

<div class="example">
<p><span id="exm:uib2" class="example"><strong>Exemple 2.4  </strong></span>La UIB té uns 12000 estudiants. El gràfic següent mostra la probabilitat que si prenem una mostra aleatòria simple de <span class="math inline">\(n\)</span> estudiants d’una població de 12000 individus, com ara la UIB, siguin tots diferents, en funció de <span class="math inline">\(n\)</span>:</p>
</div>

<pre class="sourceCode r"><code class="sourceCode r">f=<span class="cf">function</span>(N,i){<span class="kw">prod</span>((N<span class="op">:</span>(N<span class="op">-</span>i<span class="op">+</span><span class="dv">1</span>))<span class="op">/</span>N)}
prob=<span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">200</span>,f,<span class="dt">N=</span><span class="dv">1200</span>)
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">200</span>, prob, <span class="dt">type=</span><span class="st">&quot;l&quot;</span>, <span class="dt">lwd=</span><span class="dv">2</span>, <span class="dt">xlab=</span><span class="st">&quot;n&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;probabilitat&quot;</span>,
     <span class="dt">xaxp=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">200</span>,<span class="dv">20</span>),<span class="dt">yaxp=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">10</span>))</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-56-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>El gràfic següent mostra la mida màxima <span class="math inline">\(n\)</span> d’una mostra aleatòria simple extreta d’una població de mida <span class="math inline">\(N\)</span> per que la probabilitat de repeticions sigui menor que 0.05, en funció de <span class="math inline">\(N\)</span>:</p>
<pre class="sourceCode r"><code class="sourceCode r">h=<span class="cf">function</span>(n){<span class="kw">max</span>(<span class="kw">which</span>(<span class="kw">sapply</span>(<span class="dv">1</span><span class="op">:</span>(n<span class="op">/</span><span class="dv">50</span>),f,<span class="dt">N=</span>n)<span class="op">&gt;</span><span class="fl">0.95</span>))}
fites=<span class="kw">sapply</span>(<span class="dv">500</span><span class="op">+</span><span class="dv">100</span><span class="op">*</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">150</span>),h)
<span class="kw">plot</span>(<span class="dv">500</span><span class="op">+</span><span class="dv">100</span><span class="op">*</span>(<span class="dv">0</span><span class="op">:</span><span class="dv">150</span>), fites, <span class="dt">pch=</span><span class="dv">20</span>, <span class="dt">xlab=</span><span class="st">&quot;N&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;n&quot;</span>,
     <span class="dt">xaxp=</span><span class="kw">c</span>(<span class="dv">500</span>,<span class="dv">15500</span>,<span class="dv">30</span>))</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-57-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>En resum:</p>

<div class="rmdimportant">
<p>Si prenem una mostra sense reposició de mida <span class="math inline">\(n\)</span> d’una població de mida <span class="math inline">\(N\)</span> MOLT més gran que n, la tractarem com si fos una mostra aleatòria simple (i direm sense manies que és una mostra aleatòria simple).</p>
Per fixar una fita, en aquest curs entendrem que <span class="math inline">\(N\)</span> és prou MOLT més gran que <span class="math inline">\(n\)</span> com per poder aplicar aquesta regla quan <span class="math inline">\(N\)</span> és com a mínim unes 1000 vegades més gran que <span class="math inline">\(n\)</span>.
</div>

<p>A la pràctica, en realitat gairebé mai no disposarem d’una mostra <em>aleatòria</em>.
Fixau-vos, per exemple, que per poder obtenir una mostra aleatòria, necessitam una llista de tota la població, per poder sortejar qui cau i qui no cau dins la mostra, i aquesta llista normalment no existeix. Una llista de tots els conills de Mallorca, o de tots els arbres afectats per la <em>Xyllella fastidiosa</em>? Complicat. Així que ens haurem de conformar amb una <strong>mostra oportunista</strong> (o <strong>de conveniència</strong>: la que poguem obtenir).</p>
<p>Heu de tenir clar que, en principi, <em>els resultats que donarem NO són vàlids per a mostres no aleatòries</em>, però si no tenim res millor… El que es fa aleshores és explicar amb detall com s’ha obtingut la mostra i descriure amb detall les seves característiques, a fi que altres investigadors puguin decidir si els individus “són típics” i podrien passar per una mostra aleatòria, i si poden extrapolar les estimacions al seu context.</p>
<p>Per exemple, si per saber l’opinió dels estudiants de Biologia espanyols sobre un tema, ho deman als meus estudiants, serà una mostra clarament oportunista i caldrà llavors esbrinar si podria passar per una mostra aleatòria simple a efectes de l’estudi que vull portar a terme.</p>

<div class="rmdcaution">
<p>Els estimadors tenen sempre sentit per a mostres en general, però gairebé tots els teoremes que estableixen les seves propietats són vertaders només sota determinades restriccions (mostra aleatòria simple, condicions extra sobre <span class="math inline">\(X\)</span>, …), per la qual cosa les seves conseqüències tan sols són segures sota aquestes restriccions.</p>
</div>


<div class="rmdnote">
A la <a href="https://aprender-uib.github.io/AprendeR2/chap-muestreo.html#sec:muestreo">Secció 2.1 de la 2a part dels apunts de R</a> hi explicam alguns altres tipus de mostreig aleatori: estratificat, per conglomerats, sistemàtic… Donau-li una ullada.
</div>

</div>
<div id="mitjana-mostral" class="section level2">
<h2><span class="header-section-number">2.2</span> Mitjana mostral</h2>
<p>La <strong>mitjana mostral</strong> <span class="math inline">\(\overline{X}\)</span> d’una mostra aleatòria de mida <span class="math inline">\(n\)</span> d’una variable aleatòria <span class="math inline">\(X\)</span> és simplement la seva mitjana artimètica.</p>
<p>Formalment, la <strong>mitjana mostral</strong> és una variable aleatòria obtinguda prenent <span class="math inline">\(n\)</span> còpies <span class="math inline">\(X_1,\ldots,X_n\)</span> de la variable aleatòria <span class="math inline">\(X\)</span> i calculant
<span class="math display">\[
\overline{X}=\frac{X_1+\cdots+X_n}{n}
\]</span></p>
<p>Com a conseqüència del Teorema <a href="repas-de-la-distribucio-normal.html#thm:combvar">1.1</a>, tenim el següent:</p>

<div class="theorem">
<p><span id="thm:mitjmostgral" class="theorem"><strong>Teorema 2.1  </strong></span>Siguin <span class="math inline">\(X\)</span> una variable aleatòria d’esperança <span class="math inline">\(\mu_X\)</span> i desviació típica <span class="math inline">\(\sigma_X\)</span>,
<span class="math inline">\(X_1,\ldots,X_n\)</span> una mostra aleatòria de <span class="math inline">\(X\)</span> i <span class="math inline">\(\overline{X}\)</span> la seva mitjana mostral. Aleshores</p>
<ol style="list-style-type: lower-alpha">
<li><p>El valor esperat de <span class="math inline">\(\overline{X}\)</span> és <span class="math inline">\(\mu_{\overline{X}}=\mu_X\)</span>.</p></li>
<li>Si la mostra aleatòria és simple, l’<strong>error estàndard</strong> o <strong>típic</strong> de <span class="math inline">\(\overline{X}\)</span> (la <em>desviació típica</em> de <span class="math inline">\(\overline{X}\)</span>) és <span class="math inline">\(\sigma_{\overline{X}}={\sigma_X}/{\sqrt{n}}\)</span>.</li>
</ol>
</div>


<div class="rmdcorbes">
<p>En efecte, com que
<span class="math display">\[
\overline{X}=\frac{1}{n}X_1+\cdots +\frac{1}{n}X_n
\]</span>
i les variables <span class="math inline">\(X_1,\ldots,X_n\)</span> són còpies de <span class="math inline">\(X\)</span>, i per tant tenen totes esperança <span class="math inline">\(\mu_X\)</span> i variància <span class="math inline">\(\sigma^2_X\)</span>, aplicant el Teorema <a href="repas-de-la-distribucio-normal.html#thm:combvar">1.1</a> tenim que
<span class="math display">\[
\mu_{\overline{X}}=\overbrace{\frac{1}{n}\mu_X+\cdots +\frac{1}{n}\mu_X}^n=\mu_X
\]</span>
i, si <span class="math inline">\(X_1,\ldots,X_n\)</span> són independents,
<span class="math display">\[
\sigma_{\overline{X}}=\sqrt{\overbrace{\frac{1}{n^2}\sigma^2_X+\cdots+ \frac{1}{n^2}\sigma^2_X}^n}=\sqrt{\frac{n}{n^2}\sigma^2_X}=\frac{\sigma_X}{\sqrt{n}}
\]</span></p>
</div>

<p>Per tant:</p>
<ul>
<li><p><span class="math inline">\(\overline{X}\)</span> és un estimador puntual de <span class="math inline">\(\mu_X\)</span>.</p></li>
<li><p><span class="math inline">\(\mu_{\overline{X}}=\mu_X\)</span> (<em>esperam que la mitjana mostral doni <span class="math inline">\(\mu_X\)</span></em>) significa que si repetíssim moltes vegades el procés de prendre una mostra aleatòria simple de mida <span class="math inline">\(n\)</span> i calcular-ne la mitjana mostral, molt probablement el valor mitjà d’aquestes mitjanes s’acostaria molt a <span class="math inline">\(\mu_X\)</span>.</p></li>
<li><p><span class="math inline">\(\sigma_{\overline{X}}= \sigma_X/\sqrt{n}\)</span> indica que la dispersió dels resultats de <span class="math inline">\(\overline{X}\)</span> creix amb la variabilitat de <span class="math inline">\(X\)</span> i decreix amb la mida <span class="math inline">\(n\)</span> de la mostra, tendint a 0 quan <span class="math inline">\(n\to\infty\)</span>.</p></li>
</ul>

<div class="example">
<p><span id="exm:experimentTCL1" class="example"><strong>Exemple 2.5  </strong></span>El fitxer <strong>tests.txt</strong> que trobareu a l’url <a href="https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt" class="uri">https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt</a> conté les notes (sobre 100) de tests dels estudiants de Matemàtiques I de fa uns cursos. El guardam en un vector anomenat <code>tests</code>:</p>
</div>

<pre class="sourceCode r"><code class="sourceCode r">tests=<span class="kw">scan</span>(<span class="st">&quot;https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt&quot;</span>)
<span class="kw">head</span>(tests)</code></pre>
<pre><code>## [1] 70 44 90 64 76 68</code></pre>
<p>la mida de la població és</p>
<pre class="sourceCode r"><code class="sourceCode r">N=<span class="kw">length</span>(tests)
N</code></pre>
<pre><code>## [1] 185</code></pre>
<p>La seva mitjana, que és la mitjana poblacional, és</p>
<pre class="sourceCode r"><code class="sourceCode r">mu=<span class="kw">mean</span>(tests)
mu</code></pre>
<pre><code>## [1] 55.43243</code></pre>
<p>Si en prenem una mostra aleatòria simple, per exemple de mida <span class="math inline">\(n=40\)</span>, la seva mitjana mostral no té per què coincidir amb la mitjana poblacional:</p>
<pre class="sourceCode r"><code class="sourceCode r">n=<span class="dv">40</span>
MAS=<span class="kw">sample</span>(tests,n,<span class="dt">replace=</span><span class="ot">TRUE</span>) <span class="co"># Una mostra aelatòria simple</span>
x.barra=<span class="kw">mean</span>(MAS) <span class="co"># La mitjana mostral</span>
x.barra</code></pre>
<pre><code>## [1] 53.5</code></pre>
<p>Però si prenem <em>moltes</em> mostres aleatòries simples, la mitjana de les seves mitjanes és molt probable que sí que s’acosti a la mitjana poblacional. Vegem si tenim sort:</p>
<pre class="sourceCode r"><code class="sourceCode r">mitjanes=<span class="kw">replicate</span>(<span class="dv">10</span><span class="op">^</span><span class="dv">5</span>,<span class="kw">mean</span>(<span class="kw">sample</span>(tests,n,<span class="dt">replace=</span><span class="ot">TRUE</span>)))
<span class="kw">mean</span>(mitjanes)</code></pre>
<pre><code>## [1] 55.4187</code></pre>
<p>Vegem ara que la desviació típica d’aquesta mostra de mitjanes s’acosta a l’error típic de la mitjana mostral, no a la desviació típica de la població:</p>
<ul>
<li>La desviació típica poblacional:</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">sigma=<span class="kw">sd</span>(tests)
sigma</code></pre>
<pre><code>## [1] 21.44044</code></pre>
<ul>
<li>La desviació típica de la mostra de mitjanes:</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">sd</span>(mitjanes)</code></pre>
<pre><code>## [1] 3.384683</code></pre>
<ul>
<li>L’error típic de la mitjana mostral:</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r">sigma<span class="op">/</span><span class="kw">sqrt</span>(n)</code></pre>
<pre><code>## [1] 3.390031</code></pre>
<p>Recordau del Teorema <a href="repas-de-la-distribucio-normal.html#thm:combnormal">1.2</a> que una combinació lineal de variables aleatòries normals independents torna a ser normal. Com que la mitjana mostral d’una mostra aleatòria simple és una combinació lineal de variables aleatòries independents, obtenim el resultat següent:</p>

<div class="theorem">
<p><span id="thm:TCLnorm" class="theorem"><strong>Teorema 2.2  </strong></span>Siguin <span class="math inline">\(X\)</span> una variable aleatòria normal <span class="math inline">\(N(\mu_X,\sigma_X)\)</span> i <span class="math inline">\(X_1,\ldots, X_n\)</span> una mostra aleatòria simple de <span class="math inline">\(X\)</span>. Aleshores, la seva mitjana mostral <span class="math inline">\(\overline{X}\)</span> és normal, i en concret
<span class="math display">\[
\overline{X}\sim N\Big(\mu_X,\frac{\sigma_X}{\sqrt{n}}\Big).
\]</span></p>
</div>

<p>El teorema següent diu que la conclusió del teorema anterior és aproximadament vertadera si la mida <span class="math inline">\(n\)</span> de les mostres aleatòries simples és gran:</p>

<div class="theorem">
<p><span id="thm:TCL" class="theorem"><strong>Teorema 2.3  (Teorema Central del Límit)  </strong></span>Siguin <span class="math inline">\(X\)</span> una variable aleatòria <em>qualsevol</em> d’esperança <span class="math inline">\(\mu_X\)</span> i desviació típica <span class="math inline">\(\sigma_X\)</span> i <span class="math inline">\(X_1,\ldots, X_n\)</span> una mostra aleatòria simple de <span class="math inline">\(X\)</span>. Quan <span class="math inline">\(n\to \infty\)</span>, la distribució de probabilitats de la seva mitjana mostral <span class="math inline">\(\overline{X}\)</span> tendeix a la d’una varianle normal
<span class="math display">\[
N\Big(\mu_X,\frac{\sigma_X}{\sqrt{n}}\Big).
\]</span></p>
</div>


<div class="rmdcaution">
Com us podeu imaginar, quan un resultat l’anomenen <strong>Teorema Central</strong> de qualque cosa és perquè és molt important.
</div>

<p>Normalment aplicarem el Teorema Central del Límit de la manera següent:</p>

<div class="rmdimportant">
<p>Siguin <span class="math inline">\(X\)</span> una variable aleatòria <em>qualsevol</em> d’esperança <span class="math inline">\(\mu_X\)</span> i desviació típica <span class="math inline">\(\sigma_X\)</span> i <span class="math inline">\(X_1,\ldots, X_n\)</span> una mostra aleatòria simple de <span class="math inline">\(X\)</span>. Si la mida <span class="math inline">\(n\)</span> de la mostra és gran, la seva mitjana mostral <span class="math inline">\(\overline{X}\)</span> és aproximadament normal
<span class="math inline">\(N(\mu_X,\sigma_X/\sqrt{n})\)</span>.</p>
<p>En aquest curs, entendrem que <span class="math inline">\(n\)</span> és prou gran com per poder aplicar aquest “resultat” si és més gran o igual que 30, potser menys com més se sembli <span class="math inline">\(X\)</span> a una normal i potser més si la <span class="math inline">\(X\)</span> és molt diferent d’una normal.</p>
</div>


<div class="rmdcaution">
A partir d’ara, sovint cometrem l’abús de llenguatge d’ometre l’adverbi “aproximadament” de l’expressió anterior, i direm simplement que si <span class="math inline">\(n\)</span> és gran, <span class="math inline">\(\overline{X}\)</span> és normal. Però hem de recordar que aquest “és normal” en realitat vol dir “la seva distribució és aproximadament la d’una variable normal”.
</div>


<div class="example">
<span id="exm:unnamed-chunk-74" class="example"><strong>Exemple 2.6  </strong></span>Suposem que tenim una variable aleatòria <span class="math inline">\(X\)</span> de mitjana poblacional <span class="math inline">\(\mu_X=3\)</span> i desviació típica poblacional <span class="math inline">\(\sigma_X=0.2\)</span> i que en prenem mostres aleatòries simples de mida 100. Pel Teorema Central del Límit, la distribució de la mitjana mostral <span class="math inline">\(\overline{X}\)</span> és
<span class="math display">\[
N\Big(3,\frac{0.2}{\sqrt{100}}\Big)=N(3,0.02)
\]</span>
</div>


<div class="example">
<p><span id="exm:experimentTCL2" class="example"><strong>Exemple 2.7  </strong></span>Tornem a la situació de l’Exemple <a href="estimacio-puntual.html#exm:experimentTCL1">2.5</a>. Teníem les notes guardades en un vector anomenat <strong>tests</strong>. Amb l’histograma següent podem veure que aquestes notes no tenen pinta de seguir una distribució normal.</p>
</div>

<pre class="sourceCode r"><code class="sourceCode r">fact.trans=<span class="kw">hist</span>(tests,<span class="dt">plot=</span><span class="ot">FALSE</span>)<span class="op">$</span>counts[<span class="dv">1</span>]<span class="op">/</span><span class="kw">hist</span>(tests,<span class="dt">plot=</span><span class="ot">FALSE</span>)<span class="op">$</span>density[<span class="dv">1</span>]
<span class="kw">hist</span>(tests,<span class="dt">col=</span><span class="st">&quot;light blue&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Notes dels tests&quot;</span>,
     <span class="dt">ylab=</span><span class="st">&quot;Freqüències&quot;</span>,<span class="dt">main=</span><span class="st">&quot;Histograma de notes de tests&quot;</span>)
<span class="kw">curve</span>(fact.trans<span class="op">*</span><span class="kw">dnorm</span>(x,<span class="kw">mean</span>(tests),<span class="kw">sd</span>(tests)),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-75-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>A l’Exemple <a href="estimacio-puntual.html#exm:experimentTCL1">2.5</a> també hem construit un vector anomenat <strong>mitjanes</strong> format per 10<sup>5</sup> mitjanes mostrals de mostres aleatòries simples de notes de mida 40. Pel Teorema Central del Límit, aquestes mitjanes mostrals haurien de seguir aproximadament una distribució normal, malgrat que la “població original” (les notes dels tests) no sigui normal. Vegem-ho amb un histograma, on hem afegit la densitat de la normal <span class="math inline">\(N(\mu_X,\sigma_X/\sqrt{n})\)</span> predita pel Teorema Central del Límit.</p>
<pre class="sourceCode r"><code class="sourceCode r">fact.trans.m=<span class="kw">hist</span>(mitjanes,<span class="dt">plot=</span><span class="ot">FALSE</span>)<span class="op">$</span>counts[<span class="dv">1</span>]<span class="op">/</span><span class="kw">hist</span>(mitjanes,<span class="dt">plot=</span><span class="ot">FALSE</span>)<span class="op">$</span>density[<span class="dv">1</span>]
<span class="kw">hist</span>(mitjanes,<span class="dt">col=</span><span class="st">&quot;light blue&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Mitjanes&quot;</span>,
     <span class="dt">ylab=</span><span class="st">&quot;Freqüències&quot;</span>,<span class="dt">main=</span><span class="st">&quot;Histograma de la mostra de mitjanes&quot;</span>)
<span class="kw">curve</span>(fact.trans.m<span class="op">*</span><span class="kw">dnorm</span>(x,mu,sigma<span class="op">/</span><span class="kw">sqrt</span>(n)),<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-76-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>L’exemple següent és un tipus de pregunta que més endavant ens preocuparà molt.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-77" class="example"><strong>Exemple 2.8  </strong></span>L’alçada d’una espècie de matolls té valor mitjà 115 cm, amb una desviació típica de 25 cm. Si prenem una mostra aleatòria simple de 100 matolls d’aquesta espècie, quina és la probabilitat que la mitjana mostral de les alçades sigui més petita que 110 cm?</p>
</div>

<p>Diguem <span class="math inline">\(X\)</span> a la variable aleatòria definida per les alçades d’aquests matolls. Pel Teorema Central del Límit, la mitjana mostral <span class="math inline">\(\overline{X}\)</span> de mostres aleatòries simples de 100 alçades segueix una distribució <span class="math inline">\(N(115,25/\sqrt{100})=N(115,2.5)\)</span>. Llavors, la probabilitat que ens demanen és
<span class="math display">\[
P(\overline{X}&lt; 110)
\]</span>
que podem calcular amb</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">pnorm</span>(<span class="dv">110</span>,<span class="dv">115</span>,<span class="fl">2.5</span>),<span class="dv">4</span>)</code></pre>
<pre><code>## [1] 0.0228</code></pre>
<p>Un 2.28% de les mostra aleatòries simples de 100 matolls d’aquesta espècie tenen la mitjana de les alçades més petita que 110 cm.</p>
<p>Sigui ara <span class="math inline">\(X_1,\ldots, X_n\)</span> una mostra aleatòria <strong>sense reposició</strong> de mida <span class="math inline">\(n\)</span> d’una variable aleatòria <span class="math inline">\(X\)</span> d’esperança <span class="math inline">\(\mu_X\)</span> i desviació típica <span class="math inline">\(\sigma_X\)</span>. Si <span class="math inline">\(n\)</span> és molt petit en relació a la mida <span class="math inline">\(N\)</span> de la població, ja hem explicat que podem suposar que aquesta mostra aleatòria és simple i per tant tot funciona com fins ara; en particular, en aquest cas entendrem que els tres teoremes anteriors són vertaders.</p>
<p>Si <span class="math inline">\(n\)</span> és gran en relació a <span class="math inline">\(N\)</span>, aleshores el resultat per l’esperança segueix essent vertader (al Teorema <a href="estimacio-puntual.html#thm:mitjmostgral">2.1</a>.a no suposàvem que la mostra fos simple), i per tant encara tenim que
<span class="math display">\[
\mu_{\overline{X}}=\mu_X.
\]</span>
Però en aquest cas cal modificar la fórmula del Teorema <a href="estimacio-puntual.html#thm:mitjmostgral">2.1</a>.b per a la desviació típica, que ara és:
<span class="math display">\[
\sigma_{\overline{X}}=\frac{\sigma_X}{\sqrt{n}}\cdot\sqrt{\frac{N-n}{N-1}}
\]</span>
A més, en aquest cas les conclusions dels Teoremes <a href="estimacio-puntual.html#thm:TCLnorm">2.2</a> i <a href="estimacio-puntual.html#thm:TCL">2.3</a> no són certes, ni tan sols amb aquesta correcció de l’error típic.</p>
<p>Al terme
<span class="math display">\[
\sqrt{\frac{N-n}{N-1}}
\]</span>
que apareix a la fórmula anterior li diuen el <strong>factor de població finita</strong>.</p>

<div class="rmdcorbes">
<p>Si us en recordau, aquest factor de població finita és el factor que passava de la desviació típica d’una distribució binomial a la d’una hipergeomètrica. En efecte:</p>
<ul>
<li><p>Si <span class="math inline">\(X_B\sim B(n,p)\)</span>, <span class="math inline">\(\sigma^2_{X_B}=np(1-p)\)</span> i per tant <span class="math inline">\(\sigma_{X_B}=\sqrt{np(1-p)}\)</span></p></li>
<li><p>Si <span class="math inline">\(X_H\sim H(A,B,n)\)</span>, amb <span class="math inline">\(A+B=N\)</span> i <span class="math inline">\(p=A/N\)</span>,</p></li>
</ul>
<span class="math display">\[
\begin{array}{rl}
\sigma^2_{X_H} &amp; \displaystyle =\dfrac{nAB}{(A+B)^2}\cdot\dfrac{A+B-n}{A+B-1}\\ &amp; \displaystyle =n\cdot\frac{A}{N}\cdot\frac{N-A}{N}\cdot\dfrac{N-n}{N-1}\\ &amp; \displaystyle =
np(1-p)\cdot \dfrac{N-n}{N-1}
\end{array}
\]</span>
i per tant
<span class="math display">\[
\sigma_{X_H}=\sqrt{np(1-p)}\cdot \sqrt{\dfrac{N-n}{N-1}}=\sigma_{X_B}\cdot \sqrt{\dfrac{N-n}{N-1}}.
\]</span>
</div>


<div class="example">
<span id="exm:unnamed-chunk-80" class="example"><strong>Exemple 2.9  </strong></span>Tornem a la situació dels Exemples <a href="estimacio-puntual.html#exm:experimentTCL1">2.5</a> i <a href="estimacio-puntual.html#exm:experimentTCL2">2.7</a>.
Què passa si prenem les mostres aleatòries de notes de tests sense reposició?
</div>

<p>Prenguem ara 10<sup>5</sup> mostres aleatòries sense reposició de 40 notes de tests.</p>
<pre class="sourceCode r"><code class="sourceCode r">mitjanes.norep=<span class="kw">replicate</span>(<span class="dv">10</span><span class="op">^</span><span class="dv">5</span>,<span class="kw">mean</span>(<span class="kw">sample</span>(tests,<span class="dv">40</span>)))</code></pre>
<p>Un altre cop, la mitjana d’aquest vector de mitjanes hauria de ser propera a la mitjana de la població original, que era 55.43:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">mean</span>(mitjanes.norep),<span class="dv">2</span>)</code></pre>
<pre><code>## [1] 55.42</code></pre>
<p>Calculem ara la desviació típica d’aquest vector de mitjanes:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">sd</span>(mitjanes.norep),<span class="dv">2</span>)</code></pre>
<pre><code>## [1] 3</code></pre>
<p>Aquesta desviació típica no s’apropa a la desviació típica de la població partida per l’arrel quadrada de la mida de les mostres, que hem calculat abans i era 3.39.</p>
<p>Pel que acabam d’explicar, la desviació típica d’aquest vector de mitjanes de mostres sense reposició hauria de ser molt propera a la desviació típica de la població partida per l’arrel quadrada de la mida de les mostres <em>i tot multiplicat pel factor de població finita</em> <span class="math inline">\(\sqrt{(N-n)/(N-1)}\)</span>, on <span class="math inline">\(N\)</span> és la mida de la població, és a dir, la longitud del vector <code>tests</code>, i <span class="math inline">\(n\)</span> la mida de les mostres. Vegem si és veritat:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>((<span class="kw">sd</span>(tests)<span class="op">/</span><span class="kw">sqrt</span>(n))<span class="op">*</span><span class="kw">sqrt</span>((N<span class="op">-</span>n)<span class="op">/</span>(N<span class="dv">-1</span>)),<span class="dv">2</span>)</code></pre>
<pre><code>## [1] 3.01</code></pre>
<p>Això ja s’acosta més a la desviació típica del vector de mitjanes de mostres sense reposició, que ha valgut 3.</p>
</div>
<div id="proporcio-mostral" class="section level2">
<h2><span class="header-section-number">2.3</span> Proporció mostral</h2>
<p>Suposem que ara tenim una variable aleatòria poblacional <span class="math inline">\(X\)</span> que és Bernoulli amb <strong>probabilitat d’èxit</strong> (o <strong>proporció d’èxits</strong>) <span class="math inline">\(p_X\)</span>. Entendrem que <span class="math inline">\(X\)</span> pren els valors 1 (èxit) o 0 (fracàs). Recordau que <span class="math inline">\(E(X)=p_X\)</span> i <span class="math inline">\(\sigma_X=\sqrt{p_X(1-p_X)}\)</span>.</p>
<p>Sigui <span class="math inline">\(X_1,\ldots,X_n\)</span> una mostra aleatòria de mida <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span> i sigui <span class="math inline">\(S_n=\sum_{i=1}^n X_i\)</span> el nombre d’èxits observats en aquesta mostra aleatòria.</p>
<p>La <strong>proporció mostral</strong> d’èxits de la nostra mostra és
<span class="math display">\[
\widehat{p}_X=\frac{S_n}{n}=\frac{\sum_{i=1}^n X_i}{n}.
\]</span></p>

<div class="rmdcaution">
Recordau que si prenem mostres aleatòries simples, <span class="math inline">\(S_n\)</span> és una variable aleatòria binomial <span class="math inline">\(B(n,p_X)\)</span>. Però és un doi dir que la proporció mostral <span class="math inline">\(\widehat{p}_X\)</span> és una variable aleatòria binomial, ni que només sigui perquè les variables aleatòries binomials prenen valors nombres naturals i els valors que pot prendre <span class="math inline">\(\widehat{p}_X\)</span> són fraccions entre 0 i 1.
</div>

<p>Fixau-vos que <span class="math inline">\(\widehat{p}_X\)</span> és un cas particular de la mitjana mostral <span class="math inline">\(\overline{X}\)</span>, per tant per a les proporcion mostrals val tot el que hem dit fins ara per a mitjanes mostrals:</p>

<div class="theorem">
<p><span id="thm:pX" class="theorem"><strong>Teorema 2.4  </strong></span>Si <span class="math inline">\(X\)</span> és una variable aleatòria Bernoulli amb probabilitat d’èxit <span class="math inline">\(p_X\)</span> i <span class="math inline">\(X_1,\ldots,X_n\)</span> és una mostra aleatòria de mida <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span>, de proporció mostral <span class="math inline">\(\widehat{p}_X\)</span>, aleshores</p>
<ol style="list-style-type: decimal">
<li><p><span class="math inline">\(\mu_{\widehat{p}_X}=p_X\)</span></p></li>
<li><p>Si la mostra aleatòria és simple, <span class="math inline">\(\sigma_{\widehat{p}_X}=\sqrt{\dfrac{p_X(1-p_X)}{n}}\)</span></p></li>
<li><p>Si la mostra aleatòria és sense reposició i <span class="math inline">\(n\)</span> és relativament gran per comparació amb la mida de la població <span class="math inline">\(N\)</span>,
<span class="math display">\[
\sigma_{\widehat{p}_X}=\sqrt{\frac{p_X(1-p_X)}{n}}\cdot
\sqrt{\frac{\vphantom{(}N-n}{N-1}}
\]</span></p></li>
<li>Pel Teorema Central del Límit, si la mostra és aleatòria simple i la seva mida <span class="math inline">\(n\)</span> és gran, la distribució de <span class="math inline">\(\widehat{p}_X\)</span> és aproximadament la d’una variable normal
<span class="math display">\[
  N\left({p}_X,\sqrt{\frac{{p}_X(1-{p}_X)}{n}}\right)
\]</span>
i per tant
<span class="math display">\[
\frac{\widehat{p}_X-p_X}{\sqrt{\frac{{p}_X(1-{p}_X)}{n}}}
\]</span>
és aproximadament <span class="math inline">\(N(0,1)\)</span>.
</div></li>
</ol>
<p>Alguns comentaris:</p>
<ul>
<li><p><span class="math inline">\(\mu_{\widehat{p}_X}=p_X\)</span>: Si repetíssim moltes vegades el procés de prendre una mostra aleatòria simple de mida <span class="math inline">\(n\)</span> d’una variable aleatòria de Bernoulli <span class="math inline">\(X\)</span> i calcular-ne la proporció mostral d’èxits, molt probablement la mitjana d’aquestes proporcions mostrals s’acostaria molt a <span class="math inline">\(p_X\)</span></p></li>
<li><p>En particular, <span class="math inline">\(\widehat{p}_X\)</span> serveix per estimar <span class="math inline">\(p_X\)</span></p></li>
<li><p><span class="math inline">\(\sigma_{\widehat{p}_X}= \sqrt{{p_X(1-p_X)}/{n}}\)</span>: la variabilitat dels resultats de <span class="math inline">\(\widehat{p}_X\)</span> decreix amb <span class="math inline">\(n\)</span> i tendeix a 0 quan <span class="math inline">\(n\to \infty\)</span>. Pel que fa a la dependència de <span class="math inline">\(\sigma_{\widehat{p}_X}\)</span> respecte de <span class="math inline">\(p_X\)</span> si la <span class="math inline">\(n\)</span> és fixada, observau al gràfic següent que <span class="math inline">\(\sqrt{p_X(1-p_X)}\)</span> creix entre 0 i 0.5 i decreix entre 0.5 i 1, assolint el valor màxim a <span class="math inline">\(p_X=0.5\)</span>.</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">sqrt</span>(x<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>x)),<span class="dt">xlab=</span><span class="st">&quot;p&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;sqrt(p*(1-p))&quot;</span>,<span class="dt">lwd=</span><span class="dv">2</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-86-1.png" width="50%" style="display: block; margin: auto;" /></p>
<ul>
<li><p><span class="math inline">\(\sqrt{{p_X(1-p_X)}/{n}}\)</span> és l’<strong>error típic</strong> de <span class="math inline">\(\widehat{p}_X\)</span>. L’estimam amb l’<strong>error típic de l’estimació</strong> <span class="math inline">\(\sqrt{{\widehat{p}_X(1-\widehat{p}_X)}/{n}}\)</span>.</p></li>
<li><p>A partir d’ara, sovint cometrem l’abús de llenguatge d’ometre l’adverbi “aproximadament” de l’apartat (4) del teorema anterior, i direm simplement que si <span class="math inline">\(n\)</span> és gran, <span class="math inline">\(\widehat{p}_X\)</span> és normal. Però, repetim, hem de recordar que aquest “és normal” en realitat vol dir “la seva distribució és aproximadament la d’una variable normal”.</p></li>
</ul>

<div class="example">
<p><span id="exm:unnamed-chunk-87" class="example"><strong>Exemple 2.10  </strong></span>Tornem una altra vegada a la situació dels Exemples <a href="estimacio-puntual.html#exm:experimentTCL1">2.5</a> i <a href="estimacio-puntual.html#exm:experimentTCL2">2.7</a>. Vaig a traduir el fitxer de notes de tests en un vector binari: 0 per suspens (haver tret menys de 50) i 1 per aprovat (haver tret 50 o més):</p>
</div>

<pre class="sourceCode r"><code class="sourceCode r"><span class="co"># Iniciam totes les notes a 1</span>
aprovs=<span class="kw">rep</span>(<span class="dv">1</span>,<span class="kw">length</span>(tests))
<span class="co"># Posam 0 on la nota del test és suspesa</span>
aprovs[<span class="kw">which</span>(tests<span class="op">&lt;</span><span class="dv">50</span>)]=<span class="dv">0</span></code></pre>
<p>Aquest vector <code>aprovs</code> el podem entendre com una població de Bernoulli de probabilitat poblacional d’èxit (aprovat) <span class="math inline">\(p_X\)</span>.
Les proporcions de suspesos i aprovats són:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">prop.table</span>(<span class="kw">table</span>(aprovs)),<span class="dv">4</span>) </code></pre>
<pre><code>## aprovs
##      0      1 
## 0.4054 0.5946</code></pre>
<p>Per tant, <span class="math inline">\(p_X\)</span> és:</p>
<pre class="sourceCode r"><code class="sourceCode r">p_X=<span class="kw">as.numeric</span>(<span class="kw">prop.table</span>(<span class="kw">table</span>(aprovs))[<span class="dv">2</span>])
<span class="kw">round</span>(p_X,<span class="dv">4</span>)</code></pre>
<pre><code>## [1] 0.5946</code></pre>
<p>Ara n’extreurem 10<sup>5</sup> mostres aleatòries simples de mida 40, en calcularem les proporcions mostrals d’aprovats i comprovarem si es confirmen les conclusions del teorema anterior.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">100</span>)
props.mostrals=<span class="kw">replicate</span>(<span class="dv">10</span><span class="op">^</span><span class="dv">5</span>,<span class="kw">mean</span>(<span class="kw">sample</span>(aprovs,<span class="dv">40</span>,<span class="dt">rep=</span><span class="ot">TRUE</span>)))</code></pre>
<p>La mitjana d’aquest vector de proporcions hauria de ser propera a la proporció poblacional d’aprovats <span class="math inline">\(p_X=0.5946\)</span>.</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">mean</span>(props.mostrals),<span class="dv">4</span>)</code></pre>
<pre><code>## [1] 0.5942</code></pre>
<p>Vegem ara la seva desviació típica:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">sd</span>(props.mostrals),<span class="dv">4</span>)</code></pre>
<pre><code>## [1] 0.0774</code></pre>
<p>Pel Teorema <a href="estimacio-puntual.html#thm:pX">2.4</a>, sabem que això hauria de ser proper a <span class="math inline">\(\sqrt{p_X(1-p_X)/n}\)</span></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">sqrt</span>(p_X<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p_X)<span class="op">/</span><span class="dv">40</span>),<span class="dv">4</span>)</code></pre>
<pre><code>## [1] 0.0776</code></pre>
<p>I pel Teorema Central del Límit, aquestes proporcions mostrals haurien de seguir aproximadament una distribució normal $N(p_X,). Vegem-ho amb un histograma:</p>
<pre class="sourceCode r"><code class="sourceCode r">fact.trans.p=<span class="kw">hist</span>(props.mostrals,<span class="dt">plot=</span><span class="ot">FALSE</span>)<span class="op">$</span>counts[<span class="dv">1</span>]<span class="op">/</span><span class="kw">hist</span>(props.mostrals,<span class="dt">plot=</span><span class="ot">FALSE</span>)<span class="op">$</span>density[<span class="dv">1</span>]
<span class="kw">hist</span>(props.mostrals,<span class="dt">col=</span><span class="st">&quot;light blue&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Proporcions mostrals&quot;</span>,
     <span class="dt">ylab=</span><span class="st">&quot;Freqüències&quot;</span>,<span class="dt">main=</span><span class="st">&quot;Histograma de la mostra de proporcions&quot;</span>)
<span class="kw">curve</span>(fact.trans.p<span class="op">*</span><span class="kw">dnorm</span>(x,p_X,<span class="kw">sqrt</span>(p_X<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>p_X)<span class="op">/</span><span class="dv">40</span>)),
      <span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-95-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>I això que la mida de les mostres, 40, no és especialment gran.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-96" class="example"><strong>Exemple 2.11  </strong></span>Un 59.1% dels estudiants de la UIB són dones. Hem pres una mostra més o menys aleatòria de 60 estudiants de la UIB i hi hem trobat 40 dones, un 66.67%. Ens demanam si 40 de 60 és una quantitat raonable de dones en una mostra aleatòria simple d’estudiants de la UIB, o si són moltes (atès que hi esperaríem al voltant d’un 59% de dones).</p>
</div>

<p>Aquesta pregunta, que serà molt típica d’aquí a pocs temes, la traduïm en la següent pregunta:</p>
<blockquote>
<p>Si prenem una mostra aleatòria simple de 60 estudiants, quina és la probabilitat que la proporció mostral de dones sigui superior al 66.67%?</p>
</blockquote>
<p>Una manera senzilla de respondre aquesta pregunta és aprofitar el Teorema Central del Límit, segons el qual la proporció mostral <span class="math inline">\(\widehat{p}_X\)</span> de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix una distribució aproximadament normal amb <span class="math inline">\(\mu=0.591\)</span> i
<span class="math display">\[
\sigma=\sqrt{\dfrac{0.591(1-0.591)}{60}}=0.0635
\]</span>
Per tant, la probabilitat que <span class="math inline">\(\widehat{p}_X\geqslant 0.6667\)</span> és (recordau, aproximadament)</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pnorm</span>(<span class="fl">0.6667</span>,<span class="fl">0.591</span>,<span class="fl">0.0635</span>),<span class="dv">4</span>)</code></pre>
<pre><code>## [1] 0.1166</code></pre>
<p>Això ens diu que, de mitjana, aproximadament 1 de cada 9 mostres aleatòries simples de 60 estudiants de la UIB conté almenys 40 dones.</p>
<p>Naturalment, si tenim R o qualsevol altra manera de calcular probabilitats, també podem fer servir la distribució binomial per calcular aquesta probabilitat, i de fet és més correcte, ja que la probabilitat anterior ha emprat una aproximació de la distribució de <span class="math inline">\(\widehat{p}_X\)</span> i en canvi sabem que el nombre <span class="math inline">\(S_{60}\)</span> de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix de manera exacta una distribució binomial <span class="math inline">\(B(60,0.591)\)</span>. Com que el 66.67% de la pregunta en realitat representa 40 dones, la probabilitat exacta demanada és</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">pbinom</span>(<span class="dv">39</span>,<span class="dv">60</span>,<span class="fl">0.591</span>),<span class="dv">4</span>)</code></pre>
<pre><code>## [1] 0.1441</code></pre>

<div class="rmdcaution">
Recordau que si <span class="math inline">\(X\)</span> és una variable aleatòria discreta que pren valors enters, com ara la binomial,
<span class="math inline">\(P(X\geqslant 40)=1-P(X\leqslant 39)\)</span>.
</div>

<p>Aquesta probabilitat exacta (exacta, si el 59.1% és el percentatge exacte de dones a la UIB) ens diu que, de mitjana, 1 de cada 7 mostres aleatòries simples de 60 estudiants de la UIB conté almenys 40 dones.</p>
</div>
<div id="variancia-mostral" class="section level2">
<h2><span class="header-section-number">2.4</span> Variància mostral</h2>
<p>Sigui <span class="math inline">\(X_1,\ldots, X_n\)</span> una mostra aleatòria simple de mida <span class="math inline">\(n\)</span> d’una variable aleatòria <span class="math inline">\(X\)</span> d’esperança <span class="math inline">\(\mu_X\)</span> i desviació típica <span class="math inline">\(\sigma_X\)</span>.</p>
<p>La <strong>variància mostral</strong> d’aquesta mostra aleatòria simple és
<span class="math display">\[
\widetilde{S}_{X}^2=\frac{\sum_{i=1}^n (X_{i}-\overline{X})^2}{n-1}
\]</span>
La seva <strong>desviació típica mostral</strong> és
<span class="math display">\[
\widetilde{S}_{X}=+\sqrt{\widetilde{S}_{X}^2}
\]</span>
A més, de tant en tant també farem servir la <strong>variància</strong> i la <strong>desviació típica</strong> <strong>“a seques”</strong>:
<span class="math display">\[
\begin{array}{l}
\displaystyle S^2_{X}=\frac{\sum_{i=1}^n (X_{i}-\overline{X})^2}{n}=\frac{(n-1)}{n}\widetilde{S}^2_{X}\\
\displaystyle S_X=+\sqrt{S_X^2}
\end{array}
\]</span></p>
<p>La variància (a seques) admet la següent expressió senzilla:
<span class="math display">\[
S^2_X=\frac{\sum_{i=1}^n X_{i}^2}{n}-\overline{X}^2
\]</span></p>

<div class="rmdcorbes">
<p>En efecte:
<span class="math display">\[
\begin{array}{l}
\displaystyle \frac{\sum_{i=1}^n (X_{i}-\overline{X})^2}{n}=\frac{1}{n}\sum_{i=1}^n (X_{i}^2-2\overline{X}X_i+\overline{X}^2)\\
\displaystyle\qquad = \frac{1}{n}\Big(\sum_{i=1}^n X_{i}^2-2\overline{X}\sum_{i=1}^n X_{i}+n\overline{X}^2\Big)\\
\displaystyle\qquad =\frac{\sum_{i=1}^n X_{i}^2}{n}-2\overline{X}\frac{\sum_{i=1}^n X_{i}}{n}+\frac{n\overline{X}^2}{n}\\
\displaystyle\qquad =\frac{\sum_{i=1}^n X_{i}^2}{n}-2\overline{X}\cdot\overline{X} + \overline{X}^2=\frac{\sum_{i=1}^n X_{i}^2}{n}- \overline{X}^2
\end{array}
\]</span></p>
</div>


<div class="theorem">
<p><span id="thm:unnamed-chunk-101" class="theorem"><strong>Teorema 2.5  </strong></span>Si <span class="math inline">\(X\)</span> és una variable aleatòria <strong>normal</strong> de desviació típica <span class="math inline">\(\sigma_X\)</span> i <span class="math inline">\(X_1,\ldots,X_n\)</span> és una mostra aleatòria simple de mida <span class="math inline">\(n\)</span> de <span class="math inline">\(X\)</span>, amb variància mostral <span class="math inline">\(\widetilde{S}_{X}^2\)</span>, aleshores <span class="math inline">\(\mu_{\widetilde{S}_{X}^2}=\sigma_{X}^2\)</span> i
la variable aleatòria
<span class="math display">\[
\frac{(n-1)\widetilde{S}_{X}^2}{\sigma_{X}^2}
\]</span>
té distribució coneguda: <span class="math inline">\(\chi_{n-1}^2\)</span> (es llegeix <strong>khi quadrat amb <span class="math inline">\(n-1\)</span> graus de llibertat</strong>).</p>
</div>


<div class="rmdcaution">
La lletra <span class="math inline">\(\chi\)</span> en català es diu <em>khi</em>; en castellà, <em>ji</em>; i en anglès, <em>chi</em>, pronunciat <em>xai</em>.
</div>

<p>De la distribució <span class="math inline">\(\chi_n^2\)</span>, on <span class="math inline">\(n\)</span> són els <strong>graus de llibertat</strong>, heu de saber que:</p>
<ul>
<li><p>Per definició, és la distribució de la suma dels quadrats de <span class="math inline">\(n\)</span> variables aleatòries normals estàndard independents. És a dir, si <span class="math inline">\(Z_{1},Z_{2},\ldots, Z_{n}\sim N(0,1)\)</span> són independents, la variable
<span class="math display">\[
Z_{1}^{2}+Z_{2}^{2}+\cdots +Z_{n}^{2}
\]</span>
té distribució <span class="math inline">\(\chi_n^2\)</span>.</p></li>
<li><p>La <span class="math inline">\(n\)</span> és un paràmetre del que depèn la seva distribució</p></li>
<li><p>Amb R és <code>chisq</code></p></li>
<li><p>Si <span class="math inline">\(X\)</span> és una variable aleatòria amb distribució <span class="math inline">\(\chi_n^2\)</span>, aleshores <span class="math inline">\(\mu_X=n\)</span> i <span class="math inline">\(\sigma_X^2=2 n\)</span></p></li>
<li><p>Per a <span class="math inline">\(n\)</span> petits, la distribució d’una <span class="math inline">\(\chi_{n}^2\)</span> presenta una cua a la dreta, i a mida que <span class="math inline">\(n\)</span> creix, pel Teorema Central del Límit, es va aproximant a una distribució normal <span class="math inline">\(N(n,\sqrt{2n})\)</span>, com podeu veure als gràfics següents</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">dchisq</span>(x,<span class="dv">1</span>),<span class="dt">col=</span><span class="dv">1</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">20</span>),<span class="dt">xlab=</span><span class="st">&quot;&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;&quot;</span>,<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.3</span>),<span class="dt">main=</span><span class="st">&quot;Algunes khi quadrat&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dchisq</span>(x,<span class="dv">2</span>),<span class="dt">col=</span><span class="dv">2</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">dchisq</span>(x,<span class="dv">3</span>),<span class="dt">col=</span><span class="dv">3</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">dchisq</span>(x,<span class="dv">4</span>),<span class="dt">col=</span><span class="dv">4</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">dchisq</span>(x,<span class="dv">5</span>),<span class="dt">col=</span><span class="dv">5</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">dchisq</span>(x,<span class="dv">10</span>),<span class="dt">col=</span><span class="dv">6</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>,<span class="dt">col=</span><span class="dv">1</span><span class="op">:</span><span class="dv">6</span>,<span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>),
       <span class="dt">lwd=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>),<span class="dt">legend=</span><span class="kw">paste</span>(<span class="st">&quot;n=&quot;</span>,<span class="kw">c</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">5</span>,<span class="dv">10</span>),<span class="dt">sep=</span><span class="st">&quot;&quot;</span>),<span class="dt">cex=</span><span class="fl">0.8</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-103-1.png" width="50%" style="display: block; margin: auto;" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">dchisq</span>(x,<span class="dv">300</span>),<span class="dt">xlim=</span><span class="kw">c</span>(<span class="dv">150</span>,<span class="dv">450</span>),<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">xlab=</span><span class="st">&quot;&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;&quot;</span>,<span class="dt">main=</span><span class="st">&quot;Khi quadrat vs Normal&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dnorm</span>(x,<span class="dv">300</span>,<span class="kw">sqrt</span>(<span class="dv">600</span>)),<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>,<span class="dt">col=</span><span class="kw">c</span>(<span class="st">&quot;black&quot;</span>,<span class="st">&quot;red&quot;</span>),<span class="dt">lty=</span><span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>),
       <span class="dt">lwd=</span><span class="kw">c</span>(<span class="dv">2</span>,<span class="dv">2</span>),<span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;Khi quadrat amb n=300&quot;</span>,<span class="st">&quot;Normal&quot;</span>),<span class="dt">cex=</span><span class="fl">0.7</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-104-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Tornem un instant a això dels <em>graus de llibertat</em>. Per què diem que la variància (mostral o a seques) té <span class="math inline">\(n-1\)</span> graus de llibertat?</p>
<p>Doncs perquè si volem construir un conjunt de <span class="math inline">\(n\)</span> nombres <span class="math inline">\(x_1,\ldots,x_n\)</span> que tenguin variància un valor donat, posem <span class="math inline">\(y_0\)</span>, aleshores en principi podem escollir <span class="math inline">\(n-1\)</span> d’ells, <span class="math inline">\(x_1,\ldots,x_{n-1}\)</span>, com volguem i aleshores el darrer, <span class="math inline">\(x_n\)</span>, queda bastant fixat. En matemàtiques això se sol expressar dient que “tenim <span class="math inline">\(n-1\)</span> graus de llibertat a l’hora d’escollir <span class="math inline">\(x_1,\ldots,x_n\)</span> amb variància fixada <span class="math inline">\(y_0\)</span>”.</p>

<div class="rmdcorbes">
<p>En efecte, si fixam el valor <span class="math inline">\(y_0\geqslant 0\)</span> de la variància i volem trobar <span class="math inline">\(x_1,\ldots,x_{n}\)</span>
tals que
<span class="math display">\[
y_0=\frac{\sum_{i=1}^n (x_i-\overline{x})^2}{n}=\frac{\sum_{i=1}^n x_i^2}{n}-\overline{x}^2
\]</span>
vegem que per a qualssevol valors de <span class="math inline">\(x_1,\ldots,x_{n-1}\)</span>, el valor de <span class="math inline">\(x_n\)</span> queda fixat per una equació quadràtica:
<span class="math display">\[
\begin{array}{l}
ny_0 &amp; =\displaystyle \sum_{i=1}^n x_i^2-n\overline{x}^2= \sum_{i=1}^n x_i^2-n\Big(\frac{\sum_{i=1}^n x_i}{n}\Big)^2\\
&amp; =\displaystyle \sum_{i=1}^n x_i^2-\frac{(\sum_{i=1}^n x_i)^2}{n}\\
&amp; \displaystyle =\frac{1}{n}\left(n\sum_{i=1}^n x_i^2-\Big(\sum_{i=1}^{n} x_i\Big)^2\right)\\
&amp; =\displaystyle \frac{1}{n}\left(n\sum_{i=1}^{n-1} x_i^2+n\mathbf{x_n}^2-\Big(\sum_{i=1}^{n-1} x_i\Big)^2\right.\\
&amp; \displaystyle\qquad\qquad \left. -2\Big(\sum_{i=1}^{n-1} x_i\Big)\mathbf{x_n}-\mathbf{x_n}^2\right)\\
&amp; =\displaystyle \frac{1}{n}\left((n-1)\mathbf{x_n}^2-2\Big(\sum_{i=1}^{n-1} x_i\Big)\mathbf{x_n}\right.\\
&amp; \displaystyle\qquad\qquad \left.+n\sum_{i=1}^{n-1} x_i^2-\Big(\sum_{i=1}^{n-1} x_i\Big)^2 \right)
\end{array}
\]</span>
d’on (multiplicant els dos costats de la igualtat per <span class="math inline">\(n\)</span> i dividint-los per <span class="math inline">\(n-1\)</span>) obtenim, finalment, l’equació de segon grau en <span class="math inline">\(\mathbf{x_n}\)</span>
<span class="math display">\[
\mathbf{x_n}^2-\frac{2\sum_{i=1}^{n-1} x_i}{n-1}\mathbf{x_n}+\frac{n\sum_{i=1}^{n-1} x_i^2-\Big(\sum_{i=1}^{n-1} x_i\Big)^2-n^2y_0^2}{n-1}=0
\]</span>
Per tant, fixat <span class="math inline">\(y_0\)</span> i un cop escollits <span class="math inline">\(x_1,\ldots,x_{n-1}\)</span>, el darrer valor <span class="math inline">\(x_n\)</span> ha de ser per força una solució d’aquesta equació de segon grau.</p>
Fixau-vos que aquesta equació no sempre té solució real, perquè pot tenir el discriminant negatiu. Per tant exageràvem un poc dient que podíem triar <span class="math inline">\(x_1,\ldots,x_{n-1}\)</span> “com volguem”. Per exemple, si voleu que la variància sigui 0 i preneu <span class="math inline">\(x_1,\ldots,x_{n-1}\)</span> no tots iguals, podeu estar ben segurs que no trobareu cap <span class="math inline">\(x_n\)</span> que satisfaci aquesta equació: per tenir variància 0, <span class="math inline">\(x_1,\ldots,x_n\)</span> han de ser tots iguals. Però el que ha de quedar clar és que un cop escollits <span class="math inline">\(x_1,\ldots,x_{n-1}\)</span>, el valor de <span class="math inline">\(x_n\)</span> ja no pot ser qualsevol, pot prendre com a màxim dos valors diferents.
</div>

</div>
<div id="la-t-de-student" class="section level2">
<h2><span class="header-section-number">2.5</span> La t de Student</h2>
<p>Tornem a les mitjanes mostrals de variables normals.</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-106" class="theorem"><strong>Teorema 2.6  </strong></span>Sigui <span class="math inline">\(X\)</span> una variable <span class="math inline">\(N(\mu_X,\sigma_X)\)</span> i
sigui <span class="math inline">\(X_1,\ldots,X_n\)</span> una mostra aleatòria simple de <span class="math inline">\(X\)</span>, amb mitjana <span class="math inline">\(\overline{X}\)</span> i desviació típica mostral <span class="math inline">\(\widetilde{S}_{X}\)</span>. Aleshores, la variable aleatòria
<span class="math display">\[
T=\frac{\overline{X}-\mu_X}{\widetilde{S}_{X}/\sqrt{n}}
\]</span>
segueix una distribució coneguda, anomenada <strong>t de Student amb <span class="math inline">\(n-1\)</span> graus de llibertat</strong>, <span class="math inline">\(t_{n-1}\)</span>.</p>
</div>


<div class="rmdimportant">
A <span class="math inline">\(\widetilde{S}_{X}/\sqrt{n}\)</span> li diem l’<strong>error típic</strong>, o <strong>estàndard</strong>, <strong>de la mostra</strong>: estima l’error típic <span class="math inline">\(\sigma_X/\sqrt{n}\)</span> de <span class="math inline">\(\overline{X}\)</span>.
</div>

<p>De la distribució t de Student amb <span class="math inline">\(n\)</span> graus de llibertat, <span class="math inline">\(t_{n}\)</span>, heu de saber que:</p>
<ul>
<li><p>Amb R és <code>t</code></p></li>
<li><p>La <span class="math inline">\(n\)</span> és un paràmetre del que depèn la seva distribució</p></li>
<li><p>Si <span class="math inline">\(T_{n}\)</span> és una variable amb distribució <span class="math inline">\(t_{n}\)</span>, aleshores <span class="math inline">\(\mu_{T_{n}}=0\)</span> si <span class="math inline">\(n\geqslant 2\)</span> i <span class="math inline">\(\sigma_{T_{n}}^2=n/(n-2)\)</span> si <span class="math inline">\(n\geqslant 3\)</span></p></li>
<li><p>La funció de densitat d’una variable <span class="math inline">\(T_{n}\)</span> amb distribució <span class="math inline">\(t_{n}\)</span> és simètrica al voltant de 0 (com la d’una <span class="math inline">\(N(0,1)\)</span>):
<span class="math display">\[
P(T_{n}\leqslant-x)=P(T_{n}\geqslant x)=1-P(T_{n}\leqslant x)
\]</span></p></li>
<li><p>Si <span class="math inline">\(n\)</span> és gran, la distribució d’una variable <span class="math inline">\(T_{n}\)</span> amb distribució <span class="math inline">\(t_{n}\)</span> és aproximadament la d’una <span class="math inline">\(N(0,1)\)</span> (però amb més variància: un poc més aplatada), com podeu veure als gràfics següents:</p></li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x),<span class="dt">col=</span><span class="dv">1</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>),<span class="dt">xlab=</span><span class="st">&quot;&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;&quot;</span>,<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.4</span>),
      <span class="dt">main=</span><span class="st">&quot;Algunes t de Student&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">2</span>),<span class="dt">col=</span><span class="dv">2</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">3</span>),<span class="dt">col=</span><span class="dv">3</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">4</span>),<span class="dt">col=</span><span class="dv">4</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">5</span>),<span class="dt">col=</span><span class="dv">5</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">10</span>),<span class="dt">col=</span><span class="dv">6</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>,<span class="dt">col=</span><span class="dv">1</span><span class="op">:</span><span class="dv">6</span>,<span class="dt">lty=</span><span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">6</span>), <span class="dt">lwd=</span><span class="kw">rep</span>(<span class="dv">2</span>,<span class="dv">6</span>),
<span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;Normal estàndard&quot;</span>, <span class="kw">paste</span>(<span class="st">&quot;Student amb g.l.=&quot;</span>,<span class="kw">c</span>(<span class="dv">2</span><span class="op">:</span><span class="dv">5</span>,<span class="dv">10</span>),<span class="dt">sep=</span><span class="st">&quot;&quot;</span>)),<span class="dt">cex=</span><span class="fl">0.7</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-108-1.png" width="50%" style="display: block; margin: auto;" /></p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">curve</span>(<span class="kw">dnorm</span>(x),<span class="dt">col=</span><span class="dv">1</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">xlim=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">4</span>,<span class="dv">4</span>),<span class="dt">xlab=</span><span class="st">&quot;&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;&quot;</span>,<span class="dt">ylim=</span><span class="kw">c</span>(<span class="dv">0</span>,<span class="fl">0.4</span>),
      <span class="dt">main=</span><span class="st">&quot;t vs Normal estàndard&quot;</span>)
<span class="kw">curve</span>(<span class="kw">dt</span>(x,<span class="dv">50</span>),<span class="dt">col=</span><span class="dv">2</span>,<span class="dt">lwd=</span><span class="dv">2</span>,<span class="dt">add=</span><span class="ot">TRUE</span>)
<span class="kw">legend</span>(<span class="st">&quot;topleft&quot;</span>,<span class="dt">col=</span><span class="dv">1</span><span class="op">:</span><span class="dv">2</span>,<span class="dt">lty=</span><span class="kw">rep</span>(<span class="dv">1</span>,<span class="dv">2</span>), <span class="dt">lwd=</span><span class="kw">rep</span>(<span class="dv">2</span>,<span class="dv">2</span>),
       <span class="dt">legend=</span><span class="kw">c</span>(<span class="st">&quot;Normal estàndard&quot;</span>, <span class="st">&quot;Student amb g.l.=50&quot;</span>),<span class="dt">cex=</span><span class="fl">0.7</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-109-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>El fet que una t de Student sigui més aplatada que una normal estàndard <span class="math inline">\(Z\)</span> implica que les cues de la t tenen major probabilitat que les de <span class="math inline">\(Z\)</span> (fixau-vos que als gràfics anteriors els extrems de les densitats de les t estan per damunt dels de la de <span class="math inline">\(Z\)</span>), la qual cosa es tradueix en el fet que és més probable obtenir valors lluny del 0 amb una t de Student que amb una <span class="math inline">\(N(0,1)\)</span>.</p>
<p>Indicarem amb <span class="math inline">\(t_{n,q}\)</span> el <span class="math inline">\(q\)</span>-quantil d’una variable aleatòria <span class="math inline">\(T_{n}\)</span> que segueix una distribució <span class="math inline">\(t_n\)</span>. És a dir, <span class="math inline">\(t_{n,q}\)</span> és el valor tal que
<span class="math display">\[
P(T_{n}\leqslant t_{n,q})=q
\]</span>
Per la simetria de la distribució <span class="math inline">\(t_n\)</span>,
<span class="math display">\[
t_{n,q}=-t_{n,1-q}.
\]</span></p>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-110-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Hi ha algunes propietats dels quantils de la t de Student que heu de saber, per poder aplicar-les quan no tingueu a l’abast R o una apli per calcular quantils:</p>
<ul>
<li><span class="math inline">\(t_{n ,q}\approx z_{q}\)</span> si <span class="math inline">\(n\)</span> és molt gran, posem <span class="math inline">\(n \geqslant 200\)</span>. Per exemple</li>
</ul>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qt</span>(<span class="fl">0.975</span>,<span class="dv">300</span>) <span class="co"># t_{300,0.975}</span></code></pre>
<pre><code>## [1] 1.967903</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qnorm</span>(<span class="fl">0.975</span>)  <span class="co"># z_0.975</span></code></pre>
<pre><code>## [1] 1.959964</code></pre>
<ul>
<li><p><span class="math inline">\(t_{n,0.95}\)</span> (per a <span class="math inline">\(10\leqslant n\leqslant 200\)</span>) està entre 1.65 i 1.8; ho podeu aproximar <span class="math inline">\(t_{n,0.95}\approx 1.7\)</span></p></li>
<li><p><span class="math inline">\(t_{n,0.975}\)</span> (per a <span class="math inline">\(10\leqslant n\leqslant 200\)</span>) està entre 1.97 i 2.2; ho podeu aproximar <span class="math inline">\(t_{n,0.975}\approx 2\)</span></p></li>
</ul>

<div class="rmdexercici">
Comprovau amb R les afirmacions sobr els quantils de la t de Student dels darrers dos punts.
</div>


<div class="rmdcaution">
<p>Abans de tancar aquesta secció, recordau que, donada una variable aleatòria <span class="math inline">\(X\)</span>, no heu de confondre:</p>
<ul>
<li><p><strong>Desviació típica</strong> (o <strong>estàndard</strong>) <em>de la variable aleatòria</em>, <span class="math inline">\(\sigma_X\)</span>: El paràmetre poblacional, normalment desconegut</p></li>
<li><p><strong>Desviació típica</strong> (o <strong>estàndard</strong>) (sigui mostral, <span class="math inline">\(\widetilde{S}_X\)</span>, o a seques, <span class="math inline">\(S_X\)</span>) <em>d’una mostra</em>: L’estadístic que calculam sobre la mostra i que quantifica la dispersió de la mostra</p></li>
<li><p><strong>Error típic</strong> (o <strong>estàndard</strong>) <em>d’un estimador</em>: La desviació típica de la variable aleatòria que defineix l’estimador, normalment desconeguda</p></li>
<li><strong>Error típic</strong> (o <strong>estàndard</strong>) <em>d’una mostra</em>: Estimació de l’error típic de la mitjana mostral (o de la proporció mostral) a partir d’una mostra; servirà per calcular intervals de confiança. És <span class="math inline">\(\widetilde{S}_X/\sqrt{n}\)</span>.</li>
</ul>
</div>

</div>
<div id="bons-estimadors" class="section level2">
<h2><span class="header-section-number">2.6</span> “Bons” estimadors</h2>
<div id="estimadors-no-esbiaixats" class="section level3">
<h3><span class="header-section-number">2.6.1</span> Estimadors no esbiaixats</h3>
<p>Un estimador puntual <span class="math inline">\(\widehat{\theta}\)</span> d’un paràmetre poblacional <span class="math inline">\(\theta\)</span> és <strong>no esbiaixat</strong> (<strong>insesgado</strong>, en castellà) quan el seu valor esperat és precisament el valor poblacional del paràmetre, és a dir, quan
<span class="math display">\[
\mu_\widehat{\theta}=\theta
\]</span>
Es diu aleshores que l’estimació puntual és <strong>no esbiaixada</strong>.</p>
<p>El <strong>biaix</strong> d’un estimador <span class="math inline">\(\widehat{\theta}\)</span> d’un paràmetre <span class="math inline">\(\theta\)</span> és la diferència <span class="math inline">\(\mu_\widehat{\theta}-\theta\)</span></p>
<p><strong>Exemples:</strong> Ja hem vist a les seccions anteriors que</p>
<ul>
<li><p><span class="math inline">\(\mu_{\overline{X}}=\mu_X\)</span>. Per tant, <span class="math inline">\(\overline{X}\)</span> és sempre un estimador no esbiaixat de <span class="math inline">\(\mu_X\)</span></p></li>
<li><p><span class="math inline">\(\mu_{\widehat{p}_X}=p_X\)</span>. Per tant, <span class="math inline">\(\widehat{p}_X\)</span> és sempre un estimador no esbiaixat de <span class="math inline">\(p_X\)</span></p></li>
<li><p><span class="math inline">\(\mu_{\widetilde{S}_{X}^2}=\sigma_X^2\)</span> si <span class="math inline">\(X\)</span> és normal. Per tant, <span class="math inline">\(\widetilde{S}_{X}^2\)</span> és un estimador no esbiaixat de <span class="math inline">\(\sigma_X^2\)</span> quan <span class="math inline">\(X\)</span> és normal</p></li>
<li><p>Com que <span class="math inline">\({S}_{X}^2=\dfrac{n-1}{n}\widetilde{S}_{X}^2\)</span>, tenim que <span class="math inline">\(\mu_{{S}_{X}^2}=\dfrac{n-1}{n}\sigma_X^2\)</span> si <span class="math inline">\(X\)</span> és normal. Per tant, en aquest cas,
<span class="math inline">\({S}_{X}^2\)</span> <em>és un estimador esbiaixat de</em> <span class="math inline">\(\sigma_X^2\)</span>, amb biaix
<span class="math display">\[
\mu_{{S}_{X}^2}-\sigma_X^2=\dfrac{n-1}{n}\sigma_X^2-\sigma_X^2=-\dfrac{\sigma_X^2}{n}\ \mathop{\longrightarrow}_{\scriptscriptstyle
n\to\infty}\ 0
\]</span>
Diem en aquest cas que <strong>el biaix tendeix a 0</strong>.</p></li>
<li><p><span class="math inline">\(\mu_{\widetilde{S}_{X}}, \mu_{{S}_{X}}\neq \sigma_X\)</span> ni tan sols quan <span class="math inline">\(X\)</span> és normal. Per tant, <span class="math inline">\(\widetilde{S}_{X}\)</span> i <span class="math inline">\({S}_{X}\)</span> són estimadors <em>esbiaixats</em> de <span class="math inline">\(\sigma_X\)</span></p></li>
</ul>
</div>
<div id="estimadors-eficients" class="section level3">
<h3><span class="header-section-number">2.6.2</span> Estimadors eficients</h3>
<p>Donats dos estimadors <span class="math inline">\(\widehat{\theta}_1\)</span>, <span class="math inline">\(\widehat{\theta}_2\)</span> del mateix paràmetre <span class="math inline">\(\theta\)</span>, direm que <span class="math inline">\(\widehat{\theta}_1\)</span> és <strong>més eficient</strong>, o <strong>més precís</strong>, que <span class="math inline">\(\widehat{\theta}_2\)</span> quan l’error típic de <span class="math inline">\(\widehat{\theta}_1\)</span> és més petit que el de <span class="math inline">\(\widehat{\theta}_2\)</span>:
<span class="math display">\[
\sigma(\widehat{\theta}_1)&lt; \sigma(\widehat{\theta}_2).
\]</span></p>
<p>Normalment, només comparam l’eficiència de dos estimadors quan són no esbiaixats (o, com a molt, quan el seu biaix tendeix a 0). En aquest cas, que <span class="math inline">\(\widehat{\theta}_1\)</span> sigui més eficient que <span class="math inline">\(\widehat{\theta}_2\)</span> significa que la seva variabilitat és menor i que per tant <em>les estimacions amb <span class="math inline">\(\widehat{\theta}_1\)</span> es concentren més al voltant del seu valor esperat, que és el paràmetre <span class="math inline">\(\theta\)</span> que volem estimar, que les estimacions amb <span class="math inline">\(\widehat{\theta}_2\)</span></em>.</p>
<p><strong>Exemples:</strong></p>
<ul>
<li><p>Si <span class="math inline">\(X\)</span> és normal, <span class="math inline">\(\overline{X}\)</span> és l’estimador no esbiaixat més eficient de la mitjana poblacional <span class="math inline">\(\mu_X\)</span>.</p></li>
<li><p>Si <span class="math inline">\(X\)</span> és Bernoulli, <span class="math inline">\(\widehat{p}_X\)</span> és l’estimador
no esbiaixat més eficient de la proporció poblacional <span class="math inline">\(p_X\)</span>.</p></li>
<li><p>Si <span class="math inline">\(X\)</span> és normal, <span class="math inline">\(\widetilde{S}_X^2\)</span> és l’estimador
no esbiaixat més eficient de la variància poblacional <span class="math inline">\(\sigma_X^2\)</span>.</p></li>
</ul>

<div class="example">
<p><span id="exm:unnamed-chunk-114" class="example"><strong>Exemple 2.12  </strong></span>Sigui <span class="math inline">\(X\)</span> una variable aleatòria normal <span class="math inline">\(N(\mu_X,\sigma_X)\)</span>.
Considerem la mediana <span class="math inline">\(\mathit{Me}=Q_{0.5}\)</span> d’una mostra aleatòria simple de <span class="math inline">\(X\)</span> com a estimador puntual de <span class="math inline">\(\mu_X\)</span>, que coincideix amb la mediana de <span class="math inline">\(X\)</span> per la simetria de les variables normals.</p>
</div>

<p>Resulta que <span class="math inline">\(\mu_{\mathit{Me}}=\mu_X\)</span> però
<span class="math display">\[
\sigma^2(\mathit{Me})\approx \dfrac{\pi}{2}\cdot
     \dfrac{\sigma_{X}^2}{n}\approx 1.57 \cdot \frac{\sigma_{X}^2}{n}=1.57\sigma^2_{\overline{X}}
\]</span></p>
<p>Per tant, si <span class="math inline">\(X\)</span> és normal, la mediana <span class="math inline">\(\mathit{Me}\)</span> és un estimador no esbiaixat de <span class="math inline">\(\mu_X\)</span>, però menys eficient que <span class="math inline">\(\overline{X}\)</span>. Per això preferim emprar la mitjana mostral per estimar <span class="math inline">\(\mu_X\)</span>.</p>

<div class="rmdnote">
<p>Hem dit que si la població és normal, <span class="math inline">\(\widetilde{S}_X^2\)</span> és l’estimador no esbiaixat més eficient de la variància poblacional <span class="math inline">\(\sigma_X^2\)</span>. La variància a seques
<span class="math display">\[
S_X^2=\frac{(n-1)}{n} \widetilde{S}_X^2
\]</span><br />
és més eficient, perquè
<span class="math display">\[
\sigma(S_X^2)=\sqrt{\frac{(n-1)}{n}}\sigma(\widetilde{S}_X^2)&lt;\sigma(\widetilde{S}_X^2),
\]</span><br />
però és un estimador esbiaixat de <span class="math inline">\(\sigma_X^2\)</span>, amb biaix que tendeix a 0.</p>
Si <span class="math inline">\(n\)</span> és petit (per davall de 30), és millor fer servir la variància mostral <span class="math inline">\(\widetilde{S}_X^2\)</span> per estimar la variància, ja que el biaix pot desplaçar l’estimació, però si <span class="math inline">\(n\)</span> és gran, el biaix de <span class="math inline">\(S_X^2\)</span> ja és petit i es pot fer servir <span class="math inline">\(S_X^2\)</span>: de fet, si <span class="math inline">\(n\)</span> és molt gran, dividir per <span class="math inline">\(n\)</span> o per <span class="math inline">\(n-1\)</span> no varia gaire el resultat i per tant <span class="math inline">\(\widetilde{S}_X^2\)</span> i <span class="math inline">\(S_X^2\)</span> donen valors molt semblants.
</div>

</div>
<div id="estimadors-maxim-versemblants" class="section level3">
<h3><span class="header-section-number">2.6.3</span> Estimadors màxim versemblants</h3>
<p>Un estimador d’un paràmetre és <strong>màxim versemblant</strong> quan, aplicat a una mostra aleatòria simple d’una mida <span class="math inline">\(n\)</span> fixada,
dóna el valor del paràmetre que fa màxima la probabilitat d’obtenir aquesta mostra.</p>

<div class="rmdcorbes">
<p>En realitat, el que fa màxim l’estimació màxim versemblant d’un paràmetre és el producte dels valors de la funció densitat de la variable aleatòria poblacional aplicada als elements de la mostra. Quan la variable aleatòria és discreta, això coincideix amb el que hem dit, perquè la probabilitat d’obtenir un valor concret és la funció densitat aplicada a aquest valor. Però quan la variable aleatòria poblacional és contínua, la probabilitat d’obtenir una mostra concreta és sempre 0 i no té sentit parlar de maximitzar aquest 0. Per això es pren la funció densitat.</p>
En aquest curs no ens complicarem la vida i entendrem que el que maximitzam és la probabilitat d’obtenir la mostra.
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-117" class="example"><strong>Exemple 2.13  </strong></span>Suposem que tenim una variable aleatòria Bernoulli <span class="math inline">\(X\)</span> de probabilitat d’èxit <span class="math inline">\(p_X\)</span> desconeguda. Donada una mostra aleatòria simple <span class="math inline">\(x_1,\ldots,x_n\)</span> de <span class="math inline">\(X\)</span>, siguin <span class="math inline">\(\widehat{p}_x\)</span> la seva proporció mostral i<br />
<span class="math display">\[
P(x_1,\ldots,x_n\mid p_X=p)
\]</span>
la probabilitat d’obtenir la mostra quan la probabilitat poblacional <span class="math inline">\(p_X\)</span> és igual <span class="math inline">\(p\)</span>. Un estimador per a <span class="math inline">\(p_X\)</span> és màxim versemblant quan, aplicat a cada mostra aleatòria simple <span class="math inline">\(x_1,\ldots,x_n\)</span> de <span class="math inline">\(X\)</span>, ens dóna el valor de <span class="math inline">\(p\)</span> que fa que
<span class="math display">\[
P(x_1,\ldots,x_n\mid p_X=p)
\]</span>
sigui el màxim possible.</p>
</div>

<p>Quin creieu que és l’estimador màxim versemblant de <span class="math inline">\(p_X\)</span>? Doncs sí, la proporció mostral <span class="math inline">\(\widehat{p}_X\)</span>.</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-118" class="theorem"><strong>Teorema 2.7  </strong></span>El valor de <span class="math inline">\(p\)</span> per al qual <span class="math inline">\(P(x_1,\ldots,x_n\mid p)\)</span> és màxim és <span class="math inline">\(\widehat{p}_x\)</span>.</p>
</div>


<div class="rmdcorbes">
La demostració és senzilla. Suposau que dins <span class="math inline">\(x_1,\ldots,x_n\)</span> hi ha <span class="math inline">\(m\)</span> 1s i <span class="math inline">\(n-m\)</span> 0s, de manera que <span class="math inline">\(\widehat{p}_X=m/n\)</span>. Aleshores, la probabilitat d’obtenir <span class="math inline">\(x_1,\ldots,x_n\)</span> és
<span class="math display">\[
P(x_1,\ldots,x_n\mid p)=p^m(1-p)^{n-m}
\]</span>
Per trobar el valor de <span class="math inline">\(p\)</span> que fa aquest probabilitat màxima, derivau respecte de <span class="math inline">\(p\)</span> i estudiau el signe de la derivada, i concloureu que el màxim es dóna efectivament a <span class="math inline">\(p=m/n\)</span>.
</div>


<div class="rmdimportant">
La proporció <span class="math inline">\(\widehat{p}_x\)</span> és el valor que fa màxima la probabilitat d’obtenir la nostra mostra, no a l’enrevés: <strong>No és el valor més probable de <span class="math inline">\(p_X\)</span> condicionat a la nostra mostra</strong>. Vaja, no confongueu
<span class="math display">\[
P(x_1,\ldots,x_n\mid p_X=p)\text{ amb }P(p_X=p\mid x_1,\ldots,x_n).
\]</span>
D’això darrer no en sabem trobar el màxim sense alguna hipòtesi sobre la distribució de probabilitat dels valors possibles de <span class="math inline">\(p_X\)</span>.
</div>

<p>Alguns altres estimadors màxim versemblants:</p>
<ul>
<li><p><span class="math inline">\(\overline{X}\)</span> és l’estimador màxim versemblant del paràmetre <span class="math inline">\(\lambda\)</span> d’una variable aleatòria Poisson</p></li>
<li><p><span class="math inline">\(\overline{X}\)</span> és l’estimador màxim versemblant de la mitjana <span class="math inline">\(\mu\)</span> d’una variable aleatòria normal</p></li>
</ul>
</div>
</div>
<div id="sec:pobl" class="section level2">
<h2><span class="header-section-number">2.7</span> Estimació de poblacions</h2>
<div id="estimacio-de-poblacions-numerades" class="section level3">
<h3><span class="header-section-number">2.7.1</span> Estimació de poblacions numerades</h3>

<div class="example">
<p><span id="exm:taxi1" class="example"><strong>Exemple 2.14  </strong></span>Un dia vaig voler estimar quants taxis hi havia a Palma.
Per fer-ho, assegut en un bar del Passeig Marítim vaig apuntar les llicències dels 40 primers taxis que passaren. Els entraré directament en un vector de R.</p>
</div>

<pre class="sourceCode r"><code class="sourceCode r">taxis=<span class="kw">c</span>(<span class="dv">1217</span>,<span class="dv">600</span>,<span class="dv">883</span>,<span class="dv">1026</span>,<span class="dv">150</span>,<span class="dv">715</span>,<span class="dv">297</span>,<span class="dv">137</span>,<span class="dv">508</span>,<span class="dv">134</span>,<span class="dv">38</span>,<span class="dv">961</span>,<span class="dv">538</span>,<span class="dv">1154</span>,<span class="dv">314</span>,<span class="dv">1121</span>,<span class="dv">823</span>,<span class="dv">158</span>,<span class="dv">940</span>,<span class="dv">99</span>,
  <span class="dv">977</span>,<span class="dv">286</span>,<span class="dv">1006</span>,<span class="dv">1207</span>,<span class="dv">264</span>,<span class="dv">1183</span>,<span class="dv">1120</span>,<span class="dv">498</span>,<span class="dv">606</span>,<span class="dv">566</span>,<span class="dv">1239</span>,<span class="dv">860</span>,<span class="dv">114</span>,<span class="dv">701</span>,<span class="dv">381</span>,<span class="dv">836</span>,<span class="dv">561</span>,<span class="dv">494</span>,<span class="dv">858</span>,<span class="dv">187</span>)
<span class="kw">sort</span>(taxis)</code></pre>
<pre><code>##  [1]   38   99  114  134  137  150  158  187  264  286  297  314  381  494
## [15]  498  508  538  561  566  600  606  701  715  823  836  858  860  883
## [29]  940  961  977 1006 1026 1120 1121 1154 1183 1207 1217 1239</code></pre>
<p>Puc estimar quants taxis hi ha a Palma a partir d’aquesta mostra? Us pot semblar una beneitura de pregunta, però aquest és un problema de rellevància històrica, com podeu consultar en <a href="https://www.investigacionyciencia.es/files/14469.pdf">aquest article</a>.</p>
<p>La solució d’aquest problema és donada pel resultat següent:</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-122" class="theorem"><strong>Teorema 2.8  </strong></span>Sigui <span class="math inline">\(X\)</span> una variable aleatòria uniforme sobre <span class="math inline">\(\{1,2,\ldots,N\}\)</span>, i sigui <span class="math inline">\(x_1,\ldots,x_n\)</span> una mostra aleatòria de <span class="math inline">\(X\)</span>. Sigui <span class="math inline">\(m=\max(x_1,\ldots,x_n)\)</span>. Aleshores, l’estimador no esbiaixat més eficient de <span class="math inline">\(N\)</span> és
<span class="math display">\[
\widehat{N}=m+\frac{m-n}{n}
\]</span></p>
</div>


<div class="rmdcorbes">
La idea que hi ha sota aquesta fórmula és que si suposau que teniu <span class="math inline">\(x_1,\ldots,x_n\)</span> ordenats en ordre creixent, de manera que <span class="math inline">\(x_n=m\)</span>, i calculau la mitjana de la longitud dels “forats” a l’esquerra de cada valor <span class="math inline">\(x_i\)</span>, tenim que a l’esquerra de <span class="math inline">\(x_1\)</span> hi ha <span class="math inline">\(x_1-1\)</span> nombres i entre cada <span class="math inline">\(x_{i-1}\)</span> i <span class="math inline">\(x_{i}\)</span> hi ha <span class="math inline">\(x_{i}-x_{i-1}-1\)</span> nombres, i per tant aquesta mitjana és
<span class="math display">\[
\begin{array}{l}
\displaystyle \frac{(x_1-1)+(x_2-x_1-1)+\cdots+(x_{n}-x_{n-1}-1)}{n}\\
\displaystyle \qquad\quad =\frac{x_n-n}{n}=\frac{m-n}{n}
\end{array}
\]</span>
i el que fa l’estimador <span class="math inline">\(\widehat{N}\)</span> és sumar al màxim de la mostra, <span class="math inline">\(m\)</span>, la mitjana dels forats entre membres de la mostra. És a dir, estimam que la mida de la població és tal que a la dreta del màxim de la nostra mostra hi ha un “forat” de mida la mitjana dels forats de la mostra.
</div>


<div class="example">
<p><span id="exm:unnamed-chunk-124" class="example"><strong>Exemple 2.15  </strong></span>Continuem amb l’Exemple <a href="estimacio-puntual.html#exm:taxi1">2.14</a>. Emprant la fórmula anterior, obtenim</p>
</div>

<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">max</span>(taxis)<span class="op">+</span>(<span class="kw">max</span>(taxis)<span class="op">-</span><span class="kw">length</span>(taxis))<span class="op">/</span><span class="kw">length</span>(taxis)</code></pre>
<pre><code>## [1] 1268.975</code></pre>
<p>la qual cosa ens permet estimar que hi havia 1269 taxis a Palma.
En realitat, consultant la web de l’Ajuntament, després vaig saber que en aquell moment n’hi havia 1246.</p>

<div class="example">
<p><span id="exm:simultancs" class="example"><strong>Exemple 2.16  </strong></span>Fem un experiment. Generarem a l’atzar una mida N d’una població grandeta, i suposarem que els individus de la població estan numerats de l’1 a l’N. A continuació, prendrem 100 mostres aleaòries sense reposició de la nostra població i amb cada una d’aquestes mostres estimarem la N emprant la fórmula que hem donat. Al final, calcularem la mitjana d’aquestes estimacions i la compararem amb el valor real de N, que no descobrirem fins el final.</p>
</div>

<p>Perquè l’experiment sigui reproductible, fixarem la llavor d’aleatorietat, però perquè no cregueu que fem trampes amb aquesta llavor, el que farem serà generar a l’atzar la llavor d’aleatorietat amb la funció <code>sample</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">Llavor=<span class="kw">sample</span>(<span class="dv">10000</span>,<span class="dv">1</span>)
Llavor</code></pre>
<pre><code>## [1] 6283</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(Llavor)</code></pre>
<p>Ara generam la mida N de la població com un nombre a l’atzar entre 5000 i 10000.</p>
<pre class="sourceCode r"><code class="sourceCode r">N=<span class="kw">sample</span>(<span class="dv">5000</span><span class="op">:</span><span class="dv">10000</span>,<span class="dv">1</span>)</code></pre>
<p>Suposarem per tant que hi ha N individus a la nostra població, numerats de l’1 a l’N. Ara generarem 100 mostres aleatòries sense reposició d’aquesta població, i ens quedarem amb la mida i el valor màxim de cada una d’elles, que és l’únic que necessitam saber. Les mides les generarem a l’atzar entre, posem, 25 i 75:</p>
<pre class="sourceCode r"><code class="sourceCode r">Mostra=<span class="cf">function</span>(a,b,P){
  <span class="co">#a i b: mides màxima i mínima de la mostra; P: mida de la població</span>
  n=<span class="kw">sample</span>(a<span class="op">:</span>b,<span class="dv">1</span>)  <span class="co">#Mida de la mostra</span>
  X=<span class="kw">sample</span>(P,n,<span class="dt">rep=</span><span class="ot">FALSE</span>)  <span class="co"># Mostra aleatòria </span>
  <span class="kw">c</span>(n,<span class="kw">max</span>(X)) <span class="co">#Parell (mida, màxim)</span>
}
Mostres=<span class="kw">replicate</span>(<span class="dv">100</span>,<span class="kw">Mostra</span>(<span class="dv">25</span>,<span class="dv">75</span>,N))
Mostres</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
## [1,]   67   42   75   67   39   69   26   30   30    46    34    50    59
## [2,] 6442 6320 6346 6403 5805 6410 6326 6398 6365  6354  6337  6371  5932
##      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24]
## [1,]    65    55    58    74    41    28    40    39    50    52    46
## [2,]  6439  6274  6433  6426  5795  6213  6367  6066  5903  6219  6187
##      [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35]
## [1,]    74    52    43    31    45    55    63    46    73    74    45
## [2,]  6393  6333  6243  6295  6406  6409  6308  6421  6327  6354  6319
##      [,36] [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46]
## [1,]    45    53    63    54    28    36    61    52    53    37    29
## [2,]  6282  6255  6430  6335  6002  6310  6331  6381  6338  6235  6304
##      [,47] [,48] [,49] [,50] [,51] [,52] [,53] [,54] [,55] [,56] [,57]
## [1,]    65    75    37    43    73    30    70    55    45    31    62
## [2,]  6292  6394  6309  6362  6302  6426  6278  6265  6191  6442  6389
##      [,58] [,59] [,60] [,61] [,62] [,63] [,64] [,65] [,66] [,67] [,68]
## [1,]    54    36    50    28    67    25    71    40    49    65    65
## [2,]  6242  6260  6406  5937  6235  5673  6285  6269  6200  6381  6414
##      [,69] [,70] [,71] [,72] [,73] [,74] [,75] [,76] [,77] [,78] [,79]
## [1,]    55    67    55    33    39    74    29    63    39    57    51
## [2,]  6183  6304  6433  6426  6442  6372  5602  6371  6412  6369  6374
##      [,80] [,81] [,82] [,83] [,84] [,85] [,86] [,87] [,88] [,89] [,90]
## [1,]    55    61    33    33    58    71    44    62    68    34    68
## [2,]  6412  6307  5945  6259  6095  6397  6361  6379  6435  5956  6373
##      [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98] [,99] [,100]
## [1,]    37    39    63    65    66    68    64    36    55     32
## [2,]  6335  6285  6426  6437  6438  6403  6406  5954  6271   5993</code></pre>
<p>En aquesta matriu <code>Mostres</code>, cada columna correspon a una mostra aleatòria: la primera filera és la seva mida <span class="math inline">\(n\)</span> i la segona filera el màxim <span class="math inline">\(m\)</span>. Ara, amb cada una d’aquestes mostres, podem estimar la mida N de la població per mitjà de la fórmula <span class="math inline">\(m+(m-n)/n\)</span>. Donarem aquestes estimacions ordenades de menor a major.</p>
<pre class="sourceCode r"><code class="sourceCode r">Estimacions=Mostres[<span class="dv">2</span>,]<span class="op">+</span>(Mostres[<span class="dv">2</span>,]<span class="op">-</span>Mostres[<span class="dv">1</span>,])<span class="op">/</span>Mostres[<span class="dv">1</span>,]
<span class="kw">round</span>(<span class="kw">sort</span>(Estimacions),<span class="dv">1</span>)</code></pre>
<pre><code>##   [1] 5794.2 5898.9 5935.3 5952.8 6020.1 6031.5 6118.4 6124.2 6130.2 6148.0
##  [11] 6179.3 6199.1 6215.4 6220.5 6294.4 6320.5 6325.5 6327.1 6327.6 6337.6
##  [21] 6356.6 6366.7 6372.0 6372.5 6377.9 6384.0 6387.1 6387.2 6387.3 6387.8
##  [31] 6397.1 6402.5 6407.1 6409.4 6412.7 6420.6 6424.7 6429.6 6432.9 6433.8
##  [41] 6433.9 6438.9 6445.2 6447.7 6451.3 6453.8 6456.6 6457.1 6458.4 6465.7
##  [51] 6469.5 6471.1 6478.2 6478.3 6478.4 6478.5 6479.7 6480.9 6484.3 6486.1
##  [61] 6491.0 6491.1 6496.2 6497.1 6497.4 6497.6 6498.0 6501.9 6502.7 6504.6
##  [71] 6505.1 6505.2 6509.0 6511.7 6511.8 6520.4 6522.4 6524.5 6525.2 6527.0
##  [81] 6527.6 6528.6 6531.1 6533.1 6534.5 6535.0 6537.1 6537.1 6542.9 6547.4
##  [91] 6549.0 6559.6 6568.3 6575.4 6576.2 6606.2 6610.3 6619.7 6639.2 6648.8</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(Estimacions, <span class="dt">breaks=</span><span class="dv">20</span>,<span class="dt">col=</span><span class="st">&quot;light blue&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Estimacions de N&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Freqüències&quot;</span>,<span class="dt">main=</span><span class="st">&quot;&quot;</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-129-1.png" width="50%" style="display: block; margin: auto;" />
Com veieu, obtenim estimacions que van de 5794.2 a 6648.8. La mitjana d’aquestes estimacions és</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">mean</span>(Estimacions),<span class="dv">1</span>)</code></pre>
<pre><code>## [1] 6415.9</code></pre>
<p>És hora de descobrir el valor de N, per veure si ens hi hem fet a prop:</p>
<pre class="sourceCode r"><code class="sourceCode r">N</code></pre>
<pre><code>## [1] 6442</code></pre>
<p>No hem fet molt enfora, com veieu.</p>
</div>
<div id="marca-recaptura" class="section level3">
<h3><span class="header-section-number">2.7.2</span> Marca-recaptura</h3>
<p>Suposem que en una població hi ha <span class="math inline">\(N\)</span> individus, en capturam <span class="math inline">\(K\)</span> (tots diferents), els marcam i els tornam a amollar. Al cap de poc temps, en capturam <span class="math inline">\(n\)</span>, dels quals <span class="math inline">\(k\)</span> estan marcats. A partir d’aquestes dades, volem estimar <span class="math inline">\(N\)</span>.</p>
<p>Si suposam que <span class="math inline">\(N\)</span> i <span class="math inline">\(K\)</span> no han canviat de la primera a la segona captura (cap individu no ha abandonat la població ni s’hi ha incorporat), aleshores la variable aleatòria
<span class="math inline">\(X\)</span> definida per “Capturam un individu i miram si està marcat” és Bernoulli <span class="math inline">\(Be(p)\)</span> amb <span class="math inline">\(p=K/N\)</span>, on coneixem la <span class="math inline">\(K\)</span> i volem estimar la <span class="math inline">\(N\)</span>.</p>
<p>Sigui ara <span class="math inline">\(x_1,\ldots,x_n\)</span> la mostra capturada en segon lloc. La seva proporció mostral d’individus marcats és <span class="math inline">\(\widehat{p}_X=k/n\)</span>. Com que <span class="math inline">\(\widehat{p}_X\)</span> és l’estimador màxim versemblant de <span class="math inline">\(p\)</span>, estimam que
<span class="math display">\[
\dfrac{K}{N}=\dfrac{k}{n}
\]</span>
d’on, aïllant la <span class="math inline">\(N\)</span>, estimam que
<span class="math display">\[
N=\frac{n\cdot K}{k}.
\]</span></p>
<p>En resum, l’estimador
<span class="math display">\[
\widehat{N}=\frac{n\cdot K}{k}
\]</span>
maximitza la probabilitat d’obtenir <span class="math inline">\(k\)</span> individus marcats en una mostra aleatòria de <span class="math inline">\(n\)</span> individus. És l’<strong>estimador màxim versemblant</strong> de <span class="math inline">\(N\)</span> a partir de <span class="math inline">\(K\)</span>, <span class="math inline">\(k\)</span> i <span class="math inline">\(n\)</span>; també se li diu <strong>estimador de Lincoln-Petersen</strong>. Fixau-vos que aquest estimador no fa res més que traduir la proporció “Si he trobat <span class="math inline">\(k\)</span> individus marcats en un conjunt de <span class="math inline">\(n\)</span> individus, què ha de valer el nombre total <span class="math inline">\(N\)</span> de individus perquè hi hagi en total <span class="math inline">\(K\)</span> individus marcats?”</p>

<div class="example">
<p><span id="exm:MR" class="example"><strong>Exemple 2.17  </strong></span>Suposem que hem marcat 15 peixos d’un llac, i que en una captura posterior de 10 peixos, n’hi ha 4 de marcats. Quants peixos conté el llac?</p>
</div>

<p>Ho estimarem amb l’estimador de Lincoln-Petersen:
<span class="math display">\[
\widehat{N}=\frac{15\cdot 10}{4}=37.5
\]</span>
Per tant, estimam que hi haurà entre 37 i 38 peixos al llac.</p>
<p>En aquest cas podem comprovar la màxima versemblança d’aquesta estimació, calculant la probabilitat d’obtenir 4 individus marcats en una mostra aleatòria de 10 individus d’una població de <span class="math inline">\(N\)</span> individus on n’hi ha 15 de marcats i trobant la <span class="math inline">\(N\)</span> que maximitza aquesta probabilitat. Per fer-ho, recordem que si una població està formada per <span class="math inline">\(K\)</span> subjectes marcats i <span class="math inline">\(N-K\)</span> subjectes no marcats, el nombre de subjectes marcats en mostres aleatòries sense reposició de mida <span class="math inline">\(n\)</span> segueix una distribució hipergeomètrica <span class="math inline">\(H(K, N-K,n)\)</span>. Per tant, per a cada possible <span class="math inline">\(N\)</span>, la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats serà <code>dhyper(4,15,N-15,10)</code>.</p>
<pre class="sourceCode r"><code class="sourceCode r">N=<span class="dv">15</span><span class="op">:</span><span class="dv">1000</span>  <span class="co">#Rang de possibles valors de N</span>
p=<span class="kw">dhyper</span>(<span class="dv">4</span>,<span class="dv">15</span>,N<span class="dv">-15</span>,<span class="dv">10</span>)  <span class="co">#Probabilitats de 4 marcats en 10</span>
Nmax=N[<span class="kw">which</span>(p<span class="op">==</span><span class="kw">max</span>(p))] <span class="co"># N que maximitza la probabilitat</span>
Nmax</code></pre>
<pre><code>## [1] 37</code></pre>
<p>Aquest <code>Nmax</code> és la <span class="math inline">\(N\)</span> que fa màxima la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats. Vegem-ho amb un gràfic:</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">plot</span>(N[<span class="dv">1</span><span class="op">:</span><span class="dv">86</span>],p[<span class="dv">1</span><span class="op">:</span><span class="dv">86</span>],<span class="dt">type=</span><span class="st">&quot;h&quot;</span>,<span class="dt">xaxp=</span><span class="kw">c</span>(<span class="dv">15</span>,<span class="dv">100</span>,<span class="dv">17</span>),<span class="dt">xlab=</span><span class="st">&quot;N&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;p&quot;</span>)
<span class="kw">points</span>(Nmax,<span class="kw">dhyper</span>(<span class="dv">4</span>,<span class="dv">15</span>,Nmax<span class="dv">-15</span>,<span class="dv">10</span>),<span class="dt">type=</span><span class="st">&quot;h&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>,<span class="dt">lwd=</span><span class="fl">1.5</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-133-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Un altre estimador per a <span class="math inline">\(N\)</span> a partir de <span class="math inline">\(K\)</span>, <span class="math inline">\(n\)</span> i <span class="math inline">\(k\)</span> és l’<strong>estimador de Chapman</strong>:
<span class="math display">\[
\widehat{N}=\frac{(n+1)\cdot (K+1)}{k+1}-1
\]</span></p>
<p>La idea és que afegim a la població un individu extra i marcat, que suposam que també capturam a la segona mostra. Llavors, aplicam l’estimador anterior i finalment restam 1, per descomptar l’individu marcat extra que realment no pertany a la població que volem estimar.</p>
<p>En la situació de l’Exemple <a href="estimacio-puntual.html#exm:MR">2.17</a>, aquest estimador dóna
<span class="math display">\[
\widehat{N}=\frac{16\cdot 11}{5}-1=34.2
\]</span>
i ens fa estimar una població total d’uns 34 peixos. Abans hem obtingut entre 37 i 38 peixos.</p>

<div class="rmdnote">
Quina de les dues estimacions s’acosta més a la realitat? Ni idea, no ho podem saber. Amb una altra recaptura segurament haguéssim obtingut resultats diferents.
</div>

<p>L’estimador de Lincoln-Petersen
<span class="math display">\[
\widehat{N}=\frac{n\cdot K}{k}
\]</span>
és esbiaixat, amb biaix que tendeix a 0. L’estimador de Chapman és menys esbiaixat però no és màxim versemblant.</p>

<div class="example">
<p><span id="exm:simulpeixos" class="example"><strong>Exemple 2.18  </strong></span>Fem un experiment similar al de l’Exemple <a href="estimacio-puntual.html#exm:simultancs">2.16</a>. Generarem a l’atzar una mida N d’una població grandeta i en marcarem una certa quantitat K. A continuació, prendrem 50 mostres aleaòries sense reposició de la nostra població i amb cada una d’aquestes mostres estimarem la N emprant els dos estimadors que hem explicat en aquesta subsecció. Al final, calcularem les mitjanes d’aquestes estimacions i les compararem amb el valor real de N, que no descobrirem fins el final. Com a l’Exemple <a href="estimacio-puntual.html#exm:simultancs">2.16</a>, fixarem la llavor d’aleatorietat a l’atzar.</p>
</div>

<pre class="sourceCode r"><code class="sourceCode r">Llavor2=<span class="kw">sample</span>(<span class="dv">10000</span>,<span class="dv">1</span>)
Llavor2</code></pre>
<pre><code>## [1] 6244</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(Llavor2)</code></pre>
<p>Ara generam la mida N de la població com un nombre a l’atzar entre 5000 i 10000.</p>
<pre class="sourceCode r"><code class="sourceCode r">N=<span class="kw">sample</span>(<span class="dv">5000</span><span class="op">:</span><span class="dv">10000</span>,<span class="dv">1</span>)</code></pre>
<p>Ara en capturam i marcam K; per fixar idees, prendrem K=200.</p>
<pre class="sourceCode r"><code class="sourceCode r">K=<span class="dv">200</span></code></pre>
<p>Per simplificar, suposarem que els N individus de la nostra població estan numerats de l’1 a l’N i que els marcats són els K primers. Ara generarem 100 mostres aleatòries sense reposició d’aquesta població, i ens quedarem amb la mida i el nombre d’individus marcats (és a dir, el nombre de valors menor o iguals a K=100 en la mostra). Les mides les generarem a l’atzar entre, posem, 50 i 150:</p>
<pre class="sourceCode r"><code class="sourceCode r">Mostra=<span class="cf">function</span>(a,b,P,M){
  <span class="co">#a i b: mides màxima i mínima de la mostra; P: mida de la població;</span>
  <span class="co">#M: nombre de marcats</span>
  n=<span class="kw">sample</span>(a<span class="op">:</span>b,<span class="dv">1</span>)  <span class="co">#Mida de la mostra</span>
  X=<span class="kw">sample</span>(P,n,<span class="dt">rep=</span><span class="ot">FALSE</span>)  <span class="co"># Mostra aleatòria </span>
  <span class="kw">c</span>(n,<span class="kw">length</span>(<span class="kw">which</span>(X<span class="op">&lt;=</span>M))) <span class="co">#Parell (mida, nombre de marcats)</span>
}
Mostres=<span class="kw">replicate</span>(<span class="dv">100</span>,<span class="kw">Mostra</span>(<span class="dv">50</span>,<span class="dv">150</span>,N,K))
Mostres</code></pre>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13]
## [1,]   79   94  110  116  128  127   68   59  144   135   147    86    89
## [2,]    2    2    1    2    1    3    2    1    4     2    10     8     4
##      [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24]
## [1,]    51   121    95    50    54    71    67   113   141    65   129
## [2,]     0     4     4     0     2     3     0     0     4     3     3
##      [,25] [,26] [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35]
## [1,]   111    97    74   102    88    82   112    92   120   138    82
## [2,]     5     2     1     2     3     9     1     6     1     2     1
##      [,36] [,37] [,38] [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46]
## [1,]    65   103   114   106    72    57    54   123    68    51    52
## [2,]     3     6     5     1     0     0     2     3     1     2     2
##      [,47] [,48] [,49] [,50] [,51] [,52] [,53] [,54] [,55] [,56] [,57]
## [1,]    81    75   121    90    87   123   128    73   139   115   130
## [2,]     2     2     3     3     1     1     3     2     5     2     1
##      [,58] [,59] [,60] [,61] [,62] [,63] [,64] [,65] [,66] [,67] [,68]
## [1,]    50   102    80    90    92   143   125   141   132    54   102
## [2,]     2     2     3     2     1     3     5     6     1     1     4
##      [,69] [,70] [,71] [,72] [,73] [,74] [,75] [,76] [,77] [,78] [,79]
## [1,]    79   100   107   137   113   118   106   101    78    56    99
## [2,]     3     2     4     4     2     4     4     3     6     3     3
##      [,80] [,81] [,82] [,83] [,84] [,85] [,86] [,87] [,88] [,89] [,90]
## [1,]    82   118   131   102   108    63   136    60    73    81   107
## [2,]     2     4     6     0     4     1     5     4     0     1     3
##      [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98] [,99] [,100]
## [1,]   130    70    70    54   103    77   115   133    75    100
## [2,]     4     1     1     2     3     3     1     5     1      3</code></pre>
<p>En aquesta matriu <code>Mostres</code>, cada columna correspon a una mostra aleatòria: la primera filera és la seva mida <span class="math inline">\(n\)</span> i la segona filera el nombre d’individus marcats a la mostra. Ara, amb cada una d’aquestes mostres, podem estimar la mida N de la població per mitjà de l’estimador de Lincoln-Petersen.</p>
<pre class="sourceCode r"><code class="sourceCode r">EstimacionsLP=Mostres[<span class="dv">1</span>,]<span class="op">*</span>K<span class="op">/</span>Mostres[<span class="dv">2</span>,]
<span class="kw">round</span>(<span class="kw">sort</span>(EstimacionsLP),<span class="dv">1</span>)</code></pre>
<pre><code>##   [1]  1822.2  2150.0  2600.0  2940.0  3000.0  3066.7  3433.3  3733.3
##   [9]  4333.3  4333.3  4366.7  4440.0  4450.0  4560.0  4700.0  4733.3
##  [17]  4750.0  5000.0  5000.0  5100.0  5100.0  5133.3  5200.0  5266.7
##  [25]  5300.0  5320.0  5333.3  5350.0  5400.0  5400.0  5400.0  5400.0
##  [33]  5440.0  5560.0  5866.7  5900.0  5900.0  6000.0  6050.0  6500.0
##  [41]  6600.0  6666.7  6733.3  6800.0  6850.0  6866.7  7050.0  7133.3
##  [49]  7200.0  7300.0  7500.0  7900.0  8066.7  8100.0  8200.0  8200.0
##  [57]  8466.7  8533.3  8600.0  9000.0  9400.0  9533.3  9700.0 10000.0
##  [65] 10200.0 10200.0 10800.0 11300.0 11500.0 11600.0 11800.0 12600.0
##  [73] 13500.0 13600.0 13800.0 14000.0 14000.0 14800.0 15000.0 16200.0
##  [81] 16400.0 17400.0 18400.0 21200.0 22000.0 22400.0 23000.0 24000.0
##  [89] 24600.0 25600.0 26000.0 26400.0     Inf     Inf     Inf     Inf
##  [97]     Inf     Inf     Inf     Inf</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(EstimacionsLP, <span class="dt">breaks=</span><span class="dv">20</span>,<span class="dt">col=</span><span class="st">&quot;light blue&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Estimacions de N&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Freqüències&quot;</span>,<span class="dt">main=</span><span class="st">&quot;Estimador de Lincoln-Petersen&quot;</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-139-1.png" width="50%" style="display: block; margin: auto;" />
Com veieu, obtenim estimacions que van de 1822.2 a <span class="math inline">\(\infty\)</span>, que corresponen a mostres on no ens ha sortit cap individu marcat. La mitjana de les estimacions finites és</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">mean</span>(EstimacionsLP[<span class="kw">is.finite</span>(EstimacionsLP)]),<span class="dv">1</span>)</code></pre>
<pre><code>## [1] 9261.2</code></pre>
<p>També podem emprar l’estimador de Chapman:</p>
<pre class="sourceCode r"><code class="sourceCode r">EstimacionsCh=(Mostres[<span class="dv">1</span>,]<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>(K<span class="op">+</span><span class="dv">1</span>)<span class="op">/</span>(Mostres[<span class="dv">2</span>,]<span class="op">+</span><span class="dv">1</span>)<span class="op">-</span><span class="dv">1</span>
<span class="kw">round</span>(<span class="kw">sort</span>(EstimacionsCh),<span class="dv">1</span>)</code></pre>
<pre><code>##   [1]  1667.3  1942.0  2267.4  2451.2  2669.4  2703.4  2863.2  2985.3
##   [9]  3315.5  3315.5  3416.0  3483.0  3550.0  3617.0  3617.0  3684.0
##  [17]  3684.0  3684.0  3751.0  3789.3  3851.5  3858.2  3918.5  4019.0
##  [25]  4069.2  4076.4  4139.6  4220.0  4300.4  4340.6  4380.8  4471.2
##  [33]  4488.0  4571.8  4588.5  4622.0  4689.0  4782.8  4782.8  4903.4
##  [41]  4957.0  5024.0  5074.2  5091.0  5124.5  5225.0  5265.2  5359.0
##  [49]  5426.0  5493.0  5526.5  5546.6  5560.0  5707.4  5828.0  6029.0
##  [57]  6096.0  6129.5  6230.0  6364.0  6431.0  6431.0  6481.2  6531.5
##  [65]  6565.0  6766.0  6900.0  6900.0  6933.5  7134.5  7134.5  7235.0
##  [73]  7536.5  7637.0  7637.0  7771.0  7838.0  8240.0  8340.5  8843.0
##  [81]  9111.0  9312.0  9345.5 10250.0 10451.0 10752.5 11154.5 11355.5
##  [89] 11657.0 11657.0 12159.5 12461.0 12963.5 13164.5 13365.5 13667.0
##  [97] 14672.0 14873.0 20702.0 22913.0</code></pre>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">hist</span>(EstimacionsCh, <span class="dt">breaks=</span><span class="dv">20</span>,<span class="dt">col=</span><span class="st">&quot;light blue&quot;</span>,<span class="dt">xlab=</span><span class="st">&quot;Estimacions de N&quot;</span>,<span class="dt">ylab=</span><span class="st">&quot;Freqüències&quot;</span>,<span class="dt">main=</span><span class="st">&quot;Estimador de Chapman&quot;</span>)</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-141-1.png" width="50%" style="display: block; margin: auto;" />
Com veieu, obtenim estimacions que van de 1667.3 a 22913; per construcció, no hi ha estimacions infinites. La mitjana d’aquestes estimacions és</p>
<pre class="sourceCode r"><code class="sourceCode r"><span class="kw">round</span>(<span class="kw">mean</span>(EstimacionsCh),<span class="dv">1</span>)</code></pre>
<pre><code>## [1] 6618.6</code></pre>
<p>És hora de descobrir el valor de N, per veure si ens hi hem fet a prop:</p>
<pre class="sourceCode r"><code class="sourceCode r">N</code></pre>
<pre><code>## [1] 7134</code></pre>

</div>
</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="repas-de-la-distribucio-normal.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="intervals-de-confianca.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"google": false,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "google", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection",
"download": ["pdf", "epub"]
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:" && /^https?:/.test(src))
      src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
