<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Tema 11 Regressió lineal | Matemàtiques II v.2021</title>
  <meta name="description" content="Apunts Matemàtiques II bookdown::gitbook." />
  <meta name="generator" content="bookdown 0.24 and GitBook 2.6.7" />

  <meta property="og:title" content="Tema 11 Regressió lineal | Matemàtiques II v.2021" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="Apunts Matemàtiques II bookdown::gitbook." />
  <meta name="github-repo" content="cescrossello/MatesII" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Tema 11 Regressió lineal | Matemàtiques II v.2021" />
  
  <meta name="twitter:description" content="Apunts Matemàtiques II bookdown::gitbook." />
  



<meta name="date" content="2022-02-12" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="chap:ANOVA.html"/>

<script src="libs/header-attrs-2.10/header-attrs.js"></script>
<script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<script src="https://cdn.jsdelivr.net/npm/fuse.js@6.4.6/dist/fuse.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />








<link href="libs/anchor-sections-1.0.1/anchor-sections.css" rel="stylesheet" />
<script src="libs/anchor-sections-1.0.1/anchor-sections.js"></script>
<script src="libs/kePrint-0.0.1/kePrint.js"></script>
<link href="libs/lightable-0.0.1/lightable.css" rel="stylesheet" />


<style type="text/css">
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>


<link rel="stylesheet" href="style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Bioestadística II</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Presentació</a></li>
<li class="chapter" data-level="1" data-path="alguns-conceptes-bàsics.html"><a href="alguns-conceptes-bàsics.html"><i class="fa fa-check"></i><b>1</b> Alguns conceptes bàsics</a>
<ul>
<li class="chapter" data-level="1.1" data-path="alguns-conceptes-bàsics.html"><a href="alguns-conceptes-bàsics.html#tipus-de-dades"><i class="fa fa-check"></i><b>1.1</b> Tipus de dades</a></li>
<li class="chapter" data-level="1.2" data-path="alguns-conceptes-bàsics.html"><a href="alguns-conceptes-bàsics.html#població"><i class="fa fa-check"></i><b>1.2</b> Població</a></li>
<li class="chapter" data-level="1.3" data-path="alguns-conceptes-bàsics.html"><a href="alguns-conceptes-bàsics.html#variable-aleatòria"><i class="fa fa-check"></i><b>1.3</b> Variable aleatòria</a></li>
<li class="chapter" data-level="1.4" data-path="alguns-conceptes-bàsics.html"><a href="alguns-conceptes-bàsics.html#mostra"><i class="fa fa-check"></i><b>1.4</b> Mostra</a></li>
<li class="chapter" data-level="1.5" data-path="alguns-conceptes-bàsics.html"><a href="alguns-conceptes-bàsics.html#sec:mostreig"><i class="fa fa-check"></i><b>1.5</b> Mostreig aleatori</a></li>
<li class="chapter" data-level="1.6" data-path="alguns-conceptes-bàsics.html"><a href="alguns-conceptes-bàsics.html#mostres-de-conveniència"><i class="fa fa-check"></i><b>1.6</b> Mostres de conveniència</a></li>
<li class="chapter" data-level="1.7" data-path="alguns-conceptes-bàsics.html"><a href="alguns-conceptes-bàsics.html#test-de-la-lliçó-1"><i class="fa fa-check"></i><b>1.7</b> Test de la lliçó 1</a></li>
</ul></li>
<li class="chapter" data-level="2" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html"><i class="fa fa-check"></i><b>2</b> Variables aleatòries</a>
<ul>
<li class="chapter" data-level="2.1" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#generalitats-sobre-variables-aleatòries"><i class="fa fa-check"></i><b>2.1</b> Generalitats sobre variables aleatòries</a></li>
<li class="chapter" data-level="2.2" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#variables-aleatòries-discretes"><i class="fa fa-check"></i><b>2.2</b> Variables aleatòries discretes</a>
<ul>
<li class="chapter" data-level="2.2.1" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#densitat-i-distribució"><i class="fa fa-check"></i><b>2.2.1</b> Densitat i distribució</a></li>
<li class="chapter" data-level="2.2.2" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#esperança"><i class="fa fa-check"></i><b>2.2.2</b> Esperança</a></li>
<li class="chapter" data-level="2.2.3" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#variància-i-desviació-típica"><i class="fa fa-check"></i><b>2.2.3</b> Variància i desviació típica</a></li>
<li class="chapter" data-level="2.2.4" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#quantils"><i class="fa fa-check"></i><b>2.2.4</b> Quantils</a></li>
</ul></li>
<li class="chapter" data-level="2.3" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#famílies-importants-de-variables-aleatòries-discretes"><i class="fa fa-check"></i><b>2.3</b> Famílies importants de variables aleatòries discretes</a>
<ul>
<li class="chapter" data-level="2.3.1" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#variables-aleatòries-binomials"><i class="fa fa-check"></i><b>2.3.1</b> Variables aleatòries binomials</a></li>
<li class="chapter" data-level="2.3.2" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#variables-aleatòries-hipergeomètriques"><i class="fa fa-check"></i><b>2.3.2</b> Variables aleatòries hipergeomètriques</a></li>
<li class="chapter" data-level="2.3.3" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#variables-aleatòries-de-poisson"><i class="fa fa-check"></i><b>2.3.3</b> Variables aleatòries de Poisson</a></li>
</ul></li>
<li class="chapter" data-level="2.4" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#variables-aleatòries-contínues"><i class="fa fa-check"></i><b>2.4</b> Variables aleatòries contínues</a>
<ul>
<li class="chapter" data-level="2.4.1" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#densitat-i-distribució-1"><i class="fa fa-check"></i><b>2.4.1</b> Densitat i distribució</a></li>
<li class="chapter" data-level="2.4.2" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#esperança-variància-quantils"><i class="fa fa-check"></i><b>2.4.2</b> Esperança, variància, quantils…</a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#sec:normal"><i class="fa fa-check"></i><b>2.5</b> Variables aleatòries normals</a>
<ul>
<li class="chapter" data-level="2.5.1" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#amb-r"><i class="fa fa-check"></i><b>2.5.1</b> Amb R</a></li>
<li class="chapter" data-level="2.5.2" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#propietats-bàsiques"><i class="fa fa-check"></i><b>2.5.2</b> Propietats bàsiques</a></li>
<li class="chapter" data-level="2.5.3" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#intervals-de-referència"><i class="fa fa-check"></i><b>2.5.3</b> Intervals de referència</a></li>
<li class="chapter" data-level="2.5.4" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#sec:lognormal"><i class="fa fa-check"></i><b>2.5.4</b> Variables log-normals</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="variables-aleatòries.html"><a href="variables-aleatòries.html#test-de-la-lliçó-2"><i class="fa fa-check"></i><b>2.6</b> Test de la lliçó 2</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="estimació-puntual.html"><a href="estimació-puntual.html"><i class="fa fa-check"></i><b>3</b> Estimació puntual</a>
<ul>
<li class="chapter" data-level="3.1" data-path="estimació-puntual.html"><a href="estimació-puntual.html#estimadors"><i class="fa fa-check"></i><b>3.1</b> Estimadors</a></li>
<li class="chapter" data-level="3.2" data-path="estimació-puntual.html"><a href="estimació-puntual.html#mitjana-mostral"><i class="fa fa-check"></i><b>3.2</b> Mitjana mostral</a></li>
<li class="chapter" data-level="3.3" data-path="estimació-puntual.html"><a href="estimació-puntual.html#proporció-mostral"><i class="fa fa-check"></i><b>3.3</b> Proporció mostral</a></li>
<li class="chapter" data-level="3.4" data-path="estimació-puntual.html"><a href="estimació-puntual.html#variància-mostral"><i class="fa fa-check"></i><b>3.4</b> Variància mostral</a></li>
<li class="chapter" data-level="3.5" data-path="estimació-puntual.html"><a href="estimació-puntual.html#la-distribució-t-de-student"><i class="fa fa-check"></i><b>3.5</b> La distribució t de Student</a></li>
<li class="chapter" data-level="3.6" data-path="estimació-puntual.html"><a href="estimació-puntual.html#biaix-i-precisió"><i class="fa fa-check"></i><b>3.6</b> Biaix i precisió</a>
<ul>
<li class="chapter" data-level="3.6.1" data-path="estimació-puntual.html"><a href="estimació-puntual.html#estimadors-no-esbiaixats"><i class="fa fa-check"></i><b>3.6.1</b> Estimadors no esbiaixats</a></li>
<li class="chapter" data-level="3.6.2" data-path="estimació-puntual.html"><a href="estimació-puntual.html#sec:precis"><i class="fa fa-check"></i><b>3.6.2</b> Estimadors precisos</a></li>
</ul></li>
<li class="chapter" data-level="3.7" data-path="estimació-puntual.html"><a href="estimació-puntual.html#estimadors-màxim-versemblants"><i class="fa fa-check"></i><b>3.7</b> Estimadors màxim versemblants</a></li>
<li class="chapter" data-level="3.8" data-path="estimació-puntual.html"><a href="estimació-puntual.html#sec:pobl"><i class="fa fa-check"></i><b>3.8</b> Estimació de poblacions</a>
<ul>
<li class="chapter" data-level="3.8.1" data-path="estimació-puntual.html"><a href="estimació-puntual.html#estimació-de-poblacions-numerades"><i class="fa fa-check"></i><b>3.8.1</b> Estimació de poblacions numerades</a></li>
<li class="chapter" data-level="3.8.2" data-path="estimació-puntual.html"><a href="estimació-puntual.html#marca-recaptura"><i class="fa fa-check"></i><b>3.8.2</b> Marca-recaptura</a></li>
</ul></li>
<li class="chapter" data-level="3.9" data-path="estimació-puntual.html"><a href="estimació-puntual.html#test-de-la-lliçó-3"><i class="fa fa-check"></i><b>3.9</b> Test de la lliçó 3</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html"><i class="fa fa-check"></i><b>4</b> Intervals de confiança</a>
<ul>
<li class="chapter" data-level="4.1" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#definició-dinterval-de-confiança"><i class="fa fa-check"></i><b>4.1</b> Definició d’interval de confiança</a></li>
<li class="chapter" data-level="4.2" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#exemple-interval-de-confiança-del-95-per-a-la-mitjana-duna-variable-aleatòria-normal"><i class="fa fa-check"></i><b>4.2</b> Exemple: Interval de confiança del 95% per a la mitjana d’una variable aleatòria normal</a></li>
<li class="chapter" data-level="4.3" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#interval-de-confiança-per-a-la-mitjana-basat-en-la-t-de-student"><i class="fa fa-check"></i><b>4.3</b> Interval de confiança per a la mitjana basat en la t de Student</a>
<ul>
<li class="chapter" data-level="" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#la-fórmula"><i class="fa fa-check"></i>La fórmula</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#algunes-consideracions"><i class="fa fa-check"></i>Algunes consideracions</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#amb-r-1"><i class="fa fa-check"></i>Amb R</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#càlcul-de-la-mida-de-la-mostra-per-fixar-lerror"><i class="fa fa-check"></i>Càlcul de la mida de la mostra per fixar l’error</a></li>
</ul></li>
<li class="chapter" data-level="4.4" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#intervals-de-confiança-per-a-proporcions"><i class="fa fa-check"></i><b>4.4</b> Intervals de confiança per a proporcions</a>
<ul>
<li class="chapter" data-level="" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#mètode-exacte-de-clopper-pearson"><i class="fa fa-check"></i>Mètode “exacte” de Clopper-Pearson</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#mètode-de-wilson"><i class="fa fa-check"></i>Mètode de Wilson</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#mètode-de-laplace"><i class="fa fa-check"></i>Mètode de Laplace</a></li>
<li><a href="intervals-de-confiança.html#quan-podem-calcular-més-dun-interval-per-a-p_x-quin-calculam">Quan podem calcular més d’un interval per a <span class="math inline">\(p_X\)</span>, quin calculam?</a></li>
<li class="chapter" data-level="" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#càlcul-de-la-mida-de-la-mostra-per-a-fitar-lerror"><i class="fa fa-check"></i>Càlcul de la mida de la mostra per a fitar l’error</a></li>
</ul></li>
<li class="chapter" data-level="4.5" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#intervals-de-confiança-per-a-la-variància-i-la-desviació-típica-duna-variable-normal"><i class="fa fa-check"></i><b>4.5</b> Intervals de confiança per a la variància i la desviació típica d’una variable normal</a></li>
<li class="chapter" data-level="4.6" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#poblacions-finites"><i class="fa fa-check"></i><b>4.6</b> “Poblacions finites”</a></li>
<li class="chapter" data-level="4.7" data-path="intervals-de-confiança.html"><a href="intervals-de-confiança.html#test-de-la-lliçó-4"><i class="fa fa-check"></i><b>4.7</b> Test de la lliçó 4</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="contrastos-dhipòtesis-generalitats.html"><a href="contrastos-dhipòtesis-generalitats.html"><i class="fa fa-check"></i><b>5</b> Contrastos d’hipòtesis: Generalitats</a>
<ul>
<li class="chapter" data-level="5.1" data-path="contrastos-dhipòtesis-generalitats.html"><a href="contrastos-dhipòtesis-generalitats.html#les-hipòtesis-nulla-i-alternativa"><i class="fa fa-check"></i><b>5.1</b> Les hipòtesis nul·la i alternativa</a></li>
<li class="chapter" data-level="5.2" data-path="contrastos-dhipòtesis-generalitats.html"><a href="contrastos-dhipòtesis-generalitats.html#sec:moneda"><i class="fa fa-check"></i><b>5.2</b> Un exemple</a></li>
<li class="chapter" data-level="5.3" data-path="contrastos-dhipòtesis-generalitats.html"><a href="contrastos-dhipòtesis-generalitats.html#sec:pval"><i class="fa fa-check"></i><b>5.3</b> El p-valor</a></li>
<li class="chapter" data-level="5.4" data-path="contrastos-dhipòtesis-generalitats.html"><a href="contrastos-dhipòtesis-generalitats.html#tipus-derrors"><i class="fa fa-check"></i><b>5.4</b> Tipus d’errors</a></li>
<li class="chapter" data-level="5.5" data-path="contrastos-dhipòtesis-generalitats.html"><a href="contrastos-dhipòtesis-generalitats.html#sec:exttest"><i class="fa fa-check"></i><b>5.5</b> Exemple: El test t</a></li>
<li class="chapter" data-level="5.6" data-path="contrastos-dhipòtesis-generalitats.html"><a href="contrastos-dhipòtesis-generalitats.html#interval-de-confiança-dun-contrast"><i class="fa fa-check"></i><b>5.6</b> Interval de confiança d’un contrast</a></li>
<li class="chapter" data-level="5.7" data-path="contrastos-dhipòtesis-generalitats.html"><a href="contrastos-dhipòtesis-generalitats.html#la-potència"><i class="fa fa-check"></i><b>5.7</b> La potència</a></li>
<li class="chapter" data-level="5.8" data-path="contrastos-dhipòtesis-generalitats.html"><a href="contrastos-dhipòtesis-generalitats.html#recapitulació"><i class="fa fa-check"></i><b>5.8</b> Recapitulació</a></li>
<li class="chapter" data-level="5.9" data-path="contrastos-dhipòtesis-generalitats.html"><a href="contrastos-dhipòtesis-generalitats.html#el-risc-de-positiu-fals-opcional"><i class="fa fa-check"></i><b>5.9</b> El risc de positiu fals (Opcional)</a></li>
<li class="chapter" data-level="5.10" data-path="contrastos-dhipòtesis-generalitats.html"><a href="contrastos-dhipòtesis-generalitats.html#test-de-la-lliçó-5"><i class="fa fa-check"></i><b>5.10</b> Test de la lliçó 5</a></li>
</ul></li>
<li class="chapter" data-level="6" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><i class="fa fa-check"></i><b>6</b> Contrastos d’hipòtesis d’un i dos paràmetres</a>
<ul>
<li class="chapter" data-level="6.1" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#contrastos-de-mitjanes"><i class="fa fa-check"></i><b>6.1</b> Contrastos de mitjanes</a>
<ul>
<li class="chapter" data-level="6.1.1" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#test-t-per-a-una-mitjana"><i class="fa fa-check"></i><b>6.1.1</b> Test t per a una mitjana</a></li>
<li class="chapter" data-level="6.1.2" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#test-t-per-a-dues-mitjanes"><i class="fa fa-check"></i><b>6.1.2</b> Test t per a dues mitjanes</a></li>
<li class="chapter" data-level="6.1.3" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#tests-t-amb-r"><i class="fa fa-check"></i><b>6.1.3</b> Tests t amb R</a></li>
<li class="chapter" data-level="6.1.4" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#exemples"><i class="fa fa-check"></i><b>6.1.4</b> Exemples</a></li>
<li class="chapter" data-level="6.1.5" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#tests-no-paramètrics"><i class="fa fa-check"></i><b>6.1.5</b> Tests no paramètrics</a></li>
</ul></li>
<li class="chapter" data-level="6.2" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#sec:contrvar"><i class="fa fa-check"></i><b>6.2</b> Contrastos de variàncies</a>
<ul>
<li class="chapter" data-level="6.2.1" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#test-chi2-duna-variància"><i class="fa fa-check"></i><b>6.2.1</b> Test <span class="math inline">\(\chi^2\)</span> d’una variància</a></li>
<li class="chapter" data-level="6.2.2" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#test-f-per-a-dues-variàncies"><i class="fa fa-check"></i><b>6.2.2</b> Test F per a dues variàncies</a></li>
<li class="chapter" data-level="6.2.3" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#tests-no-paramètrics-1"><i class="fa fa-check"></i><b>6.2.3</b> Tests no paramètrics</a></li>
</ul></li>
<li class="chapter" data-level="6.3" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#contrastos-per-a-proporcions"><i class="fa fa-check"></i><b>6.3</b> Contrastos per a proporcions</a>
<ul>
<li class="chapter" data-level="6.3.1" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#contrastos-per-a-una-proporció"><i class="fa fa-check"></i><b>6.3.1</b> Contrastos per a una proporció</a></li>
<li class="chapter" data-level="6.3.2" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#contrastos-per-a-2-proporcions-emprant-mostres-independents"><i class="fa fa-check"></i><b>6.3.2</b> Contrastos per a 2 proporcions emprant mostres independents</a></li>
<li class="chapter" data-level="6.3.3" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#contrastos-per-a-2-proporcions-emprant-mostres-aparellades"><i class="fa fa-check"></i><b>6.3.3</b> Contrastos per a 2 proporcions emprant mostres aparellades</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="contrastos-dhipòtesis-dun-i-dos-paràmetres.html"><a href="contrastos-dhipòtesis-dun-i-dos-paràmetres.html#test-de-la-lliçó-6"><i class="fa fa-check"></i><b>6.4</b> Test de la lliçó 6</a></li>
</ul></li>
<li class="chapter" data-level="7" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html"><i class="fa fa-check"></i><b>7</b> Contrastos de bondat d’ajust</a>
<ul>
<li class="chapter" data-level="7.1" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#bondat-dajust"><i class="fa fa-check"></i><b>7.1</b> Bondat d’ajust</a></li>
<li class="chapter" data-level="7.2" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#test-chi2-de-pearson"><i class="fa fa-check"></i><b>7.2</b> Test <span class="math inline">\(\chi^2\)</span> de Pearson</a>
<ul>
<li class="chapter" data-level="7.2.1" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#el-test-bàsic"><i class="fa fa-check"></i><b>7.2.1</b> El test bàsic</a></li>
<li class="chapter" data-level="7.2.2" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#mètode-de-montecarlo"><i class="fa fa-check"></i><b>7.2.2</b> Mètode de Montecarlo</a></li>
<li class="chapter" data-level="7.2.3" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#test-chi2-amb-paràmetres-poblacionals-desconeguts"><i class="fa fa-check"></i><b>7.2.3</b> Test <span class="math inline">\(\chi^2\)</span> amb paràmetres poblacionals desconeguts</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#test-de-kolmogorov-smirnov"><i class="fa fa-check"></i><b>7.3</b> Test de Kolmogorov-Smirnov</a></li>
<li class="chapter" data-level="7.4" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#test-de-kolmogorov-smirnov-lilliefors"><i class="fa fa-check"></i><b>7.4</b> Test de Kolmogorov-Smirnov-Lilliefors</a></li>
<li class="chapter" data-level="7.5" data-path="contrastos-de-bondat-dajust.html"><a href="contrastos-de-bondat-dajust.html#test-de-la-lliçó-7"><i class="fa fa-check"></i><b>7.5</b> Test de la lliçó 7</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="contrastos-dindependència-i-homogeneïtat.html"><a href="contrastos-dindependència-i-homogeneïtat.html"><i class="fa fa-check"></i><b>8</b> Contrastos d’independència i homogeneïtat</a>
<ul>
<li class="chapter" data-level="8.1" data-path="contrastos-dindependència-i-homogeneïtat.html"><a href="contrastos-dindependència-i-homogeneïtat.html#test-chi2-dindependència"><i class="fa fa-check"></i><b>8.1</b> Test <span class="math inline">\(\chi^2\)</span> d’independència</a></li>
<li class="chapter" data-level="8.2" data-path="contrastos-dindependència-i-homogeneïtat.html"><a href="contrastos-dindependència-i-homogeneïtat.html#test-chi2-dhomogeneïtat"><i class="fa fa-check"></i><b>8.2</b> Test <span class="math inline">\(\chi^2\)</span> d’homogeneïtat</a></li>
<li class="chapter" data-level="8.3" data-path="contrastos-dindependència-i-homogeneïtat.html"><a href="contrastos-dindependència-i-homogeneïtat.html#test-chi2-de-tendència-opcional"><i class="fa fa-check"></i><b>8.3</b> Test <span class="math inline">\(\chi^2\)</span> de tendència (Opcional)</a></li>
<li class="chapter" data-level="8.4" data-path="contrastos-dindependència-i-homogeneïtat.html"><a href="contrastos-dindependència-i-homogeneïtat.html#test-de-la-lliçó-8"><i class="fa fa-check"></i><b>8.4</b> Test de la lliçó 8</a></li>
</ul></li>
<li class="chapter" data-level="9" data-path="introducció-a-lestadística-multidimensional.html"><a href="introducció-a-lestadística-multidimensional.html"><i class="fa fa-check"></i><b>9</b> Introducció a l’estadística multidimensional</a>
<ul>
<li class="chapter" data-level="9.1" data-path="introducció-a-lestadística-multidimensional.html"><a href="introducció-a-lestadística-multidimensional.html#poblacions-vectors-aleatoris"><i class="fa fa-check"></i><b>9.1</b> Poblacions: vectors aleatoris</a>
<ul>
<li class="chapter" data-level="9.1.1" data-path="introducció-a-lestadística-multidimensional.html"><a href="introducció-a-lestadística-multidimensional.html#covariància"><i class="fa fa-check"></i><b>9.1.1</b> Covariància</a></li>
<li class="chapter" data-level="9.1.2" data-path="introducció-a-lestadística-multidimensional.html"><a href="introducció-a-lestadística-multidimensional.html#correlació"><i class="fa fa-check"></i><b>9.1.2</b> Correlació</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="introducció-a-lestadística-multidimensional.html"><a href="introducció-a-lestadística-multidimensional.html#estadística-descriptiva-mostres"><i class="fa fa-check"></i><b>9.2</b> Estadística descriptiva: Mostres</a>
<ul>
<li class="chapter" data-level="9.2.1" data-path="introducció-a-lestadística-multidimensional.html"><a href="introducció-a-lestadística-multidimensional.html#covariàncies"><i class="fa fa-check"></i><b>9.2.1</b> Covariàncies</a></li>
<li class="chapter" data-level="9.2.2" data-path="introducció-a-lestadística-multidimensional.html"><a href="introducció-a-lestadística-multidimensional.html#correlació-de-pearson"><i class="fa fa-check"></i><b>9.2.2</b> Correlació de Pearson</a></li>
<li class="chapter" data-level="9.2.3" data-path="introducció-a-lestadística-multidimensional.html"><a href="introducció-a-lestadística-multidimensional.html#estimació"><i class="fa fa-check"></i><b>9.2.3</b> Estimació</a></li>
<li class="chapter" data-level="9.2.4" data-path="introducció-a-lestadística-multidimensional.html"><a href="introducció-a-lestadística-multidimensional.html#correlació-de-spearman"><i class="fa fa-check"></i><b>9.2.4</b> Correlació de Spearman</a></li>
<li class="chapter" data-level="9.2.5" data-path="introducció-a-lestadística-multidimensional.html"><a href="introducció-a-lestadística-multidimensional.html#contrastos-de-correlació"><i class="fa fa-check"></i><b>9.2.5</b> Contrastos de correlació</a></li>
</ul></li>
<li class="chapter" data-level="9.3" data-path="introducció-a-lestadística-multidimensional.html"><a href="introducció-a-lestadística-multidimensional.html#test-de-la-lliçó-9"><i class="fa fa-check"></i><b>9.3</b> Test de la lliçó 9</a></li>
</ul></li>
<li class="chapter" data-level="10" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html"><i class="fa fa-check"></i><b>10</b> ANOVA</a>
<ul>
<li class="chapter" data-level="10.1" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#nocions-bàsiques"><i class="fa fa-check"></i><b>10.1</b> Nocions bàsiques</a></li>
<li class="chapter" data-level="10.2" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#anova-d1-via"><i class="fa fa-check"></i><b>10.2</b> ANOVA d’1 via</a>
<ul>
<li class="chapter" data-level="10.2.1" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#contrast-bàsic"><i class="fa fa-check"></i><b>10.2.1</b> Contrast bàsic</a></li>
<li class="chapter" data-level="10.2.2" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#amb-r-2"><i class="fa fa-check"></i><b>10.2.2</b> Amb R</a></li>
<li class="chapter" data-level="10.2.3" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#comparacions-posteriors-per-parelles"><i class="fa fa-check"></i><b>10.2.3</b> Comparacions posteriors per parelles</a></li>
<li class="chapter" data-level="10.2.4" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#comprovació-de-les-condicions"><i class="fa fa-check"></i><b>10.2.4</b> Comprovació de les condicions</a></li>
<li class="chapter" data-level="10.2.5" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#test-no-paramètric"><i class="fa fa-check"></i><b>10.2.5</b> Test no paramètric</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#anova-de-blocs"><i class="fa fa-check"></i><b>10.3</b> ANOVA de blocs</a>
<ul>
<li class="chapter" data-level="10.3.1" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#contrast-bàsic-1"><i class="fa fa-check"></i><b>10.3.1</b> Contrast bàsic</a></li>
<li class="chapter" data-level="10.3.2" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#amb-r-3"><i class="fa fa-check"></i><b>10.3.2</b> Amb R</a></li>
<li class="chapter" data-level="10.3.3" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#comparacions-posteriors-per-parelles-1"><i class="fa fa-check"></i><b>10.3.3</b> Comparacions posteriors per parelles</a></li>
<li class="chapter" data-level="10.3.4" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#contrast-no-paramètric"><i class="fa fa-check"></i><b>10.3.4</b> Contrast no paramètric</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#anova-de-2-vies"><i class="fa fa-check"></i><b>10.4</b> ANOVA de 2 vies</a>
<ul>
<li class="chapter" data-level="10.4.1" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#contrast-bàsic-2"><i class="fa fa-check"></i><b>10.4.1</b> Contrast bàsic</a></li>
<li class="chapter" data-level="10.4.2" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#amb-r-4"><i class="fa fa-check"></i><b>10.4.2</b> Amb R</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="chap:ANOVA.html"><a href="chap:ANOVA.html#test-de-la-lliçó-10"><i class="fa fa-check"></i><b>10.5</b> Test de la lliçó 10</a></li>
</ul></li>
<li class="chapter" data-level="11" data-path="regressió-lineal.html"><a href="regressió-lineal.html"><i class="fa fa-check"></i><b>11</b> Regressió lineal</a>
<ul>
<li class="chapter" data-level="11.1" data-path="regressió-lineal.html"><a href="regressió-lineal.html#regressió-lineal-simple"><i class="fa fa-check"></i><b>11.1</b> Regressió lineal simple</a>
<ul>
<li class="chapter" data-level="11.1.1" data-path="regressió-lineal.html"><a href="regressió-lineal.html#el-model"><i class="fa fa-check"></i><b>11.1.1</b> El model</a></li>
<li class="chapter" data-level="11.1.2" data-path="regressió-lineal.html"><a href="regressió-lineal.html#mínims-quadrats"><i class="fa fa-check"></i><b>11.1.2</b> Mínims quadrats</a></li>
<li class="chapter" data-level="11.1.3" data-path="regressió-lineal.html"><a href="regressió-lineal.html#coeficient-de-determinació"><i class="fa fa-check"></i><b>11.1.3</b> Coeficient de determinació</a></li>
<li class="chapter" data-level="11.1.4" data-path="regressió-lineal.html"><a href="regressió-lineal.html#intervals-de-confiança-dels-coeficients"><i class="fa fa-check"></i><b>11.1.4</b> Intervals de confiança dels coeficients</a></li>
<li class="chapter" data-level="11.1.5" data-path="regressió-lineal.html"><a href="regressió-lineal.html#intervals-de-confiança-per-a-les-estimacions-de-la-variable-dependent"><i class="fa fa-check"></i><b>11.1.5</b> Intervals de confiança per a les estimacions de la variable dependent</a></li>
<li class="chapter" data-level="11.1.6" data-path="regressió-lineal.html"><a href="regressió-lineal.html#té-sentit-una-regressió-lineal"><i class="fa fa-check"></i><b>11.1.6</b> Té sentit una regressió lineal?</a></li>
</ul></li>
<li class="chapter" data-level="11.2" data-path="regressió-lineal.html"><a href="regressió-lineal.html#regressió-lineal-múltiple"><i class="fa fa-check"></i><b>11.2</b> Regressió lineal múltiple</a>
<ul>
<li class="chapter" data-level="11.2.1" data-path="regressió-lineal.html"><a href="regressió-lineal.html#mínims-quadrats-1"><i class="fa fa-check"></i><b>11.2.1</b> Mínims quadrats</a></li>
<li class="chapter" data-level="11.2.2" data-path="regressió-lineal.html"><a href="regressió-lineal.html#coeficient-de-determinació-múltiple"><i class="fa fa-check"></i><b>11.2.2</b> Coeficient de determinació múltiple</a></li>
<li class="chapter" data-level="11.2.3" data-path="regressió-lineal.html"><a href="regressió-lineal.html#coeficient-de-determinació-ajustat"><i class="fa fa-check"></i><b>11.2.3</b> Coeficient de determinació ajustat</a></li>
<li class="chapter" data-level="11.2.4" data-path="regressió-lineal.html"><a href="regressió-lineal.html#intervals-de-confiança-per-als-coeficients"><i class="fa fa-check"></i><b>11.2.4</b> Intervals de confiança per als coeficients</a></li>
<li class="chapter" data-level="11.2.5" data-path="regressió-lineal.html"><a href="regressió-lineal.html#intervals-de-confiança-per-a-les-estimacions-de-la-variable-resposta"><i class="fa fa-check"></i><b>11.2.5</b> Intervals de confiança per a les estimacions de la variable resposta</a></li>
<li class="chapter" data-level="11.2.6" data-path="regressió-lineal.html"><a href="regressió-lineal.html#lanova-de-la-regressió-lineal-múltiple"><i class="fa fa-check"></i><b>11.2.6</b> L’ANOVA de la regressió lineal múltiple</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="regressió-lineal.html"><a href="regressió-lineal.html#test-de-la-lliçó-11"><i class="fa fa-check"></i><b>11.3</b> Test de la lliçó 11</a></li>
</ul></li>
</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Matemàtiques II v.2021</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="regressió-lineal" class="section level1" number="11">
<h1><span class="header-section-number">Tema 11</span> Regressió lineal</h1>
<p>Comencem recordant un exemple de Matemàtiques I.</p>

<div class="example">
<p><span id="exm:edats1" class="example"><strong>Exemple 11.1  </strong></span>La taula següent dóna l’alçada mitjana (en cm) dels nins a determinades edats (en anys):</p>
</div>
<table>
<thead>
<tr>
<th style="text-align:right;">
edat
</th>
<th style="text-align:right;">
alçada
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
75
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
92
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
108
</td>
</tr>
<tr>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
121
</td>
</tr>
<tr>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
130
</td>
</tr>
<tr>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
142
</td>
</tr>
<tr>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
155
</td>
</tr>
</tbody>
</table>
<p>A Matemàtiques I aprenguéreu a calcular amb R la “millor” relació lineal
<span class="math display">\[
\text{alçada}= b_0+b_1\cdot\text{edat}
\]</span>
de la manera següent:</p>
<div class="sourceCode" id="cb682"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb682-1"><a href="regressió-lineal.html#cb682-1" aria-hidden="true" tabindex="-1"></a>edat<span class="ot">=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">9</span>,<span class="dv">11</span>,<span class="dv">13</span>)</span>
<span id="cb682-2"><a href="regressió-lineal.html#cb682-2" aria-hidden="true" tabindex="-1"></a>alçada<span class="ot">=</span><span class="fu">c</span>(<span class="dv">75</span>,<span class="dv">92</span>,<span class="dv">108</span>,<span class="dv">121</span>,<span class="dv">130</span>,<span class="dv">142</span>,<span class="dv">155</span>)</span>
<span id="cb682-3"><a href="regressió-lineal.html#cb682-3" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(alçada<span class="sc">~</span>edat)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = alçada ~ edat)
## 
## Coefficients:
## (Intercept)         edat  
##      72.321        6.464</code></pre>
<p>Obteníeu d’aquesta manera la recta
<span class="math display">\[
\text{alçada}=72.321+6.464x
\]</span>
i la representàveu amb:</p>
<div class="sourceCode" id="cb684"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb684-1"><a href="regressió-lineal.html#cb684-1" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(edat,alçada,<span class="at">pch=</span><span class="dv">20</span>)</span>
<span id="cb684-2"><a href="regressió-lineal.html#cb684-2" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(alçada<span class="sc">~</span>edat),<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">xlab=</span><span class="st">&quot;Edat&quot;</span>,<span class="at">ylab=</span><span class="st">&quot;Alçada&quot;</span>)</span></code></pre></div>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-784-1.png" width="50%" style="display: block; margin: auto;" /></p>
<p>Ara podíeu emprar aquesta recta per estimar l’alçada d’un nin d’una edat concreta. Per exemple, ens permet estimar que l’alçada d’un nin d’10 anys és
<span class="math display">\[
72.321+6.464\cdot 10=136.964,
\]</span>
uns 137 cm.</p>
<p>En aquest tema estudiarem com es calcula aquella recta, què vol dir que sigui “la millor recta” que explica l’alçada dels nins en funció de l’edat, com trobar intervals de confiança per a les estimacions associades a aquesta recta i com tractar el problema més general de trobar “la millor funció lineal” que explica una variable <span class="math inline">\(Y\)</span> en funció de diverses variables <span class="math inline">\(X_1,\ldots,X_k\)</span>.</p>
<div id="regressió-lineal-simple" class="section level2" number="11.1">
<h2><span class="header-section-number">11.1</span> Regressió lineal simple</h2>
<p>El problema plantejat a l’Exemple <a href="regressió-lineal.html#exm:edats1">11.1</a> és una instància de la situació general en la qual tenim parelles d’observacions de dues variables <span class="math inline">\(X\)</span> i <span class="math inline">\(Y\)</span> sobre una mostra de <span class="math inline">\(n\geqslant 2\)</span> subjectes,
<span class="math display">\[
(x_i,y_i)_{i=1,2,\ldots,n},
\]</span>
i volem estudiar com depèn el valor de la variable <span class="math inline">\(Y\)</span> del de <span class="math inline">\(X\)</span>. En aquest context:</p>
<ul>
<li><p>Direm que <span class="math inline">\(X\)</span> és la variable <strong>de control</strong> o <strong>independent</strong></p></li>
<li><p>Direm que <span class="math inline">\(Y\)</span> l’anomenam la variable <strong>de resposta</strong> o <strong>dependent</strong></p></li>
</ul>

<div class="rmdnote">
La variable de control no té per què ser aleatòria: nosaltres podem fixar el seu valor sobre els subjectes. Per exemple, la variable <span class="math inline">\(X\)</span> podria ser la dosi d’una medicació i que nosaltres decidíssim a cada individu, de manera planificada i gens aleatòria, quina dosi li administram. En canvi, la variable de resposta ha de ser aleatòria. Si no, no té sentit estimar res sobre ella.
</div>
<p>En general, volem trobar la millor relació funcional (el millor <strong>model estadístic</strong>, amb la terminologia introduïda en el tema anterior) que expliqui la variable <span class="math inline">\(Y\)</span> en funció de la variable <span class="math inline">\(X\)</span>. En aquest tema, cercarem un <strong>model lineal</strong>. Les tècniques que es fan servir per resoldre aquest problema s’anomenen genèricament de <strong>regressió lineal</strong>. Nosaltres n’estudiarem una de concreta: la <strong>regressió lineal per mínims quadrats</strong>.</p>

<div class="rmdnote">
El nom “regressió” per parlar del tipus de tècniques que permeten ajustar una recta a un conjunt de punts prové del títol d’un article de Galton d’1886, <em>Regression Towards Mediocrity in Hereditary Stature</em>. En aquest article hi va analitzar les alçades d’una mostra de 928 adults i les alçades mitjanes dels seus pares. Hi observà que els pares alts tendien a tenir fills més baixos que ells i que els pares baixos tendien a tenir fills més alts que ells. D’aquest efecte en digué “regressió a la mediocritat” al títol de l’article. D’aquí s’adoptà el terme “regressió” per descriure la tècnica que emprà per obtenir la recta vermella del gràfic següent, amb la qual suportava la seva conclusió comparant-la amb la diagonal (la línia discontínua), i amb el temps el nom de l’efecte que observà es canvià al menys ofensiu “regressió a la mitjana”. Més endavant tornarem sobre aquest exemple.
</div>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-787-1.png" width="50%" style="display: block; margin: auto;" /></p>
<div id="el-model" class="section level3" number="11.1.1">
<h3><span class="header-section-number">11.1.1</span> El model</h3>
<p>En el <strong>model de regressió lineal</strong> suposam que existeixen <span class="math inline">\(\beta_0,\beta_1\in \mathbb{R}\)</span> tals que
<span class="math display">\[
\mu_{Y|x}=\beta_0+\beta_1 x
\]</span>
on <span class="math inline">\(\mu_{Y|x}\)</span> és el valor esperat de <span class="math inline">\(Y\)</span> sobre els subjectes per als quals <span class="math inline">\(X\)</span> val <span class="math inline">\(x\)</span>. Volem estimar aquests paràmetres <span class="math inline">\(\beta_0\)</span> (el <strong>terme independent</strong> del model) i <span class="math inline">\(\beta_1\)</span> (la <strong>pendent</strong> del model) a partir d’una mostra.</p>

<div class="rmdimportant">
<p>Recordau la interpretació d’una funció lineal <span class="math inline">\(y=a_0+a_1x\)</span>:</p>
<ul>
<li><p>El terme independent <span class="math inline">\(a_0\)</span> és el valor de <span class="math inline">\(y\)</span> quan <span class="math inline">\(x=0\)</span></p></li>
<li><p>La pendent <span class="math inline">\(a_1\)</span> és la variació de <span class="math inline">\(y\)</span> quan <span class="math inline">\(x\)</span> augmenta en 1 unitat</p></li>
</ul>
<p>Per tant, en el nostre model de regressió lineal:</p>
<ul>
<li><p><span class="math inline">\(\beta_0\)</span> és el valor esperat de <span class="math inline">\(Y\)</span> en els subjectes en els quals <span class="math inline">\(X\)</span> val 0</p></li>
<li><p><span class="math inline">\(\beta_1\)</span> és la variació del valor esperat de <span class="math inline">\(Y\)</span> quan el valor de <span class="math inline">\(X\)</span> augmenta 1 unitat</p></li>
</ul>
</div>
<p>Amb una mostra <span class="math inline">\((x_i,y_i)_{i=1,2,\ldots,n}\)</span>, calcularem estimacions <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span> de
<span class="math inline">\(\beta_0\)</span> i <span class="math inline">\(\beta_1\)</span>. Això ens donarà la <strong>recta de regressió</strong> per a la nostra mostra:
<span class="math display">\[
\widehat{Y}=b_0+b_1 X.
\]</span>
Aquesta recta, donat un valor <span class="math inline">\(x_0\)</span> de <span class="math inline">\(X\)</span>, permet estimar el valor <span class="math inline">\(\widehat{y}_0=b_0+b_1 x_0\)</span> de <span class="math inline">\(Y\)</span> sobre un subjecte en el qual <span class="math inline">\(X\)</span> valgui <span class="math inline">\(x_0\)</span>. Hi empram <span class="math inline">\(\widehat{Y}\)</span> a la dreta per posar èmfasi que no és que <span class="math inline">\(Y\)</span> sigui <span class="math inline">\(b_0+b_1X\)</span>, sinó que això darrer estima el valor de <span class="math inline">\(Y\)</span> a partir del valor de <span class="math inline">\(X\)</span>. En concret, si <span class="math inline">\(\widehat{y}_0=b_0+b_1 x_0\)</span>, direm a <span class="math inline">\(\widehat{y}_0\)</span> el <strong>valor estimat</strong> de <span class="math inline">\(Y\)</span> quan <span class="math inline">\(X=x_0\)</span>.</p>

<div class="rmdcaution">
<p>Fixau-vos que, d’aquesta manera, donada una observació <span class="math inline">\((x_i,y_i)\)</span> de la nostra mostra, distingim entre</p>
<ul>
<li><p><span class="math inline">\(y_i\)</span>: el valor de <span class="math inline">\(Y\)</span> sobre l’individu corresponent</p></li>
<li><p><span class="math inline">\(\widehat{y}_i=b_0+b_1 x_i\)</span>: l’estimació del valor de <span class="math inline">\(Y\)</span> sobre l’individu corresponent a partir del seu valor de <span class="math inline">\(X\)</span> i la recta de regressió obtinguda</p></li>
</ul>
</div>
<p>El model anterior el reescrivim com a
<span class="math display">\[
Y|x=\mu_{Y|x}+ E_x=\beta_0+\beta_1 x+ E_x
\]</span>
on</p>
<ul>
<li><p><span class="math inline">\(Y|x\)</span> és la variable aleatòria <strong>“valor de <span class="math inline">\(Y\)</span> quan <span class="math inline">\(X\)</span> val <span class="math inline">\(x\)</span>”</strong>: Prenem un subjecte en el qual <span class="math inline">\(X\)</span> val <span class="math inline">\(x\)</span> i hi mesuram <span class="math inline">\(Y\)</span></p></li>
<li><p><span class="math inline">\(\mu_{Y|x}\)</span> és el valor esperat de <span class="math inline">\(Y|x\)</span>, és a dir, la mitjana dels valors de <span class="math inline">\(Y\)</span> sobre tots els individus en els quals <span class="math inline">\(X\)</span> valgui <span class="math inline">\(x\)</span></p></li>
<li><p><span class="math inline">\(E_x=Y|x -\mu_{Y|x}\)</span> és la variable aleatòria <strong>error</strong> o <strong>residu</strong>, que dóna la diferència entre el valor de <span class="math inline">\(Y\)</span> en un individu amb <span class="math inline">\(X=x\)</span> i el seu valor esperat</p></li>
</ul>
<p>Prenent valors esperats als dos costats de la igualtat <span class="math inline">\(Y|x=\mu_{Y|x}+ E_x\)</span> obtenim que <span class="math inline">\(\mu_{Y|x}=\mu_{Y|x}+ \mu_{E_x}\)</span> i per tant que <span class="math inline">\(\mu_{E_x}=0\)</span>. Així doncs, aquest model implica que <strong>els valors esperats de les variables error <span class="math inline">\(E_x\)</span> són tots 0</strong>.</p>
</div>
<div id="mínims-quadrats" class="section level3" number="11.1.2">
<h3><span class="header-section-number">11.1.2</span> Mínims quadrats</h3>
<p>L’<strong>error</strong> que cometem amb l’estimació <span class="math inline">\(\widehat{y}_i=b_0+b_1x_i\)</span> a cada observació <span class="math inline">\((x_i,y_i)\)</span> de la mostra és
<span class="math display">\[
e_i=y_i-\widehat{y}_i=y_i-(b_0+b_1 x_i)
\]</span></p>
<p>La <strong>Suma dels Quadrats dels Errors</strong> d’aquesta estimació és
<span class="math display">\[
SS_E=\sum_{i=1}^n e_i^2=\sum_{i=1}^n (y_i-b_0-b_1 x_i)^2
\]</span>
A la <strong>regressió lineal per mínims quadrats</strong>, s’estimen <span class="math inline">\(\beta_0\)</span> i <span class="math inline">\(\beta_1\)</span> per mitjà dels valors de <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span> que minimitzen aquesta <span class="math inline">\(SS_E\)</span>. Aquests valors són donats pel resultat següent:</p>

<div class="theorem">
<span id="thm:RLS" class="theorem"><strong>Teorema 11.1  </strong></span>Els estimadors <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span> per mínims quadrats de <span class="math inline">\(\beta_0\)</span> i <span class="math inline">\(\beta_1\)</span> són
<span class="math display">\[
b_1 =\frac{{s}_{xy}}{{s}_x^2}=\frac{\widetilde{s}_{xy}}{\widetilde{s}_x^2},\quad b_0 = \overline{y}-b_1 \overline{x}.
\]</span>
</div>

<div class="rmdcorbes">
<p>Per trobar-los, empram que els valors de <span class="math inline">\(b_0,b_1\)</span> que fan mínim
<span class="math display">\[
SS_E=\sum_{i=1}^n (y_i-b_0-b_1 x_i)^2
\]</span>
anul·len les derivades de <span class="math inline">\(SS_E\)</span> respecte de <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span>.</p>
<p>Derivem:
<span class="math display">\[
\begin{array}{l}
\displaystyle\dfrac{\partial SS_E}{\partial b_0}=-2\sum\limits_{i=1}^n (y_i -b_0-b_1 x_i)\\[2ex]
\displaystyle\dfrac{\partial SS_E}{\partial b_1}=-2\sum\limits_{i=1}^n (y_i -b_0-b_1 x_i) x_i 
\end{array}
\]</span>
El <span class="math inline">\((b_0,b_1)\)</span> que cercam satisfà
<span class="math display">\[
\begin{array}{l}
\displaystyle 2\sum\limits_{i=1}^n (y_i -b_0-b_1 x_i)=0\\[2ex]
\displaystyle 2\sum\limits_{i=1}^n (y_i -b_0-b_1 x_i) x_i =0
\end{array}
\]</span>
Ho reescrivim:
<span class="math display">\[
\begin{array}{rl}
\displaystyle n b_0 + \Big(\sum\limits_{i=1}^n x_i\Big) b_1 &amp; =\sum\limits_{i=1}^n y_i\\[1ex]
\displaystyle \Big(\sum\limits_{i=1}^n x_i\Big) b_0 + \Big(\sum\limits_{i=1}^n x_i^2\Big) b_1 &amp;=\sum\limits_{i=1}^n x_iy_i
\end{array}
\]</span>
Les solucions són
<span class="math display">\[
\begin{array}{rl}
b_1&amp; \displaystyle=\frac{n \sum\limits_{i=1}^n x_i y_i-\sum\limits_{i=1}^n x_i\sum\limits_{i=1}^n y_i} {n\sum\limits_{i=1}^n
x_i^2-\big(\sum\limits_{i=1}^n x_i\big)^2}\\[6ex]
b_0&amp; \displaystyle=\frac{\sum\limits_{i=1}^n y_i -b_1 \sum\limits_{i=1}^n x_i}{n}
\end{array}
\]</span>
i es pot comprovar que donen el mínim de <span class="math inline">\(SS_E\)</span>.</p>
Ara, recordant que
<span class="math display">\[
\begin{array}{l}
\displaystyle\overline{x}=\frac{1}{n}\sum\limits_{i=1}^n x_i,
\quad \overline{y}=\frac{1}{n} \sum\limits_{i=1}^n y_i\\[2ex]
\displaystyle s_x^2  =\frac{1}{n}\Big(\sum_{i=1}^n x_i^2\Big) -\overline{x}^2,\quad
\displaystyle s_y^2  =\frac{1}{n}\Big(\sum_{i=1}^n y_i^2\Big) -\overline{y}^2\\[2ex]
\displaystyle s_{xy}  =\frac{1}{n}\Big(\sum_{i=1}^n x_i y_i\Big)-\overline{x}\cdot\overline{y}
\end{array}
\]</span>
s’obté finalment que
<span class="math display">\[
b_1 =\frac{{s}_{xy}}{{s}_x^2},\quad b_0 = \overline{y}-b_1 \overline{x}
\]</span>
</div>
<p>La igualtat
<span class="math display">\[
\frac{{s}_{xy}}{{s}_x^2}=\frac{\widetilde{s}_{xy}}{\widetilde{s}_x^2}
\]</span>
és conseqüència que, a les dues fraccions, els denominadors del numerador i el denominador se cancel·len:
<span class="math display">\[
\frac{{s}_{xy}}{{s}_x^2}=\frac{\frac{\sum_{i=1}^n (x_i-\overline{x})(y_i-\overline{y})}{n}}{\frac{\sum_{i=1}^n (x_i-\overline{x})^2}{n}}=\frac{{\sum_{i=1}^n (x_i-\overline{x})(y_i-\overline{y})}}{{\sum_{i=1}^n (x_i-\overline{x})^2}}=\frac{\frac{\sum_{i=1}^n (x_i-\overline{x})(y_i-\overline{y})}{n-1}}{\frac{\sum_{i=1}^n (x_i-\overline{x})^2}{n-1}}=
\frac{\widetilde{s}_{xy}}{\widetilde{s}_x^2}
\]</span></p>
<p>Aquests <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span> són els que calcula la funció <code>lm</code>.</p>

<div class="example">
<p><span id="exm:edats" class="example"><strong>Exemple 11.2  </strong></span>Calculem la recta de regressió per mínims quadrats de les edats i alçades de l’Exemple <a href="regressió-lineal.html#exm:edats1">11.1</a>, que eren</p>
</div>
<table>
<thead>
<tr>
<th style="text-align:right;">
edat
</th>
<th style="text-align:right;">
alçada
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
75
</td>
</tr>
<tr>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
92
</td>
</tr>
<tr>
<td style="text-align:right;">
5
</td>
<td style="text-align:right;">
108
</td>
</tr>
<tr>
<td style="text-align:right;">
7
</td>
<td style="text-align:right;">
121
</td>
</tr>
<tr>
<td style="text-align:right;">
9
</td>
<td style="text-align:right;">
130
</td>
</tr>
<tr>
<td style="text-align:right;">
11
</td>
<td style="text-align:right;">
142
</td>
</tr>
<tr>
<td style="text-align:right;">
13
</td>
<td style="text-align:right;">
155
</td>
</tr>
</tbody>
</table>
<p>Començarem trobant els estadístics que ens calen per calcular els coeficients <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span>. Ja que hi som, també trobarem la variància de les alçades, que per calcular <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span> no ens fa falta però que més tard sí que necessitarem saber-la:</p>
<div class="sourceCode" id="cb685"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb685-1"><a href="regressió-lineal.html#cb685-1" aria-hidden="true" tabindex="-1"></a>edat<span class="ot">=</span><span class="fu">c</span>(<span class="dv">1</span>,<span class="dv">3</span>,<span class="dv">5</span>, <span class="dv">7</span>, <span class="dv">9</span>, <span class="dv">11</span>, <span class="dv">13</span>)</span>
<span id="cb685-2"><a href="regressió-lineal.html#cb685-2" aria-hidden="true" tabindex="-1"></a>alçada<span class="ot">=</span><span class="fu">c</span>(<span class="dv">75</span>, <span class="dv">92</span>, <span class="dv">108</span>, <span class="dv">121</span>, <span class="dv">130</span> , <span class="dv">142</span>, <span class="dv">155</span>)</span>
<span id="cb685-3"><a href="regressió-lineal.html#cb685-3" aria-hidden="true" tabindex="-1"></a>x.b<span class="ot">=</span><span class="fu">mean</span>(edat)</span>
<span id="cb685-4"><a href="regressió-lineal.html#cb685-4" aria-hidden="true" tabindex="-1"></a>y.b<span class="ot">=</span><span class="fu">mean</span>(alçada)</span>
<span id="cb685-5"><a href="regressió-lineal.html#cb685-5" aria-hidden="true" tabindex="-1"></a>s2.x<span class="ot">=</span><span class="fu">var</span>(edat)</span>
<span id="cb685-6"><a href="regressió-lineal.html#cb685-6" aria-hidden="true" tabindex="-1"></a>s2.y<span class="ot">=</span><span class="fu">var</span>(alçada)</span>
<span id="cb685-7"><a href="regressió-lineal.html#cb685-7" aria-hidden="true" tabindex="-1"></a>s.xy<span class="ot">=</span><span class="fu">cov</span>(edat,alçada)</span>
<span id="cb685-8"><a href="regressió-lineal.html#cb685-8" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">c</span>(x.b,y.b,s2.x,s2.y,s.xy),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1]   7.000 117.571  18.667 786.952 120.667</code></pre>
<p>Obtenim
<span class="math display">\[
\begin{array}{cccccccc}
\overline{x} &amp;  \overline{y} &amp; \widetilde{s}_x^2 &amp; \widetilde{s}_y^2 &amp; \widetilde{s}_{xy}\\ \hline
7 &amp; 117.571 &amp; 18.667 &amp; 786.952 &amp; 120.667
\end{array}
\]</span>
Aleshores
<span class="math display">\[
\begin{array}{l}
\displaystyle b_1 =\frac{\widetilde{s}_{xy}}{\widetilde{s}_x^2}=\frac{120.667}{18.667}=6.464\\[2ex]
\displaystyle b_0 = \overline{y}-b_1 \overline{x} =117.571-6.464\cdot 7=72.321
\end{array}
\]</span>
Trobam la recta de regressió
<span class="math display">\[
\widehat{Y}=72.321+6.464 X
\]</span>
que coincideix amb la recta que calcula <code>lm</code>:</p>
<div class="sourceCode" id="cb687"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb687-1"><a href="regressió-lineal.html#cb687-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(alçada<span class="sc">~</span>edat)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = alçada ~ edat)
## 
## Coefficients:
## (Intercept)         edat  
##      72.321        6.464</code></pre>
<p>Els coeficients <span class="math inline">\(b_0,b_1\)</span> s’obtenen, respectivament, afegint els sufixos <code>$coefficients[1]</code> i <code>$coefficients[2]</code> al resultat de la funció <code>lm</code>.</p>
<div class="sourceCode" id="cb689"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb689-1"><a href="regressió-lineal.html#cb689-1" aria-hidden="true" tabindex="-1"></a>b0.edat<span class="ot">=</span><span class="fu">lm</span>(alçada<span class="sc">~</span>edat)<span class="sc">$</span>coefficients[<span class="dv">1</span>]</span>
<span id="cb689-2"><a href="regressió-lineal.html#cb689-2" aria-hidden="true" tabindex="-1"></a>b0.edat</span></code></pre></div>
<pre><code>## (Intercept) 
##    72.32143</code></pre>
<div class="sourceCode" id="cb691"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb691-1"><a href="regressió-lineal.html#cb691-1" aria-hidden="true" tabindex="-1"></a>b1.edat<span class="ot">=</span><span class="fu">lm</span>(alçada<span class="sc">~</span>edat)<span class="sc">$</span>coefficients[<span class="dv">2</span>]</span>
<span id="cb691-2"><a href="regressió-lineal.html#cb691-2" aria-hidden="true" tabindex="-1"></a>b1.edat</span></code></pre></div>
<pre><code>##     edat 
## 6.464286</code></pre>
<p>Segons aquesta estimació, l’alçada mitjana dels nins augmenta 6.46 cm anuals, partint d’una alçada mitjana de 72.3 cm en néixer.</p>

<div class="rmdcaution">
Els càlculs involucrats en la regressió lineal són molt poc robusts, en el sentit que els arrodoniments poden influir molt en el resultat final. A <a href="\url%7Bhttp://en.wikipedia.org/wiki/Simple_linear_regression%7D">l’entrada sobre regressió lineal de la Wikipedia</a> hi trobareu un exemple detallat d’una regressió de pes en funció d’alçada. Calculada en metres dóna:
<span class="math display">\[
\widehat{Y}=61.272X-39.062
\]</span>
Si es passen les alçades a polzades, s’arrodoneixen, es calcula la recta de regressió, i es torna a passar el resultat a metres, dóna
<span class="math display">\[
\widehat{Y}=61.675X-39.746
\]</span>
La moralitat d’aquesta història és que, si feu els càlculs a mà, procurau no arrodonir fins al resultat final.
</div>

<div class="example">
<p><span id="exm:sal" class="example"><strong>Exemple 11.3  </strong></span>En un experiment on es volia estudiar l’associació entre el consum de sal i la tensió arterial, a alguns individus se’ls assignà aleatòriament una quantitat diària constant de sal en la seva dieta, i al cap d’un mes se’ls mesurà la tensió mitjana. Alguns resultats varen ser els següents:</p>
</div>
<table>
<thead>
<tr>
<th style="text-align:right;">
X (sal, en g)
</th>
<th style="text-align:right;">
Y (pressió, en mm de Hg)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
1.8
</td>
<td style="text-align:right;">
100
</td>
</tr>
<tr>
<td style="text-align:right;">
2.2
</td>
<td style="text-align:right;">
98
</td>
</tr>
<tr>
<td style="text-align:right;">
3.5
</td>
<td style="text-align:right;">
110
</td>
</tr>
<tr>
<td style="text-align:right;">
4.0
</td>
<td style="text-align:right;">
110
</td>
</tr>
<tr>
<td style="text-align:right;">
4.3
</td>
<td style="text-align:right;">
112
</td>
</tr>
<tr>
<td style="text-align:right;">
5.0
</td>
<td style="text-align:right;">
120
</td>
</tr>
</tbody>
</table>
<p>Volem trobar la recta de regressió lineal per mínims quadrats de <span class="math inline">\(Y\)</span> en funció de <span class="math inline">\(X\)</span> a partir d’aquesta mostra.</p>
<p>Calculem els estadístics que necessitam:</p>
<div class="sourceCode" id="cb693"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb693-1"><a href="regressió-lineal.html#cb693-1" aria-hidden="true" tabindex="-1"></a>sal<span class="ot">=</span><span class="fu">c</span>(<span class="fl">1.8</span>, <span class="fl">2.2</span>,<span class="fl">3.5</span>,<span class="fl">4.0</span>,<span class="fl">4.3</span>,<span class="fl">5.0</span>)</span>
<span id="cb693-2"><a href="regressió-lineal.html#cb693-2" aria-hidden="true" tabindex="-1"></a>tensió<span class="ot">=</span><span class="fu">c</span>(<span class="dv">100</span>,<span class="dv">98</span>,<span class="dv">110</span>,<span class="dv">110</span>,<span class="dv">112</span>,<span class="dv">120</span>)</span>
<span id="cb693-3"><a href="regressió-lineal.html#cb693-3" aria-hidden="true" tabindex="-1"></a>x.b<span class="ot">=</span><span class="fu">mean</span>(sal)</span>
<span id="cb693-4"><a href="regressió-lineal.html#cb693-4" aria-hidden="true" tabindex="-1"></a>y.b<span class="ot">=</span><span class="fu">mean</span>(tensió)</span>
<span id="cb693-5"><a href="regressió-lineal.html#cb693-5" aria-hidden="true" tabindex="-1"></a>s2.x<span class="ot">=</span><span class="fu">var</span>(sal)</span>
<span id="cb693-6"><a href="regressió-lineal.html#cb693-6" aria-hidden="true" tabindex="-1"></a>s2.y<span class="ot">=</span><span class="fu">var</span>(tensió)</span>
<span id="cb693-7"><a href="regressió-lineal.html#cb693-7" aria-hidden="true" tabindex="-1"></a>s.xy<span class="ot">=</span><span class="fu">cov</span>(sal,tensió)</span>
<span id="cb693-8"><a href="regressió-lineal.html#cb693-8" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">c</span>(x.b,y.b,s2.x,s2.y,s.xy),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1]   3.467 108.333   1.543  66.267   9.773</code></pre>
<p><span class="math display">\[
\begin{array}{ccccc}
\overline{x} &amp;  \overline{y} &amp; \widetilde{s}_x^2 &amp; \widetilde{s}_y^2 &amp; \widetilde{s}_{xy}\\ \hline
3.467 &amp; 108.333 &amp; 1.543 &amp; 66.267 &amp; 9.773
\end{array}
\]</span></p>
<p>Per tant els coeficients de la recta de regressió lineal per mínims quadrats de <span class="math inline">\(Y\)</span> (la tensió) en funció de <span class="math inline">\(X\)</span> (la quantitat de sal) són</p>
<div class="sourceCode" id="cb695"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb695-1"><a href="regressió-lineal.html#cb695-1" aria-hidden="true" tabindex="-1"></a>b1.sal<span class="ot">=</span>s.xy<span class="sc">/</span>s2.x</span>
<span id="cb695-2"><a href="regressió-lineal.html#cb695-2" aria-hidden="true" tabindex="-1"></a>b0.sal<span class="ot">=</span>y.b<span class="sc">-</span>b1.sal<span class="sc">*</span>x.b</span>
<span id="cb695-3"><a href="regressió-lineal.html#cb695-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">c</span>(b0.sal,b1.sal),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 86.371  6.335</code></pre>
<p>Obtenim la recta
<span class="math display">\[
\widehat{Y}= 86.371+6.335 X
\]</span>
Segons aquest model, a un augment d’1 g de sal consumida li correspon un augment mitjà de 6.3 mm Hg de pressió arterial.</p>
<p>Així mateix, amb aquest model estimam, per exemple, que la pressió arterial d’una persona que consumeix 3 g diaris de sal és
<span class="math display">\[
86.371+6.335 \cdot 3=105.377\text{ mm Hg}
\]</span></p>
<p>Comprovem que aquesta és la recta que obtenim amb la funció <code>lm</code>:</p>
<div class="sourceCode" id="cb697"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb697-1"><a href="regressió-lineal.html#cb697-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(tensió<span class="sc">~</span>sal)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>## (Intercept)         sal 
##    86.37079     6.33535</code></pre>

<div class="example">
<span id="exm:Galton" class="example"><strong>Exemple 11.4  </strong></span>Estimem la recta de regressió de les alçades dels fills en funció de les dels pares emprant les dades recollides per Galton. Aquestes dades formen el dataframe <code>Galton</code> del paquet <strong>HistData</strong>.
</div>
<div class="sourceCode" id="cb699"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb699-1"><a href="regressió-lineal.html#cb699-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(HistData)</span>
<span id="cb699-2"><a href="regressió-lineal.html#cb699-2" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(Galton)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    928 obs. of  2 variables:
##  $ parent: num  70.5 68.5 65.5 64.5 64 67.5 67.5 67.5 66.5 66.5 ...
##  $ child : num  61.7 61.7 61.7 61.7 61.7 62.2 62.2 62.2 62.2 62.2 ...</code></pre>
<p>Cada filera del dataframe correspon a un adult: la variable <code>child</code> dóna la seva alçada i la variable <code>parent</code> la mitjana de les alçades dels seus pares, totes dues en polzades (recordau que 1 polzada són 2.54 cm). Calculem a mà i amb R la recta de regressió de la variable de resposta <code>child</code> en funció de la variable de control <code>parent</code>:</p>
<div class="sourceCode" id="cb701"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb701-1"><a href="regressió-lineal.html#cb701-1" aria-hidden="true" tabindex="-1"></a>x.b<span class="ot">=</span><span class="fu">mean</span>(Galton<span class="sc">$</span>parent)</span>
<span id="cb701-2"><a href="regressió-lineal.html#cb701-2" aria-hidden="true" tabindex="-1"></a>y.b<span class="ot">=</span><span class="fu">mean</span>(Galton<span class="sc">$</span>child)</span>
<span id="cb701-3"><a href="regressió-lineal.html#cb701-3" aria-hidden="true" tabindex="-1"></a>s2.x<span class="ot">=</span><span class="fu">var</span>(Galton<span class="sc">$</span>parent)</span>
<span id="cb701-4"><a href="regressió-lineal.html#cb701-4" aria-hidden="true" tabindex="-1"></a>s2.y<span class="ot">=</span><span class="fu">var</span>(Galton<span class="sc">$</span>child)</span>
<span id="cb701-5"><a href="regressió-lineal.html#cb701-5" aria-hidden="true" tabindex="-1"></a>s.xy<span class="ot">=</span><span class="fu">cov</span>(Galton<span class="sc">$</span>parent,Galton<span class="sc">$</span>child)</span>
<span id="cb701-6"><a href="regressió-lineal.html#cb701-6" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">c</span>(x.b,y.b,s2.x,s2.y,s.xy),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 68.308 68.088  3.195  6.340  2.065</code></pre>
<p><span class="math display">\[
\begin{array}{ccccc}
\overline{x} &amp;  \overline{y} &amp; \widetilde{s}_x^2 &amp; \widetilde{s}_y^2 &amp; \widetilde{s}_{xy}\\ \hline
68.308 &amp; 68.088 &amp; 3.195 &amp; 6.34 &amp; 2.065
\end{array}
\]</span></p>
<p>Per tant els coeficients de la recta de regressió lineal per mínims quadrats de <span class="math inline">\(Y\)</span> (l’alçada dels fills) en funció de <span class="math inline">\(X\)</span> (la mitjana de les alçades dels pares) són</p>
<div class="sourceCode" id="cb703"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb703-1"><a href="regressió-lineal.html#cb703-1" aria-hidden="true" tabindex="-1"></a>b1.Galton<span class="ot">=</span>s.xy<span class="sc">/</span>s2.x</span>
<span id="cb703-2"><a href="regressió-lineal.html#cb703-2" aria-hidden="true" tabindex="-1"></a>b0.Galton<span class="ot">=</span>y.b<span class="sc">-</span>b1.Galton<span class="sc">*</span>x.b</span>
<span id="cb703-3"><a href="regressió-lineal.html#cb703-3" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(<span class="fu">c</span>(b0.Galton,b1.Galton),<span class="dv">3</span>)</span></code></pre></div>
<pre><code>## [1] 23.942  0.646</code></pre>
<p>Obtenim la recta
<span class="math display">\[
\widehat{Y}= 23.942+0.646 X
\]</span>
Segons aquest model, a un augment d’1 polzada (2.54 cm) en l’alçada mitjana dels pares li correspon, de mitjana, un augment de l’alçada del fill de només 0.646 polzades (1.6 cm).</p>
<p>Amb la funció <code>lm</code> obtenim la mateixa recta. Observau la sintaxi per especificar-hi el dataframe</p>
<div class="sourceCode" id="cb705"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb705-1"><a href="regressió-lineal.html#cb705-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(child<span class="sc">~</span>parent, <span class="at">data=</span>Galton)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>## (Intercept)      parent 
##  23.9415302   0.6462906</code></pre>
<p>El fet que la pendent d’aquesta recta sigui més petita que 1 és el que dóna l’efecte de “regressió a la mediocritat” que observà Galton. En efecte, calculem per a quines alçades mitjanes dels pares esperam que els fills siguin més baixos que ells. Si resolem la desigualtat “alçada dels pares més gran que l’alçada esperada dels fills”
<span class="math display">\[
X\geqslant \widehat{Y}=  23.942+0.646 X
\]</span>
obtenim
<span class="math display">\[
X\geqslant \frac{23.942}{1-0.646}=67.69
\]</span>
i això ens diu que si l’alçada mitjana dels pares és més gran que 67.69 polzades, uns 1.72 m, esperam que els fills siguin més baixos que els pares, mentre que, pel contrari, si l’alçada mitjana dels pares està per davall dels 1.72 m, esperam que els fills siguin més alts que els pares.</p>
<p>Algunes de les propietats importants de la regressió per mínims quadrats són:</p>
<ul>
<li><p>Tal i com hem calculat el terme independent <span class="math inline">\(b_0\)</span>, la recta de regressió passa pel punt mitjà <span class="math inline">\((\overline{x},\overline{y})\)</span> de la mostra:
<span class="math display">\[
b_0+b_1 \overline{x}=\overline{y}
\]</span></p></li>
<li><p>La mitjana dels valors estimats de la variable <span class="math inline">\(Y\)</span> als nostres punts és igual a la mitjana dels valors observats:
<span class="math display">\[
\overline{\widehat{y}}=\frac{1}{n}\sum_{i=1}^n\widehat{y}_i
=\frac{1}{n}\sum_{i=1}^n(b_0+b_1x_i)= b_0+b_1 \overline{x}=\overline{y}
\]</span></p></li>
<li><p>Els errors <span class="math inline">\((e_i)_{i=1,\ldots,n}\)</span> de la mostra tenen mitjana 0:
<span class="math display">\[
\begin{array}{l}
\overline{e}
 &amp; \displaystyle =\frac{1}{n}\sum_{i=1}^n e_i
=\frac{1}{n}\sum_{i=1}^n (y_i-b_0-b_1x)
=\frac{1}{n}\sum_{i=1}^n (y_i-\widehat{y}_i)\\[2ex]
&amp; \displaystyle
=\frac{1}{n}\sum_{i=1}^n{y}_i-\frac{1}{n}\sum_{i=1}^n\widehat{y}_i=
\overline{y}-\overline{\widehat{y}}
=0
\end{array}
\]</span></p></li>
<li><p>Els errors <span class="math inline">\((e_i)_{i=1,\ldots,n}\)</span> de la mostra tenen variància
<span class="math display">\[
s_e^2=\frac{1}{n}\Big(\sum_{i=1}^{n}
e^2_i\Big)-\overline{e}^2=\frac{\sum_{i=1}^{n}
e^2_i}{n}=\frac{SS_E}{n}
\]</span>
perquè <span class="math inline">\(\overline{e}=0\)</span> (i recordau que hem dit a <span class="math inline">\(\sum_{i=1}^{n} e^2_i\)</span> la <strong>Suma de Quadrats dels Errors</strong>,<br />
<span class="math inline">\(SS_E\)</span>).</p></li>
</ul>
<p>El teorema següent recull les propietats de la regressió lineal per mínims quadrats com a tècnica d’estimació dels coeficients <span class="math inline">\(\beta_0\)</span> i <span class="math inline">\(\beta_1\)</span>:</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-804" class="theorem"><strong>Teorema 11.2  </strong></span>Si les variables aleatòries error <span class="math inline">\(E_{x_i}\)</span> tenen totes mitjana 0 i la mateixa variància <span class="math inline">\(\sigma^2_E\)</span> i són, dues a dues, incorrelades, aleshores:</p>
<ul>
<li><p><span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span> són els estimadors lineals no esbiaixats més eficients (<strong>òptims</strong>) de <span class="math inline">\(\beta_0\)</span> i <span class="math inline">\(\beta_1\)</span></p></li>
<li><p>Un estimador no esbiaixat de <span class="math inline">\(\sigma_E^2\)</span> és
<span class="math display">\[
S^2=\frac{SS_E}{n-2}
\]</span></p></li>
</ul>
<p>Si <strong>a més</strong> les variables aleatòries error <span class="math inline">\(E_{x_i}\)</span> són totes <strong>normals</strong>, aleshores:</p>
<ul>
<li><span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span> són els estimadors màxim versemblants de <span class="math inline">\(\beta_0\)</span> i <span class="math inline">\(\beta_1\)</span> (a més de no esbiaixats òptims).
</div></li>
</ul>

<div class="example">
<p><span id="exm:edats5" class="example"><strong>Exemple 11.5  </strong></span>Si suposam a l’Exemple <a href="regressió-lineal.html#exm:edats1">11.1</a> que els errors tenen la mateixa variància i són incorrelats, podem estimar aquesta variància de la manera següent:</p>
</div>
<div class="sourceCode" id="cb707"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb707-1"><a href="regressió-lineal.html#cb707-1" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="fu">length</span>(edat)</span>
<span id="cb707-2"><a href="regressió-lineal.html#cb707-2" aria-hidden="true" tabindex="-1"></a>alçada.cap<span class="ot">=</span>b0.edat<span class="sc">+</span>b1.edat<span class="sc">*</span>edat   <span class="co">#Els valors estimats</span></span>
<span id="cb707-3"><a href="regressió-lineal.html#cb707-3" aria-hidden="true" tabindex="-1"></a>errors.edat<span class="ot">=</span>alçada<span class="sc">-</span>alçada.cap  <span class="co">#Els errors</span></span>
<span id="cb707-4"><a href="regressió-lineal.html#cb707-4" aria-hidden="true" tabindex="-1"></a>SS.E<span class="ot">=</span><span class="fu">sum</span>(errors.edat<span class="sc">^</span><span class="dv">2</span>)  <span class="co">#La suma dels quadrats dels errors</span></span>
<span id="cb707-5"><a href="regressió-lineal.html#cb707-5" aria-hidden="true" tabindex="-1"></a>S2.edat<span class="ot">=</span>SS.E<span class="sc">/</span>(n<span class="dv">-2</span>)  <span class="co">#L&#39;estimació de la variància</span></span>
<span id="cb707-6"><a href="regressió-lineal.html#cb707-6" aria-hidden="true" tabindex="-1"></a>S2.edat</span></code></pre></div>
<pre><code>## [1] 8.314286</code></pre>
<p>Tenim que <span class="math inline">\(S^2=8.314\)</span>, i estimam que <span class="math inline">\(\sigma_E^2\)</span> val això.</p>

<div class="rmdnote">
No sabem si us hi heu fixat, però perquè la regressió lineal per mínims quadrats tengui bones propietats, <strong>no cal que la variable <span class="math inline">\(Y\)</span></strong> (i molt menys la <span class="math inline">\(X\)</span>, que no cal ni que sigui aleatòria) <strong>sigui normal</strong>. Qui han de ser normals (i amb mitjana 0, la mateixa variància i dues a dues incorrelades) han de ser les variables error.
</div>
<p>Bé, fins ara hem explicat com s’estimen per mínims quadrats els coeficients <span class="math inline">\(\beta_0\)</span> i <span class="math inline">\(\beta_1\)</span> al model
<span class="math display">\[
\mu_{Y|x}=\beta_0+\beta_1 x
\]</span>
però ens pot interessar més:</p>
<ul>
<li><p>Com és de significativa l’estimació obtinguda?</p></li>
<li><p>Quin és l’error típic d’aquests estimadors?</p></li>
<li><p>Quins serien els intervals de confiança d’aquests coeficients per a un nivell de confiança donat?</p></li>
<li><p>Com obtenim un interval de confiança per al valor estimat de <span class="math inline">\(Y\)</span> sobre un subjecte a partir del seu valor de <span class="math inline">\(X\)</span>?</p></li>
</ul>
<p>Amb la funció <code>lm</code>, R calcula molt més que els coeficients de la recta:</p>
<div class="sourceCode" id="cb709"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb709-1"><a href="regressió-lineal.html#cb709-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(alçada<span class="sc">~</span>edat))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = alçada ~ edat)
## 
## Residuals:
##       1       2       3       4       5       6       7 
## -3.7857  0.2857  3.3571  3.4286 -0.5000 -1.4286 -1.3571 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  72.3214     2.1966   32.92 4.86e-07 ***
## edat          6.4643     0.2725   23.73 2.48e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.883 on 5 degrees of freedom
## Multiple R-squared:  0.9912, Adjusted R-squared:  0.9894 
## F-statistic: 562.9 on 1 and 5 DF,  p-value: 2.477e-06</code></pre>
<p>Veurem què és tot això que ens dóna R i per què serveix.</p>
<p>D’entrada, pot ser útil saber que el vector <code>Residuals</code> (que s’obté amb el sufix <code>$residuals</code>) conté el vector dels errors <span class="math inline">\((e_i)_i\)</span>. Comprovem-ho amb les dades de l’Exemple <a href="regressió-lineal.html#exm:edats1">11.1</a>, els residus de les quals hem calculat a l’Exemple <a href="regressió-lineal.html#exm:edats5">11.5</a>:</p>
<div class="sourceCode" id="cb711"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb711-1"><a href="regressió-lineal.html#cb711-1" aria-hidden="true" tabindex="-1"></a>errors.edat</span></code></pre></div>
<pre><code>## [1] -3.7857143  0.2857143  3.3571429  3.4285714 -0.5000000 -1.4285714 -1.3571429</code></pre>
<div class="sourceCode" id="cb713"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb713-1"><a href="regressió-lineal.html#cb713-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(alçada<span class="sc">~</span>edat))<span class="sc">$</span>residuals</span></code></pre></div>
<pre><code>##          1          2          3          4          5          6          7 
## -3.7857143  0.2857143  3.3571429  3.4285714 -0.5000000 -1.4285714 -1.3571429</code></pre>
</div>
<div id="coeficient-de-determinació" class="section level3" number="11.1.3">
<h3><span class="header-section-number">11.1.3</span> Coeficient de determinació</h3>
<p>Una primera pregunta que ens hem de fer és si la recta de regressió lineal que hem obtingut s’ajusta bé a la mostra obtinguda. Amb un enfocament proper al de l’ANOVA,</p>
<blockquote>
<p>Consideram que la recta de regressió <span class="math inline">\(\widehat{Y}=b_0+b_1X\)</span> ens dóna una bona aproximació de <span class="math inline">\(Y\)</span> com a funció lineal de <span class="math inline">\(X\)</span> sobre la nostra mostra quan la variabilitat dels valors estimats <span class="math inline">\(\widehat{y}_i\)</span> representa una fracció molt gran de la variabilitat dels valors observats <span class="math inline">\(y_i\)</span>.</p>
</blockquote>
<p>Això es quantifica amb el <strong>coeficient de determinació</strong> <span class="math inline">\(R^2\)</span> que tot seguit definim.</p>
<p>Siguin:</p>
<ul>
<li><p><span class="math inline">\(SS_{Tot} =\sum\limits_{i=1}^n(y_i-\overline{y})^2\)</span>: és la <strong>Suma Total de Quadrats</strong> i representa la <strong>variabilitat dels valors observats <span class="math inline">\(y_i\)</span></strong>. Fixau-vos que
<span class="math display">\[
SS_{Tot}=n\cdot s_y^2
\]</span></p></li>
<li><p><span class="math inline">\(SS_R=\sum\limits_{i=1}^n(\widehat{y}_i-\overline{y})^2\)</span>: és la <strong>Suma de Quadrats de la Regressió</strong> i representa la <strong>variabilitat dels valors estimats <span class="math inline">\(\widehat{y}_i\)</span></strong>. Fixau-vos que
<span class="math display">\[
SS_R=n\cdot s_{\widehat{y}}^2
\]</span></p></li>
</ul>
<p>Considerarem que la recta <span class="math inline">\(\widehat{y}=b_0+b_1x\)</span> és una bona aproximació de <span class="math inline">\(Y\)</span> com a funció lineal de <span class="math inline">\(X\)</span> sobre la nostra mostra quan <span class="math inline">\(s^2_{\widehat{y}}\)</span> sigui molt proper a <span class="math inline">\(s^2_y\)</span>. Per mesurar-ho, emprarem el <strong>coeficient de determinació</strong> <span class="math inline">\(R^2\)</span>, que és simplement el seu quocient:
<span class="math display">\[
R^2=\frac{SS_R}{SS_{Tot}}=\frac{s_{\widehat{y}}^2}{s_y^2}
\]</span></p>
<p>Recordau ara que hem definit la <strong>Suma de Quadrats dels Errors</strong> <span class="math inline">\(SS_E=\sum\limits_{i=1}^n(y_i-\widehat{y}_i)^2\)</span> i que
<span class="math display">\[
SS_E=n\cdot s_e^2
\]</span>
on <span class="math inline">\(s_e^2\)</span> és la variància dels errors. A la regressió lineal per mínims quadrats s’hi satisfà la <strong>identitat de les sumes de quadrats</strong> següent:</p>

<div class="theorem">
<span id="thm:unnamed-chunk-809" class="theorem"><strong>Teorema 11.3  </strong></span>En una regressió lineal pel mètode de mínims quadrats,
<span class="math display">\[
SS_{Tot}=SS_R+SS_E
\]</span>
o equivalentment (dividint per la mida <span class="math inline">\(n\)</span> de la mostra),
<span class="math display">\[
s^2_y=s^2_{\widehat{y}}+s^2_e.
\]</span>
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-810" class="example"><strong>Exemple 11.6  </strong></span>Comprovem aquesta igualtat amb les dades de l’Exemple <a href="regressió-lineal.html#exm:edats1">11.1</a>:</p>
</div>
<div class="sourceCode" id="cb715"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb715-1"><a href="regressió-lineal.html#cb715-1" aria-hidden="true" tabindex="-1"></a>SS.Tot<span class="ot">=</span><span class="fu">sum</span>((alçada<span class="sc">-</span><span class="fu">mean</span>(alçada))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb715-2"><a href="regressió-lineal.html#cb715-2" aria-hidden="true" tabindex="-1"></a>SS.R<span class="ot">=</span><span class="fu">sum</span>((alçada.cap<span class="sc">-</span><span class="fu">mean</span>(alçada))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb715-3"><a href="regressió-lineal.html#cb715-3" aria-hidden="true" tabindex="-1"></a>SS.E<span class="ot">=</span><span class="fu">sum</span>(errors.edat<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb715-4"><a href="regressió-lineal.html#cb715-4" aria-hidden="true" tabindex="-1"></a><span class="fu">c</span>(SS.Tot,SS.R,SS.E)</span></code></pre></div>
<pre><code>## [1] 4721.71429 4680.14286   41.57143</code></pre>
<div class="sourceCode" id="cb717"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb717-1"><a href="regressió-lineal.html#cb717-1" aria-hidden="true" tabindex="-1"></a>SS.R<span class="sc">+</span>SS.E</span></code></pre></div>
<pre><code>## [1] 4721.714</code></pre>
<p>Així, doncs, a la regressió per mínims quadrats</p>
<blockquote>
<p>la variabilitat dels valors observats <span class="math inline">\(y_i\)</span> de <span class="math inline">\(Y\)</span> és igual a la suma de la variabilitat dels valors estimats <span class="math inline">\(\widehat{y}_i\)</span> de <span class="math inline">\(Y\)</span> més la variabilitat dels errors.</p>
</blockquote>
<p>Aleshores, si la regressió lineal és per mínims quadrats,
<span class="math display">\[
R^2=\frac{SS_R}{SS_{Tot}}=\frac{SS_{Tot}-SS_E}{SS_{Tot}}=1-\frac{SS_E}{SS_{Tot}}=1-\frac{s_e^2}{s_y^2}
\]</span>
En particular:</p>

<div class="rmdimportant">
En una regressió per mínims quadrats, <span class="math inline">\(R^2\leqslant 1\)</span>, i <span class="math inline">\(R^2= 1\)</span> exactament quan tots els <span class="math inline">\(e_i\)</span> són 0, és a dir, quan <span class="math inline">\(\widehat{y}_i=y_i\)</span> per a tot <span class="math inline">\(i=1,\ldots,n\)</span>. Com més gran (més proper a 1) sigui <span class="math inline">\(R^2\)</span>, més bona entendrem que és la regressió lineal.
</div>

<div class="rmdnote">
Per si de cas no hi heu caigut, observau que <span class="math inline">\(R^2\geqslant 0\)</span>, perquè és un quocient de quadrats. Només val 0 quan <span class="math inline">\(s^2_{\widehat{y}}=0\)</span>, és a dir, quan tots els valors estimats <span class="math inline">\(\widehat{y}_i\)</span> són iguals (i això només passa quan <span class="math inline">\(b_1=0\)</span>, és a dir, quan <span class="math inline">\(s_{x,y}=0\)</span>).
</div>
<p>R dóna el <span class="math inline">\(R^2\)</span> en el <code>summary(lm( ))</code>: és el valor <code>Multiple R-squared</code> a la penúltima línia de la seva sortida:</p>
<div class="sourceCode" id="cb719"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb719-1"><a href="regressió-lineal.html#cb719-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(alçada<span class="sc">~</span>edat))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = alçada ~ edat)
## 
## Residuals:
##       1       2       3       4       5       6       7 
## -3.7857  0.2857  3.3571  3.4286 -0.5000 -1.4286 -1.3571 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  72.3214     2.1966   32.92 4.86e-07 ***
## edat          6.4643     0.2725   23.73 2.48e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.883 on 5 degrees of freedom
## Multiple R-squared:  0.9912, Adjusted R-squared:  0.9894 
## F-statistic: 562.9 on 1 and 5 DF,  p-value: 2.477e-06</code></pre>
<p>S’obté directament del <code>summary(lm( ))</code> amb el sufix <code>$r.squared</code></p>
<div class="sourceCode" id="cb721"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb721-1"><a href="regressió-lineal.html#cb721-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(alçada<span class="sc">~</span>edat))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.9911957</code></pre>
<p>El resultat següent ja l’anunciàrem al Tema <a href="#chap:ED"><strong>??</strong></a>.</p>

<div class="theorem">
<span id="thm:unnamed-chunk-816" class="theorem"><strong>Teorema 11.4  </strong></span>En una regressió lineal per mínims quadrats, el coeficient de determinació és el quadrat de la correlació de Pearson de les mostres de les dues variables:
<span class="math display">\[
R^2=r_{x,y}^2
\]</span>
</div>

<div class="rmdcorbes">
<p>En efecte:
<span class="math display">\[
\begin{array}{rl}
R^2 &amp; \displaystyle =\frac{SS_R}{SS_{Tot}}=\frac{\sum\limits_{i=1}^n(b_1x_i+b_0-\overline{y})^2}{ns_y^2}\\[2ex] 
&amp; \displaystyle =\frac{\sum\limits_{i=1}^n\Big(\dfrac{s_{xy}}{s_x^2}x_i-\dfrac{s_{xy}}{s_x^2}\overline{x}\Big)^2}{ns_y^2} =\frac{\dfrac{s_{xy}^2}{s_x^4}\sum\limits_{i=1}^n(x_i-\overline{x})^2}{ns_y^2}\\[2ex] &amp; \displaystyle =\dfrac{s_{xy}^2}{s_x^4}\cdot \frac{s_x^2}{s_y^2}=\frac{s_{xy}^2}{s_x^2\cdot s_y^2}=r_{xy}^2
\end{array}
\]</span></p>
</div>

<div class="example">
<p><span id="exm:unnamed-chunk-818" class="example"><strong>Exemple 11.7  </strong></span>Comprovem-ho a l’Exemple <a href="regressió-lineal.html#exm:edats1">11.1</a>:</p>
</div>
<div class="sourceCode" id="cb723"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb723-1"><a href="regressió-lineal.html#cb723-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(alçada<span class="sc">~</span>edat))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.9911957</code></pre>
<div class="sourceCode" id="cb725"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb725-1"><a href="regressió-lineal.html#cb725-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(edat,alçada)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 0.9911957</code></pre>

<div class="example">
<p><span id="exm:unnamed-chunk-820" class="example"><strong>Exemple 11.8  </strong></span>Comprovem ara la identitat de les sumes de quadrats i la igualtat <span class="math inline">\(R^2=r^2\)</span> a l’Exemple <a href="regressió-lineal.html#exm:sal">11.3</a>:</p>
</div>
<div class="sourceCode" id="cb727"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb727-1"><a href="regressió-lineal.html#cb727-1" aria-hidden="true" tabindex="-1"></a>tensió.cap<span class="ot">=</span>b0.sal<span class="sc">+</span>b1.sal<span class="sc">*</span>sal <span class="co">#Els valors estimats</span></span>
<span id="cb727-2"><a href="regressió-lineal.html#cb727-2" aria-hidden="true" tabindex="-1"></a>SS.Tot<span class="ot">=</span><span class="fu">sum</span>((tensió<span class="sc">-</span><span class="fu">mean</span>(tensió))<span class="sc">^</span><span class="dv">2</span>) <span class="co">#La Suma Total de Quadrats</span></span>
<span id="cb727-3"><a href="regressió-lineal.html#cb727-3" aria-hidden="true" tabindex="-1"></a>SS.Tot</span></code></pre></div>
<pre><code>## [1] 331.3333</code></pre>
<div class="sourceCode" id="cb729"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb729-1"><a href="regressió-lineal.html#cb729-1" aria-hidden="true" tabindex="-1"></a>SS.R<span class="ot">=</span><span class="fu">sum</span>((tensió.cap<span class="sc">-</span><span class="fu">mean</span>(tensió))<span class="sc">^</span><span class="dv">2</span>) <span class="co">#La Suma de Quadrats de la Regressió</span></span>
<span id="cb729-2"><a href="regressió-lineal.html#cb729-2" aria-hidden="true" tabindex="-1"></a>SS.R</span></code></pre></div>
<pre><code>## [1] 309.5874</code></pre>
<div class="sourceCode" id="cb731"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb731-1"><a href="regressió-lineal.html#cb731-1" aria-hidden="true" tabindex="-1"></a>SS.E<span class="ot">=</span><span class="fu">sum</span>((tensió<span class="sc">-</span>tensió.cap)<span class="sc">^</span><span class="dv">2</span>) <span class="co">#La suma de Quadrats dels Errors</span></span>
<span id="cb731-2"><a href="regressió-lineal.html#cb731-2" aria-hidden="true" tabindex="-1"></a>SS.E</span></code></pre></div>
<pre><code>## [1] 21.74589</code></pre>
<p>Vegem que <span class="math inline">\(SS_R+SS_E\)</span> és igual a <span class="math inline">\(SS_{Tot}\)</span>:</p>
<div class="sourceCode" id="cb733"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb733-1"><a href="regressió-lineal.html#cb733-1" aria-hidden="true" tabindex="-1"></a>SS.R<span class="sc">+</span>SS.E</span></code></pre></div>
<pre><code>## [1] 331.3333</code></pre>
<p>Calculem ara <span class="math inline">\(R^2=SS_R/SS_{Tot}\)</span> i comprovem que coincideix amb el valor que dóna R i amb el quadrat de la correlació de Pearson de les mostres de quantitats de sal i tensions:</p>
<div class="sourceCode" id="cb735"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb735-1"><a href="regressió-lineal.html#cb735-1" aria-hidden="true" tabindex="-1"></a>R2<span class="ot">=</span>SS.R<span class="sc">/</span>SS.Tot</span>
<span id="cb735-2"><a href="regressió-lineal.html#cb735-2" aria-hidden="true" tabindex="-1"></a>R2</span></code></pre></div>
<pre><code>## [1] 0.9343685</code></pre>
<div class="sourceCode" id="cb737"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb737-1"><a href="regressió-lineal.html#cb737-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(tensió<span class="sc">~</span>sal))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.9343685</code></pre>
<div class="sourceCode" id="cb739"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb739-1"><a href="regressió-lineal.html#cb739-1" aria-hidden="true" tabindex="-1"></a><span class="fu">cor</span>(sal,tensió)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 0.9343685</code></pre>

<div class="rmdnote">
Fixau-vos que si coneixeu <span class="math inline">\(\widetilde{s}_y^2\)</span> (<code>var(y)</code>) i <span class="math inline">\(r_{x,y}\)</span> (<code>cor(x,y)</code>), llavors
<span class="math display">\[
r_{x,y}^2=R^2=1-\frac{s_e^2}{s_y^2}\Longrightarrow  s_e^2=s_y^2(1-r_{x,y}^2)
\]</span>
i per tant podeu calcular la <span class="math inline">\(S^2\)</span> que estima la variància comuna dels errors <span class="math inline">\(E_{x_i}\)</span> de la manera següent:
<span class="math display">\[
S^2=\frac{SS_E}{n-2}=\frac{n s_e^2}{n-2}=\frac{ns_y^2(1-r_{x,y}^2)}{n-2}=\frac{(n-1)\widetilde{s}_y^2(1-r_{x,y}^2)}{n-2}
\]</span>
Això us pot ser útil als exercicis.
</div>

<div class="rmdcaution">
El valor de <span class="math inline">\(R^2\)</span> no és suficient per valorar la bondat d’un model de regressió lineal. És sempre convenient també dibuixar els punts i la recta de regressió i donar una ullada.
</div>
<p>Un exemple clàssic de les mancances del <span class="math inline">\(R^2\)</span> són els quatre conjunts de dades <span class="math inline">\((x_{1,i},y_{1,i})_{i=1,\ldots,11}\)</span>, <span class="math inline">\((x_{2,i},y_{2,i})_{i=1,\ldots,11}\)</span>, <span class="math inline">\((x_{3,i},y_{3,i})_{i=1,\ldots,11}\)</span>, <span class="math inline">\((x_{4,i},y_{4,i})_{i=1,\ldots,11}\)</span> que formen el <em>dataframe</em> <code>anscombe</code> de R i que ja empràrem al Tema <a href="#chap:ED"><strong>??</strong></a>:</p>
<div class="sourceCode" id="cb741"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb741-1"><a href="regressió-lineal.html#cb741-1" aria-hidden="true" tabindex="-1"></a><span class="fu">str</span>(anscombe)</span></code></pre></div>
<pre><code>## &#39;data.frame&#39;:    11 obs. of  8 variables:
##  $ x1: num  10 8 13 9 11 14 6 4 12 7 ...
##  $ x2: num  10 8 13 9 11 14 6 4 12 7 ...
##  $ x3: num  10 8 13 9 11 14 6 4 12 7 ...
##  $ x4: num  8 8 8 8 8 8 8 19 8 8 ...
##  $ y1: num  8.04 6.95 7.58 8.81 8.33 ...
##  $ y2: num  9.14 8.14 8.74 8.77 9.26 8.1 6.13 3.1 9.13 7.26 ...
##  $ y3: num  7.46 6.77 12.74 7.11 7.81 ...
##  $ y4: num  6.58 5.76 7.71 8.84 8.47 7.04 5.25 12.5 5.56 7.91 ...</code></pre>
<p>Les rectes de regressió per mínims quadrats dels quatre conjunts de dades són gairebé iguals i donen valors de <span class="math inline">\(R^2\)</span> molt semblants:</p>
<div class="sourceCode" id="cb743"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb743-1"><a href="regressió-lineal.html#cb743-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y1<span class="sc">~</span>x1,<span class="at">data=</span>anscombe)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>## (Intercept)          x1 
##   3.0000909   0.5000909</code></pre>
<div class="sourceCode" id="cb745"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb745-1"><a href="regressió-lineal.html#cb745-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y1<span class="sc">~</span>x1,<span class="at">data=</span>anscombe))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.6665425</code></pre>
<div class="sourceCode" id="cb747"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb747-1"><a href="regressió-lineal.html#cb747-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y2<span class="sc">~</span>x2,<span class="at">data=</span>anscombe)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>## (Intercept)          x2 
##    3.000909    0.500000</code></pre>
<div class="sourceCode" id="cb749"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb749-1"><a href="regressió-lineal.html#cb749-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y2<span class="sc">~</span>x2,<span class="at">data=</span>anscombe))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.666242</code></pre>
<div class="sourceCode" id="cb751"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb751-1"><a href="regressió-lineal.html#cb751-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y3<span class="sc">~</span>x3,<span class="at">data=</span>anscombe)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>## (Intercept)          x3 
##   3.0024545   0.4997273</code></pre>
<div class="sourceCode" id="cb753"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb753-1"><a href="regressió-lineal.html#cb753-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y3<span class="sc">~</span>x3,<span class="at">data=</span>anscombe))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.666324</code></pre>
<div class="sourceCode" id="cb755"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb755-1"><a href="regressió-lineal.html#cb755-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y4<span class="sc">~</span>x4,<span class="at">data=</span>anscombe)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>## (Intercept)          x4 
##   3.0017273   0.4999091</code></pre>
<div class="sourceCode" id="cb757"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb757-1"><a href="regressió-lineal.html#cb757-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y4<span class="sc">~</span>x4,<span class="at">data=</span>anscombe))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.6667073</code></pre>
<p>Però si els dibuixam veureu que els seus ajusts a la recta de regressió són molt diferents:</p>
<div class="sourceCode" id="cb759"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb759-1"><a href="regressió-lineal.html#cb759-1" aria-hidden="true" tabindex="-1"></a><span class="fu">par</span>(<span class="at">mfrow=</span><span class="fu">c</span>(<span class="dv">2</span>,<span class="dv">2</span>))</span>
<span id="cb759-2"><a href="regressió-lineal.html#cb759-2" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(anscombe<span class="sc">$</span>x1,anscombe<span class="sc">$</span>y1,<span class="at">main=</span><span class="st">&quot;Conjunt de dades 1&quot;</span>,<span class="at">pch=</span><span class="dv">20</span>)</span>
<span id="cb759-3"><a href="regressió-lineal.html#cb759-3" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y1<span class="sc">~</span>x1,<span class="at">data=</span>anscombe),<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lwd=</span><span class="fl">1.5</span>)</span>
<span id="cb759-4"><a href="regressió-lineal.html#cb759-4" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(anscombe<span class="sc">$</span>x2,anscombe<span class="sc">$</span>y2,<span class="at">data=</span>anscombe,<span class="at">main=</span><span class="st">&quot;Conjunt de dades 2&quot;</span>,<span class="at">pch=</span><span class="dv">20</span>)</span>
<span id="cb759-5"><a href="regressió-lineal.html#cb759-5" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y2<span class="sc">~</span>x2,<span class="at">data=</span>anscombe),<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lwd=</span><span class="fl">1.5</span>)</span>
<span id="cb759-6"><a href="regressió-lineal.html#cb759-6" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(anscombe<span class="sc">$</span>x3,anscombe<span class="sc">$</span>y3,<span class="at">main=</span><span class="st">&quot;Conjunt de dades 3&quot;</span>,<span class="at">pch=</span><span class="dv">20</span>)</span>
<span id="cb759-7"><a href="regressió-lineal.html#cb759-7" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y3<span class="sc">~</span>x3,<span class="at">data=</span>anscombe),<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lwd=</span><span class="fl">1.5</span>)</span>
<span id="cb759-8"><a href="regressió-lineal.html#cb759-8" aria-hidden="true" tabindex="-1"></a><span class="fu">plot</span>(anscombe<span class="sc">$</span>x4,anscombe<span class="sc">$</span>y4,<span class="at">main=</span><span class="st">&quot;Conjunt de dades 4&quot;</span>,<span class="at">pch=</span><span class="dv">20</span>)</span>
<span id="cb759-9"><a href="regressió-lineal.html#cb759-9" aria-hidden="true" tabindex="-1"></a><span class="fu">abline</span>(<span class="fu">lm</span>(y4<span class="sc">~</span>x4,<span class="at">data=</span>anscombe),<span class="at">col=</span><span class="st">&quot;red&quot;</span>,<span class="at">lwd=</span><span class="fl">1.5</span>)</span></code></pre></div>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-828-1.png" width="90%" style="display: block; margin: auto;" /></p>

<div class="rmdnote">
Al Tema <a href="#chap:ED"><strong>??</strong></a> ja us parlàrem del paquet <strong>datasaurus</strong>, les funcions del qual us permeten crear conjunts de punts de “formes” diferents i els mateixos estadístics. Vegem com el nostres dinosaure i estrella tenen rectes de regressió i valors de <span class="math inline">\(R^2\)</span> molt semblants.
</div>
<div class="sourceCode" id="cb760"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb760-1"><a href="regressió-lineal.html#cb760-1" aria-hidden="true" tabindex="-1"></a>datasaure<span class="ot">=</span><span class="fu">read.table</span>(<span class="st">&quot;https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/Datasaurus.txt&quot;</span>,<span class="at">header=</span><span class="cn">TRUE</span>,<span class="at">sep=</span><span class="st">&quot;</span><span class="sc">\t</span><span class="st">&quot;</span>)</span>
<span id="cb760-2"><a href="regressió-lineal.html#cb760-2" aria-hidden="true" tabindex="-1"></a>dino<span class="ot">=</span>datasaure[datasaure<span class="sc">$</span>dataset<span class="sc">==</span><span class="st">&quot;dino&quot;</span>,<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb760-3"><a href="regressió-lineal.html#cb760-3" aria-hidden="true" tabindex="-1"></a>star<span class="ot">=</span>datasaure[datasaure<span class="sc">$</span>dataset<span class="sc">==</span><span class="st">&quot;star&quot;</span>,<span class="dv">2</span><span class="sc">:</span><span class="dv">3</span>]</span>
<span id="cb760-4"><a href="regressió-lineal.html#cb760-4" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(dino<span class="sc">$</span>y<span class="sc">~</span>dino<span class="sc">$</span>x)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>## (Intercept)      dino$x 
##  53.3353196  -0.1011268</code></pre>
<div class="sourceCode" id="cb762"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb762-1"><a href="regressió-lineal.html#cb762-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(dino<span class="sc">$</span>y<span class="sc">~</span>dino<span class="sc">$</span>x))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.0039641</code></pre>
<div class="sourceCode" id="cb764"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb764-1"><a href="regressió-lineal.html#cb764-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(star<span class="sc">$</span>y<span class="sc">~</span>star<span class="sc">$</span>x)<span class="sc">$</span>coefficients</span></code></pre></div>
<pre><code>## (Intercept)      star$x 
##   53.326679   -0.101113</code></pre>
<div class="sourceCode" id="cb766"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb766-1"><a href="regressió-lineal.html#cb766-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(star<span class="sc">$</span>y<span class="sc">~</span>star<span class="sc">$</span>x))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.0039641</code></pre>
<p><img src="Bioestadistica-II_files/figure-html/unnamed-chunk-831-1.png" width="90%" style="display: block; margin: auto;" /></p>
</div>
<div id="intervals-de-confiança-dels-coeficients" class="section level3" number="11.1.4">
<h3><span class="header-section-number">11.1.4</span> Intervals de confiança dels coeficients</h3>
<p>Suposarem d’ara endavant que <strong>cada <span class="math inline">\(E_{x_i}\)</span> segueix una distribució normal amb mitjana <span class="math inline">\(\mu_{E_{x_i}}=0\)</span> i totes amb la mateixa variància <span class="math inline">\(\sigma_E^2\)</span>, i que <span class="math inline">\(\sigma_{E_{x_i},E_{x_j}}=0\)</span> per a cada parella <span class="math inline">\(i,j\)</span></strong>. Recordau que sota aquestes condicions, els estimadors per mínims quadrats <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span> de <span class="math inline">\(\beta_0\)</span> i <span class="math inline">\(\beta_1\)</span> són màxim versemblants i no esbiaixats òptims.</p>
<p>Si tenim molt pocs valors <span class="math inline">\(y\)</span> per a cada <span class="math inline">\(x\)</span> a la mostra, això no es pot contrastar amb un mínim raonable de potència, però si és veritat, implica que els <span class="math inline">\((e_i)_{i=1,\ldots,n}\)</span> s’ajusten a una variable <span class="math inline">\(N(0,\sigma_E^2)\)</span>, amb <span class="math inline">\(\sigma_E^2\)</span> estimada per <span class="math inline">\(S^2\)</span>, i això sí que ho podem contrastar. Si ho podem rebutjar, hem de rebutjar que els <span class="math inline">\(E_{x_i}\)</span> satisfan les condicions requerides.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-832" class="example"><strong>Exemple 11.9  </strong></span>A l’Exemple <a href="regressió-lineal.html#exm:edats">11.2</a>:</p>
</div>
<div class="sourceCode" id="cb768"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb768-1"><a href="regressió-lineal.html#cb768-1" aria-hidden="true" tabindex="-1"></a>SS.E.edat<span class="ot">=</span><span class="fu">sum</span>(errors.edat<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb768-2"><a href="regressió-lineal.html#cb768-2" aria-hidden="true" tabindex="-1"></a>S2.edat<span class="ot">=</span>SS.E.edat<span class="sc">/</span>(<span class="fu">length</span>(edat)<span class="sc">-</span><span class="dv">2</span>)  <span class="co">#L&#39;estimació de la variància comuna dels errors</span></span>
<span id="cb768-3"><a href="regressió-lineal.html#cb768-3" aria-hidden="true" tabindex="-1"></a><span class="fu">ks.test</span>(errors.edat,<span class="st">&quot;pnorm&quot;</span>,<span class="dv">0</span>,<span class="fu">sqrt</span>(S2.edat))</span></code></pre></div>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  errors.edat
## D = 0.17482, p-value = 0.958
## alternative hypothesis: two-sided</code></pre>
<p>Podem acceptar que els errors s’ajusten a una variable normal de mitjana 0.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-834" class="example"><strong>Exemple 11.10  </strong></span>A l’Exemple <a href="regressió-lineal.html#exm:sal">11.3</a>:</p>
</div>
<div class="sourceCode" id="cb770"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb770-1"><a href="regressió-lineal.html#cb770-1" aria-hidden="true" tabindex="-1"></a>errors.sal<span class="ot">=</span><span class="fu">summary</span>(<span class="fu">lm</span>(tensió<span class="sc">~</span>sal))<span class="sc">$</span>residuals</span>
<span id="cb770-2"><a href="regressió-lineal.html#cb770-2" aria-hidden="true" tabindex="-1"></a>SS.E.sal<span class="ot">=</span><span class="fu">sum</span>(errors.sal<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb770-3"><a href="regressió-lineal.html#cb770-3" aria-hidden="true" tabindex="-1"></a>S2.sal<span class="ot">=</span>SS.E.sal<span class="sc">/</span>(<span class="fu">length</span>(sal)<span class="sc">-</span><span class="dv">2</span>)</span>
<span id="cb770-4"><a href="regressió-lineal.html#cb770-4" aria-hidden="true" tabindex="-1"></a><span class="fu">ks.test</span>(errors.sal,<span class="st">&quot;pnorm&quot;</span>,<span class="dv">0</span>,<span class="fu">sqrt</span>(S2.sal))</span></code></pre></div>
<pre><code>## 
##  One-sample Kolmogorov-Smirnov test
## 
## data:  errors.sal
## D = 0.25544, p-value = 0.7472
## alternative hypothesis: two-sided</code></pre>
<p>També podem acceptar que els errors s’ajusten a una variable normal de mitjana 0.</p>
<p>Per cert, R calcula la <span class="math inline">\(S\)</span>, l’arrel quadrada d’aquesta <span class="math inline">\(S^2\)</span>, en fer la <code>lm</code>. És el <code>Residual standard error</code> de la tercera línia començant per avall a la sortida del <code>summary(lm( ))</code> i s’obté amb el sufix <code>$sigma</code>:</p>
<div class="sourceCode" id="cb772"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb772-1"><a href="regressió-lineal.html#cb772-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(tensió<span class="sc">~</span>sal))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = tensió ~ sal)
## 
## Residuals:
##      1      2      3      4      5      6 
##  2.226 -2.309  1.455 -1.712 -1.613  1.952 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  86.3708     3.0621  28.206  9.4e-06 ***
## sal           6.3354     0.8395   7.546  0.00165 ** 
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.332 on 4 degrees of freedom
## Multiple R-squared:  0.9344, Adjusted R-squared:  0.918 
## F-statistic: 56.95 on 1 and 4 DF,  p-value: 0.001652</code></pre>
<div class="sourceCode" id="cb774"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb774-1"><a href="regressió-lineal.html#cb774-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(tensió<span class="sc">~</span>sal))<span class="sc">$</span>sigma</span></code></pre></div>
<pre><code>## [1] 2.331625</code></pre>
<div class="sourceCode" id="cb776"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb776-1"><a href="regressió-lineal.html#cb776-1" aria-hidden="true" tabindex="-1"></a><span class="fu">sqrt</span>(S2.sal)</span></code></pre></div>
<pre><code>## [1] 2.331625</code></pre>
<p>Resulta que si se satisfan les condicions demanades sobre les variables <span class="math inline">\(E_{x_i}\)</span>, aleshores coneixem els errors típics dels estimadors <span class="math inline">\(b_1\)</span> i <span class="math inline">\(b_0\)</span> i uns estadístics associats a aquests estimadors segueixen lleis t de Student que permeten calcular intervals de confiança per a <span class="math inline">\(\beta_0\)</span> i <span class="math inline">\(\beta_1\)</span>. En concret:</p>
<ul>
<li><p>Pel que fa a <span class="math inline">\(b_1\)</span>,</p>
<ul>
<li>El seu error típic és
<span class="math display">\[
\frac{\sigma_E}{s_x\sqrt{n}}.
\]</span></li>
<li>L’estimació d’aquest error típic sobre una mostra concreta és
<span class="math display">\[
\frac{S}{s_x\sqrt{n}}
\]</span></li>
<li>La fracció
<span class="math display">\[
T_1=\frac{b_1-\beta_1}{\frac{S}{s_x\sqrt{n}}}
\]</span>
segueix una llei <span class="math inline">\(t\)</span> de Student amb <span class="math inline">\(n-2\)</span> graus de llibertat.</li>
</ul></li>
</ul>

<div class="rmdnote">
<p>Observau que l’error típic de <span class="math inline">\(b_1\)</span>:</p>
<ul>
<li><p>Decreix amb <span class="math inline">\(n\)</span>: com més gran és la mostra, menys incertesa esperam en l’estimació de <span class="math inline">\(\beta_1\)</span>. Això ens ha passat en totes les estimacions del curs, no és cap sorpresa. En general, com més dades tenim, millor.</p></li>
<li><p>Decreix amb <span class="math inline">\(s_x\)</span>: com més dispersa és la mostra, menys incertesa esperam en l’estimació de <span class="math inline">\(\beta_1\)</span>. Això és una novetat, en altres casos (per exemple, en estimar una mitjana) la incertesa creixia amb la desviació típica de la mostra. Però aquí és raonable. Pensau en termes físics: si voleu unir dos punts amb una recta, com és més fàcil que aquesta recta sigui estable, si els dos punts estan molt junts o si estan separats? Separats, no?</p></li>
<li><p>Creix amb <span class="math inline">\(\sigma_E\)</span>: com més variabilitat tenguin els errors residuals, més incertesa tendrem. Fixau-vos que si <span class="math inline">\(\sigma_E=0\)</span>, aleshores no hi ha gens d’incertesa: significa que els punts <span class="math inline">\((x_i,y_i)\)</span> estan sobre una recta i aquesta recta és la de regressió.</p></li>
</ul>
</div>
<ul>
<li><p>Pel que fa a <span class="math inline">\(b_0\)</span>,</p>
<ul>
<li>El seu error típic és
<span class="math display">\[
\frac{\sigma_E\sqrt{s_x^2+\overline{x}^2}}{s_x\sqrt{n}}
\]</span></li>
<li>L’estimació d’aquest error típic sobre una mostra concreta és
<span class="math display">\[
\frac{S\sqrt{s_x^2+\overline{x}^2}}{s_x\sqrt{n}}
\]</span></li>
<li>La fracció
<span class="math display">\[
T_0=\frac{b_0-\beta_0}{\frac{S\sqrt{s_x^2+\overline{x}^2}}{s_x\sqrt{n}}}
\]</span>
també segueix una llei <span class="math inline">\(t\)</span> de Student amb <span class="math inline">\(n-2\)</span> graus de llibertat.</li>
</ul></li>
</ul>

<div class="rmdnote">
És raonable esperar que l’error típic de <span class="math inline">\(b_0\)</span> sigui més gran que el de <span class="math inline">\(b_1\)</span>, perquè per calcular <span class="math inline">\(b_0\)</span> hem de calcular primer <span class="math inline">\(b_1\)</span> i a més emprar-hi les mitjanes <span class="math inline">\(\overline{x}\)</span> i <span class="math inline">\(\overline{y}\)</span>, la qual cosa fa que en estimar <span class="math inline">\(\beta_0\)</span> per mitjà de <span class="math inline">\(b_0\)</span> hi hagi més incertesa que en estimar <span class="math inline">\(\beta_1\)</span> per mitjà de <span class="math inline">\(b_1\)</span>.
</div>
<p>Com que els estadístics <span class="math inline">\(T_1\)</span> i <span class="math inline">\(T_0\)</span> tenen distribucions t de Student, operant amb ells com en el cas de l’interval de confiança per a la mitjana poblacional <span class="math inline">\(\mu\)</span> obtenim fórmules per als intervals de confiança per a <span class="math inline">\(\beta_1\)</span> i <span class="math inline">\(\beta_1\)</span> de la forma que ens agrada:
<span class="math display">\[
\text{estimador}\pm \text{quantil}\times \text{error típic}
\]</span></p>
<p>En concret, sota les hipòtesis imposades al principi d’aquesta secció</p>
<ul>
<li><p>Un interval de confiança amb nivell de confiança <span class="math inline">\(q\)</span> per a <span class="math inline">\(\beta_1\)</span> és
<span class="math display">\[
b_1\pm t_{n-2,(1+q)/2}\cdot \frac{S}{s_x\sqrt{n}}
\]</span></p></li>
<li><p>Un interval de confiança amb nivell de confiança <span class="math inline">\(q\)</span> per a <span class="math inline">\(\beta_0\)</span> és
<span class="math display">\[
b_0\pm t_{n-2,(1+q)/2}\cdot \frac{S\sqrt{s_x^2+\overline{x}^2}}{s_x\sqrt{n}}
\]</span></p></li>
</ul>

<div class="example">
<p><span id="exm:edatsIC" class="example"><strong>Exemple 11.11  </strong></span>Tornem a l’Exemple <a href="regressió-lineal.html#exm:edats1">11.1</a>. Hi havíem obtingut la recta de regressió</p>
</div>
<p><span class="math display">\[
\widehat{Y}=72.321+6.464X
\]</span>
i a més <span class="math inline">\(n=7\)</span> i havíem calculat que <span class="math inline">\(\overline{x}=7\)</span>, <span class="math inline">\(s_x^2=18.667\)</span> i <span class="math inline">\(S^2=3.624\)</span>.</p>
<p>Aleshores:</p>
<ul>
<li><p>Un interval de confiança al 95% per <span class="math inline">\(\beta_1\)</span> és
<span class="math display">\[
\begin{array}{l}
\displaystyle b_1\pm t_{n-2,(1+0.95)/2}\cdot \frac{S}{s_x\sqrt{n}} =6.464\pm t_{5,0.975}\cdot \frac{\sqrt{8.314}}{4\sqrt{7}}\\[2ex]
\qquad =
6.464\pm 2.5706 \cdot 0.2724=6.464\pm  0.7
\end{array}
\]</span>
Obtenim l’interval <span class="math inline">\([5.764,7.164]\)</span>.</p></li>
<li><p>Un interval de confiança al 95% per a <span class="math inline">\(\beta_0\)</span> és
<span class="math display">\[
\begin{array}{l}
\displaystyle b_0\pm t_{n-2,(1+0.95)/2}\cdot\frac{S\sqrt{s_x^2+\overline{x}^2}}{s_x\sqrt{n}}
=72.321\pm t_{5,0.975}\cdot \frac{\sqrt{8.314}\cdot\sqrt{16+7^2}}{4\sqrt{7}}\\[2ex]
\qquad =
72.321\pm 2.5706 \cdot 2.1966=72.321\pm 5.647
\end{array}
\]</span>
Obtenim l’interval <span class="math inline">\([66.674,77.968]\)</span>.</p></li>
</ul>
<p>Amb R aquests intervals de confiança s’obtenen amb la funció <code>confint</code> aplicada al resultat de la <code>lm</code>. El nivell de confiança s’hi indica amb el paràmetre <code>level</code> i el seu valor per defecte és, com sempre, 0.95.</p>
<div class="sourceCode" id="cb778"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb778-1"><a href="regressió-lineal.html#cb778-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">lm</span>(alçada<span class="sc">~</span>edat),<span class="at">level=</span><span class="fl">0.95</span>)</span></code></pre></div>
<pre><code>##                 2.5 %    97.5 %
## (Intercept) 66.674769 77.968088
## edat         5.763904  7.164668</code></pre>

<div class="rmdexercici">
Calculau “a mà”, amb les fórmules que hem donat, els intervals de confiança per als coeficients de la recta de regressió de l’Exemple <a href="regressió-lineal.html#exm:sal">11.3</a>. Us han de donar:
</div>
<div class="sourceCode" id="cb780"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb780-1"><a href="regressió-lineal.html#cb780-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">lm</span>(tensió<span class="sc">~</span>sal))</span></code></pre></div>
<pre><code>##                 2.5 %    97.5 %
## (Intercept) 77.869064 94.872509
## sal          4.004434  8.666266</code></pre>
</div>
<div id="intervals-de-confiança-per-a-les-estimacions-de-la-variable-dependent" class="section level3" number="11.1.5">
<h3><span class="header-section-number">11.1.5</span> Intervals de confiança per a les estimacions de la variable dependent</h3>
<p>També podem calcular intervals de confiança per al valor estimat de la <span class="math inline">\(Y\)</span> sobre els individus amb un valor de <span class="math inline">\(X\)</span> donat. En aquest cas, tenim dos intervals:</p>
<ul>
<li><p>L’interval per al <strong>valor esperat</strong> <span class="math inline">\(\mu_{Y|x_0}\)</span> de <span class="math inline">\(Y\)</span> sobre els individus en els que <span class="math inline">\(X\)</span> val <span class="math inline">\(x_0\)</span>, és a dir, per al valor mitjà de la <span class="math inline">\(Y\)</span> sobre tots els individus de la població en els que <span class="math inline">\(X\)</span> valgui <span class="math inline">\(x_0\)</span>.</p></li>
<li><p>L’interval per al <strong>valor predit</strong> <span class="math inline">\(y_0\)</span> de <span class="math inline">\(Y\)</span> sobre un individu concret en el que <span class="math inline">\(X\)</span> valgui <span class="math inline">\(x_0\)</span>.</p></li>
</ul>
<p>Tot i que tant el valor esperat <span class="math inline">\(\mu_{Y|x_0}\)</span> com el valor <span class="math inline">\(y_0\)</span> de <span class="math inline">\(Y\)</span> sobre un individu concret en el que <span class="math inline">\(X\)</span> valgui <span class="math inline">\(x_0\)</span> tenen el mateix valor estimat,
<span class="math display">\[
\widehat{y}_0=b_0+b_1x_0,
\]</span>
l’interval de confiança del valor esperat serà més estret que el del valor sobre un individu concret. Això reflecteix el fet que, naturalment, hi ha molta més incertesa en saber què val la <span class="math inline">\(Y\)</span> sobre un individu concret que en saber quin és el valor mitjà de <span class="math inline">\(Y\)</span> sobre tots els individus que tenguin el mateix valor de <span class="math inline">\(X\)</span> que aquest individu concret.</p>
<p>Bé passem a les fórmules. Sota les condicions sobre els errors que hem suposat al començament de la secció anterior (variables error normals de mitjana 0 i mateixa desviació típica, i incorrelades dues a dues):</p>
<ul>
<li><p>L’error típic de <span class="math inline">\(\widehat{y}_0\)</span> com a estimador de <span class="math inline">\(\mu_{Y|x_0}\)</span> és
<span class="math display">\[
\sigma_E\cdot \sqrt{\frac{1}{n}+\frac{(x_0-\overline{x})^2}{ns^2_x}}
\]</span>
i la fracció
<span class="math display">\[
\frac{\widehat{y}_0-\mu_{Y/x_0}}{S\cdot \sqrt{\frac{1}{n}+\frac{(x_0-\overline{x})^2}{n
s^2_x}}}
\]</span>
segueix una llei <span class="math inline">\(t\)</span> de Student amb <span class="math inline">\(n-2\)</span> graus de llibertat.</p></li>
<li><p>L’error típic de <span class="math inline">\(\widehat{y}_0\)</span> com a estimador de <span class="math inline">\(y_0\)</span> és
<span class="math display">\[
\sigma_E\cdot \sqrt{1+\frac{1}{n}+\frac{(x_0-\overline{x})^2}{ns^2_x}}
\]</span>
i la fracció
<span class="math display">\[
\frac{\widehat{y}_0-y_0}{S\cdot \sqrt{1+\frac{1}{n}+\frac{(x_0-\overline{x})^2}{n
s^2_x}}}
\]</span>
segueix una llei <span class="math inline">\(t\)</span> de Student amb <span class="math inline">\(n-2\)</span> graus de llibertat.</p></li>
</ul>

<div class="rmdimportant">
Fixau-vos que l’error típic de l’estimació de <span class="math inline">\(\mu_{Y|x_0}\)</span> és més petit que el de l’estimació de <span class="math inline">\(y_0\)</span>.
</div>

<div class="rmdnote">
Aquests errors típics creixen amb la distància entre <span class="math inline">\(x_0\)</span> i la mitjana de la mostra <span class="math inline">\(\overline{x}\)</span>. És raonable: la recta passa per <span class="math inline">\((\overline{x},\overline{y})\)</span> i a partir d’aquest punt, com més enfora estigui <span class="math inline">\(x_0\)</span>, petites variacions en el valor de la pendent de la recta donaran lloc a diferències molt més grans en el valor de <span class="math inline">\(b_0+b_1x_0\)</span>.
</div>
<p>Per tant, sota aquestes hipòtesis,</p>
<ul>
<li><p>Un interval de confiança de nivell de confiança <span class="math inline">\(q\)</span> per a <span class="math inline">\(\mu_{Y|x_0}\)</span> és
<span class="math display">\[
\widehat{y}_0\pm t_{n-2,(1+q)/2}\cdot S\cdot \sqrt{\frac{1}{n}+\frac{(x_0-\overline{x})^2}{n
s^2_x}}
\]</span></p></li>
<li><p>Un interval de confiança de nivell de confiança <span class="math inline">\(q\)</span> per a <span class="math inline">\(y_0\)</span> és
<span class="math display">\[
\widehat{y}_0\pm t_{n-2,(1+q)/2}\cdot S\cdot \sqrt{1+\frac{1}{n}+\frac{(x_0-\overline{x})^2}{n
s^2_x}}
\]</span></p></li>
</ul>

<div class="example">
<p><span id="exm:unnamed-chunk-845" class="example"><strong>Exemple 11.12  </strong></span>Tornem una altra vegada a l’Exemple <a href="regressió-lineal.html#exm:edats1">11.1</a>. Hi havíem obtingut la recta de regressió</p>
</div>
<p><span class="math display">\[
\widehat{Y}=72.321+6.464X
\]</span>
i a més <span class="math inline">\(n=7\)</span> i havíem calculat que <span class="math inline">\(\overline{x}=7\)</span>, <span class="math inline">\(s_x^2=18.667\)</span> i <span class="math inline">\(S^2=3.624\)</span>.</p>
<p>Suposem que volem estimar l’alçada <span class="math inline">\(y_0\)</span> d’un nin de <span class="math inline">\(x_0=10\)</span> anys. L’estimació amb la recta de regressió és
<span class="math display">\[
\widehat{y}_0=72.321+6.464\cdot 10=136.964
\]</span></p>
<p>Ara volem saber els intervals de confiança del 95% per a aquesta estimació:</p>
<ul>
<li><p>Un interval de confiança del 95% per a <span class="math inline">\(y_0\)</span> és
<span class="math display">\[
\begin{array}{l}
\displaystyle
\widehat{y}_0\pm t_{n-2,(1+0.95)/2}\cdot S\sqrt{1+\frac{1}{n}+\frac{(x_0-\overline{x})^2}{ns^2_x}}
\\[2ex]
\displaystyle\qquad=136.961\pm t_{5,0.975}\cdot \sqrt{8.314}\cdot\sqrt{1+\frac{1}{7}+\frac{(10-7)^2}{7\cdot 16 }}\\[2ex]
\qquad =
136.961\pm 2.5706 \cdot  3.189=136.961\pm  8.198
\end{array}
\]</span>
Obtenim l’interval <span class="math inline">\([128.8,145.2]\)</span>. Per tant, estam molt segurs que si prenem un nin d’10 anys, la seva alçada estarà entre els 128.8 cm i els 145.2 cm.</p></li>
<li><p>Un interval de confiança del 95% per al <strong>valor esperat</strong> <span class="math inline">\(\mu_{Y|x_0}\)</span> de <span class="math inline">\(y_0\)</span> és
<span class="math display">\[
\begin{array}{l}
\displaystyle
\widehat{y}_0\pm t_{n-2,(1+0.95)/2}\cdot S\sqrt{\frac{1}{n}+\frac{(x_0-\overline{x})^2}{ns^2_x}}
\\[2ex]
\displaystyle\qquad=136.961\pm t_{5,0.975}\cdot \sqrt{8.314}\cdot\sqrt{\frac{1}{7}+\frac{(10-7)^2}{7\cdot 16 }}\\[2ex]
\qquad =
136.961\pm 2.5706 \cdot  1.362=136.961\pm  3.501
\end{array}
\]</span>
Obtenim l’interval <span class="math inline">\([133.5, 140.5]\)</span>. Per tant, estam molt segurs que l’alçada mitjana dels nins d’10 anys està entre els 133.5 cm i els 140.5 cm.</p></li>
</ul>
<p>Si en canvi volguéssim emprar aquesta recta per estimar l’alçada d’un nin d’15 anys, els intervals que obtenim són (comprovau-ho):</p>
<ul>
<li><p>Per a <span class="math inline">\(y_0\)</span>, <span class="math inline">\([159.6, 179]\)</span></p></li>
<li><p>Per a <span class="math inline">\(\mu_{Y|x_0}\)</span>, <span class="math inline">\([163, 175.6]\)</span></p></li>
</ul>
<p>Com veieu, són molt més amples que els intervals de confiança per als 10 anys.</p>
<p>Amb R, aquests intervals es calculen amb la funció <code>predict.lm</code> aplicada a</p>
<ul>
<li><p>el resultat de la <code>lm</code></p></li>
<li><p>un <em>data frame</em> amb el valor (o els valors, si ho volem fer de cop per a més d’un valor) de <span class="math inline">\(X\)</span></p></li>
<li><p>el paràmetre <code>interval</code> igualat al tipus d’interval que volem:</p>
<ul>
<li><code>"prediction"</code> si és per al valor en un individu,</li>
<li><code>"confidence"</code> si és per al valor esperat</li>
</ul></li>
</ul>
<p>A més, s’hi pot entrar el nivell de significació amb el paràmetre <code>level</code>; si és 0.95, no cal. El resultat és un dataframe amb tres columnes: <code>fit</code>, el valor predit, i <code>lwr</code> i <code>upr</code>, els extrems inferior i superior de l’interval.</p>
<p>En el nostre exemple, primer hem de definir un data frame amb l’edat o les edats. Calcularem els intervals de confiança per als 10 i 15 anys. Per tant, definim un <em>data frame</em> format per dues observacions de la variable <code>edat</code>, que valguin 10 i 15:</p>
<div class="sourceCode" id="cb782"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb782-1"><a href="regressió-lineal.html#cb782-1" aria-hidden="true" tabindex="-1"></a>nin<span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">edat=</span><span class="fu">c</span>(<span class="dv">10</span>,<span class="dv">15</span>))</span></code></pre></div>
<p>Aleshores, els intervals de confiança del 95% per a les alçades d’un nin d’10 anys i d’un nin d’15 anys són, respectivament,</p>
<div class="sourceCode" id="cb783"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb783-1"><a href="regressió-lineal.html#cb783-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.lm</span>(<span class="fu">lm</span>(alçada<span class="sc">~</span>edat),nin,<span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 136.9643 128.7665 145.1620
## 2 169.2857 159.5809 178.9905</code></pre>
<p>i els intervals de confiança del 95% per a les alçades mitjanes dels nins d’10 i d’15 anys són, respectivament,</p>
<div class="sourceCode" id="cb785"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb785-1"><a href="regressió-lineal.html#cb785-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.lm</span>(<span class="fu">lm</span>(alçada<span class="sc">~</span>edat),nin,<span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 136.9643 133.4624 140.4662
## 2 169.2857 163.0213 175.5501</code></pre>
</div>
<div id="té-sentit-una-regressió-lineal" class="section level3" number="11.1.6">
<h3><span class="header-section-number">11.1.6</span> Té sentit una regressió lineal?</h3>
<p>Si <span class="math inline">\(\beta_1=0\)</span>, el model de regressió lineal no té sentit, perquè en aquest cas
<span class="math display">\[
Y|x=\beta_0+E_x
\]</span>
i les variacions en els valors de <span class="math inline">\(Y\)</span> es deuen tan sols als errors aleatoris.</p>
<p>El contrast
<span class="math display">\[
\left\{\begin{array}{l}
H_0:\beta_1=0\\
H_1:\beta_1 \neq 0
\end{array}
\right.
\]</span>
el podem realitzar amb l’interval de confiança per a <span class="math inline">\(\beta_1\)</span>: si 0 no hi pertany,
rebutjam la hipòtesi nul·la amb el nivell de significació corresponent al nivell de confiança de l’interval.</p>
<p>Per exemple, a l’Exemple <a href="regressió-lineal.html#exm:edatsIC">11.11</a> hem obtingut l’IC 95% per a <span class="math inline">\(\beta_1\)</span> <span class="math inline">\([5.764,7.164]\)</span>. Com que no conté el 0, concloem (amb un nivell de significació de 0.05) que <span class="math inline">\(\beta_1\neq 0\)</span>.</p>
<p>Si mirau la sortida del <code>summary(lm( ))</code></p>
<div class="sourceCode" id="cb787"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb787-1"><a href="regressió-lineal.html#cb787-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(alçada<span class="sc">~</span>edat))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = alçada ~ edat)
## 
## Residuals:
##       1       2       3       4       5       6       7 
## -3.7857  0.2857  3.3571  3.4286 -0.5000 -1.4286 -1.3571 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)    
## (Intercept)  72.3214     2.1966   32.92 4.86e-07 ***
## edat          6.4643     0.2725   23.73 2.48e-06 ***
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.883 on 5 degrees of freedom
## Multiple R-squared:  0.9912, Adjusted R-squared:  0.9894 
## F-statistic: 562.9 on 1 and 5 DF,  p-value: 2.477e-06</code></pre>
<p>a la matriu <code>Coefficients</code>:</p>
<ul>
<li><p>Els <code>Estimate</code> són les estimacions <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span></p></li>
<li><p>Els <code>Std. Error</code> són (les estimacions de) els seus errors típics</p></li>
<li><p>Els <code>t value</code> són els valors dels estadístics de contrast dels contrastos bilaterals amb hipòtesi nul·la <span class="math inline">\(H_0:\)</span> “coeficient <span class="math inline">\(=0\)</span>”; aquests estadístics de contrast són justament els estadístics <span class="math inline">\(T_0\)</span> i <span class="math inline">\(T_1\)</span> que hem definit fa una estona (substituint-hi <span class="math inline">\(\beta_0\)</span> i <span class="math inline">\(\beta_1\)</span> pels valors que contrastam, 0)</p></li>
<li><p>Els <code>Pr(&gt;|t|)</code> són els p-valors d’aquests contrastos (que no us engani la notació, aquests p-valors es defineixen com toca:
<span class="math display">\[
2P(t_{n-2}\geqslant |T_0|),\quad 2P(t_{n-2}\geqslant |T_1|)
\]</span>
respectivament).</p>
<p>Com veiem, en aquest cas podem rebutjar amb <span class="math inline">\(\alpha=0.05\)</span> que <span class="math inline">\(\beta_1=0\)</span> (i també que <span class="math inline">\(\beta_0=0\)</span>).</p></li>
</ul>
</div>
</div>
<div id="regressió-lineal-múltiple" class="section level2" number="11.2">
<h2><span class="header-section-number">11.2</span> Regressió lineal múltiple</h2>
<p>Comencem amb un exemple.</p>

<div class="example">
<p><span id="exm:mult" class="example"><strong>Exemple 11.13  </strong></span>Es postula que l’alçada esperada d’un nadó en cm (<span class="math inline">\(Y\)</span>) té una relació lineal amb la seva edat en dies (<span class="math inline">\(X_1\)</span>), la seva alçada en néixer en cm (<span class="math inline">\(X_2\)</span>), el seu pes en kg en néixer (<span class="math inline">\(X_3\)</span>) i l’augment en tant per cent del seu pes actual respecte del seu pes en néixer (<span class="math inline">\(X_4\)</span>). És a dir, es creu que existeixen coeficients <span class="math inline">\(\beta_0,\ldots,\beta_4\in \mathbb{R}\)</span> tals que el model
<span class="math display">\[
\mu_{Y|x_1,x_2,x_3,x_4}=\beta_0+\beta_1x_1+\beta_2x_2+\beta_3x_3+\beta_4x_4
\]</span>
és correcte, on <span class="math inline">\(\mu_{Y|x_1,x_2,x_3,x_4}\)</span> és l’alçada esperada, en cm, d’un nadó de <span class="math inline">\(x_1\)</span> dies que en néixer va fer <span class="math inline">\(x_2\)</span> cm i <span class="math inline">\(x_3\)</span> kg i des de llavors el seu pes ha augmentat un <span class="math inline">\(x_4\)</span>%. En una mostra de <span class="math inline">\(n=9\)</span> nins, els resultats varen ser els de la taula següent:</p>
</div>
<table>
<thead>
<tr>
<th style="text-align:right;">
Alçada (en cm)
</th>
<th style="text-align:right;">
Edat (en dies)
</th>
<th style="text-align:right;">
Alçada en néixer (en cm)
</th>
<th style="text-align:right;">
Pes en néixer (en kg)
</th>
<th style="text-align:right;">
% d’increment de pes
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
57.5
</td>
<td style="text-align:right;">
78
</td>
<td style="text-align:right;">
8.2
</td>
<td style="text-align:right;">
2.75
</td>
<td style="text-align:right;">
29.5
</td>
</tr>
<tr>
<td style="text-align:right;">
52.8
</td>
<td style="text-align:right;">
69
</td>
<td style="text-align:right;">
45.5
</td>
<td style="text-align:right;">
2.15
</td>
<td style="text-align:right;">
26.3
</td>
</tr>
<tr>
<td style="text-align:right;">
61.3
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
46.3
</td>
<td style="text-align:right;">
4.41
</td>
<td style="text-align:right;">
32.2
</td>
</tr>
<tr>
<td style="text-align:right;">
67.0
</td>
<td style="text-align:right;">
88
</td>
<td style="text-align:right;">
49.0
</td>
<td style="text-align:right;">
5.52
</td>
<td style="text-align:right;">
36.5
</td>
</tr>
<tr>
<td style="text-align:right;">
53.5
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:right;">
43.0
</td>
<td style="text-align:right;">
3.21
</td>
<td style="text-align:right;">
27.2
</td>
</tr>
<tr>
<td style="text-align:right;">
62.7
</td>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
4.32
</td>
<td style="text-align:right;">
27.7
</td>
</tr>
<tr>
<td style="text-align:right;">
56.2
</td>
<td style="text-align:right;">
74
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
2.31
</td>
<td style="text-align:right;">
28.3
</td>
</tr>
<tr>
<td style="text-align:right;">
68.5
</td>
<td style="text-align:right;">
94
</td>
<td style="text-align:right;">
53.0
</td>
<td style="text-align:right;">
4.30
</td>
<td style="text-align:right;">
30.3
</td>
</tr>
<tr>
<td style="text-align:right;">
79.2
</td>
<td style="text-align:right;">
102
</td>
<td style="text-align:right;">
58.0
</td>
<td style="text-align:right;">
3.71
</td>
<td style="text-align:right;">
28.7
</td>
</tr>
</tbody>
</table>
<p>A partir d’aquesta mostra, volem estimar els coeficients <span class="math inline">\(\beta_0,\ldots,\beta_4\in \mathbb{R}\)</span> de la relació lineal predita.</p>
<p>Aquest és un problema de <strong>regressió lineal múltiple</strong>. Ara tenim <span class="math inline">\(k\)</span> variables <strong>independents</strong>, o <strong>de control</strong> <span class="math inline">\(X_1,\ldots, X_k\)</span> (com al cas simple, no necessàriament aleatòries) i una
variable aleatòria <strong>dependent</strong>, o <strong>de resposta</strong>, <span class="math inline">\(Y\)</span>. Suposam que el model
<span class="math display">\[
\mu_{Y|x_1,\ldots,x_k}= \beta_0+\beta_1 x_1+\cdots+\beta_k x_k
\]</span>
o, equivalentment,
<span class="math display">\[
Y|x_1,\ldots,x_k=\beta_0+\beta_1 x_{1}+\cdots+\beta_{k} x_k+E_{x_1,\ldots,x_k}
\]</span>
és correcte, on:</p>
<ul>
<li><p><span class="math inline">\(Y|x_1,\ldots,x_k\)</span> és la variable aleatòria que dóna el valor de <span class="math inline">\(Y\)</span> sobre individus en els quals <span class="math inline">\(X_i=x_i\)</span> per a cada <span class="math inline">\(i=1,\ldots,k\)</span></p></li>
<li><p><span class="math inline">\(\mu_{Y|x_1,\ldots,x_k}\)</span> és el valor esperat de <span class="math inline">\(Y|x_1,\ldots,x_k\)</span>, és a dir, la mitjana dels valors de <span class="math inline">\(Y\)</span> sobre tots els individus de la població en els quals <span class="math inline">\(X_i=x_i\)</span> per a cada <span class="math inline">\(i=1,\ldots,k\)</span></p></li>
<li><p>Les <span class="math inline">\(E_{x_1,\ldots,x_k}\)</span> són les variables aleatòries <strong>error</strong>, o <strong>residu</strong>, i representen l’error aleatori de la variable <span class="math inline">\(Y\)</span> sobre un individu en el qual <span class="math inline">\((X_1,\ldots,X_k)=(x_1,\ldots,x_k)\)</span></p></li>
<li><p><span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_{k}\in \mathbb{R}\)</span>:</p>
<ul>
<li><p><span class="math inline">\(\beta_0\)</span> és el valor esperat de <span class="math inline">\(Y\)</span> quan <span class="math inline">\(X_1=\cdots=X_k=0\)</span></p></li>
<li><p>Cada <span class="math inline">\(\beta_i\)</span> és la variació del valor esperat de <span class="math inline">\(Y\)</span> quan <span class="math inline">\(X_i\)</span> augmenta una unitat i les altres variables <span class="math inline">\(X_j\)</span> no varien</p></li>
</ul></li>
</ul>
<p>Els paràmetres <span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_{k}\)</span> són desconeguts, i els volem estimar a partir d’una mostra
<span class="math display">\[
(x_{1i},x_{2i},\ldots,x_{ki},y_i)_{i=1,\ldots,n}
\]</span>
d’observacions del vector aleatori <span class="math inline">\((X_1,\ldots,X_k,Y)\)</span> sobre <span class="math inline">\(n\)</span> individus. Requerirem que
<span class="math inline">\(n&gt;k\)</span> (el nombre d’observacions ha de ser més gran que el nombre de variables) a fi que el sistema d’equacions lineals amb incògnites els coeficients <span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_{k}\)</span>
<span class="math display">\[
\left\{
\begin{array}{l}
y_1=\beta_0+\beta_1x_{11}+\cdots +\beta_kx_{k1}\\
\quad\vdots\\
y_n=\beta_0+\beta_1x_{1n}+\cdots +\beta_kx_{kn}
\end{array}
\right.
\]</span>
no sigui indeterminat. Direm <span class="math inline">\(b_0,b_1,\ldots,b_k\)</span> a les estimacions dels paràmetres <span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_k\)</span> a partir d’una mostra, i per escurçar escriurem <span class="math inline">\(\underline{x}_i\)</span> per indicar <span class="math inline">\((x_{1i},x_{2i},\ldots,x_{ki})\)</span>.</p>
<p>Per a cada <span class="math inline">\(i=1,\ldots,n\)</span>, diguem
<span class="math display">\[
\begin{array}{l}
\widehat{y}_i= b_0+b_1 x_{1i}+\cdots+b_{k} x_{ki}\\
e_i=y_i-\widehat{y}_i=y_i-(b_0+b_1 x_{1i}+\cdots+b_{k} x_{ki})
\end{array}
\]</span>
Amb aquestes notacions:</p>
<ul>
<li><p><span class="math inline">\(\widehat{y}_i\)</span> és el <strong>valor predit</strong> de <span class="math inline">\(Y\)</span> sobre l’individu <span class="math inline">\(i\)</span>-èsim de la mostra a partir del seu vector de valors <span class="math inline">\(\underline{x}_{i}\)</span> i de les estimacions <span class="math inline">\(b_0,b_1,\ldots,b_k\)</span> dels paràmetres</p></li>
<li><p><span class="math inline">\(e_i\)</span> és l’<strong>error</strong> que es comet amb aquesta estimació sobre aquest individu</p></li>
</ul>
<p>Direm la <strong>Suma de Quadrats dels Errors</strong> a:
<span class="math display">\[
\begin{array}{rl}
SS_E= &amp;\displaystyle\sum\limits_{i=1}^n
e^2_i=\sum\limits_{i=1}^n (y_i-\widehat{y}_i)^2 \\
= &amp;\displaystyle\sum\limits_{i=1}^n (y_i-b_0-b_1 x_{1i}-\cdots -b_{k} x_{ki})^2.
\end{array}
\]</span></p>
<div id="mínims-quadrats-1" class="section level3" number="11.2.1">
<h3><span class="header-section-number">11.2.1</span> Mínims quadrats</h3>
<p>Els estimadors de <span class="math inline">\(\beta_0,\beta_1,\ldots, \beta_k\)</span> pel <strong>mètode de mínims quadrats</strong> són els
valors <span class="math inline">\(b_0,b_1,\ldots, b_k\)</span> que minimitzen <span class="math inline">\(SS_E\)</span> sobre la nostra mostra. Per calcular-los, calculam les derivades parcials de <span class="math inline">\(SS_E\)</span> respecte de cada <span class="math inline">\(b_i\)</span>, les igualam a 0, resolem el sistema resultant, comprovam que la solució <span class="math inline">\((b_0,\ldots,b_k)\)</span> trobada dóna un mínim… Tot plegat, al final s’obté el resultat següent:</p>

<div class="theorem">
<p><span id="thm:unnamed-chunk-851" class="theorem"><strong>Teorema 11.5  </strong></span>Siguin
<span class="math display">\[
\mathbf{y}=
\left(
\begin{array}{l}
y_1\\ y_2\\ \vdots\\ y_n
\end{array}
\right),\ \mathbf{X}=\left(
\begin{array}{lllll}
1&amp;x_{11}&amp;x_{21}&amp;\ldots&amp;x_{k1}\\
1&amp;x_{12}&amp;x_{22}&amp;\ldots&amp;x_{k2}\\
\vdots&amp;\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
1&amp;x_{1n}&amp;x_{2n}&amp;\ldots&amp;x_{kn}
\end{array}
\right)
\]</span></p>
<p>Aleshores, els estimadors per mínims quadrats <span class="math inline">\(\mathbf{b}=(b_0,b_1,\ldots,b_k)^t\)</span> de <span class="math inline">\(\beta_0,\beta_1,\ldots,\beta_k\)</span> a partir de la mostra <span class="math inline">\((\underline{x}_{i},y_i)_{i=1,2,\ldots,n}\)</span> són donats per l’equació següent:
<span class="math display">\[
\mathbf{b}=\left(\mathbf{X}^t\cdot \mathbf{X}\right)^{-1}\cdot \left(\mathbf{X}^t \cdot \mathbf{y}\right).
\]</span></p>
</div>

<div class="rmdcorbes">
Amb una mica de paciència podeu comprovar que si <span class="math inline">\(k=1\)</span>, aquesta fórmula dóna la de <span class="math inline">\((b_0,b_1)^t\)</span> a la regressió lineal simple.
</div>
<p>Com al cas simple, la funció resultant l’escriurem
<span class="math display">\[
\widehat{Y}=b_0+b_1X_1+\cdots +b_kX_k
\]</span>
i en direm la <strong>funció de regressió lineal per mínims quadrats</strong> de <span class="math inline">\(Y\)</span> en funció de <span class="math inline">\(X_1,\ldots,X_k\)</span>.</p>

<div class="example">
<p><span id="exm:unnamed-chunk-853" class="example"><strong>Exemple 11.14  </strong></span>Tornem a l’Exemple <a href="regressió-lineal.html#exm:mult">11.13</a>. Recordau les dades:</p>
</div>
<table>
<thead>
<tr>
<th style="text-align:right;">
Alçada (en cm)
</th>
<th style="text-align:right;">
Edat (en dies)
</th>
<th style="text-align:right;">
Alçada en néixer (en cm)
</th>
<th style="text-align:right;">
Pes en néixer (en kg)
</th>
<th style="text-align:right;">
% d’increment de pes
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
57.5
</td>
<td style="text-align:right;">
78
</td>
<td style="text-align:right;">
8.2
</td>
<td style="text-align:right;">
2.75
</td>
<td style="text-align:right;">
29.5
</td>
</tr>
<tr>
<td style="text-align:right;">
52.8
</td>
<td style="text-align:right;">
69
</td>
<td style="text-align:right;">
45.5
</td>
<td style="text-align:right;">
2.15
</td>
<td style="text-align:right;">
26.3
</td>
</tr>
<tr>
<td style="text-align:right;">
61.3
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
46.3
</td>
<td style="text-align:right;">
4.41
</td>
<td style="text-align:right;">
32.2
</td>
</tr>
<tr>
<td style="text-align:right;">
67.0
</td>
<td style="text-align:right;">
88
</td>
<td style="text-align:right;">
49.0
</td>
<td style="text-align:right;">
5.52
</td>
<td style="text-align:right;">
36.5
</td>
</tr>
<tr>
<td style="text-align:right;">
53.5
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:right;">
43.0
</td>
<td style="text-align:right;">
3.21
</td>
<td style="text-align:right;">
27.2
</td>
</tr>
<tr>
<td style="text-align:right;">
62.7
</td>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
4.32
</td>
<td style="text-align:right;">
27.7
</td>
</tr>
<tr>
<td style="text-align:right;">
56.2
</td>
<td style="text-align:right;">
74
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
2.31
</td>
<td style="text-align:right;">
28.3
</td>
</tr>
<tr>
<td style="text-align:right;">
68.5
</td>
<td style="text-align:right;">
94
</td>
<td style="text-align:right;">
53.0
</td>
<td style="text-align:right;">
4.30
</td>
<td style="text-align:right;">
30.3
</td>
</tr>
<tr>
<td style="text-align:right;">
79.2
</td>
<td style="text-align:right;">
102
</td>
<td style="text-align:right;">
58.0
</td>
<td style="text-align:right;">
3.71
</td>
<td style="text-align:right;">
28.7
</td>
</tr>
</tbody>
</table>
<p>Calculem la funció lineal de regressió per mínims quadrats de l’alçada en funció de les altres variables. Pel teorema anterior, si diem
<span class="math display">\[
\mathbf{X}=\left(
\begin{array}{ccccc}
1&amp;78&amp;48.2&amp;2.75&amp;29.5\\
1&amp;69&amp;45.5&amp;2.15&amp;26.3\\
1&amp;77&amp;46.3&amp;4.41&amp;32.2\\
1&amp;88&amp;49&amp;5.52&amp;36.5\\
1&amp;67&amp;43&amp;3.21&amp;27.2\\
1&amp;80&amp;48&amp;4.32&amp;27.7\\
1&amp;74&amp;48&amp;2.31&amp;28.3\\
1&amp;94&amp;53&amp;4.3&amp;30.3\\
1&amp;102&amp;58&amp;3.71&amp;28.7
\end{array}
\right),\
\mathbf{y}=\left(
\begin{array}{c}
57.5\\ 52.8\\ 61.3\\ 67\\ 53.5\\ 62.7\\ 56.2\\ 68.5\\ 79.2
\end{array}
\right)
\]</span></p>
<p>aleshores <span class="math inline">\((b_0,b_1,b_2,b_3,b_4)\)</span> s’obté mitjançant
<span class="math display">\[
\left(\begin{array}{c} b_0 \\ \vdots \\ b_4\end{array}\right)=\left(\mathbf{X}^t\cdot \mathbf{X} \right)^{-1}\cdot \left(\mathbf{X}^t \cdot \mathbf{y}\right)
\]</span></p>
<p>Per calcular aquest vector, primer entram les dades i definim aquestes matrius</p>
<div class="sourceCode" id="cb789"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb789-1"><a href="regressió-lineal.html#cb789-1" aria-hidden="true" tabindex="-1"></a>y<span class="ot">=</span><span class="fu">c</span>(<span class="fl">57.5</span>,<span class="fl">52.8</span>,<span class="fl">61.3</span>,<span class="dv">67</span>,<span class="fl">53.5</span>,<span class="fl">62.7</span>,<span class="fl">56.2</span>,<span class="fl">68.5</span>,<span class="fl">79.2</span>)</span>
<span id="cb789-2"><a href="regressió-lineal.html#cb789-2" aria-hidden="true" tabindex="-1"></a>x1<span class="ot">=</span><span class="fu">c</span>(<span class="dv">78</span>,<span class="dv">69</span>,<span class="dv">77</span>,<span class="dv">88</span>,<span class="dv">67</span>,<span class="dv">80</span>,<span class="dv">74</span>,<span class="fl">94.0</span>,<span class="dv">102</span>)</span>
<span id="cb789-3"><a href="regressió-lineal.html#cb789-3" aria-hidden="true" tabindex="-1"></a>x2<span class="ot">=</span><span class="fu">c</span>(<span class="fl">8.2</span>,<span class="fl">45.5</span>,<span class="fl">46.3</span>,<span class="dv">49</span>,<span class="dv">43</span>,<span class="dv">48</span>,<span class="dv">48</span>,<span class="dv">53</span>,<span class="dv">58</span>)</span>
<span id="cb789-4"><a href="regressió-lineal.html#cb789-4" aria-hidden="true" tabindex="-1"></a>x3<span class="ot">=</span><span class="fu">c</span>(<span class="fl">2.75</span>,<span class="fl">2.15</span>,<span class="fl">4.41</span>,<span class="fl">5.52</span>,<span class="fl">3.21</span>,<span class="fl">4.32</span>,<span class="fl">2.31</span>,<span class="fl">4.3</span>,<span class="fl">3.71</span>)</span>
<span id="cb789-5"><a href="regressió-lineal.html#cb789-5" aria-hidden="true" tabindex="-1"></a>x4<span class="ot">=</span><span class="fu">c</span>(<span class="fl">29.5</span>,<span class="fl">26.3</span>,<span class="fl">32.2</span>,<span class="fl">36.5</span>,<span class="fl">27.2</span>,<span class="fl">27.7</span>,<span class="fl">28.3</span>,<span class="fl">30.3</span>,<span class="fl">28.7</span>)</span>
<span id="cb789-6"><a href="regressió-lineal.html#cb789-6" aria-hidden="true" tabindex="-1"></a>X<span class="ot">=</span><span class="fu">cbind</span>(<span class="dv">1</span>,x1,x2,x3,x4)</span>
<span id="cb789-7"><a href="regressió-lineal.html#cb789-7" aria-hidden="true" tabindex="-1"></a>X</span></code></pre></div>
<pre><code>##          x1   x2   x3   x4
##  [1,] 1  78  8.2 2.75 29.5
##  [2,] 1  69 45.5 2.15 26.3
##  [3,] 1  77 46.3 4.41 32.2
##  [4,] 1  88 49.0 5.52 36.5
##  [5,] 1  67 43.0 3.21 27.2
##  [6,] 1  80 48.0 4.32 27.7
##  [7,] 1  74 48.0 2.31 28.3
##  [8,] 1  94 53.0 4.30 30.3
##  [9,] 1 102 58.0 3.71 28.7</code></pre>
<p>Ara ja podem estimar els coeficients de la funció de regressió lineal:</p>
<div class="sourceCode" id="cb791"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb791-1"><a href="regressió-lineal.html#cb791-1" aria-hidden="true" tabindex="-1"></a>B<span class="ot">=</span><span class="fu">solve</span>(<span class="fu">t</span>(X)<span class="sc">%*%</span>X)<span class="sc">%*%</span>(<span class="fu">t</span>(X)<span class="sc">%*%</span>y)</span>
<span id="cb791-2"><a href="regressió-lineal.html#cb791-2" aria-hidden="true" tabindex="-1"></a><span class="fu">round</span>(B,<span class="dv">4</span>)</span></code></pre></div>
<pre><code>##       [,1]
##     9.9464
## x1  0.6626
## x2  0.0483
## x3  1.0618
## x4 -0.2543</code></pre>
<p>Obtenim
<span class="math display">\[
\begin{array}{ccccc}
b_0 &amp; b_1 &amp; b_2 &amp; b_3&amp; b_4\\ \hline
9.9464 &amp; 0.6626 &amp; 0.0483 &amp; 1.0618 &amp; -0.2543
\end{array}
\]</span>
i per tant la funció de regressió lineal per mínims quadrats
<span class="math display">\[
\widehat{Y}=9.9464+0.6626X_1+0.0483X_2+1.0618X_3-0.2543X_4
\]</span></p>
<p>Fixau-vos que les igualtats
<span class="math display">\[
\widehat{y}_i=b_0+b_1x_{1i}+b_2x_{2i}+\cdots +b_nx_{ni}
\]</span>
es tradueixen en la igualtat matricial
<span class="math display">\[
\left(
\begin{array}{l}
\widehat{y}_1\\ \widehat{y}_2\\ \vdots\\ \widehat{y}_n
\end{array}
\right)=\left(
\begin{array}{lllll}
1&amp;x_{11}&amp;x_{21}&amp;\ldots&amp;x_{k1}\\
1&amp;x_{12}&amp;x_{22}&amp;\ldots&amp;x_{k2}\\
\vdots&amp;\vdots&amp;\vdots&amp;\ddots&amp;\vdots\\
1&amp;x_{1n}&amp;x_{2n}&amp;\ldots&amp;x_{kn}
\end{array}
\right)\cdot
\left(
\begin{array}{l}
b_0 \\ b_1\\ b_2\\ \vdots\\ b_k
\end{array}
\right)
\]</span></p>
<p>En el nostre exemple, els valors estimats de <span class="math inline">\(Y\)</span> sobre els nins de la nostra mostra serien</p>
<div class="sourceCode" id="cb793"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb793-1"><a href="regressió-lineal.html#cb793-1" aria-hidden="true" tabindex="-1"></a>Y.cap<span class="ot">=</span>X<span class="sc">%*%</span>B</span>
<span id="cb793-2"><a href="regressió-lineal.html#cb793-2" aria-hidden="true" tabindex="-1"></a><span class="fu">t</span>(<span class="fu">round</span>(Y.cap,<span class="dv">1</span>))</span></code></pre></div>
<pre><code>##      [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9]
## [1,] 57.4 53.5 59.7 67.2 52.9 62.8 56.6 71.7   77</code></pre>
<p>i per tant els errors <span class="math inline">\(e_i=y_i-\widehat{y}_i\)</span> són</p>
<div class="sourceCode" id="cb795"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb795-1"><a href="regressió-lineal.html#cb795-1" aria-hidden="true" tabindex="-1"></a>e.i<span class="ot">=</span>y<span class="sc">-</span>Y.cap</span>
<span id="cb795-2"><a href="regressió-lineal.html#cb795-2" aria-hidden="true" tabindex="-1"></a><span class="fu">t</span>(e.i)</span></code></pre></div>
<pre><code>##            [,1]       [,2]     [,3]       [,4]   [,5]       [,6]       [,7]
## [1,] 0.05698925 -0.6579705 1.603446 -0.2006111 0.5914 -0.1154555 -0.3529814
##           [,8]    [,9]
## [1,] -3.150977 2.22616</code></pre>
<p>Amb R, la regressió lineal múltiple per mínims quadrats també es fa amb la funció <code>lm</code>, aplicada a la fórmula que agrupa la variable resposta en funció de <strong>la suma</strong> de les variables de control. Al nostre exemple <a href="regressió-lineal.html#exm:mult">11.13</a> seria</p>
<div class="sourceCode" id="cb797"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb797-1"><a href="regressió-lineal.html#cb797-1" aria-hidden="true" tabindex="-1"></a><span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4)</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Coefficients:
## (Intercept)           x1           x2           x3           x4  
##      9.9464       0.6626       0.0483       1.0618      -0.2543</code></pre>
<p>Obtenim la mateixa funció lineal de regressió que abans:
<span class="math display">\[
\widehat{Y}=9.9464+0.6626X_1+0.0483X_2+1.0618X_3-0.2543X_4
\]</span></p>
<p>A més, com al cas simple, aquesta funció també calcula els errors <span class="math inline">\(e_i\)</span>:</p>
<div class="sourceCode" id="cb799"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb799-1"><a href="regressió-lineal.html#cb799-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>residuals</span></code></pre></div>
<pre><code>##           1           2           3           4           5           6 
##  0.05698925 -0.65797046  1.60344630 -0.20061111  0.59140004 -0.11545548 
##           7           8           9 
## -0.35298144 -3.15097741  2.22616031</code></pre>
<p>La regressió lineal múltiple per mínims quadrats satisfà les mateixes propietats que la simple:</p>
<ul>
<li><p>La recta de regressió passa pel vector mitjà <span class="math inline">\((\overline{x}_1,\overline{x}_2,\ldots,\overline{x}_k,\overline{y})\)</span>:
<span class="math display">\[
\overline{y}=b_0+b_1 \overline{x}_1+\cdots+b_k \overline{x}_k
\]</span></p></li>
<li><p>La mitjana dels valors estimats és igual a la mitjana dels observats:
<span class="math display">\[
\overline{\widehat{y}}=\overline{y}
\]</span></p></li>
<li><p>Els errors <span class="math inline">\((e_i)_{i=1,\ldots,n}\)</span> tenen mitjana 0 i variància
<span class="math display">\[
s_e^2=\frac{SS_E}{n}
\]</span></p></li>
<li><p>Si les variables aleatòries error <span class="math inline">\(E_{\underline{x}_i}\)</span> tenen totes mitjana 0 i la mateixa variància <span class="math inline">\(\sigma^2_E\)</span> i són, dues a dues, incorrelades, aleshores els <span class="math inline">\(b_i\)</span> són els estimadors lineals no esbiaixats òptims dels <span class="math inline">\(\beta_i\)</span> i
<span class="math display">\[
S^2=\frac{SS_E}{n-k-1}
\]</span>
és un estimador no esbiaixat de <span class="math inline">\(\sigma_E^2\)</span></p></li>
<li><p>Si <strong>a més</strong> les variables aleatòries error <span class="math inline">\(E_{\underline{x}_i}\)</span> són totes normals, aleshores
els <span class="math inline">\(b_i\)</span> són els estimadors màxim versemblants dels <span class="math inline">\(\beta_i\)</span></p></li>
<li><p>Se satisfà la mateixa <strong>identitat de les sumes de quadrats</strong>
<span class="math display">\[
SS_{Tot}=SS_R+SS_E
\]</span>
o, equivalentment,
<span class="math display">\[
s^2_y=s^2_{\widehat{y}}+s^2_e
\]</span>
on:</p>
<ul>
<li><p><span class="math inline">\(SS_{Tot}=\sum_{i=1}^n (y_i-\overline{y})^2\)</span> és la <strong>Suma de Quadrats Total</strong>, que mesura la variabilitat dels valors observats <span class="math inline">\(y_i\)</span> de la <span class="math inline">\(Y\)</span> i satisfà que <span class="math inline">\(SS_{Tot}=n\cdot s_y^2\)</span>, on <span class="math inline">\(s_y^2\)</span> és la variància de les <span class="math inline">\(y_i\)</span>.</p></li>
<li><p><span class="math inline">\(SS_R=\sum_{i=1}^n(\widehat{y}_i-\overline{y})^2\)</span> és la <strong>Suma de Quadrats de la Regressió</strong>, que mesura la variabilitat de les estimacions <span class="math inline">\(\widehat{y}_i\)</span> de la <span class="math inline">\(Y\)</span> sobre la nostra mostra i satisfà que <span class="math inline">\(SS_R=n\cdot s_{\widehat{y}}^2\)</span>, on <span class="math inline">\(s_{\widehat{y}}^2\)</span> és la variància de les <span class="math inline">\(\widehat{y}_i\)</span>.</p></li>
<li><p><span class="math inline">\(SS_E=\sum_{i=1}^n (y_i-\widehat{y}_i)^2\)</span> és la de <strong>Suma de Quadrats dels Errors</strong> que ja hem definit i satisfà que <span class="math inline">\(SS_E=n\cdot s_{e}^2\)</span>, on <span class="math inline">\(s_{e}^2\)</span> és la variància dels errors <span class="math inline">\(e_i\)</span>.</p></li>
</ul></li>
</ul>
<p>Com al cas simple, quan R calcula una funció de regressió lineal per mínims quadrats també calcula un munt de coses més:</p>
<div class="sourceCode" id="cb801"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb801-1"><a href="regressió-lineal.html#cb801-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>
<p>D’aquesta caterva d’informació, ja sabem algunes coses que són: els coeficients de la funció (la columna <code>Estimate</code> de la matriu <code>Coefficients</code>), els residus (<code>Residuals</code>), l’arrel quadrada de la <span class="math inline">\(S^2\)</span> (<code>Residual standard error</code>). I algunes tenen el mateix significat que a la regressió lineal simple: la resta d’entrades de la matriu <code>Coefficients</code> o el <code>Multiple R-squared</code>. Els tres darrers valors que dóna R (<code>Adjusted R-squared</code>, <code>F-statistic</code> i <code>p-value</code>) tendran només interès a la regressió múltiple, com veurem.</p>
</div>
<div id="coeficient-de-determinació-múltiple" class="section level3" number="11.2.2">
<h3><span class="header-section-number">11.2.2</span> Coeficient de determinació múltiple</h3>
<p>Com al cas simple, consideram que la funció lineal de regressió
<span class="math display">\[
\widehat{Y}=b_0+b_1X_1+\cdots+b_kX_k
\]</span>
és una bona aproximació de <span class="math inline">\(Y\)</span> com a funció lineal de <span class="math inline">\(X_1,\ldots,X_k\)</span> sobre la nostra mostra quan la variabilitat dels valors estimats <span class="math inline">\(\widehat{y}_i\)</span> representa una fracció molt gran de la variabilitat dels valors observats <span class="math inline">\(y_i\)</span>. Això es quantifica amb el <strong>coeficient de determinació</strong> (<strong>múltiple</strong>) <span class="math inline">\(R^2\)</span>, que es defineix exactament igual que al cas simple i es calcula igual:
<span class="math display">\[
R^2=\frac{SS_R}{SS_{Tot}}=\frac{s^2_{\widehat{y}}}{s^2_y}
\]</span></p>

<div class="example">
<p><span id="exm:unnamed-chunk-863" class="example"><strong>Exemple 11.15  </strong></span>Al nostre Exemple <a href="regressió-lineal.html#exm:mult">11.13</a>, el coeficient de determinació és</p>
</div>
<div class="sourceCode" id="cb803"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb803-1"><a href="regressió-lineal.html#cb803-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.9679545</code></pre>

<div class="rmdnote">
Suposam que encara recordau que, en el cas simple, el coeficient de determinació era el quadrat del coeficient de correlació de Pearson. En el cas múltiple, el que es fa és <strong>definir</strong> el
<strong>coeficient de correlació múltiple</strong> d’un vector <span class="math inline">\(y\)</span> respecte d’uns vectors <span class="math inline">\(x_1,\ldots, x_k\)</span> (tots ells mesures de diferents variables aleatòries sobre els mateixos individus) com
<span class="math display">\[
R= \sqrt{R^2}
\]</span>
i així també se té que <strong>el coeficient de determinació múltiple és el quadrat del coeficient de correlació múltiple</strong>.
</div>
</div>
<div id="coeficient-de-determinació-ajustat" class="section level3" number="11.2.3">
<h3><span class="header-section-number">11.2.3</span> Coeficient de determinació ajustat</h3>
<p><span class="math inline">\(R^2\)</span> tendeix a créixer si afegim variables independents al model, fins i tot quan les variables que afegim són irrellevants. Vegem-ne un exemple.</p>

<div class="example">
<p><span id="exm:multfake" class="example"><strong>Exemple 11.16  </strong></span>Imaginau que a la taula de dades de l’Exemple <a href="regressió-lineal.html#exm:mult">11.13</a> li afegim una nova variable <span class="math inline">\(X_5\)</span> que mesura la distància (en km) a vol d’ocell de la llibreria on la mare sol comprar els llibres a la consulta del pediatra que ha mesurat l’alçada <span class="math inline">\(Y\)</span>. Ens inventarem els valors d’aquesta nova variable, generant-los amb distribució normal <span class="math inline">\(N(2000,1000)\)</span></p>
</div>
<div class="sourceCode" id="cb805"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb805-1"><a href="regressió-lineal.html#cb805-1" aria-hidden="true" tabindex="-1"></a>x5<span class="ot">=</span><span class="fu">round</span>(<span class="fu">rnorm</span>(<span class="dv">9</span>,<span class="dv">2000</span>,<span class="dv">1000</span>))</span>
<span id="cb805-2"><a href="regressió-lineal.html#cb805-2" aria-hidden="true" tabindex="-1"></a>x5</span></code></pre></div>
<pre><code>## [1] 2085 2226 2433 2558 2060 1885  979 1703 2168</code></pre>
<p>Per tant, les dades ara són</p>
<pre><code>## [1] 2085 2226 2433 2558 2060 1885  979 1703 2168</code></pre>
<table>
<thead>
<tr>
<th style="text-align:right;">
Alçada (en cm)
</th>
<th style="text-align:right;">
Edat (en dies)
</th>
<th style="text-align:right;">
Alçada en néixer (en cm)
</th>
<th style="text-align:right;">
Pes en néixer (en kg)
</th>
<th style="text-align:right;">
% d’increment de pes
</th>
<th style="text-align:right;">
Distància llibreria-pediatra (en m)
</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:right;">
57.5
</td>
<td style="text-align:right;">
78
</td>
<td style="text-align:right;">
8.2
</td>
<td style="text-align:right;">
2.75
</td>
<td style="text-align:right;">
29.5
</td>
<td style="text-align:right;">
2085
</td>
</tr>
<tr>
<td style="text-align:right;">
52.8
</td>
<td style="text-align:right;">
69
</td>
<td style="text-align:right;">
45.5
</td>
<td style="text-align:right;">
2.15
</td>
<td style="text-align:right;">
26.3
</td>
<td style="text-align:right;">
2226
</td>
</tr>
<tr>
<td style="text-align:right;">
61.3
</td>
<td style="text-align:right;">
77
</td>
<td style="text-align:right;">
46.3
</td>
<td style="text-align:right;">
4.41
</td>
<td style="text-align:right;">
32.2
</td>
<td style="text-align:right;">
2433
</td>
</tr>
<tr>
<td style="text-align:right;">
67.0
</td>
<td style="text-align:right;">
88
</td>
<td style="text-align:right;">
49.0
</td>
<td style="text-align:right;">
5.52
</td>
<td style="text-align:right;">
36.5
</td>
<td style="text-align:right;">
2558
</td>
</tr>
<tr>
<td style="text-align:right;">
53.5
</td>
<td style="text-align:right;">
67
</td>
<td style="text-align:right;">
43.0
</td>
<td style="text-align:right;">
3.21
</td>
<td style="text-align:right;">
27.2
</td>
<td style="text-align:right;">
2060
</td>
</tr>
<tr>
<td style="text-align:right;">
62.7
</td>
<td style="text-align:right;">
80
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
4.32
</td>
<td style="text-align:right;">
27.7
</td>
<td style="text-align:right;">
1885
</td>
</tr>
<tr>
<td style="text-align:right;">
56.2
</td>
<td style="text-align:right;">
74
</td>
<td style="text-align:right;">
48.0
</td>
<td style="text-align:right;">
2.31
</td>
<td style="text-align:right;">
28.3
</td>
<td style="text-align:right;">
979
</td>
</tr>
<tr>
<td style="text-align:right;">
68.5
</td>
<td style="text-align:right;">
94
</td>
<td style="text-align:right;">
53.0
</td>
<td style="text-align:right;">
4.30
</td>
<td style="text-align:right;">
30.3
</td>
<td style="text-align:right;">
1703
</td>
</tr>
<tr>
<td style="text-align:right;">
79.2
</td>
<td style="text-align:right;">
102
</td>
<td style="text-align:right;">
58.0
</td>
<td style="text-align:right;">
3.71
</td>
<td style="text-align:right;">
28.7
</td>
<td style="text-align:right;">
2168
</td>
</tr>
</tbody>
</table>
<p>Ara calculem el <span class="math inline">\(R^2\)</span> de la regressió de <span class="math inline">\(Y\)</span> en funció de <span class="math inline">\(X_1,\ldots,X_5\)</span> i comparem-lo amb l’obtingut amb <span class="math inline">\(X_1,\ldots,X_4\)</span>:</p>
<div class="sourceCode" id="cb808"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb808-1"><a href="regressió-lineal.html#cb808-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4<span class="sc">+</span>x5))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.974853</code></pre>
<div class="sourceCode" id="cb810"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb810-1"><a href="regressió-lineal.html#cb810-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>r.squared</span></code></pre></div>
<pre><code>## [1] 0.9679545</code></pre>
<p>Com veieu, la regressió tenint en compte la distància de ca’l llibreter a ca’l pediatra té coeficient de determinació més gran que sense tenir-lo en compte. Però imaginam que teniu clar que aquesta variable és irrellevant a l’hora d’explicar l’alçada d’un nin.</p>
<p>Per tenir en compte aquest fet i compensar el nombre de variables emprat en la regressió, en lloc d’emprar el coeficient de determinació
<span class="math display">\[
R^2=\frac{SS_R}{SS_{Tot}}=\frac{SS_{Tot}-SS_E}{SS_{Tot}}
\]</span>
s’empra el <strong>coeficient de determinació ajustat</strong>
<span class="math display">\[
R^2_{adj}=\frac{MS_{Total}-MS_E}{MS_{Total}}
\]</span>
on
<span class="math display">\[
MS_{Total}=\frac{SS_{Tot}}{n-1}\text{ i } MS_E=\frac{SS_E}{n-k-1}.
\]</span></p>

<div class="rmdcaution">
Fixau-vos que <span class="math inline">\(MS_{Total}\)</span> no és res més que <span class="math inline">\(\widetilde{s}_y^2\)</span> i que fa una estona a <span class="math inline">\(MS_E\)</span> li hem dit <span class="math inline">\(S^2\)</span>: l’estimador no esbiaixat de la variància comuna de les variables error <span class="math inline">\(E_{\underline{x}_i}\)</span> quan totes aquestes variables tenen la mateixa variància.
</div>
<p>Operant, queda
<span class="math display">\[
R^2_{adj}=\frac{(n-1)R^2-k}{n-k-1}
\]</span></p>
<p>A la sortida del <code>summary(lm( ))</code> és el <code>Adjusted R-squared</code> de la penúltima línia:</p>
<div class="sourceCode" id="cb812"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb812-1"><a href="regressió-lineal.html#cb812-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>
<p>Es considera que una regressió lineal múltiple per mínims quadrats és “millor” que una altra quan té el coeficient de determinació ajustat més gran. Això només té interès per a regressions amb diferents nombres de variables independents i la mateixa mostra d’individus, perquè fixats <span class="math inline">\(n\)</span> i <span class="math inline">\(k\)</span>, la funció
<span class="math display">\[
R^2\mapsto R^2_{adj}=\frac{(n-1)R^2-k}{n-k-1}
\]</span>
és creixent, i per tant si fixam els valors de <span class="math inline">\(n\)</span> i de <span class="math inline">\(k\)</span>, comparar <span class="math inline">\(R^2\)</span> és equivalent a comparar <span class="math inline">\(R^2_{adj}\)</span>.</p>
<p>Amb R es calcula amb el sufix <code>$adj.r.squared</code>. Calculem els del nostre exemple, amb i sense la variable “falsa”, a veure què passa:</p>
<div class="sourceCode" id="cb814"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb814-1"><a href="regressió-lineal.html#cb814-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.9359091</code></pre>
<div class="sourceCode" id="cb816"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb816-1"><a href="regressió-lineal.html#cb816-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4<span class="sc">+</span>x5))<span class="sc">$</span>adj.r.squared</span></code></pre></div>
<pre><code>## [1] 0.9329412</code></pre>
<p>Com veieu, sense tenir en compte la distància de la llibreria de capçalera de la mare a la consulta del pediatra obtenim un valor més gran de <span class="math inline">\(R^2_{adj}\)</span> i per tant consideram que és una regressió millor que tenint-la en compte. Ja que hi som, comprovem l’equació
<span class="math display">\[
R^2_{adj}=\frac{(n-1)R^2-k}{n-k-1}
\]</span>
per al model amb 4 variables independents:</p>
<div class="sourceCode" id="cb818"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb818-1"><a href="regressió-lineal.html#cb818-1" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">9</span></span>
<span id="cb818-2"><a href="regressió-lineal.html#cb818-2" aria-hidden="true" tabindex="-1"></a>k<span class="ot">=</span><span class="dv">4</span></span>
<span id="cb818-3"><a href="regressió-lineal.html#cb818-3" aria-hidden="true" tabindex="-1"></a>R2<span class="ot">=</span><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>r.squared</span>
<span id="cb818-4"><a href="regressió-lineal.html#cb818-4" aria-hidden="true" tabindex="-1"></a>((n<span class="dv">-1</span>)<span class="sc">*</span>R2<span class="sc">-</span>k)<span class="sc">/</span>(n<span class="sc">-</span>k<span class="dv">-1</span>)</span></code></pre></div>
<pre><code>## [1] 0.9359091</code></pre>
</div>
<div id="intervals-de-confiança-per-als-coeficients" class="section level3" number="11.2.4">
<h3><span class="header-section-number">11.2.4</span> Intervals de confiança per als coeficients</h3>
<p>Suposarem en el que queda de tema que les variables aleatòries error <span class="math inline">\(E_i=E_{\underline{x}_{i}}\)</span> són totes normals de mitjana 0 i la mateixa variància, <span class="math inline">\(\sigma_E^2\)</span>, i dues a dues incorrelades. Recordem que, sota aquestes hipòtesis:</p>
<ul>
<li><p>Els estimadors <span class="math inline">\(b_0,\ldots, b_k\)</span> de <span class="math inline">\(\beta_0,\ldots,\beta_k\)</span> són màxim versemblants i a més no esbiaixats òptims.</p></li>
<li><p>Un estimador no esbiaixat de <span class="math inline">\(\sigma_E^2\)</span> és
<span class="math display">\[
S^2(=MS_E)=\frac{SS_E}{n-k-1}
\]</span></p></li>
</ul>
<p>A l’Exemple <a href="regressió-lineal.html#exm:mult">11.13</a>, aquesta estimació de la variància comuna dels errors <span class="math inline">\(\sigma_E^2\)</span> és</p>
<div class="sourceCode" id="cb820"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb820-1"><a href="regressió-lineal.html#cb820-1" aria-hidden="true" tabindex="-1"></a>S2<span class="ot">=</span><span class="fu">sum</span>(e.i<span class="sc">^</span><span class="dv">2</span>)<span class="sc">/</span>(n<span class="sc">-</span>k<span class="dv">-1</span>)</span>
<span id="cb820-2"><a href="regressió-lineal.html#cb820-2" aria-hidden="true" tabindex="-1"></a>S2</span></code></pre></div>
<pre><code>## [1] 4.604896</code></pre>
<p>Com al cas simple, la sortida de <code>summary(lm( ))</code> dóna el valor de la <span class="math inline">\(S\)</span> (és a dir, l’arrel quadrada de <span class="math inline">\(S^2\)</span>, que per tant estima la desviació típica comuna de les variables error) com a <code>Residual standard error</code>
i s’obté amb el sufix <code>$sigma</code>:</p>
<div class="sourceCode" id="cb822"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb822-1"><a href="regressió-lineal.html#cb822-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>
<div class="sourceCode" id="cb824"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb824-1"><a href="regressió-lineal.html#cb824-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>sigma</span></code></pre></div>
<pre><code>## [1] 2.145902</code></pre>
<div class="sourceCode" id="cb826"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb826-1"><a href="regressió-lineal.html#cb826-1" aria-hidden="true" tabindex="-1"></a>(<span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>sigma)<span class="sc">^</span><span class="dv">2</span></span></code></pre></div>
<pre><code>## [1] 4.604896</code></pre>
<p>Resulta que sota les condicions imposades al principi d’aquesta secció sobre les variables <span class="math inline">\(E_i\)</span>, podem calcular intervals de confiança per als coeficients <span class="math inline">\(\beta_i\)</span> de la funció de regressió lineal.</p>

<div class="rmdmercifulgod">
Donam les fórmules per pura completesa, no esperam que calculeu aquests intervals a mà mai.
</div>
<ul>
<li>L’error típic de cada estimador <span class="math inline">\(b_i\)</span> és l’arrel quadrada de la <span class="math inline">\(i\)</span>-èsima entrada de la diagonal de la matriu <span class="math inline">\(\sigma_E^2\cdot (\mathbf{X}^t \mathbf{X})^{-1}\)</span>, començant a comptar amb <span class="math inline">\(i=0\)</span>:
<span class="math display">\[
\sqrt{(\sigma_E^2\cdot (X^t X)^{-1})_{ii}}
\]</span>
L’estimam sobre una mostra substituint-hi <span class="math inline">\(\sigma_E^2\)</span> per <span class="math inline">\(S^2\)</span>. R ens dóna aquestes estimacions a la columna <code>Std. Error</code> de la matriu <code>Coefficients</code> a la sortida de <code>summary(lm( ))</code>:</li>
</ul>
<div class="sourceCode" id="cb828"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb828-1"><a href="regressió-lineal.html#cb828-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>
<div class="sourceCode" id="cb830"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb830-1"><a href="regressió-lineal.html#cb830-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>coefficients[,<span class="dv">2</span>]</span></code></pre></div>
<pre><code>## (Intercept)          x1          x2          x3          x4 
## 11.06339306  0.07996131  0.06346116  1.30586646  0.42423970</code></pre>
<ul>
<li><p>Cada fracció
<span class="math display">\[
T_i=\frac{b_i-\beta_i}{\sqrt{(S^2\cdot (X^t X)^{-1})_{ii}}}
\]</span>
segueix un llei t de Student amb <span class="math inline">\(n-k-1\)</span> graus de llibertat</p></li>
<li><p>Un interval de confiança de nivell de confiança <span class="math inline">\(q\)</span> per a <span class="math inline">\(\beta_i\)</span> és
<span class="math display">\[
b_i\pm t_{n-k-1,(1+q)/2}\cdot \sqrt{(S^2\cdot (X^t X)^{-1})_{ii}}
\]</span></p></li>
</ul>
<p>Amb R, aquests intervals de confiança s’obtenen com al cas simple, aplicant la funció <code>confint</code> al resultat de la <code>lm</code>:</p>
<div class="sourceCode" id="cb832"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb832-1"><a href="regressió-lineal.html#cb832-1" aria-hidden="true" tabindex="-1"></a><span class="fu">confint</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>##                   2.5 %     97.5 %
## (Intercept) -20.7704551 40.6633520
## x1            0.4406012  0.8846176
## x2           -0.1278951  0.2244978
## x3           -2.5638682  4.6874649
## x4           -1.4322167  0.9235397</code></pre>
<p>Els podem calcular “a mà” a partir de les estimacions dels errors típics que dóna <code>summary(lm( ))</code> amb la fórmula genèrica “estimació <span class="math inline">\(\pm\)</span> quantil per error típic”. Per exemple, l’IC 95% per a <span class="math inline">\(\beta_1\)</span> seria</p>
<div class="sourceCode" id="cb834"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb834-1"><a href="regressió-lineal.html#cb834-1" aria-hidden="true" tabindex="-1"></a>n<span class="ot">=</span><span class="dv">9</span></span>
<span id="cb834-2"><a href="regressió-lineal.html#cb834-2" aria-hidden="true" tabindex="-1"></a>k<span class="ot">=</span><span class="dv">4</span></span>
<span id="cb834-3"><a href="regressió-lineal.html#cb834-3" aria-hidden="true" tabindex="-1"></a>b1<span class="ot">=</span><span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4)<span class="sc">$</span>coefficients[<span class="dv">2</span>]</span>
<span id="cb834-4"><a href="regressió-lineal.html#cb834-4" aria-hidden="true" tabindex="-1"></a>Error.Tip.b1<span class="ot">=</span><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>coefficients[<span class="dv">2</span>,<span class="dv">2</span>]</span>
<span id="cb834-5"><a href="regressió-lineal.html#cb834-5" aria-hidden="true" tabindex="-1"></a>IC<span class="ot">=</span>b1<span class="sc">+</span><span class="fu">qt</span>(<span class="fl">0.975</span>,n<span class="sc">-</span>k<span class="dv">-1</span>)<span class="sc">*</span>Error.Tip.b1<span class="sc">*</span><span class="fu">c</span>(<span class="sc">-</span><span class="dv">1</span>,<span class="dv">1</span>)</span>
<span id="cb834-6"><a href="regressió-lineal.html#cb834-6" aria-hidden="true" tabindex="-1"></a>IC</span></code></pre></div>
<pre><code>## [1] 0.4406012 0.8846176</code></pre>
</div>
<div id="intervals-de-confiança-per-a-les-estimacions-de-la-variable-resposta" class="section level3" number="11.2.5">
<h3><span class="header-section-number">11.2.5</span> Intervals de confiança per a les estimacions de la variable resposta</h3>
<p>Si les variables error <span class="math inline">\(E_i\)</span> satisfan les condicions imposades al principi de la secció anterior, també podem calcular intervals de confiança per al valor estimat de la <span class="math inline">\(Y\)</span> sobre els individus amb valors de <span class="math inline">\((X_1,\ldots,X_k)\)</span> donats. Com al cas simple, tenim dos intervals:</p>
<ul>
<li><p>L’interval per al <strong>valor esperat</strong> <span class="math inline">\(\mu_{Y|x_{10},\ldots,x_{k0}}\)</span> de <span class="math inline">\(Y\)</span> sobre els individus en els que <span class="math inline">\((X_1,\ldots,X_k)\)</span> val <span class="math inline">\((x_{10},\ldots,x_{k0})\)</span>, és a dir, per al valor mitjà de la <span class="math inline">\(Y\)</span> sobre tots els individus de la població en els que <span class="math inline">\((X_1,\ldots,X_k)\)</span> valgui <span class="math inline">\((x_{10},\ldots,x_{k0})\)</span></p></li>
<li><p>L’interval per al <strong>valor predit</strong> <span class="math inline">\(y_0\)</span> de <span class="math inline">\(Y\)</span> sobre un individu concret en el que <span class="math inline">\((X_1,\ldots,X_k)\)</span> valgui <span class="math inline">\((x_{10},\ldots,x_{k0})\)</span>.</p></li>
</ul>
<p>La discussió sobre les diferències entre una i altra estimació i per què el segon interval és més ample que el primer són les mateixes que al cas simple, no la repetirem aquí. I, contràriament, al cas simple, us estalviarem les fórmules. Simplement heu de saber que aquests intervals també es calculen amb R amb la funció <code>predict.lm</code> aplicada a:</p>
<ul>
<li>un data frame amb els valors de les variables independents sobre l’individu, o els individus, per al que volem estimar la <span class="math inline">\(Y\)</span></li>
<li>el resultat de la <code>lm</code></li>
<li>el paràmetre <code>interval</code> igualat al tipus d’interval que volem: <code>"prediction"</code> si és per al valor en un individu, <code>"confidence"</code> si és per al valor esperat</li>
</ul>

<div class="example">
<p><span id="exm:unnamed-chunk-880" class="example"><strong>Exemple 11.17  </strong></span>Suposem que volem estimar amb un 95% de confiança l’alçada d’un infant de <span class="math inline">\(X_1=69\)</span> dies que en néixer va fer <span class="math inline">\(X_2=45.5\)</span> cm i va pesar <span class="math inline">\(X_3=2.55\)</span> kg i des de llavors el seu pes ha augmentat un <span class="math inline">\(X_4=26.3\)</span>%.</p>
</div>
<p>Primer definim un data frame que reculli les dades d’aquest infant:</p>
<div class="sourceCode" id="cb836"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb836-1"><a href="regressió-lineal.html#cb836-1" aria-hidden="true" tabindex="-1"></a>infant<span class="ot">=</span><span class="fu">data.frame</span>(<span class="at">x1=</span><span class="dv">69</span>,<span class="at">x2=</span><span class="fl">45.5</span>,<span class="at">x3=</span><span class="fl">2.55</span>,<span class="at">x4=</span><span class="fl">26.3</span>)</span></code></pre></div>
<p>Aleshores:</p>
<ul>
<li>Un interval de confiança del 95% per al valor estimat de l’alçada d’aquest infant és</li>
</ul>
<div class="sourceCode" id="cb837"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb837-1"><a href="regressió-lineal.html#cb837-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.lm</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4), infant, <span class="at">interval=</span><span class="st">&quot;prediction&quot;</span>)</span></code></pre></div>
<pre><code>##        fit      lwr      upr
## 1 53.88269 46.99166 60.77372</code></pre>
<ul>
<li>Un interval de confiança del 95% per al valor estimat de l’alçada mitjana de tots els infants amb els mateixos valors de <span class="math inline">\(X_1,\ldots,X_4\)</span> que aquest infant és</li>
</ul>
<div class="sourceCode" id="cb839"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb839-1"><a href="regressió-lineal.html#cb839-1" aria-hidden="true" tabindex="-1"></a><span class="fu">predict.lm</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4), infant, <span class="at">interval=</span><span class="st">&quot;confidence&quot;</span>)</span></code></pre></div>
<pre><code>##        fit     lwr      upr
## 1 53.88269 50.4202 57.34518</code></pre>
<p>Obtenim que:</p>
<ul>
<li><p>Estimam que l’alçada d’aquest infant és 53.9 cm.</p></li>
<li><p>Estimam amb un 95% de confiança que l’alçada d’aquest infant està entre els 47 i els 60.8 cm.</p></li>
<li><p>Estimam amb un 95% de confiança que l’alçada mitjana dels infants amb les mateixes característiques que aquest està entre els 50.4 i els 57.3 cm. És a dir que, de mitjana, els infants com aquest fan entre 50.4 i els 57.3 cm.</p></li>
</ul>
</div>
<div id="lanova-de-la-regressió-lineal-múltiple" class="section level3" number="11.2.6">
<h3><span class="header-section-number">11.2.6</span> L’ANOVA de la regressió lineal múltiple</h3>
<p>Com en el cas simple, en una regressió lineal múltiple ens interessa realitzar el contrast
<span class="math display">\[
\left\{\begin{array}{l} H_0: \beta_1=\beta_2=\cdots=\beta_k=0 \\
H_1: \text{hi ha qualque }\beta_i\not= 0 \end{array}
\right.
\]</span>
perquè si <span class="math inline">\(\beta_1=\beta_2=\cdots=\beta_k=0\)</span>, el model esdevé
<span class="math display">\[
Y|{x_1,\ldots,x_k}=\beta_0+E_{x_1,\ldots,x_k}
\]</span>
i la <span class="math inline">\(Y\)</span> no depèn de les <span class="math inline">\(X_i\)</span>, de manera que el model lineal no és adequat.</p>
<p>Això es pot fer amb <span class="math inline">\(k\)</span> contrastos
<span class="math display">\[
\left\{\begin{array}{l} H_0: \beta_i=0 \\
H_1: \beta_i\neq 0 \end{array}
\right.
\]</span>
emprant els estadístics <span class="math inline">\(T_i\)</span> que hem definit fa una estona, que segueixen lleis t de Student amb <span class="math inline">\(n-k-1\)</span> graus de llibertat. Els p-valors d’aquests contrastos són els de la columna <code>Pr(&gt;|t|)</code> a la matriu de <code>Coefficients</code> de la sortida de <code>summary(lm( ))</code>. No cal ajustar-los, el nombre <span class="math inline">\(n-k-1\)</span> de graus de llibertat ja té en compte que fem <span class="math inline">\(k+1\)</span> contrastos.</p>
<div class="sourceCode" id="cb841"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb841-1"><a href="regressió-lineal.html#cb841-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>
<p>Només obtenim evidència estadística que <span class="math inline">\(\beta_1\neq 0\)</span>.</p>
<p>Una altra possibilitat és emprar una ANOVA. Fixau-vos que si
<span class="math display">\[
\beta_1=\beta_2=\cdots=\beta_k=0,
\]</span>
aleshores
<span class="math display">\[
\mu_{Y|x_{11},\ldots,x_{k1}}=\cdots=\mu_{Y|x_{1n},\ldots,x_{kn}}=\beta_0
\]</span>
Per tant, si al contrast
<span class="math display">\[
\left\{\begin{array}{l}
H_0:\mu_{Y|x_{11},\ldots,x_{1k}}=\cdots=\mu_{Y|x_{n1},\ldots,x_{nk}}\\
H_1:\text{no és veritat que }\mu_{Y|x_{11},\ldots,x_{1k}}=\cdots=\mu_{Y|x_{n1},\ldots,x_{nk}}
\end{array}
\right.
\]</span>
rebutjam la hipòtesi nul·la, això implicarà que podem rebutjar que <span class="math inline">\(\beta_1=\beta_2=\cdots=\beta_k=0\)</span> i podrem concloure que el model lineal té sentit.</p>
<p>La <strong>taula</strong> d’aquesta ANOVA és
<span class="math display">\[
\begin{array}{llllll}\hline
\text{Font de} &amp; \text{Graus de} &amp; \text{Suma de} &amp; \text{Quadrats} &amp; \text{Estadístic} &amp; \text{p-valor}\\
\text{variació} &amp; \text{llibertat} &amp;  \text{quadrats} &amp; \text{mitjans}      &amp;\text{de contrast}  &amp; \\\hline
\text{Regressió} &amp; k &amp; SS_R  &amp; MS_R &amp; F &amp;  p\\
\text{Error} &amp; n-k-1 &amp; SS_E  &amp; MS_E &amp; &amp;\\
\hline 
\end{array}
\]</span>
on
<span class="math display">\[
MS_R=\frac{SS_R}{k},\quad MS_E=\frac{SS_E}{n-k-1}
\]</span>
Com a les altres ANOVA, l’estadístic de contrast <span class="math inline">\(F\)</span> és
<span class="math display">\[
F=\frac{MS_R}{MS_E}
\]</span>
Si la hipòtesi nul·la és vertadera (i els errors satisfan les condicions establertes al començament de la secció anterior), aquest estadístic de contrast segueix una llei F de Fisher amb <span class="math inline">\(k\)</span> i <span class="math inline">\(n-k-1\)</span> graus de llibertat i té valor proper a 1, de manera que se pren com a p-valor
<span class="math display">\[
\text{p-valor}=P(F_{k,n-k-1}\geqslant F).
\]</span></p>
<p>Calculem la taula ANOVA de l’Exemple <a href="regressió-lineal.html#exm:mult">11.13</a></p>
<div class="sourceCode" id="cb843"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb843-1"><a href="regressió-lineal.html#cb843-1" aria-hidden="true" tabindex="-1"></a>SS.R<span class="ot">=</span><span class="fu">sum</span>((Y.cap<span class="sc">-</span><span class="fu">mean</span>(y))<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb843-2"><a href="regressió-lineal.html#cb843-2" aria-hidden="true" tabindex="-1"></a>SS.R</span></code></pre></div>
<pre><code>## [1] 556.376</code></pre>
<div class="sourceCode" id="cb845"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb845-1"><a href="regressió-lineal.html#cb845-1" aria-hidden="true" tabindex="-1"></a>SS.E<span class="ot">=</span><span class="fu">sum</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4)<span class="sc">$</span>residuals<span class="sc">^</span><span class="dv">2</span>)</span>
<span id="cb845-2"><a href="regressió-lineal.html#cb845-2" aria-hidden="true" tabindex="-1"></a>SS.E</span></code></pre></div>
<pre><code>## [1] 18.41959</code></pre>
<div class="sourceCode" id="cb847"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb847-1"><a href="regressió-lineal.html#cb847-1" aria-hidden="true" tabindex="-1"></a>MS.R<span class="ot">=</span>SS.R<span class="sc">/</span>k</span>
<span id="cb847-2"><a href="regressió-lineal.html#cb847-2" aria-hidden="true" tabindex="-1"></a>MS.R</span></code></pre></div>
<pre><code>## [1] 139.094</code></pre>
<div class="sourceCode" id="cb849"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb849-1"><a href="regressió-lineal.html#cb849-1" aria-hidden="true" tabindex="-1"></a>MS.E<span class="ot">=</span>SS.E<span class="sc">/</span>(n<span class="sc">-</span>k<span class="dv">-1</span>)</span>
<span id="cb849-2"><a href="regressió-lineal.html#cb849-2" aria-hidden="true" tabindex="-1"></a>MS.E</span></code></pre></div>
<pre><code>## [1] 4.604896</code></pre>
<div class="sourceCode" id="cb851"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb851-1"><a href="regressió-lineal.html#cb851-1" aria-hidden="true" tabindex="-1"></a>F<span class="ot">=</span>MS.R<span class="sc">/</span>MS.E</span>
<span id="cb851-2"><a href="regressió-lineal.html#cb851-2" aria-hidden="true" tabindex="-1"></a>F</span></code></pre></div>
<pre><code>## [1] 30.20567</code></pre>
<div class="sourceCode" id="cb853"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb853-1"><a href="regressió-lineal.html#cb853-1" aria-hidden="true" tabindex="-1"></a>p.val<span class="ot">=</span><span class="dv">1</span><span class="sc">-</span><span class="fu">pf</span>(F,k,n<span class="sc">-</span>k<span class="dv">-1</span>)</span>
<span id="cb853-2"><a href="regressió-lineal.html#cb853-2" aria-hidden="true" tabindex="-1"></a>p.val</span></code></pre></div>
<pre><code>## [1] 0.003014918</code></pre>
<p><span class="math display">\[
\begin{array}{llllll}\hline
\text{Font de} &amp; \text{Graus de} &amp; \text{Suma de} &amp; \text{Quadrats} &amp; \text{Estadístic} &amp; \text{p-valor}\\
\text{variació} &amp; \text{llibertat} &amp;  \text{quadrats} &amp; \text{mitjans}      &amp;\text{de contrast}  &amp; \\\hline
\text{Regressió} &amp; 4 &amp; 556.376  &amp; 139.094 &amp;  30.21 &amp;  0.003\\
\text{Error} &amp; 4 &amp; 18.42  &amp; 4.605 &amp; &amp;\\
\hline 
\end{array}
\]</span></p>
<p>Hem trobat evidència estadística que el model lineal és adequat.</p>

<div class="rmdromans">
Podeu creure que no hi ha cap funció de cap paquet de R que calculi aquesta taula per a la regressió lineal múltiple?
</div>
<p>L’estadístic de contrast i el p-valor d’aquesta ANOVA els podeu trobar a la darrera línia de la sortida <code>summary(lm( ))</code>; són el <code>F-statistic</code> (i a més us diu els graus de llibertat, <code>DF</code>, de la seva distribució) i el <code>p-value</code>:</p>
<div class="sourceCode" id="cb855"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb855-1"><a href="regressió-lineal.html#cb855-1" aria-hidden="true" tabindex="-1"></a><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## 
## Call:
## lm(formula = y ~ x1 + x2 + x3 + x4)
## 
## Residuals:
##        1        2        3        4        5        6        7        8 
##  0.05699 -0.65797  1.60345 -0.20061  0.59140 -0.11546 -0.35298 -3.15098 
##        9 
##  2.22616 
## 
## Coefficients:
##             Estimate Std. Error t value Pr(&gt;|t|)   
## (Intercept)  9.94645   11.06339   0.899  0.41946   
## x1           0.66261    0.07996   8.287  0.00116 **
## x2           0.04830    0.06346   0.761  0.48899   
## x3           1.06180    1.30587   0.813  0.46179   
## x4          -0.25434    0.42424  -0.600  0.58113   
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Residual standard error: 2.146 on 4 degrees of freedom
## Multiple R-squared:  0.968,  Adjusted R-squared:  0.9359 
## F-statistic: 30.21 on 4 and 4 DF,  p-value: 0.003015</code></pre>

<div class="rmdromans">
Podeu creure que no podem extreure el p-valor del <code>summary(lm(y~x1+x2+x3+x4))</code> amb un sufix, sinó que l’hem de calcular? Per sort és fàcil, emprant el contingut de <code>summary(lm( ))$fstatistic</code>, que és un vector de 3 entrades: el valor de l’estadístic <span class="math inline">\(F\)</span> i els seus dos graus de llibertat. Per tant, per calcular el p-valor, podem fer el següent:
</div>
<div class="sourceCode" id="cb857"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb857-1"><a href="regressió-lineal.html#cb857-1" aria-hidden="true" tabindex="-1"></a>FF<span class="ot">=</span><span class="fu">summary</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>fstatistic</span>
<span id="cb857-2"><a href="regressió-lineal.html#cb857-2" aria-hidden="true" tabindex="-1"></a><span class="dv">1</span><span class="sc">-</span><span class="fu">pf</span>(FF[<span class="dv">1</span>],FF[<span class="dv">2</span>],FF[<span class="dv">3</span>])</span></code></pre></div>
<pre><code>##       value 
## 0.003014918</code></pre>

<div class="rmdnote">
Una altra opció és emprar la funció <code>glance</code> del paquet <strong>broom</strong>, que aplicada a un objecte dóna un <em>dataframe</em> (de fet, una adaptació del concepte de <em>dataframe</em> a l’anàlisi de dades massives, un <strong>tibble</strong>) amb els seus continguts més importants; vaja, que us permet “donar una ullada” a l’objecte.
</div>
<div class="sourceCode" id="cb859"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb859-1"><a href="regressió-lineal.html#cb859-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(broom)</span>
<span id="cb859-2"><a href="regressió-lineal.html#cb859-2" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))</span></code></pre></div>
<pre><code>## # A tibble: 1 × 12
##   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC
##       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;
## 1     0.968         0.936  2.15      30.2 0.00301     4  -16.0  44.0  45.2
## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</code></pre>
<div class="sourceCode" id="cb861"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb861-1"><a href="regressió-lineal.html#cb861-1" aria-hidden="true" tabindex="-1"></a><span class="fu">glance</span>(<span class="fu">lm</span>(y<span class="sc">~</span>x1<span class="sc">+</span>x2<span class="sc">+</span>x3<span class="sc">+</span>x4))<span class="sc">$</span>p.value</span></code></pre></div>
<pre><code>##       value 
## 0.003014918</code></pre>
</div>
</div>
<div id="test-de-la-lliçó-11" class="section level2" number="11.3">
<h2><span class="header-section-number">11.3</span> Test de la lliçó 11</h2>
<p><strong>(1)</strong> En una regressió lineal d’una variable Y respecte d’una variable independent X, hem emprat les observacions (x,y) d’100 individus i hem obtingut la recta de regressió per mínims quadrats y=3.02-0.96x. El valor mitjà de la variable X a la mostra que hem emprat ha estat 0.8. Quines de les afirmacions següents són vertaderes?</p>
<ol style="list-style-type: decimal">
<li>Amb les dades que ens donen, no podem saber el valor mitjà de la variable Y a la mostra que hem emprat.</li>
<li>El valor mitjà de la variable Y a la mostra que hem emprat ha estat 2.252.</li>
<li>El valor mitjà de la variable Y a la mostra que hem emprat ha estat 3.02.
!. Segons aquest model, en els individus de la població objecte d’estudi, quan la variable X augmenta una unitat, el valor esperat de la variable Y augmenta 0.96</li>
<li>Segons aquest model, en els individus de la població objecte d’estudi, quan la variable X augmenta una unitat, el valor esperat de la variable Y disminueix 0.96</li>
<li>Cap de les altres afirmacions és correcta.</li>
</ol>
<p><strong>(2)</strong> En una regressió lineal per mínims quadrats d’una variable Y respecte d’una variable independent X, hem emprat les observacions (x,y) d’100 individus. A la nostra mostra, la mitjana de X ha estat 0.05, la mitjana de Y ha estat -1.3, la variància de X ha estat 2.56, la variància de Y ha estat 8.36 i la covariància de X i Y ha estat 4.54. Què val el coeficient de determinació de la regressió per mínims quadrats de Y respecte de X (arrodonit a 3 xifres decimals)?</p>
<ol style="list-style-type: decimal">
<li>0.212</li>
<li>0.963</li>
<li>0.981</li>
<li>1.773</li>
<li>No el podem calcular amb les dades que ens donen</li>
<li>Cap de les altres respostes és correcta</li>
</ol>
<p><strong>(3)</strong> Quines de les afirmacions següents sobre la regressió per mínims quadrats és vertadera?</p>
<ol style="list-style-type: decimal">
<li>Quan es fa a mà, primer s’estima la pendent de la recta i després el terme independent</li>
<li>Quan es fa a mà, primer s’estima el terme independent de la recta i després la pendent</li>
<li>La suma de quadrats total és la suma de quadrats dels tractaments més la suma de quadrats dels errors</li>
<li>La suma de quadrats total és la suma de quadrats de la regressió més la suma de quadrats dels errors</li>
<li>Els coeficients de la recta són els que fan mínima la suma de quadrats de la regressió</li>
<li>Els coeficients de la recta són els que fan màxima la suma de quadrats de la regressió</li>
<li>Cap de les altres respostes és correcta</li>
</ol>
<p><strong>(4)</strong> Sota les hipòtesis adients per als errors, els estimadors <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span> de <span class="math inline">\(\beta_0\)</span> i <span class="math inline">\(\beta_1\)</span> són màxim versemblants. Però, … què significa que un estimador sigui màxim versemblant?</p>
<ol style="list-style-type: decimal">
<li>Que aplicat a una m.a.s. sempre dóna el p-valor més gran en els contrastos bilaterals del paràmetre que volem estimar</li>
<li>Que aplicat a una m.a.s. sempre dóna el p-valor més petit en els contrastos bilaterals del paràmetre que volem estimar</li>
<li>Que aplicat a una m.a.s. sempre dóna el valor més probable del paràmetre.</li>
<li>Que aplicat a una m.a.s. sempre dóna el valor del paràmetre que fa més probable la m.a.s.</li>
<li>Que aplicat a una m.a.s. sempre dóna el valor més probable de l’estimador.</li>
<li>Que té valor esperat el valor real del paràmetre</li>
</ol>
<p><strong>(5)</strong> Quines de les afirmacions següents sobre el coeficient de determinació en una regressió per mínims quadrats són vertaderes?</p>
<ol style="list-style-type: decimal">
<li>El seu quadrat és la covariància dels vectors x, y de la mostra</li>
<li>El seu quadrat és la correlació dels vectors x, y de la mostra</li>
<li>La seva arrel quadrada positiva és la covariància dels vectors x, y de la mostra</li>
<li>La seva arrel quadrada positiva és la correlació dels vectors x, y de la mostra</li>
<li>Cap de les altres respostes és correcta</li>
</ol>
<p><strong>(6)</strong> Quines de les afirmacions següents sobre el coeficient de determinació de la regressió lineal per mínims quadrats són vertaderes? Marcau totes les vertaderes.</p>
<ol style="list-style-type: decimal">
<li>En el cas de la regressió lineal simple, el seu quadrat és la correlació entre els valors de la variable independent i els de la variable dependent a la nostra mostra</li>
<li>En el cas de la regressió lineal simple, és el quadrat de la correlació entre els valors de la variable independent i els de la variable dependent a la nostra mostra</li>
<li>En el cas de la regressió lineal múltiple, si afegim al nostre model variables independents, el valor del coeficient de determinació no decreix.</li>
<li>En el cas de la regressió lineal múltiple, si empram un nombre més gran de variables independents (però no necessàriament mantenint les variables anteriors) el valor del coeficient de determinació no decreix.</li>
<li>Cap de les altres respostes és correcta.</li>
</ol>
<p><strong>(7)</strong> En fer la regressió lineal d’una variable Y respecte d’una variable X, hem obtingut la recta y=0.8+1.2x. Quina de les conclusions següents és la més correcta segons aquest model?</p>
<ol style="list-style-type: decimal">
<li>Un augment d’1 unitat de la variable X causa un augment d’1.2 unitats de la variable Y</li>
<li>Un augment d’1 unitat de la variable X està associada a un augment d’1.2 unitats de la variable Y</li>
<li>Un augment d’1 unitat de la variable X causa un augment de 0.8 unitats de la variable Y</li>
<li>Un augment d’1 unitat de la variable X està associada a un augment de 0.8 unitats de la variable Y</li>
</ol>
<p><strong>(8)</strong> Quines de les afirmacions següents sobre l’estimació de la variable dependent Y a partir de la variable independent X per mitjà d’una recta de regressió per mínims quadrats són vertaderes (quan els errors satisfan les condicions adients)?</p>
<ol style="list-style-type: decimal">
<li>L’estimació puntual del valor de Y sobre un individu concret on X valgui x<sub>0</sub> i l’estimació de valor mitjà de Y sobre tots els individus on X valgui x<sub>0</sub> sempre coincideixen</li>
<li>L’estimació puntual del valor de Y sobre un individu concret on X valgui x<sub>0</sub> sempre és estrictament més gran que l’estimació del valor mitjà de Y sobre tots els individus on X valgui x<sub>0</sub></li>
<li>L’interval de confiança del 95% per al valor de Y sobre un individu concret on X valgui x<sub>0</sub> i l’interval de confiança del 95% per al valor mitjà de Y sobre tots els individus on X valgui x<sub>0</sub> sempre coincideixen</li>
<li>L’interval de confiança del 95% per al valor de Y sobre un individu concret on X valgui x<sub>0</sub> sempre és més ample que l’interval de confiança del 95% per al valor mitjà de Y sobre tots els individus on X valgui x<sub>0</sub></li>
<li>L’interval de confiança del 95% per al valor de Y sobre un individu concret on X valgui x<sub>0</sub> sempre és més estret que l’interval de confiança del 95% per al valor mitjà de Y sobre tots els individus on X valgui x<sub>0</sub></li>
<li>Cap de les altres respostes és correcta.</li>
</ol>
<p><strong>(9)</strong> Emprant un model de regressió lineal per mínims quadrats d’una variable Y respecte d’una variable X, hem estimat el valor de Y quan X=5 amb la funció <code>predict.lm</code> i els dos valors possibles del paràmetre <code>interval</code> i hem obtingut els intervals de confiança del 95% [2,5] i [3,9], però no sabem quin és l’interval de confiança per al valor predit de Y sobre un individu per al qual X=5 i quin és l’interval de confiança per al valor mitjà de Y sobre els individus per al quals X=5.</p>
<ol style="list-style-type: decimal">
<li>[2,5] és l’interval de confiança per al valor predit de Y sobre un individu per al qual X=5 i [3,9] és l’interval de confiança per al valor mitjà de Y sobre els individus per al quals X=5.</li>
<li>[2,5] és l’interval de confiança per al valor mitjà de Y sobre els individus per al quals X=5 i [3,9] és l’interval de confiança per al valor predit de Y sobre un individu per al qual X=5.</li>
<li>No podem saber quin interval és quin</li>
<li>En realitat, hi ha un error: és impossible que [2,5] i [3,9] (en l’ordre que sigui) siguin intervals de confiança per al valor predit de Y sobre un individu per al qual X=5 i per al valor mitjà de Y sobre els individus per al quals X=5</li>
</ol>
<p><strong>(10)</strong> Emprant un model de regressió lineal per mínims quadrats d’una variable Y respecte d’una variable X, hem estimat el valor de Y quan X=5 amb la funció <code>predict.lm</code> i els dos valors possibles del paràmetre <code>interval</code> i hem obtingut els intervals de confiança del 95% [2,5] i [1,6], però no sabem quin és l’interval de confiança per al valor predit de Y sobre un individu per al qual X=5 i quin és l’interval de confiança per al valor mitjà de Y sobre els individus per al quals X=5.</p>
<ol style="list-style-type: decimal">
<li>[2,5] és l’interval de confiança per al valor predit de Y sobre un individu per al qual X=5 i [1,6] és l’interval de confiança per al valor mitjà de Y sobre els individus per al quals X=5.</li>
<li>[2,5] és l’interval de confiança per al valor mitjà de Y sobre els individus per al quals X=5 i [1,6] és l’interval de confiança per al valor predit de Y sobre un individu per al qual X=5.</li>
<li>No podem saber quin interval és quin</li>
<li>En realitat, hi ha un error: és impossible que [2,5] i [1,6] (en l’ordre que sigui) siguin intervals de confiança per al valor predit de Y sobre un individu per al qual X=5 i per al valor mitjà de Y sobre els individus per al quals X=5</li>
</ol>
<p><strong>(11)</strong> Quines de les afirmacions següents sobre la recta de regressió per mínims quadrats és vertadera?</p>
<ol style="list-style-type: decimal">
<li>Sempre passa per l’origen de coordenades</li>
<li>Sempre és creixent</li>
<li>El coeficient <span class="math inline">\(b_1\)</span> no canvia si canviam les unitats amb les que mesuram la variable independent multiplicant-les per una constant (com ara si canviam cm per m), però no canviam les unitats amb les que mesuram la variable dependent</li>
<li>El coeficient <span class="math inline">\(b_0\)</span> no canvia si canviam les unitats amb les que mesuram la variable independent multiplicant-les per una constant (com ara si canviam cm per m), però no canviam les unitats amb les que mesuram la variable dependent</li>
<li>Sempre passa pel punt mig de les observacions que formen la mostra</li>
<li>Els valors de <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span> determinen el valor de <span class="math inline">\(R^2\)</span></li>
<li>Cap de les altres respostes és correcta</li>
</ol>
<p><strong>(12)</strong> Quines de les afirmacions següents sobre el coeficient de determinació en una regressió per mínims quadrats són vertaderes?</p>
<ol style="list-style-type: decimal">
<li>El seu signe és sempre el del coeficient <span class="math inline">\(b_1\)</span> de la recta de regressió</li>
<li>El seu signe és sempre el de la covariància dels vectors x i y de la mostra</li>
<li>És el quadrat de la correlació poblacional de les variables X i Y</li>
<li>Si sabeu el seu valor i la recta de regressió, podeu saber el valor de la correlació dels vectors x i y de la mostra</li>
<li>Cap de les altres respostes és correcta</li>
</ol>
<p><strong>(13)</strong> Hem mesurat dues variables X i Y sobre 100 subjectes. La variància de la mostra x de X obtinguda ha estat 3 i la variància de la mostra x de X ha estat 12. Quin, o quins, dels valors següents no poden ser el de la covariància de x i y?</p>
<ol style="list-style-type: decimal">
<li>0</li>
<li>1.5</li>
<li>6</li>
<li>9</li>
<li><span class="math inline">\(-\sqrt{2}\)</span></li>
<li>-6</li>
<li>-9</li>
<li>La covariància d’aquests vectors x i y pot ser qualsevol número real</li>
</ol>
<p><strong>(14)</strong> En una regressió lineal simple per mínims quadrats, en el contrast sobre si <span class="math inline">\(\beta_0=0\)</span> o no obtenim un p-valor 0.018 i en el contrast sobre si <span class="math inline">\(\beta_1=0\)</span> o no obtenim un p-valor 0.005. Si se satisfan les condicions sobre les variables error perquè aquests p-valors siguin fiables, quines de les afirmacions següents són correctes?</p>
<ol style="list-style-type: decimal">
<li>Hem obtingut evidència estadística que <span class="math inline">\(\beta_0=0\)</span> i <span class="math inline">\(\beta_1=0\)</span></li>
<li>No hem obtingut evidència estadística que <span class="math inline">\(\beta_0=0\)</span> i <span class="math inline">\(\beta_1=0\)</span></li>
<li>Hem obtingut evidència estadística que <span class="math inline">\(\beta_0\neq 0\)</span> i <span class="math inline">\(\beta_1\neq 0\)</span></li>
<li>No hem obtingut evidència estadística que <span class="math inline">\(\beta_0\neq 0\)</span> i <span class="math inline">\(\beta_1\neq 0\)</span></li>
<li>En la realitat, la probabilitat que <span class="math inline">\(\beta_0=0\)</span> és més petita que la de <span class="math inline">\(\beta_1=0\)</span></li>
<li>En la realitat, la probabilitat que <span class="math inline">\(\beta_0=0\)</span> és més gran que la de <span class="math inline">\(\beta_1=0\)</span></li>
<li>Estam segurs que <span class="math inline">\(b_0\)</span> i <span class="math inline">\(b_1\)</span> han donat diferent de 0</li>
<li>Cap de les altres respostes és correcta</li>
</ol>
<p><strong>(15)</strong> En una regressió lineal simple per mínims quadrats d’una variable Y respecte d’una variable X, hem obtingut <span class="math inline">\(b_1=0.18\)</span> i un interval de confiança del 95% per a <span class="math inline">\(\beta_1\)</span> entre 0.1 i 0.26. Si se satisfan les condicions sobre les variables error perquè aquest interval de confiança sigui fiable, quines de les afirmacions següents són correctes?</p>
<ol style="list-style-type: decimal">
<li>Com que 0.18 pertany a [0.1,0.26], estam molt segurs que <span class="math inline">\(\beta_1=0.18\)</span></li>
<li>Amb nivell de significació 0.05 segur que rebutjarem que <span class="math inline">\(\beta_1\neq 0\)</span></li>
<li>Si calculàssim l’IC del 90% per a <span class="math inline">\(\beta_1\)</span> amb la mateixa mostra, seria més ample que el del 95%</li>
<li>Si calculàssim l’IC del 90% per a <span class="math inline">\(\beta_1\)</span> amb la mateixa mostra, seria més estret que el del 95%</li>
<li>Per a un 95% de les mostres de la mateixa mida que la nostra, el coeficient <span class="math inline">\(b_1\)</span> estaria entre 0.1 i 0.26</li>
<li>Amb nivell de significació 0.05, podem concloure que el model lineal té sentit, en el sentit que la variable Y|x no és la variable error Ex més una constant</li>
<li>Cap de les altres respostes és correcta</li>
</ol>
<p><strong>(16)</strong> Quines de les afirmacions següents sobre la regressió lineal múltiple per mínims quadrats són vertaderes? Marcau totes les vertaderes.</p>
<ol style="list-style-type: decimal">
<li>La funció que s’obté sempre passa per l’origen de coordenades</li>
<li>La funció que s’obté sempre passa pel punt mig de les observacions que formen la mostra</li>
<li>La mitjana dels valors estimats de la variable dependent sobre els subjectes de la mostra coincideix amb la mitjana dels valors observats d’aquesta variable sobre aquests subjectes</li>
<li>La mitjana dels valors estimats de la variable dependent sobre els subjectes de la mostra coincideix amb la variància dels valors observats d’aquesta variable sobre aquests subjectes</li>
<li>La suma de quadrats total és la suma de quadrats dels tractaments més la suma de quadrats dels errors</li>
<li>La suma de quadrats total és la suma de quadrats de la regressió més la suma de quadrats dels errors</li>
<li>Els coeficients de la funció lineal són els que fan mínima la suma de quadrats dels errors</li>
<li>La mitjana dels valors estimats de la variable dependent sobre els subjectes de la mostra coincideix amb la mitjana dels errors en l’estimació d’aquesta variable sobre aquests subjectes</li>
<li>La mitjana dels errors en l’estimació de la variable dependent sobre els subjectes de la mostra és 0</li>
<li>La variància dels errors en l’estimació de la variable dependent sobre els subjectes de la mostra és 0</li>
</ol>
<p><strong>(17)</strong> En una regressió lineal, hem obtingut la funció de regressió lineal <span class="math inline">\(Y=2+3X_1-5X_2+4X_3\)</span>. Quines de les afirmacions són vertaderes?</p>
<ol style="list-style-type: decimal">
<li>Segons aquest model, si en un subjecte A el valor de <span class="math inline">\(X_1\)</span> és més gran que en un subjecte B, el valor esperat de <span class="math inline">\(Y\)</span> en el subjecte A és més gran que el valor esperat de <span class="math inline">\(Y\)</span> en el subjecte B</li>
<li>Segons aquest model, si en un subjecte A el valor de <span class="math inline">\(X_1\)</span> és més gran que en un subjecte B, pot passar que el valor esperat de <span class="math inline">\(Y\)</span> en el subjecte A sigui més petit que el valor esperat de <span class="math inline">\(Y\)</span> en el subjecte B</li>
<li>Segons aquest model, si <span class="math inline">\(X_1\)</span> i <span class="math inline">\(X_3\)</span> romanen constants i <span class="math inline">\(X_2\)</span> augmenta en 1 unitat, el valor esperat de <span class="math inline">\(Y\)</span> disminueix 3 unitats</li>
<li>Segons aquest model, si <span class="math inline">\(X_1\)</span> i <span class="math inline">\(X_3\)</span> romanen constants i <span class="math inline">\(X_2\)</span> augmenta en 1 unitat, el valor esperat de <span class="math inline">\(Y\)</span> disminueix 5 unitats</li>
<li>Segons aquest model, si <span class="math inline">\(X_1\)</span> i <span class="math inline">\(X_3\)</span> romanen constants i <span class="math inline">\(X_2\)</span> augmenta en 1 unitat, el valor esperat de <span class="math inline">\(Y\)</span> augmenta 5 unitats</li>
<li>Cap de les altres respostes és vertadera</li>
</ol>
<p><strong>(18)</strong> Quines de les afirmacions següents sobre el coeficient de determinació de la regressió lineal per mínims quadrats són vertaderes? Marcau totes les vertaderes.</p>
<ol style="list-style-type: decimal">
<li>En el cas de la regressió lineal simple, el seu quadrat és la correlació entre els valors de la variable independent i els de la variable dependent a la nostra mostra</li>
<li>En el cas de la regressió lineal simple, és el quadrat de la correlació entre els valors de la variable independent i els de la variable dependent a la nostra mostra</li>
<li>En el cas de la regressió lineal múltiple, si afegim al nostre model variables independents, el valor del coeficient de determinació no decreix.</li>
<li>En el cas de la regressió lineal múltiple, si empram un nombre més gran de variables independents (però no necessàriament mantenint les variables anteriors) el valor del coeficient de determinació no decreix.</li>
<li>No pot valer 0</li>
<li>No pot ser estrictament negatiu</li>
<li>Cap de les altres respostes és correcta.</li>
</ol>
<p><strong>(19)</strong> En la regressió lineal múltiple de Y en funció de les variables independents <span class="math inline">\(X_1,X_2,X_3,X_4,X_5\)</span> a partir d’una certa mostra hem obtingut que <span class="math inline">\(R^2=0.92\)</span> i <span class="math inline">\(R^2_{adj}=0.82\)</span>, mentre que si fem la regressió lineal múltiple de Y en funció només de les variables independents <span class="math inline">\(X_1,X_2,X_3\)</span> a partir de la mateixa mostra hem obtingut que <span class="math inline">\(R^2=0.91\)</span> i <span class="math inline">\(R^2_{adj}=0.865\)</span>. Quina de les afirmacions següents és vertadera?</p>
<ol style="list-style-type: decimal">
<li>Això no pot ser, perquè <span class="math inline">\(R^2_{adj}\)</span> sempre és més gran o igual que R2.</li>
<li>Això no pot ser, perquè quan <span class="math inline">\(R^2\)</span> decreix, <span class="math inline">\(R^2_{adj}\)</span> també decreix.</li>
<li>Això no pot ser, perquè quan eliminam variables independents, la <span class="math inline">\(R^2\)</span> sempre creix.</li>
<li>Això sí que pot ser, i llavors consideram que el model amb 5 variables independents és millor, perquè té el valor de <span class="math inline">\(R^2\)</span> més gran</li>
<li>Això sí que pot ser, i llavors consideram que el model amb 3 variables independents és millor, perquè té el valor de <span class="math inline">\(R^2_{adj}\)</span> més gran</li>
<li>Això sí que pot ser, i llavors consideram que el model amb 3 variables independents és millor, perquè té el valor de <span class="math inline">\(R^2\)</span> més petit</li>
<li>Cap de les altres respostes és correcta.</li>
</ol>
<p><strong>(20)</strong> Quines de les afirmacions següents sobre <span class="math inline">\(R^2_{adj}\)</span> són vertaderes?</p>
<ol style="list-style-type: decimal">
<li>Sempre és més petit que <span class="math inline">\(R^2\)</span></li>
<li>Pot ser més petit o més gran que <span class="math inline">\(R^2\)</span></li>
<li>Pot ser estrictament negatiu</li>
<li>Pot valer 0</li>
<li>Si afegim variables independents a la regressió lineal, el seu valor no decreix</li>
<li>Si afegim variables independents a la regressió lineal, el seu valor no creix</li>
<li>Cap de les altres respostes és vertadera</li>
</ol>
<p><strong>(21)</strong> En el contrast d’hipòtesis sobre si un coeficient <span class="math inline">\(\beta_i\)</span> és 0 o no, la conclusió amb nivell de significació 0.1 ha estat que hem d’acceptar la hipòtesi nul·la. Quines de les afirmacions següents són vertadera en aquesta situació?</p>
<ol style="list-style-type: decimal">
<li>Hem acceptat la hipòtesi nul·la perquè hem obtingut evidència estadística que la hipòtesi nul·la és vertadera.</li>
<li>Hem acceptat la hipòtesi nul·la perquè no hem obtingut evidència estadística que la hipòtesi nul·la sigui falsa.</li>
<li>Hem acceptat que <span class="math inline">\(\beta_i=0\)</span></li>
<li>Hem acceptat la hipòtesi nul·la perquè hem obtingut evidència estadística que la probabilitat que la hipòtesi alternativa sigui vertadera és 0.1 o menys.</li>
<li>Assumim una probabilitat d’equivocar-nos acceptant la hipòtesi nul·la quan és falsa de 0.1.</li>
<li>Assumim una probabilitat d’equivocar-nos rebutjant la hipòtesi nul·la quan és vertadera de 0.1.</li>
<li>Cap de les altres respostes és correcta</li>
</ol>
<p><strong>(22)</strong> Quina o quines de les afirmacions següents sobre la regressió lineal per mínims quadrats d’una variable Y respecte d’un conjunt de variables independents són vertaderes?</p>
<ol style="list-style-type: decimal">
<li>Si el nombre de variables independents és el mateix, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la mitjana dels valors de Y dels punts de la mostra entre la mitjana dels valors estimats de Y sobre els punts de la mostra.</li>
<li>Si el nombre de variables independents és el mateix, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la variància dels valors de Y dels punts de la mostra entre la variància dels valors estimats de Y sobre els punts de la mostra.</li>
<li>Si el nombre de variables independents és el mateix, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la variància dels valors estimats de Y sobre els punts de la mostra entre la variància dels valors de Y dels punts de la mostra</li>
<li>Independentment del nombre de variables independents, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la mitjana dels valors de Y dels punts de la mostra entre la mitjana dels valors estimats de Y sobre els punts de la mostra.</li>
<li>Independentment del nombre de variables independents, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la variància dels valors de Y dels punts de la mostra entre la variància dels valors estimats de Y sobre els punts de la mostra.</li>
<li>Independentment del nombre de variables independents, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la variància dels valors estimats de Y sobre els punts de la mostra entre la variància dels valors de Y dels punts de la mostra</li>
</ol>
<p><strong>(23)</strong> Roda el món i torna al Born. Quan diem que el 0.975-quantil d’una variable aleatòria normal estàndard Z és 1.96, això significa que:</p>
<ol style="list-style-type: decimal">
<li>P(Z=0.975)=1.96</li>
<li>P(Z&lt;0.975)=1.96</li>
<li>P(Z&gt;0.975)=1.96</li>
<li>P(Z=1.96)=0.975</li>
<li>P(Z&lt;1.96)=0.975</li>
<li>P(Z&gt;1.96)=0.975</li>
<li>En realitat no significa res de tot això.</li>
</ol>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="chap:ANOVA.html" class="navigation navigation-prev navigation-unique" aria-label="Previous page"><i class="fa fa-angle-left"></i></a>

    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"whatsapp": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "sans",
"size": 2
},
"edit": {
"link": null,
"text": null
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"search": {
"engine": "fuse",
"options": null
},
"toc": {
"collapse": "subsection",
"download": ["pdf", "epub"]
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
