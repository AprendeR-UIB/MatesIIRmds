[
["index.html", "Matemàtiques II v.2021 Presentació", " Matemàtiques II v.2021 2021-05-24 Presentació Això és una edició en línea dels apunts de Matemàtiques II dels graus de Biologia i Bioquímica de la UIB. Aquests apunts no són autocontinguts pel que fa al R: suposam que l’estudiant va llegint les lliçons de R corresponents a cada tema a la 2a part del manual AprendeR. Aquests apunts estan en construcció. A la llista següent hi anirem anunciant les actualitzacions. 21-05-2021: Pujat tema 10 9-04-2021: Corregits alguns errors detectats als temes 4, 5 i 6 21-03-2021: Pujats temes 7 a 9 8-03-2021: Pujat tema 6 5-03-2021: Pujat tema 5 23-02-2021: Pujat tema 4 22-02-2021: Afegit un comentari després de l’Exemple 1.1 21-02-2021: Pujats temes 1 a 3 Significats d’algunes capses: Material molt important. Alerta! Exercici. Detalls matemàtics que us poden interessar, però que no cal saber. Comentari que volem emfatitzar. Comentari que volem que recordeu. Qüestió en què volem que caigueu. Acabam de matar un moixet. El llibre està escrit en R Markdown, emprant RStudio com a editor de textos i el paquet bookdown per convertir els fitxers markdown en un llibre Aquest treball se publica sota llicència Atribució-No Comercial-SenseDerivats 4.0 "],
["chap-conceptes.html", "Tema 1 Alguns conceptes bàsics 1.1 Tipus de dades 1.2 Població 1.3 Variable aleatòria 1.4 Mostra 1.5 Mostreig aleatori 1.6 Mostres de conveniència 1.7 Test de la lliçó 1", " Tema 1 Alguns conceptes bàsics 1.1 Tipus de dades Els tipus bàsics de dades que consideram en aquest curs són els següents: Dades qualitatives. Són les que expressen una qualitat, com ara el sexe anatòmic (mascle, femella), el gènere d’una persona (home, dona, lesbiana, gai, bisexual, transsexual, intersexual, asexual, sestosexual…), el tipus de càncer (de mama, de còlon, de pròstata…), l’espècie d’un ésser viu, la soca d’un bacteri o un virus… Si només poden prendre dos valors (per exemple “Sí” i “No”, o “Home” i “Dona”) diem que són binàries o dicotòmiques, depenent del que volguem complicar l’adjectiu. Les dades qualitatives poden ser iguals o diferents, i no admeten cap altre tipus de comparació. Dades ordinals. Són dades similars a les qualitatives, en el sentit que expressen una qualitat, però amb la diferència que les ordinals es poden ordenar de manera natural. Per exemple, els nivells de gravetat d’una malaltia (sa, lleu, greu, molt greu, …) o les qualificacions en un examen (suspens, aprovat, notable, excel·lent) són dades ordinals. En canvi, no es poden ordenar de manera significativa les malalties de les persones o les espècies dels animals: per això són dades qualitatives, no ordinals. Dades quantitatives. Són nombres genuïns, “de veritat”, amb els quals té sentit operar, com ara edats, longituds, pesos, temps, nombres d’individus, etc. En distingim dos tipus: Discretes: Prenen valors que avancen a salts i que podem identificar amb nombres naturals: nombre de germans d’una persona, nombre d’exemplars d’una espècie en una regió, nombre de fulles en una branca… Contínues: Podrien prendre qualsevol valor real dins d’un interval si es poguessin mesurar amb precisió infinita: longituds, alçades, temperatures, temps… Exemple 1.1 Hem anotat algunes característiques d’un grup de nins i nines: el nom, l’alçada (en cm), el nombre de germans, el color dels cabells i el nombre setmanal de refrescs que solen prendre. Hem recollit aquestes dades a la Taula 1.1, on cada filera representa un nin o una nina i cada columna recull una de les característiques que hem anotat: Taula 1.1: Una petita taula de dades Nom Alçada Germans Cabell Refrescs setmanals 1 Marta 135 2 ros 2-3 2 Laura 132 1 negre 2-3 3 Xavier 138 0 negre 0-1 4 Joan 141 3 castany 4-5 5 Maria 134 2 vermell 0-1 6 Maria 136 1 castany 6 o més Aleshores: Les dades de la columna “Nom” són qualitatives. Les dades de la columna “Alçada” són quantitatives contínues. Les dades de la columna “Germans” són quantitatives discretes. Les dades de la columna “Cabell” són qualitatives. Les dades de la columna “Refrescs setmanals” són ordinals. Els valors de la variable “Refrescs setmanals” no són nombres, sinó franges de nombres, per la qual cosa no són dades quantitatives. Però certament estan ordenats: na Marta en beu més que en Xavier. Per tant són dades ordinals. Si en lloc de donar com a valors les franges, donàssim el nombre de refrescos (0,1,2,3,4,5,6,…) sí que serien dades quantitatives, en aquest cas discretes. L’anàlisi, tant descriptiva com inferencial, d’un conjunt de dades és diferent segons el seu tipus. Així, per a dades qualitatives només té interès estudiar i representar les freqüències amb què apareixen els seus diferents valors, mentre que l’anàlisi de dades quantitatives sol involucrar el càlcul de mesures estadístiques, com ara la mitjana o la desviació típica, que expressin numèricament les seves propietats. Dos punts rellevants a tenir en compte: No tot nombre és una dada quantitativa. Només els consideram quantitatius quan són nombres genuïns. Per exemple, si demanam a un pacient que qualifiqui el seu dolor amb un nombre natural de 0 a 10, no és una dada quantitativa, sinó ordinal: No és una mesura precisa del dolor; no són números “de veritat”, sinó abreviatures de “Res”, “Una miqueta”,…, “Matau-me”. Tenir dolor 6 no significa “tenir el doble de dolor” que tenir dolor 3 (si ho significàs, quin seria el valor corresponent “al doble de dolor” que 6?). En canvi, una persona amb 6 germans sí que en té el doble que una amb 3 germans. No té sentit sumar-los o operar-los en general. Per exemple, si jo tenc dolor de nivell 6 i tu tens dolor de nivell 5, entre tots dos no tenim dolor de nivell 11. En canvi, si jo tenc 6 germans i tu 5, entre tots dos si que tenim 11 germans. La distinció discret-continu és purament teòrica. En realitat, tota dada és discreta perquè no podem mesurar res amb precisió infinita, però les eines matemàtiques “contínues” (derivades, integrals, etc.) són molt més potents que les discretes, per la qual cosa sempre que tengui sentit, és convenient considerar una variable com a contínua. Observau, per exemple, la diferència entre l’alçada mesurada en cm i arrodonida a unitats i el nombre de germans tal i com les hem recollit a la Taula 1.1. Les dues dades es presenten com a nombres naturals, però els nombres de germans no admeten més precisió, mentre que les alçades les podríem mesurar, amb els aparells adequats, en mm, en µm, en nm…. Com que, a més, les eines per a tractar dades contínues són molt més potents, consideram les alçades com a dades contínues, mentre que els nombres de germans no hi ha més remei que tractar-los com a discrets. En concret, és convenient considerar en la pràctica com a dades contínues aquelles que donen lloc a nombres naturals molt grans, com per exemple el nombre de glòbuls vermells en un litre de sang, de bases nuclèiques en un genoma, o de persones d’un país: la diferència entre 10000000, 10000001, 10000002… pot considerar-se com a contínua: de fet, si prenem el milió com a unitat de mesura, la diferència entre aquests nombres està en la sisena xifra decimal: 10.000000, 10.000001, 10.000002. 1.2 Població En general, una població és simplement un conjunt d’individus o objectes sobre els quals volem conèixer alguna informació. Una població pot estar perfectament definida en un lloc i temps: per exemple, els habitants d’Espanya just avui. Però normalment la seva definició serà difusa. Si, per exemple, volem estimar alguna cosa sobre una espècie de plantes, de qui estam parlant exactament? De les plantes que estan vives just ara? De totes les plantes d’aquesta espècie de la història del món? Hi hem d’incloure les que encara no han nascut? Tranquils, no ens trencarem gens el cap amb això. Però almanco heu de ser conscients que una població pot contenir objectes que en realitat no existeixen ni hagin existit ni vagin a existir, sinó simplement que “podrien existir”. Parlarem llavors d’una població virtual (en altres llocs en diuen una població metafòrica). Per exemple, quan diem que “La probabilitat que surti cara en llançar una moneda equilibrada és 1/2”, el que significa és que “Si prenem la població formada per tots els possibles llançaments individuals de totes les possibles monedes equilibrades, en la meitat dels seus membres el resultat és Cara.” Els membres d’aquesta població són tots els “possibles” llançaments de monedes equilibrades, els que s’han realitzat al llarg de la història, els que es realitzaran en el futur, i els que es podrien haver realitzat o es podrien realitzar en el futur però en realitat no s’han fet ni s’arribaran a fer mai. 1.3 Variable aleatòria Una variable aleatòria definida sobre una població \\(\\Omega\\) és simplement una funció \\[ X: \\Omega\\to \\mathbb{R} \\] que assigna a cada subjecte de \\(\\Omega\\) un nombre real. La idea intuïtiva que hi ha al darrera d’aquesta definició és que una variable aleatòria mesura una característica dels subjectes de \\(\\Omega\\) que varia a l’atzar d’un subjecte a un altre. Per exemple: Prenem una persona d’una població i mesuram el seu nivell de colesterol, o la seva alçada, o el seu nombre de fills… En aquest cas, \\(\\Omega\\) és la població sota estudi, de la qual prenem la persona que mesuram. Llançam una moneda equilibrada 3 vegades i comptam les cares que obtenim. En aquest cas, \\(\\Omega\\) és la població “virtual” formada per totes les seqüències de 3 llançaments d’una moneda equilibrada passades, presents, futures i hipotètiques. Procurau adquirir la disciplina de descriure sempre les variables aleatòries mitjançant una plantilla de l’estil de “Prenem … i mesuram …” perquè us quedi clar quina és la població i quina la funció. A més, afegiu-hi les unitats si és necessari. Per exemple: \\(X\\): “Prenem una persona de Mallorca i mesuram la seva alçada (en cm)”. Fixau-vos que aquesta variable aleatòria no és la mateixa que \\(Y\\): “Prenem una persona de Mallorca i mesuram la seva alçada (en m)” perquè, encara que totes dues mesuren el mateix sobre els mateixos subjectes, els assignen números diferents. I \\(X\\) també és diferent de \\(Z\\): “Prenem una persona de Suècia i mesuram la seva alçada (en cm)” perquè ha canviat la població. En canvi a “Llançam una moneda 3 vegades i comptam les cares” no hi ha necessitat d’especificar unitats, tret que volgueu emprar una unitat inesperada (jo què sé, que compteu les cares en fraccions de dotzena). Per a més informació sobre variables aleatòries, consultau el Tema 2. 1.4 Mostra En un estudi inferencial, volem deduir (inferir) informació sobre una o diverses variables aleatòries definides sobre una població a partir d’una mostra: La població objectiu, o d’interès és el conjunt de subjectes sobre els quals desitjam obtenir informació. La mostra de la població es el grup de subjectes concrets en els quals mesuram les característiques d’interès, usualment molt petit per comparació amb la població. Una mostra d’una variable aleatòria és el conjunt de valors obtenguts prenent una mostra de la població i mesurant la variable sobre aquests subjectes. Procurau tenir sempre present que, per molta cura que posem en obtenir una mostra d’una població, sempre serà només una aproximació imperfecta d’aquesta. Figura 1.1: Població versus mostra Exemple 1.2 Si volem saber si un brou és fat, no ens el bebem tot, perquè ens quedaríem sense brou i ja tant faria si era fat o salat. El que fem és tastar-ne només una cullerada. El brou és la població, la cullerada la mostra. Exemple 1.3 En un estudi recent es volgué determinar si la llum artificial a la nit afecta el ritme circadià dels ocells cantors. Per fer-ho, s’exposà un grup de 34 ferrericos (Parus major) a diferents intensitats de llum artificial durant la nit i s’anotà com els afectava tant a nivell de comportament com a nivell metabòlic o d’expressió gènica. Aquí la població d’interès és la formada per tots els ocells cantors (passats, presents i futurs) i la mostra són els 34 pobres ferrericos. Exemple 1.4 Una sèrie de 10 llançaments d’una moneda equilibrada concreta és una mostra de la població dels “possibles llançaments de monedes equilibrades”. Si podem mesurar tots els individus de la població, no ens fa falta emprar estadística inferencial per mirar d’endevinar el que volem saber sobre la població: ho mesuram sobre tothom i per avall. Però el més normal és que no poguem mesurar tots els individus de la població. La població pot ser massa gran. Per exemple, si volem calcular l’alçada mitjana dels europeus que avui tenen 18 anys, és pràcticament impossible amidar-los tots. Com ja hem comentat, la població pot ser virtual o metafòrica en el sentit que pot contenir membres que en aquest moment ni existeixin. Per exemple, per saber si la llum artificial a la nit afecta els ocells cantors, els autors de la investigació citada a l’Exemple 1.3 no podien accedir a tots els ocells cantors actuals, i molt manco als que ja no són entre nosaltres o als que encara no han nascut. Pot ser que per obtenir la informació d’un subjecte l’hàgim de sacrificar. En aquest cas, per mesurar tota la població l’hauríem d’exterminar. Pot ser simplement que sigui difícil accedir a tota la població: per exemple, els estudiants de la UIB són relativament pocs, uns 12000, però seria complicat aconseguir amidar-los tots. Exemple 1.5 Vosaltres què sou: una població o una mostra? Doncs depèn: Sou una població quan el que interessa és saber qualque cosa sobre vosaltres i només vosaltres. Sou una mostra si a partir d’informació sobre vosaltres miram d’inferir informació sobre un grup més gran de subjectes: sobre els estudiants de primer curs de Biologia i Bioquímica d’Espanya, o sobre els estudiants de la UIB d’aquest curs, o sobre els joves europeus, o sobre els mamífers, o… En aquest curs sobrecarregarem el terme variable, en el sentit que tendrà dos significats diferents que hauríeu de poder distingir segons el context: D’una banda, direm variable a una característica que pot prendre diferents valors sobre diferents individus; quan tengui aquest sentit, de vegades li afegirem l’adjectiu poblacional. Per exemple, l’alçada de les persones (de tot el món, d’un país, d’una ciutat…) és una variable poblacional. D’altra banda, també direm variable a un vector format pels valors d’una variable poblacional sobre una mostra concreta d’individus. Per exemple, les alçades recollides en la Taula 1.1 formen una variable en aquest sentit. 1.5 Mostreig aleatori Com ja hem explicat, en un estudi estadístic inferencial, es pren una mostra d’individus d’una població i s’estimen algunes característiques de la població a partir de les de la mostra. Perquè això tengui sentit, és necessari que la mostra sigui representativa de la població. Però, és clar, sense conèixer les característiques de la població, no podem saber si una mostra és representativa o no. Per sortir d’aquest atzucac, la solució acceptada és prendre una mostra aleatòria, és a dir, triant els seus subjectes a l’atzar i tots amb la mateixa probabilitat de ser escollits. En fer-ho així: S’eviten preferències en l’elecció, per la qual cosa esperam que la mostra sigui representativa de la població. Naturalment, això no està garantit: per pura mala sort ens pot sortir una mostra súper rara, és el que té l’atzar. Però almanco hem fet “el que tothom considera que és el que toca” per intentar que sigui representativa. Figura 1.2: http://dilbert.com/strip/2001-10-25 Es poden usar tècniques estadístiques per delimitar errors en l’estimació i la seva probabilitat; per exemple, podrem calcular la probabilitat que la nostra mostra sigui súper rara en algun sentit concret. Exemple 1.6 Per tastar el brou, abans de prendre’n una cullerada el remenam bé. D’aquesta manera esperam que les molècules del brou s’organitzin de manera aleatòria dins l’olla i que la cullerada que en prenguem sigui representativa del brou. Específicament, el mostreig aleatori consisteix a seleccionar una mostra de la població de manera que totes les mostres de la mateixa mida siguin equiprobables; és a dir, que si fixam el nombre de subjectes de la mostra, tots els conjunts d’aquest nombre de subjectes tenguin la mateixa probabilitat de ser seleccionats. Hi ha dos tipus bàsics de mostreig aleatori que hem de distingir: amb i sense reposició. Per fixar idees, suposem que disposam d’una població de la qual volem extreure una mostra de mida \\(n\\). Una manera de fer-ho seria repetir \\(n\\) vegades el procés d’escollir, a l’atzar i de manera equiprobable, un individu de la població, anotar qui és i “retornar-lo a la població”, de manera que pugui tornar a ser triat dins la mateixa mostra. El tipus de mostra obtenguda d’aquesta manera rep el nom de mostra aleatòria amb reposició, o mostra aleatòria simple. Observau que amb aquest procediment un mateix individu pot aparèixer diverses vegades en una mostra, i que tots els subconjunts “amb possibles repeticions” (el seu nom tècnic és multiconjunts) de \\(n\\) individus de la població tenen la mateixa probabilitat d’obtenir-se. El mostreig aleatori simple és l’estándard d’excel·lència entre els mètodes de mostreig, i gairebé tots els resultats que explicarem en aquest curs pressuposen que la mostra és aleatòria simple. Sí, ja sabem que sembla contradictori que quan, per exemple, volgueu conèixer l’opinió de la població sobre un tema, el mètode recomanat per construir la mostra d’individus que entrevistareu permeti comptar més d’una vegada l’opinió d’un mateix subjecte. Una altra manera d’extreure la nostra mostra seria repetir \\(n\\) vegades el procés d’escollir, a l’atzar i de manera equiprobable, un individu de la població, anotar qui és i “retirar-lo de la població”, de manera que ja no pugui tornar a ser triat dins la mateixa mostra. Això és equivalent a extreure de cop \\(n\\) individus diferents de la població. Aquestes mostres no tenen individus repetits, i qualsevol selecció de \\(n\\) individus diferents té la mateixa probabilitat de ser l’obtenguda. En aquest cas es parla d’una mostra aleatòria sense reposició. Quan la mida de la població és MOLT gran per comparació amb la mostra, la probabilitat que hi hagi repeticions en una mostra aleatòria simple és molt petita. Recordau que si una població té \\(N\\) individus, la probabilitat que una mostra aleatòria simple de mida \\(n\\) tengui tots els seus membres diferents és \\[ \\frac{N(N-1)\\cdots (N-n+1)}{N^n} \\] i per tant la probabilitat que tengui qualque membre repetit és \\[ 1-\\frac{N(N-1)\\cdots (N-n+1)}{N^n}. \\] Amb R: La funció pbirthday(n,N) ens dóna la probabilitat que en una mostra aleatòria simple de mida \\(n\\) d’una població de mida \\(N\\) hi hagi algun element repetit. La funció qbirthday(p,N) ens dóna la mida mínima d’una mostra aleatòria simple d’una població de mida \\(N\\) perquè la probabilitat que hi hagi algun element repetit sigui com a mínim \\(p\\). El nom birthday fa referència a la paradoxa de l’aniversari: el típic problema de calcular la probabilitat que dos estudiants d’una classe celebrin l’aniversari el mateix dia i sorprendre’s que en una classe de 50 estudiants hi hagi més d’un 95% de probabilitats que hi hagi algun aniversari repetit. En efecte, podem entendre una classe de 50 estudiants com una mostra aleatòria simple de 50 dies de l’any (els aniversaris dels estudiants) triats d’un conjunt de 366 possibles dies. La probabilitat que almanco 2 estudiants celebrin l’aniversari el mateix dia és la probabilitat que es doni almanco una repetició en aquesta mostra. Podem calcular-la amb R: pbirthday(50,366) ## [1] 0.9700731 1-prod((366:(366-49))/366) # Amb la fórmula de la probabilitat ## [1] 0.9700731 Emprau la funció qbirthday per trobar el nombre mínim d’estudiants que hi ha d’haver en una classe perquè la probabilitat que es repeteixi una data d’aniversari arribi al 95%. I comprovau que el valor trobat és correcte. Per exemple, si triam 100 individus de les Balears (que tenen al voltant de 1,150,000 habitants) a l’atzar permetent repeticions, la probabilitat que surti qualque individu repetit és pbirthday(100,1150000) ## [1] 0.004295221 Només en 1 de cada 250 mostres de 100 balears triats a l’atzar permetent repeticions hi hauria qualque repetició. En canvi, si triam 100 estudiants de la UIB (que té al voltant de 12000 estudiants) a l’atzar permetent repeticions, la probabilitat que surti qualque estudiant repetit és de pbirthday(100,12000) ## [1] 0.3387643 En 1 de cada 3 mostres de 100 estudiants de la UIB triats a l’atzar permetent repeticions hi hauria qualque repetició. Però si triam 10 estudiants de la UIB a l’atzar permetent repeticions, la probabilitat que surti qualque estudiant repetit ja és pbirthday(10,12000) ## [1] 0.003743964 Exemple 1.7 El gràfic següent mostra la probabilitat que si prenem una mostra aleatòria simple de mida \\(n\\) d’una població de 12000 individus, com ara la formada pels estudiants de la UIB, els seus membres siguin tots diferents: f=function(n,N){1-pbirthday(n,N)} prob=sapply(1:300,f,N=12000) plot(1:300, prob, type=&quot;l&quot;, lwd=2, xlab=&quot;n&quot;, ylab=&quot;probabilitat&quot;, xaxp=c(0,300,30),yaxp=c(0,1,10)) El gràfic següent mostra la mida màxima \\(n\\) d’una mostra aleatòria simple extreta d’una població de mida \\(N\\) perquè la probabilitat de repeticions sigui menor que 0.01 (és a dir, perquè més del 99% de les mostres aleatòries simples tenguin tots els seus elements diferents), en funció de \\(N\\): fites=sapply(500+100*(0:150), qbirthday, prob=0.01) plot(500+100*(0:150), fites, pch=20, xlab=&quot;N&quot;, ylab=&quot;n&quot;, cex=0.5, xaxp=c(500,15500,30),yaxp=c(0,20,20)) Així doncs, si la mida de la població és molt gran en relació a la de la mostra, és molt probable que els elements d’una mostra aleatòria simple siguin tots diferents. Això implica que, quan la població és molt gran en relació a la mostra, els mostrejos aleatoris amb i sense reposició són (aproximadament) equivalents en el sentit següent: Si la població és molt, molt gran, un mostreig amb reposició donaria gairebé segur una mostra amb tots els seus elements diferents. Per tant, podem prendre directament la mostra sense reposició i suposar que permetíem repeticions, però que no n’hi ha hagut, i que per tant la mostra és simple. Una mostra aleatòria de 100 individus diferents de les Balears, o de 10 estudiants diferents de la UIB, pot passar perfectament per una mostra presa permetent repeticions, perquè encara que les permetéssim, només obtendríem qualque repetició en 1 de cada 250 mostres com aquesta. Però en canvi ja és més mal de creure que una mostra aleatòria de 100 estudiants diferents de la UIB hagi estat presa permetent repeticions, perquè si les permetéssim, en 1 de cada 3 vegades sortiria qualcú repetit. A més, si la mida de la població és molt més gran que \\(n\\), quan construïu una mostra aleatòria de mida \\(n\\) escollint els individus un a un a l’atzar sense repeticions, la probabilitat a cada moment d’escollir un individu concret dels que quedin és gairebé la mateixa que si permetéssiu repeticions. Exemple 1.8 Imaginau que teniu una població de 106 individus i en voleu extreure una mostra aleatòria de 10. Llavors, per exemple, quan ja portau 9 individus escollits, la probabilitat de triar un individu concret dels que queden és \\(1/999991=10^{-6}+9·10^{-12}\\), mentre que si permeteu que surti qualcun dels ja escollits aquesta probabilitat és \\(1/10^6=10^{-6}\\). En resum: Si prenem una mostra aleatòria sense reposició de mida \\(n\\) d’una població de mida \\(N\\) MOLT més gran que n, podem suposar que és una mostra aleatòria simple. Per fixar una fita, en aquest curs entendrem que \\(N\\) és prou MOLT més gran que \\(n\\) com per poder aplicar aquesta regla quan \\(N\\) és com a mínim unes 1000 vegades més gran que \\(n\\). Hi ha un tipus de mostreig aleatori que caldrà tenir present més endavant i volem esmentar ara. Es tracta del mostreig aleatori estratificat. S’utilitza quan la població està classificada en estrats que són d’interès per a la propietat estudiada. Aquests estrats seran grups d’individus definits per una característica concreta, de manera que individus del mateix estrat tenguin aquesta característica en comú i individus d’estrats diferents tenguin aquesta característica diferent. Per exemple: sexes, franges d’edat, zones geogràfiques, subespècies d’una espècie… En aquest cas, es pren una mostra aleatòria (amb o sense repetició) d’una mida prefixada de cada estrat i s’uneixen en una mostra global: el resultat és una mostra aleatòria (amb repetició o sense) estratificada. Pel que fa a les mides de les mostres de cada estrat, se sol optar per una de les dues estratègies següents: Imposar que la composició per estrats de la mostra global mantengui les proporcions de la població original, de manera que la mida de la mostra de cada estrat representi el mateix percentatge del total de la mostra que l’estrat corresponent en la població completa. Prendre les mides de manera que els estrats que representin una fracció molt petita de la població (tan petita que no esperaríem que tenguessin representació en una mostra aleatòria transversal de la població, és a dir, presa del total de la població sense tenir en compte la seva composició en estrats) tenguin una representació en la mostra molt més gran que la que els tocaria. Per exemple, els estrats podrien ser grups d’edat i podríem prendre la mostra de cada grup d’edat de mida proporcional a la fracció que representa aquest grup d’edat en la població total. O podrien ser els sexes i procuraríem que la nostra mostra estigués formada per un 50% d’homes i un 50% de dones. O, a les Illes Balears, els estrats podrien ser les illes, i llavors podríem imposar que el nombre de representants de cada illa en la mostra fos proporcional a la seva població relativa dins del conjunt total de la comunitat autònoma, o podríem triar la mateixa quantitat d’individus de cada illa, independentment de la seva població. L’avantatge del mostreig aleatori estratificat respecte del transversal és que, com que l’investigador pren una mostra de cada estrat de la mida que desitja: Permet estimar la informació d’interès per a cada estrat per separat, com si es tractàs d’estudis independents. Permet estimar la informació sobre subpoblaciones minoritàries que en una mostra aleatòria transversal apareixerien subrepresentades. L’inconvenient és que, òbviament, si preneu una mostra amb nombres prefixats i artificials de subjectes de cada estrat, amb aquesta mostra no podeu estimar la proporció de subjectes de cada estrat dins el total de la població. El que volem dir és que si, per exemple, construïu una mostra escollint a l’atzar 100 mallorquins, 100 menorquins i 100 pitiüsos, no la podeu emprar per estimar la proporció de mallorquins en el total de la població de les Balears. Gairebé mai és factible efectuar un mostreig aleatori. El motiu és que, per poder prendre una mostra aleatòria d’una població en el sentit d’aquest apartat, amb o sense reposició, és necessari disposar d’una llista completa de tots els seus individus per poder sortejar a qui seleccionarem. Això sol ser impossible, o almanco difícil d’aconseguir. Qualcú té la llista completa de, per exemple, tots els diabètics d’Espanya? Que inclogui els que no saben que ho són? I ja no en parlem si a més ha d’incloure tots els espanyols diabètics del passat i del futur… Per tant, gairebe mai no podrem prendre mostres aleatòries en aquest sentit. Tenim una població classificada en dos estrats, A i B. La subpoblació A representa un 20% de la població i la B el 80% restant. Hem pres una mostra aleatòria estratificada formada per 100 subjectes de cada subpoblació. Hem mesurat una certa característica X d’aquests subjectes. La mitjana dels valors de X dels subjectes d’A ha donat 5 i la mitjana dels valors de X dels subjectes de B ha donat 10. (a) Què val la mitjana dels valors de X de tota la mostra de 200 subjectes? (b) A partir d’aquestes dades, què estimau que val la mitjana de X en el total de la població? Trobareu més tipus de tècniques de mostreig aleatori i les funcions de R relacionades amb mostrejos a la lliçó sobre mostreig del manual de R. 1.6 Mostres de conveniència Malgrat que tots els resultats que donarem en aquest curs siguin per a mostres aleatòries i la gran majoria per a mostres aleatòries simples, a la vida real les mostres gairebé mai no ho són, d’aleatòries: normalment ens hem de conformar amb els subjectes disponibles, que formen una mostra de conveniència. Per exemple, a la UIB, per estimar l’opinió que d’un professor tenen els alumnes d’una classe, només es té en compte les respostes dels estudiants que voluntàriament emplenen l’enquesta d’opinió, que de cap manera formen una mostra aleatòria, ni tan sols representativa: el perfil de l’estudiant que contesta voluntàriament una enquesta d’aquest tipus és molt específic i no ve determinat per l’atzar. En aquest cas es tractaria d’una mostra auto-seleccionada. Un altre tipus de mostres no aleatòries són les oportunistes. Aquest és el cas, per exemple, si per estimar l’opinió que d’un professor tenen els alumnes d’una assignatura es visita un dia la classe i es passa l’enquesta als estudiants que aquest dia assistiren a classe. Un altre cop, pot ser que els alumnes presents no siguin representatius de l’alumnat de l’assignatura (poden ser els més aplicats, o els manco malaltissos, o els no repetidors). Les tècniques d’estadística inferencial no es poden aplicar a mostres no aleatòries. Però normalment només podem aconseguir mostres de conveniència. En aquest cas, el que s’ha de fer és descriure detalladament les característiques de la mostra per justificar que, malgrat no ser aleatòria, és raonablement representativa de la població i podria passar per aleatòria. Exemple 1.9 No perquè sigui oportunista una mostra deixa forçosament de ser vàlida. El nostre exemple preferit és el que podríem titular El cas d’Abraham Wald i els forats que faltaven. Figura 1.3: Abraham Wald. Durant la Segona Guerra Mundial es va fer palesa la necessitat de reforçar el blindatge dels bombarders aliats. Però un blindatge excessiu augmentaria el pes del bombarder i faria que consumís més carburant i perdés autonomia de vol o fins i tot que no pogués enlairar-se. Per tant calia blindar només les parts més delicades de l’avió. El problema es passà llavors al Statistical Research Group (SRG), un grup “secret” d’estadístics que assessorava els militars nord americans i que molts historiadors comparen amb el projecte Manhattan, canviant bombes per equacions. Els militars els passaren gràfics dels bombarders que tornaven de missions per Europa amb les marques dels forats de bala que duien. Aquests impactes no estaven uniformement distribuïts pel fuselatge, com podeu veure a l’exemple de la Figura 1.4 que recull els forats d’alguns avions que tornaren d’una missió concreta. La idea dels militars era reforçar les zones més castigades, i el que volien que el SRG els calculàs era quant reforç havien d’afegir a cada zona. Figura 1.4: Diagrama dels impactes de projectil sobre el fuselatge d’un bombarder en tornar d’una missió. La resposta d’Abraham Wald, un dels estadístics més brillants del SRG, va ser “Senyors, on necessiten afegir blindatge és on no hi ha forats, perquè és aquí on eren els forats als avions que no tornaren” Vaja, que no havien de reforçar les zones amb més impactes: havien de reforçar les zones amb molt pocs impactes. El seu raonament era que els avions rebien els impactes distribuïts de manera uniforme per tot el seu fuselatge. Si els avions que tornaven de les missions no tenien impactes a determinades zones, o n’hi tenien molt pocs, era segurament perquè els avions que rebien molt càstig en aquestes zones no tornaven. En canvi, els impactes a les zones que mostraven més càstig en els avions que pogueren inspeccionar no impedien que l’avió tornàs. Naturalment, tot això justificat amb un càlcul molt enginyós de la probabilitat que un avió fos abatut en funció del nombre d’impactes de bala rebuts a les diferents zones del fuselatge: enginyós, perquè només podia emprar la informació dels avions que no havien estat abatuts. Si us interessen les butzes matemàtiques del seu treball, les trobareu explicades en aquest article. El que us volem vendre és que la mostra de bombarders era oportunista: els que retornaven de les seves missions. Però fins i tot d’aquesta mostra es pogué obtenir informació amb les tècniques adients. 1.7 Test de la lliçó 1 (1) Quina, o quines, de les dades següents són quantitatives discretes? La pressió arterial sistòlica. L’estadi d’un càncer (que s’indica amb un número del 0 al 4) El nombre d’ingressos hospitalaris a través d’urgències al llarg d’un dia. El nombre de dones en un grup de persones. La proporció de dones en un grup de persones. (2) Quina, o quines, de les dades següents (podem entendre que) són quantitatives contínues? La pressió arterial sistòlica. L’estadi d’un càncer (que s’indica amb un número del 0 al 4) El nombre d’ingressos hospitalaris a través d’urgències al llarg d’un dia. El nombre de dones en un grup de persones. La proporció de dones en un grup de persones. (3) En termes estadístics, una població (marcau totes les respostes correctes): Només pot estar formada per persones Pot ser finita Pot ser infinita Pot ser qualsevol conjunt de coses en les quals estiguem interessats Pot incloure coses que no existeixin Les altres respostes són totes falses (4) En un estudi es volgué determinar el percentatge mitjà d’increment del temps de resposta a un estímul auditiu sota els efectes d’una intoxicació alcohòlica aguda. Per fer-ho, es reclutaren 6 voluntaris, es mesura el seu temps de resposta (en segons) a una sèrie d’estímuls auditius, a continuació se’ls administrà una quantitat alta d’alcohol i es tornà a mesurar el seu temps de resposta als mateixos estímuls auditius. Quina és la variable aleatòria d’interès? Prenem una persona, la intoxicam amb alcohol i mesuram el seu temps de resposta a un estímul auditiu Prenem una persona, la intoxicam amb alcohol i mesuram el seu temps de resposta a un estímul auditiu (en segons) Prenem una persona i calculam el seu percentatge d’increment del temps de resposta a un estímul auditiu sota els efectes d’una intoxicació alcohòlica aguda Prenem un grup de 6 persones i calculam la mitjana dels seus percentatges d’increment del temps de resposta a un estímul auditiu sota els efectes d’una intoxicació alcohòlica aguda Prenem una persona i calculam la diferència (en segons) entre el seu temps de resposta a un estímul auditiu abans i després d’una intoxicació alcohòlica aguda El percentatge mitjà d’increment del temps de resposta a un estímul auditiu sota els efectes d’una intoxicació alcohòlica aguda (5) Què sou vosaltres? Marcau l’única resposta correcta. Una mostra aleatòria simple dels estudiants de 1r curs d’algun grau de ciències d’Espanya. Una mostra aleatòria sense reposició dels estudiants de 1r curs d’algun grau de ciències d’Espanya. Una mostra de conveniència dels estudiants de 1r curs d’algun grau de ciències d’Espanya. Cap de les altres respostes és correcta. (6) Quan diem que una mostra aleatòria d’una població és simple? Marcau una sola resposta. Quan la prenem de cop. Quan és l’única mostra aleatòria que prenem. Quan la prenem de manera que els subjectes no es poden repetir. Quan la prenem de manera que els subjectes es poden repetir. Quan no és “múltiple”, és a dir, quan no conté subjectes repetits (encara que l’hàgim presa de manera que es puguin repetir). Cap de les altres respostes és correcta. (7) Els avantatges del mostreig aleatori inclouen (marcau totes les respostes correctes): Que sempre es pot aplicar a qualsevol població Que no hi ha cap subpoblació els subjectes de la qual tenguin major probabilitat de ser triats Que és fàcil de dur a terme Que garanteix que la mostra triada serà representativa de la població original Les altres respostes són totes falses (8) En un estudi sobre pacients d’hospitals, es va prendre una mostra aleatòria de 20 hospitals diferents a partir d’una llista de tots els hospitals d’un país. A continuació, es va triar a l’atzar un 10% dels pacients hospitalitzats en un dia concret a cadascun d’aquests 20 hospitals. Quina, o quines, de les afirmacions següents són vertaderes en aquesta situació? Tots els hospitals tenen la mateixa probabilitat de ser triats Tots els pacients hospitalitzats aquest dia tenien la mateixa probabilitat de ser triats Totes les possibles mostres de pacients hospitalitzats aquest dia tenien la mateixa probabilitat de ser triades La mostra de pacients va ser estratificada Les altres respostes són totes falses (9) En un estudi sobre pacients d’hospitals, es va prendre una mostra aleatòria de 20 hospitals diferents a partir d’una llista de tots els hospitals d’un país. A continuació, es va triar a l’atzar 10 pacients hospitalitzats diferents en un dia concret a cadascun d’aquests 20 hospitals. Quina, o quines, de les afirmacions següents són vertaderes en aquesta situació? Tots els hospitals tenen la mateixa probabilitat de ser triats Tots els pacients hospitalitzats aquest dia tenien la mateixa probabilitat de ser triats Totes les possibles mostres de 200 pacients hospitalitzats aquest dia tenien la mateixa probabilitat de ser triades La mostra de pacients va ser estratificada Les altres respostes són totes falses "],
["chap-varal.html", "Tema 2 Variables aleatòries 2.1 Generalitats sobre variables aleatòries 2.2 Variables aleatòries discretes 2.3 Famílies importants de variables aleatòries discretes 2.4 Variables aleatòries contínues 2.5 Variables aleatòries normals 2.6 Test de la lliçó 2", " Tema 2 Variables aleatòries 2.1 Generalitats sobre variables aleatòries Una variable aleatòria definida sobre una població \\(\\Omega\\) és simplement una funció \\[ X: \\Omega\\to \\mathbb{R} \\] que assigna a cada subjecte de \\(\\Omega\\) un nombre real. La idea intuïtiva que hi ha al darrera d’aquesta definició és que una variable aleatòria mesura una característica dels subjectes de \\(\\Omega\\) que varia a l’atzar d’un subjecte a un altre. Per exemple: Prenem una persona d’una població i mesuram el seu nivell de colesterol, o la seva alçada, o el seu nombre de fills… En aquest cas, \\(\\Omega\\) és la població baix estudi, de la qual prenem la persona que mesuram. Llançam una moneda equilibrada 3 vegades i comptam les cares que obtenim. En aquest cas, \\(\\Omega\\) és la població formada per totes les seqüències de 3 llançaments d’una moneda equilibrada passades, presents i futures. El que més ens interessarà d’una variable aleatòria són les probabilitats dels esdeveniments que defineix. I quin tipus d’esdeveniments són els que més ens interessen quan mesuram característiques numèriques? Doncs bàsicament esdeveniments definits mitjançant igualtats i desigualtats. Per exemple, si \\(X\\) és la variable aleatòria “Prenem una persona i mesuram el seu nivell de colesterol en plasma (en mg/dl)”, ens poden interessar esdeveniments de l’estil de: El conjunt de les persones amb nivell de colesterol entre 200 i 240. la indicarem amb \\[ 200\\leqslant X\\leqslant 240 \\] El conjunt de les persones amb nivell de colesterol més petit o igual que 200: \\[ X\\leqslant 200 \\] El conjunt de les persones amb nivell de colesterol més gran que 180: \\[ X&gt;180 \\] El conjunt de les persones amb nivell de colesterol exactament 180: \\[ X=180 \\] Etc. Com dèiem, el que ens interessarà d’aquests esdeveniments serà la seva probabilitat, i llavors emprarem notacions de l’estil de les següents: \\(P(200\\leqslant X\\leqslant 240)\\). Això indica la probabilitat que una persona tengui el nivell de colesterol entre 200 i 240. Per abreujar, ho llegirem la “probabilitat que \\(X\\) estigui entre 200 i 240” i representa la proporció de persones (de la població \\(\\Omega\\) on hàgim definit la variable \\(X\\)) amb nivell de colesterol entre 200 i 240. \\(P(X\\leqslant 200)\\). Això indica la probabilitat que una persona tengui el nivell de colesterol més petit o igual que 200 (per abreujar, la probabilitat que “\\(X\\) sigui més petit o igual que 200”). És a dir, la proporció de persones amb nivell de colesterol més petit o igual que 200. Etc. En aquest context, indicarem normalment la unió amb una o i la intersecció amb una coma. Per exemple, si \\(X\\) és la variable aleatòria “Llançam una moneda 6 vegades i comptam les cares que obtenim”: \\(P(X\\leqslant 2\\text{ o }X\\geqslant 5)\\): Probabilitat de treure com a màxim 2 cares o com a mínim 5. \\(P(2\\leqslant X, X&lt; 5)\\): Probabilitat de treure un nombre de cares que sigui més gran o igual que 2 i més petit que 5; és a dir, \\(P(2\\leqslant X&lt; 5)\\). Dues variables aleatòries \\(X,Y\\) són independents quan, per a tots els parells de valors \\(a,b\\in \\mathbb{R}\\), els esdeveniments \\[ X\\leqslant a, Y\\leqslant b \\] són independents. És a dir, intuïtivament, quan el valor que pren \\(X\\) sobre un subjecte no afecta per res el valor que hi pren \\(Y\\), i viceversa. Per exemple, si prenem una persona i: \\(X\\): li demanam que llanci una moneda 3 vegades i comptam les cares \\(Y\\): mesuram el seu nivell de colesterol en plasma (en mg/dl) (segurament) \\(X\\) i \\(Y\\) són independents. Recordau que els esdeveniments \\(X\\leqslant a\\) i \\(Y\\leqslant b\\) són independents quan satisfan les tres condicions equivalents següents: \\[ \\begin{array}{l} P(X\\leqslant a|Y\\leqslant b)=P(X\\leqslant a)\\\\ P(Y\\leqslant b|X\\leqslant a)=P(Y\\leqslant b)\\\\ P(X\\leqslant a, Y\\leqslant b)=P(X\\leqslant a)\\cdot P(Y\\leqslant b) \\end{array} \\] Més en general, unes variables aleatòries \\(X_1,X_2,\\ldots,X_n\\) són independents quan, per a tots \\(a_1,a_2,\\ldots,a_n\\in \\mathbb{R}\\), els esdeveniments \\[ X_1\\leqslant a_1, X_2\\leqslant a_2,\\ldots, X_n\\leqslant a_n \\] són independents. És a dir, quan el valor que pren una d’aquestes variables sobre un subjecte no afecta per res els valors que hi prenen les altres. 2.2 Variables aleatòries discretes Una variable aleatòria és discreta quan els seus possibles valors són dades quantitatives discretes. Per exemple, Nombre de cares en 3 llançaments d’una moneda Nombre de fills d’una dona Nombre de casos nous de COVID-19 en un dia a Mallorca 2.2.1 Densitat i distribució Sigui \\(X: \\Omega\\to \\mathbb{R}\\) una variable aleatòria discreta. El seu domini \\(D_X\\) és el conjunt dels valors que pot prendre: més concretament, és el conjunt dels \\(x\\in \\mathbb{R}\\) tals que \\(P(X=x)&gt;0\\). La seva funció de densitat és la funció \\(f_X:\\mathbb{R}\\to [0,1]\\) que assigna a cada \\(x\\in \\mathbb{R}\\) la probabilitat que \\(X\\) valgui \\(x\\): \\[ f_X(x)=P(X=x) \\] És a dir, \\(f_X(x)\\) és la proporció de subjectes de la població en els quals \\(X\\) val \\(x\\). La seva funció de distribució és la funció \\(F_X:\\mathbb{R}\\to [0,1]\\) que assigna a cada \\(x\\in \\mathbb{R}\\) la probabilitat que \\(X\\) sigui més petit o igual que \\(x\\): \\[ F_X(x)=P(X\\leqslant x) \\] És a dir, \\(F_X(x)\\) és la proporció de subjectes de la població en els quals \\(X\\) pren un valor \\(\\leqslant x\\). A la funció de distribució també se li sol dir funció de probabilitat acumulada per posar èmfasi en el fet que \\(F_X(x)\\) mesura la “freqüència relativa acumulada” de \\(x\\) en el total de la població. Exemple 2.1 Sigui \\(X\\) la variable aleatòria “Llançam 3 vegades una moneda equilibrada i comptam les cares que obtenim”. Aleshores: El seu domini és el conjunt dels seus possibles valors: \\(D_X=\\{0,1,2,3\\}\\). La seva funció de densitat és definida per \\(f_X(x)=P(X=x)\\): \\(f_X(0)=P(X=0)=1/8\\) (la probabilitat de treure 0 cares en 3 llançaments) \\(f_X(1)=P(X=1)=3/8\\) (la probabilitat de treure 1 cara en 3 llançaments) \\(f_X(2)=P(X=2)=3/8\\) (la probabilitat de treure 2 cares en 3 llançaments) \\(f_X(3)=P(X=3)=1/8\\) (la probabilitat de treure 3 cares en 3 llançaments) \\(f_X(x)=P(X=x)=0\\) per a qualsevol altre valor de \\(x\\) (si \\(x\\notin\\{0,1,2,3\\}\\), la probabilitat de treure \\(x\\) cares en 3 llançaments és 0) En resum, la funció de densitat de \\(X\\) és \\[ f_X(x) =\\left\\{ \\begin{array}{ll} 1/8 &amp; \\text{ si $x=0$}\\\\ 3/8 &amp; \\text{ si $x=1$}\\\\ 3/8 &amp; \\text{ si $x=2$}\\\\ 1/8 &amp; \\text{ si $x=3$}\\\\ 0 &amp; \\text{ si $x\\neq 0,1,2,3$} \\end{array} \\right. \\] Figura 2.1: Funció de densitat de la variable aleatòria que compta el nombre de cares en 3 llançaments Si \\(X\\) és una variable aleatòria discreta, \\(P(X\\in A)=0\\) per a qualsevol subconjunt \\(A\\) disjunt amb \\(D_X\\), perquè, per la definició del domini \\(D_X\\), \\(X\\) no pot prendre cap valor fora de \\(D_X\\). Per exemple, quina és la probabilitat de treure entre 2.5 i 2.7 cares en llançar 3 vegades una moneda? 0. I la de treure \\(\\pi\\) cares? 0 un altre cop. Vegem ara la seva funció de distribució \\(F_X\\). Recordau que \\(F_X(x)=P(X\\leqslant x)\\) i que la nostra variable només pot prendre els valors 0, 1, 2 i 3. Si \\(x&lt;0\\), \\(F_X(x)=P(X\\leqslant x)=0\\), perquè \\(X\\) no pot prendre cap valor estrictament negatiu. Si \\(0\\leqslant x&lt;1\\), \\(F_X(x)=P(X\\leqslant x)=P(X=0)=f_X(0)=1/8\\), perquè si \\(0\\leqslant x&lt;1\\), l’únic valor \\(\\leqslant x\\) que pot prendre \\(X\\) és el 0. Si \\(1\\leqslant x&lt;2\\), \\(F_X(x)=P(X\\leqslant x)=P(X=0\\text{ o }X=1)\\) \\(=f_X(0)+f_X(1)=4/8=1/2\\), perquè si \\(1\\leqslant x&lt;2\\), els únics valors \\(\\leqslant x\\) que pot prendre \\(X\\) són 0 i 1. Si \\(2\\leqslant x&lt;3\\), \\(F_X(x)=P(X\\leqslant x)=P(X=0\\text{ o }X=1\\text{ o }X=2)\\) \\(=f_X(0)+f_X(1)+f_X(2)=7/8\\), perquè si \\(2\\leqslant x&lt;3\\), els únics valors \\(\\leqslant x\\) que pot prendre \\(X\\) són 0, 1 i 2. Si \\(3\\leqslant x\\), \\(F_X(x)=P(X\\leqslant x)=1\\), perquè si \\(x\\geqslant 3\\), segur que obtenim un nombre de cares \\(\\leqslant x\\). Per tant, la funció \\(F_X\\) és la funció \\[ F_X(x) =\\left\\{ \\begin{array}{ll} 0 &amp; \\text{ si $x&lt;0$}\\\\ 1/8 &amp; \\text{ si $0\\leqslant x&lt; 1$}\\\\ 4/8 &amp; \\text{ si $1\\leqslant x&lt; 2$}\\\\ 7/8 &amp; \\text{ si $2\\leqslant x&lt; 3$}\\\\ 1 &amp; \\text{ si $3\\leqslant x$} \\end{array} \\right. \\] El seu gràfic és el següent: Figura 2.2: Funció de distribució de la variable aleatòria que compta el nombre de cares en 3 llançaments Observau en aquest gràfic que aquesta funció de distribució \\(F_X\\) és creixent i escalonada. Això és general. Si \\(X\\) és una variable aleatòria discreta: \\(F_X\\) és una funció escalonada, amb bots en els valors de \\(D_X\\), que són els únics amb probabilitat estrictament més gran que 0 i per tant els únics que “sumen” probabilitat. Més en concret: Si \\(x_0,y_0\\in D_X\\) i \\(x_0&lt;y_0\\), llavors \\(F_X(x_0)&lt; F_X(y_0)\\), perquè, com que \\(P(X=y_0)&gt;0\\), \\[ \\begin{array}{rl} F_X(x_0)\\!\\!\\!\\!\\! &amp; =P(X\\leqslant x_0)&lt;P(X\\leqslant x_0)+P(X=y_0)\\\\ &amp; =P(X\\leqslant x_0\\text{ o }X=y_0)\\leqslant P(X\\leqslant y_0)=F_X(y_0) \\end{array} \\] Si \\(x_0\\in D_X\\) i dins \\((x_0,x]\\) no hi ha cap element de \\(D_X\\), aleshores \\(F_X(x_0)=F_X(x)\\), perquè \\[ \\begin{array}{rl} F_X(x)\\!\\!\\!\\!\\! &amp; =P(X\\leqslant x)=P(X\\leqslant x_0)+P(x_0&lt;X\\leqslant x)\\\\ &amp; =P(X\\leqslant x_0)+0= P(X\\leqslant x_0)=F_X(x_0) \\end{array} \\] ja que, com que \\((x_0,x]\\cap D_X=\\emptyset\\), \\(P(x_0&lt;X\\leqslant x)=0\\). Si \\(x_0\\in D_X\\), \\(P(X&lt;x_0)&lt;P(X\\leqslant x_0)\\), perquè \\[ P(X\\leqslant x_0)=P(X&lt;x_0)+P(X=x_0)&gt;P(X&lt;x_0) \\] \\(F_X\\) és creixent, perquè si \\(x\\leqslant y\\), tots els subjectes que compleixen que \\(X\\leqslant x\\) també compleixen que \\(X\\leqslant y\\), i per tant \\[ P(X\\leqslant x)\\leqslant P(X\\leqslant y). \\] Com que els valors que pren \\(F_X\\) són probabilitats, no poden ser ni més petits que 0 ni més grans que 1. El coneixement de \\(f_X\\), més les regles del càlcul de probabilitats, permet calcular la probabilitat de qualsevol esdeveniment relacionat amb \\(X\\): \\[ P(X\\in A) =\\sum_{x\\in A} P(X=x) = \\sum_{x\\in A} f_X(x) \\] En particular \\[ F_X(x_0)=P(X\\leqslant x_0)=\\sum_{x\\leqslant x_0} f_X(x) \\] La moda d’una variable aleatòria discreta \\(X\\) és el valor (o els valors) \\(x_0\\) tal que \\(f_X(x_0)=P(X=x_0)\\) és màxim. Per tant, la moda és el valor de \\(X\\) més probable o més freqüent en la població. Per exemple, per a la nostra variable aleatòria que compta el nombre de cares en 3 llançaments d’una moneda equilibrada, la moda són els valors 1 i 2. Exemple 2.2 Una variable aleatòria discreta \\(X\\) és uniforme quan el seu domini \\(D_X\\) és finit i tots els seus elements tenen la mateixa probabilitat. És a dir, si \\(D_X\\) té \\(m\\) elements, aleshores \\(P(X=x)=1/m\\) per a cada \\(x\\in D_X\\). Per exemple, el resultat de llançar un dau equilibrat és una variable aleatòria discreta. Com que tots els resultats del domini d’una variable aleatòria discreta uniforme tenen la mateixa probabilitat, tots en són la moda (o cap no ho és, depèn de si veieu el tassó mig ple o mig buit). Considerau la variable aleatòria \\(X\\) “Llançam una moneda equilibrada tantes vegades com sigui necessari fins que surti una cara per primera vegada, i comptam quantes vegades l’hem haguda de llançar”. Quin és el seu domini? Quina és la seva funció de densitat? Quina és la seva moda? Què significa? Quina és la seva funció de distribució? (Indicació: Calculau primer \\(P(X&gt;x)\\), tenint en compte que \\(X&gt;x\\) significa que en els primer \\(x\\) llançaments ha sortit creu, i per això hem hagut de llançar la moneda més de \\(x\\) vegades per obtenir una cara.) 2.2.2 Esperança Quan prenem una mostra d’una variable aleatòria \\(X\\) definida sobre una població, podem calcular la mitjana i la desviació típica dels seus valors a fi i efecte d’obtenir una idea de quin és el valor central de la mostra i si els seus valors estan tots molt a prop d’aquest valor central o no. Naturalment, també ens podem preguntar per aquesta mena d’informació per al total de la població: Quin és el “valor mitjà” de \\(X\\) sobre tota la població? Aquesta variable, pren valors molt dispersos, o més aviat els pren concentrats al voltant del seu valor mitjà? La primera pregunta la responem amb la mitjana, o esperança, de \\(X\\), i la segona amb la seva variància i la seva desviació típica. Comencem amb la primera. La mitjana, o esperança (o valor esperat, valor mitjà…), d’una variable aleatòria discreta \\(X\\) amb densitat \\(f_X:D_X\\to [0,1]\\) és \\[ E(X)=\\sum_{x\\in D_X} x\\cdot f_X(x) \\] Sovint també la indicarem amb \\(\\mu_X\\). La interpretació natural de \\(E(X)\\) és que és la mitjana dels valors de la variable \\(X\\) en el total de la població \\(\\Omega\\). En efecte, com que \\(P(X=x)\\) és la proporció de subjectes de \\(\\Omega\\) en els quals \\(X\\) val \\(x\\), \\[ E(X)=\\sum_{x\\in D_X} x\\cdot P(X=x) \\] és la mitjana del valor de \\(X\\) sobre tots els subjectes de \\(\\Omega\\). Comparau-ho amb l’exemple següent. Exemple 2.3 Si, en una classe, un 10% dels estudiants han tret un 4 en un examen, un 20% un 6, un 50% un 8 i un 20% un 10, quina ha estat la nota mitjana obtenguda? Segurament calcularíeu aquesta mitjana de la manera següent: \\[ 4\\cdot 0.1+6\\cdot 0.2+8\\cdot 0.5+10\\cdot 0.2=7.6 \\] Doncs aquest valor és la mitjana de la variable aleatòria \\(X\\) “Prenc un estudiant d’aquesta classe i mir quina nota ha tret en aquest examen”: \\[ \\begin{array}{rl} E(X)\\!\\!\\!\\!\\! &amp;=4\\cdot P(X=4)+6\\cdot P(X=6)+8\\cdot P(X=8)+10\\cdot P(X=10)\\\\ &amp; = 4\\cdot 0.1+6\\cdot 0.2+8\\cdot 0.5+10\\cdot 0.2=7.6 \\end{array} \\] A banda de la seva interpretació com a “la mitjana de \\(X\\) en el total de la població”, \\(E(X)\\) és també el valor esperat de \\(X\\), en el sentit següent: Suposau que prenem a l’atzar una mostra de \\(n\\) subjectes de la població, mesuram \\(X\\) sobre ells i calculam la mitjana aritmètica dels \\(n\\) valors obtenguts. Aleshores, quan la mida \\(n\\) de la mostra tendeix a \\(\\infty\\), aquesta mitjana aritmètica tendeix a valer \\(E(X)\\) “gairebé sempre”, en el sentit que la probabilitat que el seu límit sigui \\(E(X)\\) és 1. És a dir: si mesuràssim \\(X\\) sobre molts subjectes triats a l’atzar i calculàssim la mitjana dels valors obtenguts, és gairebé segur que obtendríem un valor molt proper a \\(E(X)\\). Exemple 2.4 Seguim amb la variable aleatòria \\(X\\) “Llançam una moneda equilibrada 3 vegades i comptam les cares que obtenim”. La seva esperança és \\[ E(X)= 0\\cdot \\frac{1}{8}+1\\cdot \\frac{3}{8}+2\\cdot \\frac{3}{8}+3\\cdot \\frac{1}{8}=1.5 \\] Això ens diu que: La mitjana de \\(X\\) és 1.5: El valor mitjà de la variable \\(X\\) sobre tota la població de seqüències de 3 llançaments d’una moneda equilibrada és 1.5. El valor esperat de \\(X\\) és 1.5: Si repetíssim moltes vegades l’experiment de llançar la moneda 3 vegades i comptar les cares, de mitjana obtendríem, molt probablement, un valor molt pròxim a 1.5. Abreujam això dient que si llançam la moneda 3 vegades, esperam treure 1.5 cares. Més en general, si \\(X\\) és una variable aleatòria i \\(g:\\mathbb{R}\\to \\mathbb{R}\\) és una funció, l’esperança de \\(g(X)\\) és \\[ E(g(X))=\\sum_{x\\in D_X} g(x)\\cdot f_X(x). \\] Un altre cop, la interpretació natural d’aquest valor és que és la mitjana de \\(g(X)\\) sobre la població, i també que és el valor “esperat” de \\(g(X)\\) en el sentit anterior. Exemple 2.5 Si llançam una moneda equilibrada 3 vegades, comptam les cares i elevam aquest nombre de cares al quadrat, quin valor esperam obtenir? Serà l’esperança de \\(X^2\\), on \\(X\\) és la variable aleatòria “Llançam una moneda equilibrada 3 vegades i comptam les cares que obtenim” (és a dir, aquesta \\(X^2\\) és la variable aleatòria “Llançam una moneda equilibrada 3 vegades, comptam les cares i elevam aquest número al quadrat”): \\[ E(X^2)= 0\\cdot \\frac{1}{8}+1\\cdot \\frac{3}{8}+2^2\\cdot \\frac{3}{8}+3^2\\cdot \\frac{1}{8}=3 \\] Fixau-vos que \\(E(X^2) \\neq E(X)^2\\). Per exemple, en els dos darrers exemples hem vist que si \\(X\\) és la variable aleatòria que compta el nombre de cares en 3 llançaments d’una moneda equilibrada, \\(E(X^2)=3\\) però \\(E(X)^2=1.5^2=2.25\\). En general, donades una variable aleatòria \\(X\\) i una aplicació \\(g:\\mathbb{R}\\to \\mathbb{R}\\), el més habitual és que \\(E(g(X))\\neq g(E(X))\\). L’esperança de les variables aleatòries discretes té les propietats següents, totes molt raonables si les interpretau en termes del valor mitjà de \\(X\\) sobre la població: Sigui \\(b\\) una variable aleatòria constant, que sobre tots els individus de la població pren el mateix valor \\(b\\in \\mathbb{R}\\). Aleshores, \\(E(b)=b\\). Si en una classe tothom treu un 8 d’un examen, la nota mitjana és un 8, no? Sí, ja sabem que parlar de variables constants és un oxímoron, però de vegades una variable aleatòria pren el mateix valor sobre tots els subjectes d’una població. Per exemple “Prenc un estudiant de Biologia o Bioquímica del curs 2019/20 i compt el seu nombre de cames”. L’esperança és lineal: Si \\(X\\) és una variable aleatòria i \\(a,b\\in \\mathbb{R}\\), \\(E(aX+b)=aE(X)+b\\) Si en una classe la mitjana d’un examen ha estat un 6 i decidim multiplicar per 1.2 totes les notes i sumar-les 1 punt, la mitjana de la nova nota serà 1.2·6+1=8.2, no? Si \\(X,Y\\) són dues variables aleatòries, \\(E(X+Y)=E(X)+E(Y)\\). Si en una classe la mitjana de la part de qüestions d’un examen ha estat un 3.5 i la de la part d’exercicis ha estat un 3, i la nota de l’examen és la suma de les notes de les dues parts, la nota mitjana de l’examen serà un 3.5+3=6.5, no? Combinant les dues propietats anteriors, si \\(X_1,\\ldots,X_n\\) són variables aleatòries i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ E(a_1X_1+\\cdots+a_nX_n+b)=a_1E(X_1)+\\cdots+a_nE(X_n)+b \\] L’esperança és monòtona creixent: Si \\(X\\leqslant Y\\) (en el sentit que el valor de \\(X\\) sobre cada subjecte de la població \\(\\Omega\\) és més petit o igual que el valor de \\(Y\\) sobre ell), llavors \\(E(X)\\leqslant E(Y)\\). Si tots traieu millor nota de Matemàtiques II que de Matemàtiques I, la nota mitjana de Matemàtiques II serà més gran que la de Matemàtiques I, no? Siguin \\(N\\) un nombre natural estrictament positiu i \\(X\\) una variable aleatòria discreta uniforme amb domini \\(D_X=\\{1,\\ldots,N\\}\\). Què val el seu valor esperat? 2.2.3 Variància i desviació típica La variància d’una variable aleatòria discreta \\(X\\) és \\[ \\sigma(X)^2 =E((X-\\mu_X)^2) =\\sum_{x\\in D_X} (x-\\mu_X)^2\\cdot f_X(x) \\] És a dir, és la mitjana del quadrat de la diferència entre \\(X\\) i la seva mitjana \\(\\mu_X\\). També la indicarem amb \\(\\sigma_X^2\\). Fixau-vos que es tracta de la traducció “poblacional” de la definició de variància per a una mostra, i per tant serveix per mesurar el mateix que aquella: la dispersió dels resultats de \\(X\\) respecte de la mitjana. Només que ara és per a tota la població, i no per a una mostra. La identitat següent vos pot ser útil. Teorema 2.1 \\(\\sigma(X)^2=E(X^2)-\\mu_X^2\\). Operem (i recordau que \\(E(X)=\\mu_X\\)) \\[ \\begin{array}{rl} \\sigma(X)^2\\!\\!\\!\\!\\! &amp; =E((X-\\mu_X)^2)=E(X^2-2\\mu_X\\cdot X+\\mu_X^2)\\\\ &amp; = E(X^2)-2\\mu_X\\cdot E(X)+\\mu_X^2\\\\ &amp; \\text{(per la linealitat d&#39;$E$)}\\\\ &amp; = E(X^2)-2\\mu_X^2+\\mu_X^2=E(X^2)-\\mu_X^2 \\end{array} \\] La desviació típica (o desviació estàndard) d’una variable aleatòria discreta \\(X\\) és l’arrel quadrada positiva de la seva variància: \\[ \\sigma(X)=+\\sqrt{\\sigma(X)^2} \\] També mesura la dispersió dels valors de \\(X\\) respecte de la mitjana. Sovint la indicarem amb \\(\\sigma_X\\). En el context de les variables aleatòries, no hi ha “variància” i “variància mostral”, només “variància”. El mateix nom us hauria de donar la pista que la “variància mostral” està definida només per a mostres. El motiu per introduir la variància i la desviació típica per mesurar la dispersió dels valors de \\(X\\) és la mateixa que en estadística descriptiva: la variància és més fàcil de manejar (no involucra arrels quadrades) però les seves unitats són les de \\(X\\) al quadrat, mentre que les unitats de la desviació típica són les de \\(X\\), i per tant el seu valor és més fàcil d’interpretar. Exemple 2.6 Seguim amb la variable aleatòria \\(X\\) “Llançam una moneda equilibrada 3 vegades i comptam les cares que obtenim”. Recordem que \\(\\mu_X=E(X)=1.5\\). Aleshores, la seva variància és: \\[ \\begin{array}{rl} \\sigma(X)^2 \\!\\!\\!\\!\\! &amp; \\displaystyle=(0-1.5)^2\\cdot \\frac{1}{8}+(1-1.5)^2\\cdot \\frac{3}{8}\\\\ &amp;\\displaystyle\\qquad +(2-1.5)^2\\cdot \\frac{3}{8}+(3-1.5)^2\\cdot \\frac{1}{8}=0.75 \\end{array} \\] Si recordam que \\(E(X^2)=3\\), podem veure que \\[ E(X^2)-\\mu_X^2=3-1.5^2=0.75=\\sigma(X)^2 \\] La seva desviació típica és \\[ \\sigma(X) =\\sqrt{\\sigma(X)^2}=\\sqrt{0.75}= 0.866 \\] Vegem algunes propietats de la variància i la desviació típica: Si \\(b\\) és una variable aleatòria constant que sobre tots els individus de la població pren el valor \\(b\\in \\mathbb{R}\\), aleshores \\(\\sigma(b)^2=\\sigma(b)=0\\). Una variable aleatòria constant té zero dispersió. El recíproc també és cert: si \\(\\sigma(X)^2=0\\), la variable \\(X\\) és constant. En efecte, observau a \\[ \\sigma(X)^2 =\\sum_{x\\in D_X} (x-\\mu_X)^2\\cdot f_X(x) \\] que \\(\\sigma(X)^2\\) és una suma de nombres positius. Per tant, si és 0, tots els sumands \\((x-\\mu_X)^2\\cdot f_X(x)\\) han de ser 0. Però \\(f_X(x)&gt;0\\) per a cada \\(x\\in D_X\\). Per tant, si \\(\\sigma(X)^2=0\\), tots els \\(x-\\mu_X\\), amb \\(x\\in D_X\\), han de ser 0, és a dir, \\(D_X=\\{\\mu_X\\}\\): \\(X\\) només pot prendre un valor. \\(\\sigma(aX+b)^2=a^2\\cdot \\sigma(X)^2\\). En efecte \\[ \\begin{array}{l} \\sigma(aX+b)^2 =E((aX+b)^2)-E(aX+b)^2\\\\ \\quad = E(a^2X^2+2abX+b^2)-(aE(X)+b)^2\\\\ \\quad \\text{(per la linealitat de $E$)}\\\\ \\quad = a^2E(X^2)+2abE(X)+b^2-a^2E(X)^2-2abE(X)-b^2\\\\ \\quad \\text{(una altre cop, per la linealitat de $E$)}\\\\ \\quad = a^2(E(X^2)-E(X)^2)=a^2\\sigma(X)^2 \\end{array} \\] \\(\\sigma(aX+b)=|a|\\cdot \\sigma(X)\\) (recordau que la desviació típica és positiva, i \\(+\\sqrt{a^2}=|a|\\)). Si \\(X,Y\\) són variables aleatòries independents, \\[ \\sigma(X+Y)^2=\\sigma(X)^2+\\sigma(Y)^2 \\] i per tant \\[ \\sigma(X+Y)=\\sqrt{\\sigma(X)^2+\\sigma(Y)^2} \\] Si no són independents, en general aquesta igualtat és falsa. Per posar un exemple extrem, \\[ \\sigma(X+X)^2=4\\sigma(X)^2 \\neq \\sigma(X)^2+\\sigma(X)^2. \\] Més en general, si \\(X_1,\\ldots,X_n\\) són variables aleatòries independents (i, en principi, només en aquest cas) i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ \\begin{array}{l} \\sigma(a_1X_1+\\cdots+a_nX_n+b)^2=a_1^2\\cdot\\sigma(X_1)^2+\\cdots+a_n^2\\cdot\\sigma(X_n)^2\\\\ \\sigma(a_1X_1+\\cdots+a_nX_n+b)=\\sqrt{a_1^2\\cdot\\sigma(X_1)^2+\\cdots+a_n^2\\cdot\\sigma(X_n)^2} \\end{array} \\] 2.2.4 Quantils Sigui \\(p\\in [0,1]\\). El quantil d’ordre \\(p\\) (o \\(p\\)-quantil) d’una variable aleatòria discreta \\(X\\) és el valor \\(x_p\\in D_X\\) tal que \\(P(X\\leqslant x_p)\\geqslant p\\) però \\(P(X&lt; x_p)&lt;p\\). És a dir, el valor \\(x_p\\in D_X\\) més petit tal que \\(P(X\\leqslant x_p)\\geqslant p\\). Per exemple, que el 0.25-quantil d’una variable aleatòria discreta \\(X\\) sigui, jo què sé, 8, significa que almanco un 25% de la població té un valor de \\(X\\) més petit o igual que 8, però manco d’un 25% de la població té un valor de \\(X\\) estrictament més petit que 8. És a dir, 8 és el valor més petit per al qual la probabilitat acumulada arriba al 25%. Si existeix algun \\(x_p\\in D_X\\) tal que \\(P(X\\leqslant x_p)=p\\), llavors el \\(p\\)-quantil és aquest \\(x_p\\), perquè, per a tot altre \\(x\\in D_x\\): Si \\(x&lt;x_p\\), \\(P(X\\leqslant x)&lt;P(X\\leqslant x_p)=F_X(x_p)=p\\) i per tant \\(x\\) no pot ser el \\(p\\)-quantil de \\(X\\). Si \\(x&gt;x_p\\), \\(p=P(X\\leqslant x_p)\\leqslant P(X&lt;x)\\), i per tant \\(x\\) tampoc no pot ser el \\(p\\)-quantil de \\(X\\). Com en estadística descriptiva, alguns quantils de variables aleatòries tenen noms propis. Per exemple: La mediana de \\(X\\) és el seu 0.5-quantil. El primer i el tercer quartils de \\(X\\) són els seus \\(0.25\\)-quantil i \\(0.75\\)-quantil, respectivament. Etc. Exemple 2.7 Seguim amb la variable aleatòria \\(X\\) “Llançam una moneda equilibrada 3 vegades i comptam les cares que obtenim”. Recordem que la seva funció de distribució és \\[ F_X(x)=\\left\\{ \\begin{array}{ll} 0 &amp; \\text{ si $x&lt;0$}\\\\ 0.125 &amp; \\text{ si $0\\leqslant x&lt;1$}\\\\ 0.5 &amp; \\text{ si $1\\leqslant x&lt;2$}\\\\ 0.875 &amp; \\text{ si $2\\leqslant x&lt;3$}\\\\ 1 &amp; \\text{ si $3\\leqslant x $} \\end{array} \\right. \\] Llavors, per exemple: El seu 0.125-quantil és 0 El seu 0.25-quantil és 1 La seva mediana és 1 El seu 0.75-quantil és 2 Siguin \\(N\\) un nombre natural estrictament positiu i \\(X\\) una variable aleatòria discreta uniforme amb domini \\(D_X=\\{1,\\ldots,N\\}\\). Què val la seva mediana? Encara que emprem “mitjana”, “variància”, “quantils”, etc. tant per a variables aleatòries com per a mostres, no heu de confondre-les. Una variable aleatòria representa una característica numèrica dels subjectes d’una població: “Prenem un estudiant de la UIB i mesuram la seva alçada en m.” La mitjana i la variància d’aquesta variable són les de tota la població d’estudiants de la UIB i descriuen propietats de tota la població d’estudiants de la UIB. Una mostra d’una variable aleatòria són els valors de la variable sobre un subconjunt de la població. Mesuram les alçades (en m) de 50 estudiants de la UIB d’aquest curs. La mitjana i la variància d’aquesta mostra són només les d’aquestes 50 alçades, i poden servir per descriure aquest conjunt de 50 alçades o per estimar els valors de la mitjana i la variància de la població d’estudiants de la UIB Quan volguem destacar que una mitjana, una variància etc. són les d’una variable aleatòria sobre tota una població, les qualificarem de poblacionals. 2.3 Famílies importants de variables aleatòries discretes En aquesta secció descriurem tres famílies de variables aleatòries “distingides” que heu de conèixer: Binomial Hipergeomètrica Poisson Cadascuna d’aquestes famílies tenen un tipus específic de funció de densitat que depèn d’un o diversos paràmetres. De cadascuna d’aquestes famílies de variables heu de saber: Distingir quan una variable aleatòria és d’aquest tipus. Les seves propietats bàsiques, com ara quins són els seus paràmetres, quin és el seu valor esperat i si la seva densitat és simètrica o té una cua a qualque costat. Emprar R per calcular coses quan sigui necessari. 2.3.1 Variables aleatòries binomials Un experiment de Bernoulli és una acció amb només dos resultats possibles, que identificam amb “Èxit” (\\(E\\)) i “Fracàs” (\\(F\\)), i de la qual, en principi, no podem predir el seu resultat per mor de la influència de l’atzar. Per exemple, llançar un dau cúbic i mirar si ha sortit un 6 (\\(E\\): treure un 6; \\(F\\): no treure un 6). La probabilitat d’èxit \\(p\\) d’un experiment de Bernoulli és la probabilitat d’obtenir un èxit \\(E\\). És a dir, \\(P(E)=p\\). Naturalment, llavors, \\(P(F)=1-p\\). A l’exemple del llançament d’un dau, on \\(E\\) és treure un 6, \\(p=1/6\\). Més exemples d’experiments de Bernoulli: Llançar una moneda equilibrada i mirar si dóna cara. \\(E\\): donar cara \\(p=1/2\\) Demanar a una persona si l’estadística l’avorreix. \\(E\\): que l’estadística l’avorreixi \\(p\\): la proporció de persones a qui avorreix l’estadística Figura 2.3: Qui dels dos ets? Una variable aleatòria de Bernoulli de paràmetre \\(p\\) (abreujadament, \\(Be(p)\\)) és una variable aleatòria \\(X\\) que consisteix a efectuar un experiment de Bernoulli i donar 1 si s’obté un èxit i 0 si s’obté un fracàs. Una variable aleatòria binomial de paràmetres \\(n\\) i \\(p\\) (abreujadament, \\(B(n,p)\\)) és una variable aleatòria \\(X\\) que compta el nombre d’èxits \\(E\\) en una seqüència de \\(n\\) repeticions independents d’un mateix experiment de Bernoulli de probabilitat d’èxit \\(p\\). Independents significa que les \\(n\\) variables aleatòries de Bernoulli, una per a cada repetició de l’experiment de Bernoulli, són independents; és a dir, que el resultat de cada experiment en la seqüència no depèn dels resultats dels altres. Direm a \\(n\\) la mida de les mostres i a \\(p\\) la probabilitat (poblacional) d’èxit. De vegades també direm d’una variable \\(X\\) de tipus \\(B(n,p)\\) que té distribució binomial de paràmetres \\(n\\) i \\(p\\). Per exemple: Una variable de Bernoulli \\(Be(p)\\) és una variable binomial \\(B(1,p)\\). Llançar una moneda equilibrada 10 vegades i comptar les cares que surten és una variable binomial \\(B(10,0.5)\\). Triar 20 estudiants de la UIB a l’atzar, l’un rere l’altre, permetent repeticions i cada tria independent de les altres, i mirar si al primer semestre han aprovat totes les assignatures o no, és una variable binomial \\(B(20,p)\\) amb \\(p\\) la proporció d’estudiants de la UIB que han aprovat totes les assignatures del primer semestre. El tipus més comú de variables binomials que ens interessaran és aquest darrer: Tenim un subconjunt \\(A\\) d’una població \\(\\Omega\\) (per exemple, \\(\\Omega\\) els estudiants de la UIB i \\(A\\) els que han aprovat totes les assignatures del primer semestre). Sigui \\(p\\) la proporció poblacional d’individus de la població que pertanyen a \\(A\\), és a dir \\(p=P(A)\\). Prenem mostres aleatòries simples de mida \\(n\\) de la població i comptam quants subjectes de la mostra són de \\(A\\). Aquesta variable aleatòria és binomial \\(B(n,p)\\). Tenim el resultat següent. Teorema 2.2 Si \\(X\\) és una variable \\(B(n,p)\\): El seu domini és \\(D_X=\\{0,1,\\ldots,n\\}\\) La seva funció de densitat és \\[ f_X(k)=\\left\\{\\begin{array}{ll} \\displaystyle\\binom{n}{k}p^k(1-p)^{n-k} &amp; \\text{ si $k\\in D_X$}\\\\ 0 &amp; \\text{ si $k \\notin D_X$} \\end{array} \\right. \\] El seu valor esperat és \\(E(X)=np\\) La seva variància és \\(\\sigma(X)^2=np(1-p)\\) Recordau que: El factorial \\(m!\\) d’un nombre natural \\(m\\) és \\(m!=m(m-1)\\cdots 2\\cdot 1\\) si \\(m\\geqslant 1\\). Si \\(m=0\\), es pren \\(0!=1\\). El nombre combinatori \\(\\binom{n}{k}\\), amb \\(k,n\\) nombres naturals tals que \\(0\\leqslant k\\leqslant n\\), és \\[ \\binom{n}{k}=\\frac{\\overbrace{n\\cdot (n-1)\\cdots (n-k+1)}^k}{k\\cdot (k-1)\\cdots 2\\cdot 1}=\\frac{n!}{k!(n-k)!} \\] i ens dóna el nombre de subconjunts de \\(k\\) elements de \\(\\{1,\\ldots,n\\}\\). Si \\(k&gt;n\\) o \\(k&lt;0\\), es pren \\(\\binom{n}{k}=0\\). Suposem que efectuam \\(n\\) repeticions consecutives i independents d’un experiment de Bernoulli de probabilitat d’èxit \\(p\\) i comptam el nombre d’\\(E\\)’s; direm \\(X\\) a la variable aleatòria resultant. Per seguir la demostració, si no us sentiu molt còmodes amb el raonament amb enes i kas abstractes, anau repetint-lo prenent, per exemple, \\(n=4\\). Els possibles resultats són totes les paraules possibles de \\(n\\) lletres formades per \\(E\\)’s i \\(F\\)’s. Com que els experiments successius són independents, la probabilitat de cadascuna d’aquestes paraules és el producte de les probabilitats dels seus resultats individuals. Per tant, si una paraula concreta té \\(k\\) lletres \\(E\\) i \\(n-k\\) lletres \\(F\\) (s’han obtengut \\(k\\) èxits i \\(n-k\\) fracassos), la seva probabilitat és \\(p^k(1-p)^{n-k}\\), independentment de l’ordre en el qual hàgim obtengut els resultats. Per calcular la probabilitat d’obtenir una seqüència amb \\(k\\) èxits, sumarem les probabilitats d’obtenir cadascuna de les seqüències de \\(n\\) lletres amb \\(k\\) \\(E\\)’s. Com que totes tenen la mateixa probabilitat, el resultat serà la probabilitat d’una paraula amb \\(k\\) \\(E\\)’s i \\(n-k\\) \\(F\\)’s multiplicada pel nombre total de paraules diferents amb \\(k\\) \\(E\\)’s i \\(n-k\\) \\(F\\)’s. Ara, quantes paraules hi ha amb \\(k\\) \\(E\\)’s i \\(n-k\\) \\(F\\)’s? Cada una d’elles queda caracteritzada per les posicions de les \\(k\\) \\(E\\)’s, per tant hi ha tantes paraules d’aquestes com possibles eleccions de conjunts de \\(k\\) posicions per a les \\(E\\)’s. El nombre d’això darrer és el de possibles subconjunts de \\(k\\) elements (les posicions on hi haurà les \\(E\\)’s) de \\(\\{1,\\ldots,n\\}\\), que és el nombre combinatori \\(\\binom{n}{k}\\). Per tant ja tenim \\[ P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}. \\] A partir d’aquí, el càlcul del valor esperat i la variància és sumar \\[ \\begin{array}{l} \\displaystyle E(X)=\\sum_{k=0}^n k\\cdot \\binom{n}{k}p^k(1-p)^{n-k}\\\\ \\displaystyle \\sigma(X)^2=\\sum_{k=0}^n k^2\\cdot \\binom{n}{k}p^k(1-p)^{n-k}-\\Big(\\sum_{k=0}^n k\\cdot \\binom{n}{k}p^k(1-p)^{n-k})^2 \\end{array} \\] Us podeu fiar de nosaltres, donen \\(np\\) i \\(np(1-p)\\), respectivament. Si ho pensau, veureu que el valor de \\(E(X)\\) és l’“esperat”. Vegem, si preneu una mostra aleatòria de \\(n\\) subjectes d’una població en la qual la proporció de subjectes \\(E\\) és \\(p\\), quants subjectes \\(E\\) “esperau” obtenir en la vostra mostra? Doncs una proporció \\(p\\) de la mostra, és a dir \\(p\\cdot n\\), no? La funció de distribució d’una variable binomial no té una fórmula explícita. Només podem dir que si \\(X\\) és \\(B(n,p)\\), \\[ F_X(x)=\\sum_{k=0}^{\\lfloor x\\rfloor} \\binom{n}{k}p^k(1-p)^{n-k} \\] És un doi, però, per si de cas, us volem fer observar que si \\(X\\) és \\(B(n,p)\\), \\(P(X=k)\\) no només depèn de \\(k\\) sinó també dels paràmetres \\(n\\) i \\(p\\). Això serà general. Totes les variables aleatòries d’una mateixa família tenen la funció de densitat de la mateixa forma, i només hi varien els valors dels paràmetres. El tipus de teorema anterior és el que fa que ens interessi conèixer algunes famílies distingides freqüents de variables aleatòries. Si, per exemple, reconeixem que una variable aleatòria és binomial i coneixem els seus valors de \\(n\\) i \\(p\\) i sabem el teorema anterior, automàticament sabem la seva funció de densitat, i amb ella la seva funció de distribució, el seu valor esperat, la seva variància etc., sense necessitat de deduir tota aquesta informació cada vegada que trobem una variable d’aquestes. El coneixement estalvia temps. Naturalment, conèixer les propietats de les variables aleatòries binomials només és útil si sabem reconèixer quan estam al davant d’una. Fixau-vos que en una variable aleatòria binomial: Comptam quantes vegades ocorre un esdeveniment (l’èxit \\(E\\)) en una seqüència d’intents. En cada intent, l’esdeveniment que ens interessa passa o no passa, sense grisos. El nombre d’intents és fix, \\(n\\). Cada intent és independent dels altres. En cada intent, la probabilitat que passi l’esdeveniment que ens interessa és sempre la mateixa, \\(p\\). Així, per exemple: Una dona té 4 fills. La probabilitat que un fill sigui nina és fixa, 0.51. El sexe de cada fill és independent dels altres. Comptam quantes filles té. És una variable binomial \\(B(4,0.51)\\). En una aula hi ha 5 homes i 45 dones. Triam 10 estudiants, un rere l’altre i sense repetir-los, per fer-los una pregunta. Cada elecció és independent de les altres. Comptam quants homes hem interrogat. No és una variable binomial: com que no podem repetir estudiants, en cada ronda la probabilitat de triar un home depèn del sexe dels estudiants triats abans que ell. Per tant la \\(p\\) no és la mateixa en cada elecció. Per exemple, en la primera ronda la probabilitat de triar un home és 5/50=0.1. Ara, si en la primera ronda surt triat un home, la probabilitat que en la segona ronda tornem a triar un home es redueix a 4/49=0.0816, mentre que si en la primera elecció surt una dona, la probabilitat de triar un home en la segona ronda puja a 5/49=0.102. En una aula hi ha 5 homes i 45 dones. Triam 10 estudiants, un rere l’altre però cada estudiant pot ser triat més d’una vegada, per a fer-los una pregunta. Cada elecció és independent de les altres. Comptam quants homes hem interrogat. Ara sí que és una variable binomial \\(B(10,0.1)\\), ja que la probabilitat de triar un home no varia d’una ronda a la següent. En una aula hi ha 5 homes i 45 dones. Triam estudiants un rere l’altre i cada estudiant pot ser triat més d’una vegada, per fer-los una pregunta. Cada elecció és independent de les altres. Comptam quants estudiants hem hagut de triar per arribar a interrogar 5 homes. No és una variable binomial: no compta el nombre d’èxits en una seqüència d’un nombre fix d’intents, sinó quants intents hem necessitat per arribar a un nombre fix d’èxits. En una aula hi ha 5 homes i 45 dones. Llançam una moneda equilibrada: si surt cara triam 10 estudiants i si surt creu en triam 20, per a fer-los una pregunta. Tant en un cas com en l’altre, els triarem un rere l’altre, cada estudiant podrà ser triat més d’una vegada i cada elecció serà independent de les altres. Comptam quants homes hem interrogat. No és una variable binomial: el nombre d’intents no és fix. La probabilitat que un dia de novembre plogui és d’un 32%. Triam una setmana de novembre i comptam quants dies ha plogut. No és d’una variable binomial. Encara que a priori cada dia tengui la mateixa probabilitat de pluja, que plogui un dia no és independent que plogui l’anterior. Perquè fos binomial, hauríem d’haver triat 7 dies de novembre a l’atzar, permetent que sortissin repetits. A Espanya hi ha 46,700,000 persones, de les quals un 11.7% són diabètics. Triam 100 espanyols diferents a l’atzar (de manera independent els uns dels altres) i comptam quants són diabètics. No és binomial, pel mateix motiu que no ho era quan escollíem estudiants sense permetre repeticions. Però pràcticament sí que ho és, perquè les probabilitats gairebé no varien d’una elecció a la següent. Per exemple, quan ja duim 99 individus escollits, la probabilitat de triar un individu concret dels que queden és \\(1/(46700000-99)=2.141332\\times 10^{-8}\\) mentre que si permetem repeticions, aquesta probabilitat és \\(1/46700000=2.141328\\times 10^{-8}\\). Coincideixen fins la dotzena xifra decimal. En aquest cas farem la trampa de considerar-la binomial. Vegem alguns gràfics de la funció de densitat de variables aleatòries binomials. Primer, per a \\(n=10\\) i diferents valors de \\(p\\). Ara per a \\(n=100\\): Com podeu veure, la moda d’una binomial \\(B(n,p)\\) és la seva mitjana \\(np\\) o, si aquest nombre no és enter, un dels dos enters que l’envolten. Si \\(p=0.5\\), la funció de densitat és simètrica respecte de \\(n/2\\): com que \\(E\\) i \\(F\\) tenen la mateixa probabilitat, 0.5, la probabilitat de treure \\(k\\) \\(E\\)’s és la mateixa que la de treure \\(k\\) \\(F\\)’s, és a dir, la de treure \\(n-k\\) \\(E\\)’s. En canvi, si \\(p\\neq 0.5\\), la funció de densitat no és simètrica, com podeu veure als gràfics de més a dalt. Per agilitzar els tests de COVID-19, s’ha proposat l’estratègia següent (anomenada pooled sample testing o simplement pooling). Unim grups de 10 mostres en una sola mostra i l’analitzam. Si dóna negatiu, serà senyal que totes la mostres originals eren negatives. Declararem llavors negatius els 10 subjectes de les mostres originals. Si dóna positiu, serà perquè almanco una de les mostres originals era positiva. En aquest cas, analitzarem les 10 mostres per separat. Observau llavors que si les 10 mostres eren negatives, fem un sol test, mentre que si alguna mostra és positiva, en fem 11. Amb l’enfocament tradicional, un test per mostra i per avall, faríem sempre 10 tests. Suposem que el test és exacte: dóna positiu sempre que ha de donar positiu i negatiu sempre que ha de donar negatiu. Sigui \\(p\\) la prevalença de la COVID-19 en un moment i població donats. Donades 10 mostres preses en aquest moment en aquesta població, quin és el valor esperat de tests que hem de realitzar? Si \\(p\\) fos petita, de l’ordre de l’1% al 5%, significaria el pooling un estalvi esperat considerable de tests? Com efectuar càlculs amb una variable aleatòria d’una família donada? Una possibilitat és usar una aplicació de mòbil o tauleta. La nostra preferida és Probability distributions, disponible tant per a Android com per a iOS. Figura 2.4: L’apli Probability Distributions. Una altra possibilitat és usar R. R coneix totes la distribucions de variables aleatòries importants; per exemple, per a R la binomial és binom. Aleshores Afegint al nom de la distribució el prefix d, tenim la seva funció de densitat: de la binomial serà dbinom. Afegint al nom de la distribució el prefix p, tenim la seva funció de distribució: de la binomial, pbinom. Afegint al nom de la distribució el prefix q, tenim els seus quantils: per a la binomial, qbinom. Afegint al nom de la distribució el prefix r, tenim una funció que produeix mostres aleatòries de nombres amb aquesta distribució de probabilitat: per a la binomial, rbinom. Aquestes funcions s’apliquen a l’argument de la funció i els paràmetres de la variable aleatòria en el seu ordre usual. Per exemple, per a la binomial, s’apliquen a (argument, \\(n\\), \\(p\\)). Per a més detalls sobre tot això, consultau la lliçó de R sobre el tema. Vegem alguns exemples. Si llançam 20 vegades un dau cúbic equilibrat, quina és la probabilitat de treure exactament 5 uns? Diguem \\(X\\) a la variable aleatòria que compta el nombre d’uns en seqüències de 20 llançaments d’un dau equilibrat. És una variable binomial \\(B(20,1/6)\\). Ens demanen \\(P(X=5)\\), i aquesta probabilitat ens la dóna la funció de densitat de \\(X\\). És \\(f_X(5)\\): dbinom(5,20,1/6) ## [1] 0.1294103 Si llançam 20 vegades un dau cúbic equilibrat, quina és la probabilitat de treure com a màxim 5 uns? Amb les notacions anteriors, ens demanen \\(P(X\\leqslant 5)\\), i aquesta probabilitat ens la dóna la funció de distribució de \\(X\\). És \\(F_X(5)\\): pbinom(5,20,1/6) ## [1] 0.8981595 Si llançam 20 vegades un dau cúbic equilibrat, quina és la probabilitat de treure manco de 5 uns? Amb les notacions anteriors, ens demanen \\(P(X&lt; 5)\\), és a dir, \\(P(X\\leqslant 4)=F_X(4)\\): pbinom(4,20,1/6) ## [1] 0.7687492 Si llançam 20 vegades un dau cúbic equilibrat, quina és la probabilitat de treure 8 uns o més? Amb les notacions anteriors, ens demanen \\(P(X\\geqslant 8)\\). Com que el contrari de treure 8 uns o més és treure 7 uns o manco, tenim que \\(P(X\\geqslant 8)=1-P(X\\leqslant 7)=1-F_X(7)\\): 1-pbinom(7,20,1/6) ## [1] 0.01125328 Si llançam 20 vegades un dau equilibrat, quin és el més petit nombre \\(N\\) d’uns per al qual la probabilitat de treure com a màxim \\(N\\) uns arriba al 25%? Ens demanen el més petit valor \\(N\\) tal que \\(P(X\\leqslant N)\\geqslant 0.25\\), i això per definició és el 0.25-quantil de \\(X\\): qbinom(0.25,20,1/6) ## [1] 2 Vegem que en efecte \\(N=2\\) compleix el demanat: la probabilitat de treure com a màxim 2 uns és pbinom(2,20,1/6) ## [1] 0.3286591 i la probabilitat de treure’n com a màxim 1 és pbinom(1,20,1/6) ## [1] 0.1304203 Veiem per tant que amb 1 no arribam al 25% de probabilitat i amb 2 sí. Volem simular 50 rondes de llançar 20 vegades un dau equilibrat i comptar els uns, és a dir, volem una mostra aleatòria de mida 50 de la nostra variable \\(X\\): rbinom(50,20,1/6) ## [1] 6 4 4 2 4 2 2 4 2 2 7 7 4 3 5 2 2 5 3 2 5 3 2 3 1 3 4 0 2 5 0 5 0 4 3 2 1 1 ## [39] 1 4 7 2 4 4 3 1 1 2 5 4 Cada vegada que repetim aquesta instrucció segurament obtendrem una mostra aleatòria nova: rbinom(50,20,1/6) ## [1] 1 3 2 2 3 5 4 2 4 4 1 4 4 2 3 2 4 6 1 2 7 4 3 5 5 1 4 2 4 2 4 3 2 3 2 7 2 2 ## [39] 3 1 0 4 2 2 2 4 1 3 1 2 rbinom(50,20,1/6) ## [1] 5 4 6 6 3 2 6 4 5 2 1 2 3 2 3 3 1 3 4 4 3 4 4 4 2 2 2 5 6 2 4 3 4 3 0 4 2 4 ## [39] 5 4 4 2 3 3 6 2 3 3 4 4 rbinom(50,20,1/6) ## [1] 2 3 5 4 3 4 2 0 3 1 0 2 1 2 4 3 4 5 5 4 2 3 3 5 3 8 3 2 4 3 5 5 5 5 4 3 4 4 ## [39] 2 2 2 1 3 2 3 1 4 5 2 6 2.3.2 Variables aleatòries hipergeomètriques Recordau que el paradigma de variable aleatòria binomial és: tenc una població amb una proporció \\(p\\) de subjectes que satisfan una condició \\(E\\), en prenc una mostra aleatòria simple de mida \\(n\\) i compt el nombre de subjectes \\(E\\) en la meva mostra. Si canviam “mostra aleatòria simple” per “mostra aleatòria sense reposició”, la distribució de la variable aleatòria que obtenim és una altra: és hipergeomètrica. Una variable aleatòria és hipergeomètrica (o té distribució hipergeomètrica) de paràmetres \\(N\\), \\(M\\) i \\(n\\) (abreujadament, \\(H(N,M,n)\\)) quan es pot identificar amb el procés següent. Tenim una població formada per \\(N\\) subjectes que satisfan una condició \\(E\\) i \\(M\\) subjectes que no la satisfan (per tant, en total, \\(N+M\\) subjectes), prenem una mostra aleatòria sense reposició de mida \\(n\\) i comptam el nombre de subjectes \\(E\\) en aquesta mostra. Direm a \\(N\\) el nombre poblacional d’èxits, a \\(M\\) el nombre poblacional de fracassos i a \\(n\\) la mida de les mostres. Fixau-vos llavors que \\(N+M\\) és la mida total de la població i que \\(N/(N+M)\\) és la probabilitat poblacional d’èxit (la fracció de subjectes que satisfan \\(E\\) en el total de la població). Amb R, igual que la distribució binomial era binom, la distribució hipergeomètrica és hyper. Tenim el resultat següent: Teorema 2.3 Si \\(X\\) és una variable \\(H(N,M,n)\\): El seu domini és \\(D_X=\\{0,1,\\ldots,\\text{min}(N,n)\\}\\) La seva funció de densitat és \\[ f_X(k)=\\left\\{\\begin{array}{ll} \\displaystyle\\dfrac{\\binom{N}{k}\\cdot \\binom{M}{n-k}}{\\binom{N+M}{n}} &amp; \\text{ si $k\\in D_X$}\\\\ 0 &amp; \\text{ si $k\\notin D_X$} \\end{array} \\right. \\] El seu valor esperat és \\(E(X)=\\dfrac{nN}{N+M}\\) La seva variància és \\(\\sigma(X)^2=\\dfrac{nNM(N+M-n)}{(N+M)^2(N+M-1)}\\) La demostració de la fórmula per a la densitat és senzilla, en termes de casos favorables partit per casos possibles. Vegem: \\(f_X(k)\\) és la probabilitat que un subconjunt de \\(n\\) subjectes (diferents) de la població contengui \\(k\\) subjectes \\(E\\) i \\(n-k\\) subjectes dels altres (en direm \\(F\\)). Casos possibles: Tots els possibles subconjunts de \\(n\\) elements de la població. El nombre de tots els subconjunts de \\(n\\) elements d’una població de mida \\(N+M\\) és \\(\\binom{N+M}{n}\\). Ja tenim el denominador. Casos favorables: Tots els possibles subconjunts formats per \\(k\\) subjectes \\(E\\) i \\(n-k\\) subjectes \\(F\\). Cada un d’aquests subconjunts s’obté Triant un subconjunt de \\(k\\) subjectes \\(E\\): com que n’hi ha \\(N\\), d’aquests subconjunts n’hi ha \\(\\binom{N}{k}\\) Triant un subconjunt de \\(n-k\\) subjectes \\(F\\): com que n’hi ha \\(M\\), d’aquests subconjunts n’hi ha \\(\\binom{M}{n-k}\\) Per cada tria d’un subconjunt de \\(k\\) subjectes \\(E\\) i un subconjunt de \\(n-k\\) subjectes \\(F\\), obtenim un subconjunt “favorable” diferent. Per tant, el seu nombre és el producte \\(\\binom{N}{k}\\cdot\\binom{M}{n-k}\\) Això ens dóna el numerador. Fixau-vos que si diem \\(p\\) a la probabilitat poblacional d’èxit, \\(p=N/(N+M)\\), llavors \\[ E(X)=np. \\] És la mateixa fórmula que per a les variables binomials \\(B(n,p)\\) (i si ho pensau una estona veureu que, un altre cop i pel mateix argument, és el que la intuïció ens diu que ha de valer). D’altra banda, si diem \\(\\mathbf{P}\\) a la mida total de la població, \\(\\mathbf{P}=N+M\\), llavors \\[ \\sigma(X)^2=n\\cdot\\dfrac{N}{N+M}\\cdot\\dfrac{M}{N+M}\\cdot\\frac{N+M-n}{N+M-1}=np(1-p)\\cdot\\dfrac{\\mathbf{P}-n}{\\mathbf{P}-1} \\] que és la variància d’una variable \\(B(n,p)\\) multiplicada per un factor de correcció a causa del fet que ara prenem mostres sense repetició i la variància és més petita que si les prenem amb repetició. A l’arrel quadrada d’aquest factor \\[ \\sqrt{\\frac{\\mathbf{P}-n}{\\mathbf{P}-1}} \\] se l’anomena factor de població finita. Fixau-vos que si \\(\\mathbf{P}\\) és molt més gran que \\(n\\), tendrem que \\(\\mathbf{P}-n\\approx \\mathbf{P}-1\\) i per tant \\((\\mathbf{P}-n)/(\\mathbf{P}-1)\\approx 1\\) i la variància de la hipergeomètrica serà aproximadament la de la binomial. Això és consistent amb el que ja hem comentat: si la població és molt més gran que la mostra, prendre les mostres amb o sense reposició no afecta massa a les mostres obtengudes, per la qual cosa la distribució de probabilitat ha de ser molt semblant. Recordau els exemples següents: A Espanya hi ha 46,700,000 persones, de les quals un 11.7% són diabètics. Triam 100 espanyols diferents i comptam quants són diabètics. Aquesta variable és, en realitat, hipergeomètrica amb \\(N=0.117\\cdot 46700000=5463900\\), \\(M=46700000-N=41236100\\) i \\(n=100\\), però en la pràctica la consideram binomial \\(B(100,0.117)\\). El quocient \\((\\mathbf{P}-n)/(\\mathbf{P}-1)\\) és \\[ \\frac{46700000-100}{46700000-1}=0.9999979 \\] Pràcticament 1. En canvi: En una aula hi ha 5 homes i 45 dones. Triam 10 estudiants, un rere l’altre i sense repetir-los, per fer-los una pregunta. Cada elecció és independent de les altres. Comptam quants homes hem interrogat. Aquesta variable és \\(H(5,45,10)\\). El quocient \\((\\mathbf{P}-n)/(\\mathbf{P}-1)\\) en aquesta cas no és aproximadament 1: dóna \\[ \\frac{50-10}{50-1}=0.8163 \\] No és correcte aproximar-la per una binomial \\(B(10,0.1)\\). El gràfic següent compara la funció de densitat d’una variable \\(B(10,0.1)\\) amb les de variables hipergeomètriques \\(H(5,45,10)\\), \\(H(50,450,10)\\) i \\(H(5000,45000,10)\\) perquè vegeu com a mesura que la mida de la població creix (mantenint constant la proporció poblacional d’èxits), la distribució hipergeomètrica s’aproxima a la binomial. 2.3.3 Variables aleatòries de Poisson Una variable aleatòria \\(X\\) és de Poisson (o té distribució de Poisson) de paràmetre \\(\\lambda&gt;0\\) (abreujadament, \\(Po(\\lambda)\\)) quan: El seu domini és \\(D_X=\\mathbb{N}\\), el conjunt de tots els nombres naturals. La seva funció de densitat és \\[ f_X(k)=\\left\\{\\begin{array}{ll} e^{-\\lambda}\\cdot \\dfrac{\\lambda^k}{k!} &amp; \\text{ si $k\\in \\mathbb{N}$}\\\\ 0 &amp; \\text{ si $k \\notin \\mathbb{N}$} \\end{array} \\right. \\] Per a R, la distribució de Poisson és pois. Teorema 2.4 Si \\(X\\) és una variable \\(Po(\\lambda)\\), aleshores \\(E(X)= \\sigma(X)^2= \\lambda\\). És a dir, el paràmetre \\(\\lambda\\) d’una variable de Poisson és el seu valor esperat, i coincideix amb la seva variància. Us deveu estar demanant: per a què ens serveix definir una variable de Poisson mitjançant la seva densitat, si el que ens interessa és poder classificar una variable com a Poisson (o binomial, o hipergeomètrica etc.) per a així saber “gratis” la seva densitat? La resposta és que la família de Poisson inclou un tipus de variables aleatòries molt freqüent que tot seguit descrivim. Suposem que tenim un tipus d’objectes que poden donar-se en una regió contínua de temps o espai. Per exemple, defuncions de persones per una determinada malaltia en el decurs del temps, exemplars d’una espècie de planta en un terreny, mutacions en bocins de cromosoma, o nombres de bacteris en bocins d’una superfície. Suposem a més que les aparicions d’aquests objectes satisfan les propietats següents (per simplificar el llenguatge, hi suposarem que observam aparicions d’aquests objectes en el temps; si es tracta d’una variable que compta objectes en regions de l’espai, canviau-hi “instant” per “punt”): Les aparicions dels objectes són aleatòries: en cada instant, un objecte es dóna, o no, a l’atzar, amb una probabilitat fixa i constant. Les aparicions dels objectes són independents: que es doni un objecte en un instant concret, no depèn que s’hagi donat o no un objecte en un altre instant. Les aparicions dels objectes no són simultànies: és pràcticament impossible que dos objectes d’aquests es donin en el mateix instant exacte, mesurat amb precisió infinita. En aquesta situació, la variable \\(X_t\\) que pren un interval de temps de durada \\(t\\) i compta el nombre d’objectes que s’hi donen és de Poisson \\(Po(\\lambda_t)\\), amb \\(\\lambda_t\\) el nombre esperat d’objectes en aquest interval de temps, és a dir, el nombre mitjà d’objectes en intervals de temps d’aquesta mida. Per exemple, quan el que compten ocorre a l’atzar, són variables de Poisson: El nombre de malalts admesos en urgències en un dia (o en 12 hores, o en una setmana…) El nombre de defuncions per una malaltia concreta en un dia (o en una setmana, o en un any…) El nombre d’albiraments de dofins en una hora durant un vol d’inspecció El nombre de bacteris en un quadrat d’1 cm de costat (o d’1 m de costat…) Fixau-vos que aquest tipus de coneixement ens serveix per a dues coses: Si sabem que aquestes variables són de Poisson, coneixem la seva densitat i per tant podem calcular el que volguem per a elles. Si les dades que observam haurien de seguir una distribució de Poisson però sembla que no (per exemple, perquè la seva variància sigui molt diferent de la seva mitjana, tan diferent que sigui difícil de creure que la mitjana i la variància poblacionals siguin iguals), llavors és senyal que qualque cosa “estranya” està passant que afecta la seva aparició. Exemple 2.8 Observau la diferència entre les dues variables següents: Nombres mensuals de defuncions per un tipus de càncer en un país. El moment exacte de les defuncions es produeix a l’atzar, segurament mai no es donen dues defuncions exactament en el mateix instant amb precisió infinita, i les defuncions es produeixen de manera independent. És de Poisson. Nombres mensuals de defuncions per una malatia infecciosa en un país. Un altre cop, el moment exacte de les defuncions es produeix a l’atzar i segurament mai no es donen dues defuncions exactament en el mateix instant amb precisió infinita. Però les infeccions no són independents, precisament perquè es tracta d’una malaltia infecciosa, i per tant les defuncions tampoc: com ens hem cansat d’observar amb la COVID-19, en un mateix cluster de la malaltia es poden produir diverses morts associades. No és de Poisson. Com que les aparicions dels objectes que compta una variable de Poisson són aleatòries i independents, el nombre mitjà d’objectes és lineal en la mida de la regió. És a dir, per exemple, en un interval de dos dies esperam veure el doble d’objectes que en un dia, i en una setmana 7 vegades els d’un dia. Vegem alguns gràfics de la funció de densitat de variables aleatòries de Poisson. Com veieu, la densitat d’una variable Poisson és asimètrica, amb un màxim al voltant de \\(\\lambda\\) i una cua a la dreta, però a mida que \\(\\lambda\\) creix, l’asimetria va minvant. El nombre d’estudiants que entren en el bar del vostre edifici al Campus en un interval de 5 minuts, creieu que segueix una distribució de Poisson? 2.4 Variables aleatòries contínues Una variable aleatòria és contínua quan els seus possibles valors són dades quantitatives contínues. Per exemple: Pes Nivell de colesterol en sang Diàmetre d’un tumor En aquest curs ens restringirem a variables aleatòries contínues \\(X: \\Omega\\to \\mathbb{R}\\) que satisfan la propietat extra següent: la seva funció de distribució \\[ \\begin{array}{rcl} F_X: \\mathbb{R} &amp; \\to &amp; [0,1]\\\\ x &amp;\\mapsto &amp;P(X\\leqslant x) \\end{array} \\] és contínua. Totes les variables aleatòries contínues que us puguin interessar en algun moment satisfan aquesta propietat, així que no perdem res imposant-la. I el que hi guanyam és que: Si \\(X\\) és una variable aleatòria contínua amb funció de distribució contínua, la probabilitat que prengui cada valor concret és 0: \\[ P(X=a)=0 \\text{ per a tot $a \\in \\mathbb{R}$}. \\] Per si passa per aquí qualcú que en necessiti una demostració: \\[ \\begin{array}{l} \\displaystyle P(X=a) = P(X\\leqslant a)-P(X&lt;a)=P(X\\leqslant a)-P\\Big(\\bigcup_{n\\geqslant 1} \\Big(X\\leqslant a-\\frac{1}{n}\\Big)\\Big)\\\\ \\displaystyle \\qquad= P(X\\leqslant a)-\\lim_{n\\geqslant 1}P\\Big(X\\leqslant a-\\frac{1}{n}\\Big)= F_X(a)-\\lim_{n\\geqslant 1}F_X\\Big(a-\\frac{1}{n}\\Big)=0 \\end{array} \\] perquè \\(F_X\\) és contínua. En particular: Per a una variable aleatòria contínua, probabilitat 0 no significa impossible. Cada valor de \\(X\\) té probabilitat 0, però si prenem un subjecte de la població, \\(X\\) tendrà qualque valor sobre ell, no? Per tant, aquest valor de \\(X\\) és possible, malgrat tengui probabilitat 0. De \\(P(X=a)=0\\) es dedueix que la probabilitat d’un esdeveniment definit amb una desigualtat és exactament la mateixa que la de l’esdeveniment corresponent definit amb una desigualtat estricta. En particular, contràriament al que passava a les variables aleatòries discretes, per a una variable aleatòria contínua sempre tenim que \\[ P(X\\leqslant a)=P(X&lt;a) \\] perquè \\[ P(X\\leqslant a)=P(X&lt;a)+P(X=a)=P(X&lt;a)+0=P(X&lt;a). \\] Més exemples: \\(P(X\\geqslant a)=P(X&gt; a)+P(X=a)=P(X&gt; a)\\) \\(P(a \\leqslant X\\leqslant b)=P(a&lt;X &lt;b)+P(X=a)+P(X=b)\\) \\(=P(a&lt;X &lt;b)\\) 2.4.1 Densitat i distribució Sigui \\(X\\) una variable aleatòria contínua. Com ja hem dit, la seva funció de distribució \\(F_X\\) torna a ser \\[ x\\mapsto F_X(x)=P(X\\leqslant x) \\] Però com que ara tenim que \\(P(X=x)=0\\) per a tot \\(x\\in \\mathbb{R}\\), no podem definir la funció de densitat de \\(X\\) com a \\(f_X(x)=P(X=x)\\). Què podem fer? Recordau que, a les variables aleatòries discretes, \\[ F_X(a)=\\sum_{x\\leqslant a} f_X(x) \\] En el context de matemàtiques “contínues”, la suma \\(\\sum\\) es tradueix en una integral \\(\\int\\). Definim aleshores la funció de densitat d’una variable aleatòria contínua \\(X\\) com la funció \\(f_X:\\mathbb{R}\\to \\mathbb{R}\\) tal que: \\(f_X(x)\\geqslant 0\\), per a tot \\(x\\in \\mathbb{R}\\) \\(\\displaystyle F_X(a)=\\int_{-\\infty}^a f_{X}(x)\\, dx\\) per a tot \\(a \\in \\mathbb{R}\\). Recordau que la integral té una interpretació senzilla en termes d’àrees. En concret, donats \\(a \\in \\mathbb{R}\\) i una funció \\(f(x)\\), el valor de la integral \\[ \\int_{-\\infty}^a f(x)\\, dx \\] és igual a l’àrea de la regió compresa entre la corba \\(y=f(x)\\) i l’eix d’abscisses \\(y=0\\) a l’esquerra de la recta vertical \\(x=a\\). Per tant, la funció de densitat \\(f_X\\) de \\(X\\) és la funció positiva tal que, per a tot \\(a\\in \\mathbb{R}\\), \\(F_X(a)\\) és igual a l’àrea davall de la corba \\(y=f_X(x)\\) (és a dir, entre aquesta corba i l’eix d’abscisses) a l’esquerra de \\(x=a\\). Quina és la idea intuïtiva que hi ha al darrere d’aquesta definició de densitat? Suposau que dibuixam histogrames de freqüències relatives dels valors de \\(X\\) sobre tota la població. Com que estam parlant de tota la població, la freqüència relativa de cada classe és la proporció d’individus de la població en els quals el valor de \\(X\\) pertany a aquesta classe: és a dir, la probabilitat que \\(X\\) caigui dins la classe. Recordau que, en un histograma de freqüències relatives: La freqüència relativa (ara, la probabilitat) de cada classe és l’àrea de la seva barra, és a dir, l’amplada de la classe per l’alçada de la barra. Diem a l’alçada d’una barra la densitat de la classe (i per tant, qualque cosa tendrà a veure amb la densitat de \\(X\\), no ho trobau?). Si \\(a\\) és un extrem d’una classe, la freqüència relativa acumulada fins \\(a\\) (la probabilitat que \\(X\\leqslant a\\)) és la suma de les àrees de les barres a l’esquerra d’\\(a\\). Si dibuixam els histogrames de \\(X\\) prenent classes cada vegada més estretes, els seus polígons de freqüències (en vermell) tendeixen a dibuixar una corba: Quan l’amplada de les classes tendeix a 0, obtenim una corba que és el límit d’aquests polígons de freqüències: En el límit, la probabilitat que \\(X\\leqslant a\\) serà el límit de les sumes de les àrees de les barres a l’esquerra d’\\(a\\), i per tant l’àrea davall d’aquesta corba límit a l’esquerra d’\\(a\\). Això ens diu que que aquesta corba és precisament la funció de densitat \\(y=f_X(x)\\). La funció de densitat \\(f_X\\) d’una variable aleatòria contínua \\(X\\) és la funció límit dels polígons de freqüències d’histogrames de \\(X\\) quan l’amplada de les classes tendeix a 0. Vegem algunes propietats que es dedueixen del fet que \\(F_X(a)=P(X\\leqslant a)\\) sigui igual a l’àrea davall de la corba \\(y=f_X(x)\\) a l’esquerra de \\(x=a\\): Com que \\(P(X&lt;\\infty)=P(\\Omega)=1\\), l’àrea davall de tota la corba \\(y=f_X(x)\\) és 1. \\(P(a\\leqslant X\\leqslant b)=P(X\\leqslant b)-P(X&lt;a)\\) és l’àrea davall de la corba \\(y=f_X(x)\\) a l’esquerra de \\(x=b\\) manco l’àrea davall de la corba \\(y=f_X(x)\\) a l’esquerra de \\(x=a\\). Per tant, \\(P(a\\leqslant X\\leqslant b)\\) és igual a l’àrea davall de la corba \\(y=f_X(x)\\) entre \\(x=a\\) i \\(x=b\\). Si \\(\\varepsilon&gt;0\\) és molt, molt petit, l’àrea davall de la corba \\(y=f_X(x)\\) entre \\(a-\\varepsilon\\) i \\(a+\\varepsilon\\) és aproximadament igual a la del rectangle de base l’interval \\([a-\\varepsilon,a+\\varepsilon]\\) i alçada \\(f_X(a)\\), és a dir, a \\(2\\varepsilon\\cdot f_X(a)\\) (vegeu la Figura 2.5). És a dir, \\[ P(a-\\varepsilon\\leqslant X\\leqslant a+\\varepsilon)\\approx 2\\varepsilon\\cdot f_X(a). \\] Per tant, \\(f_X(a)\\) ens dóna una indicació de la probabilitat que \\(X\\) valgui aproximadament \\(a\\) (però no és \\(P(X=a)\\), que val 0). És a dir, per exemple, si \\(f_X(a)=0.1\\) i \\(f_X(b)=0.5\\), la probabilitat que \\(X\\) prengui un valor proper a \\(b\\) és 5 vegades més gran que la probabilitat que prengui un valor proper a \\(a\\). Figura 2.5: L’àrea davall de la corba al voltant d’\\(a\\) és aproximadament igual a la del rectangle d’alçada fX(a) Però \\(P(X=a)=P(X=b)=0\\), així que, per favor, evitau dir que “la probabilitat que \\(X\\) valgui \\(b\\) és 5 vegades més gran que la probabilitat que valgui \\(a\\)”. Sí, ja sabem que \\(5\\cdot 0=0\\), però la frase és enganyosa: la probabilitat que \\(X\\) valgui \\(b\\) no més gran que la probabilitat que valgui \\(a\\). A les variables aleatòries discretes, hi definíem la moda com el valor (o els valors) més probable. Però ara no té sentit definir la moda d’una variable contínua \\(X\\) com el valor \\(x_0\\) tal que \\(P(X=x_0)\\) sigui màxim, perquè… \\(P(X=x)=0\\) per a tot \\(x\\in \\mathbb{R}\\). Aleshores, es defineix la moda d’una variable aleatòria contínua \\(X\\) com el valor (o els valors) \\(x_0\\) tal que \\(f_X(x_0)\\) és màxim. Com que \\(f_X(x_0)\\) mesura la probabilitat que \\(X\\) valgui “aproximadament” \\(x_0\\), tenim que la moda de \\(X\\) és el valor prop del qual és més probable que caigui el valor de \\(X\\). Unes consideracions finals: Ho hem dit en la definició, i ho hem emprat implícitament en tota la secció, però ho tornam a repetir: \\(f_X(x)\\geqslant 0\\) per a tot \\(x\\in \\mathbb{R}\\). En realitat, que \\(f_X(x)\\) sigui \\(\\geqslant 0\\) per a tot \\(x\\in \\mathbb{R}\\) és conseqüència del fet que la funció \\(F_X(x)\\) sigui positiva i creixent (les funcions de distribució són sempre creixents, perquè si \\(x&lt;y\\), \\(F_X(x)=P(X\\leqslant x)\\leqslant P(X\\leqslant y)=F_X(y)\\)) i coincideixi amb \\(\\int_{-\\infty}^x f_X(x)\\,dx\\). Però és més senzill donar-ho com a part de la definició i així ens estalviam la demostració. \\(f_X(x)\\) no és una probabilitat, i per tant pot ser més gran que 1. Per exemple, el gràfic següent mostra la densitat d’una variable normal \\(N(0,0.01)\\) (vegeu la Secció 2.5), que arriba a valer gairebé 40. La funció de densitat \\(f_X\\) no té per què ser contínua, malgrat la funció de distribució \\(F_X\\) ho sigui. 2.4.2 Esperança, variància, quantils… L’esperança i la variància d’una variable aleatòria contínua \\(X\\), amb funció de densitat \\(f_X\\), es defineixen com en el cas discret, substituint la suma \\(\\sum_{x\\in D_x}\\) per una integral, i tenen les mateixes propietats. La mitjana, o esperança (o valor mitjà, valor esperat…), de \\(X\\) és \\[ E(X)=\\int_{-\\infty}^{\\infty}x \\cdot f_{X}(x)\\, dx \\] És a dir, és l’àrea compresa entre l’eix d’abscisses i la corba \\(y=xf_X(x)\\). Com en el cas discret, també la indicarem de vegades amb \\(\\mu_X\\). Aquest valor té la mateixa interpretació que en el cas discret: Representa el valor mitjà de \\(X\\) sobre el total de la població. És (amb probabilitat 1) el límit de les mitjanes aritmètiques de mostres aleatòries de mida \\(n\\) de valors de \\(X\\), quan \\(n\\to \\infty\\). Si \\(g:\\mathbb{R}\\to \\mathbb{R}\\) és una funció contínua, l’esperança de \\(g(X)\\) és \\[ E(g(X))=\\int_{-\\infty}^{+\\infty} g(x) f_X(x)dx \\] La variància de \\(X\\) és \\[ \\sigma(X)^2=E((X-\\mu_X)^2)=\\int_{-\\infty}^{+\\infty} (x-\\mu_X)^2 f_X(x)dx \\] i es pot demostrar que és igual a \\[ \\sigma(X)^2=E(X^2)-\\mu_X^2. \\] També la indicarem de vegades amb \\(\\sigma_X^2\\). La desviació típica de \\(X\\) és \\[ \\sigma(X)=+\\sqrt{\\sigma(X)^2} \\] i també la indicarem de vegades amb \\(\\sigma_X\\). Com en el cas discret, la variància i la desviació típica quantifiquen la variabilitat dels resultats de \\(X\\). Aquests paràmetres de \\(X\\) tenen les mateixes propietats en el cas continu que en el discret. Les recordam: Si \\(b\\) és una variable aleatòria constant, \\(E(b)=b\\) i \\(\\sigma(b)^2=0\\). Si \\(\\sigma(X)^2=0\\), \\(X\\) és constant. I és clar, si \\(X\\) només pot prendre un valor, aleshores ja no és contínua, sino discreta. Per tant, per conveni, d’ara endavant suposarem que les nostres variables aleatòries contínues sempre tenen variància no nul·la. Si \\(X_1,\\ldots,X_n\\) són variables aleatòries i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ E(a_1X_1+\\cdots+a_nX_n+b)=a_1E(X_1)+\\cdots+a_nE(X_n)+b \\] Si \\(X\\leqslant Y\\), aleshores \\(E(X)\\leqslant E(Y)\\). Si \\(a,b\\in \\mathbb{R}\\), \\(\\sigma(aX+b)^2=a^2 \\sigma(X)^2\\) i \\(\\sigma(aX+b)=|a|\\cdot \\sigma(X)\\). Si \\(X_1,\\ldots,X_n\\) són variables aleatòries independents (i, en principi, només en aquest cas) i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ \\begin{array}{l} \\sigma(a_1X_1+\\cdots+a_nX_n+b)^2=a_1^2\\cdot\\sigma(X_1)^2+\\cdots+a_n^2\\cdot\\sigma(X_n)^2\\\\ \\sigma(a_1X_1+\\cdots+a_nX_n+b)=\\sqrt{a_1^2\\cdot\\sigma(X_1)^2+\\cdots+a_n^2\\cdot\\sigma(X_n)^2} \\end{array} \\] Si no són independents, aquestes igualtats poden ser falses. El quantil d’ordre \\(p\\) (o \\(p\\)-quantil) d’una variable aleatòria contínua \\(X\\) és el valor \\(x_p\\in \\mathbb{R}\\) més petit tal que \\[ F_X(x_p)=P(X\\leqslant x_p)=p \\] Observau que, com que \\(F_X(x)\\) tendeix a 0 (la probabilitat del conjunt buit) quan \\(x\\to -\\infty\\) i tendeix a 1 (la probabilitat de tot \\(\\mathbb{R}\\)) quan \\(x\\to +\\infty\\) i és contínua (no pega bots), pren tots els valors de l’interval \\((0,1)\\) i per tant, per a qualsevol \\(p\\in (0,1)\\), existeix qualque \\(x\\) tal que \\(F_X(x)=p\\). La mediana de \\(X\\) és el seu 0.5-quantil, el primer i tercer quartils són el seu 0.25-quantil i el seu 0.75-quantil, etc. 2.5 Variables aleatòries normals Una variable aleatòria contínua \\(X\\) és normal (o té distribució normal) de paràmetres \\(\\mu\\) i \\(\\sigma\\) (per abreujar, \\(N(\\mu,\\sigma)\\)) quan la seva funció de densitat és \\[ f_{X}(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{{-(x-\\mu)^2}/(2\\sigma^{2})} \\] Naturalment, no us heu de saber aquesta fórmula. Però sí que heu de saber que: Una variable aleatòria normal \\(X\\) és contínua, i per tant \\(P(X=x)=0\\), \\(P(X\\leqslant x)=P(X&lt;x)\\) etc. Si \\(X\\) és normal, la seva funció de distribució \\(F_X\\) és injectiva i estrictament creixent: si \\(x&lt;y\\), \\(F_X(x)&lt;F_X(y)\\). Si \\(X\\) és \\(N(\\mu,\\sigma)\\), aleshores \\(\\mu_X=\\mu\\) i \\(\\sigma_X=\\sigma\\). Una variable aleatòria normal diem que és estàndard (o típica) quan és \\(N(0,1)\\). Normalment indicarem les variables normals estàndard amb \\(Z\\). Observau, doncs, que si \\(Z\\) és normal estàndard, \\(\\mu_Z=0\\) i \\(\\sigma_Z=1\\). La gràfica de la densitat d’una variable aleatòria normal és la famosa campana de Gauss: Figura 2.6: Densitat d’una variable normal estàndard La distribució normal és una distribució teòrica, no la trobareu exacta en la vida real. I malgrat el seu nom, no és més “normal” que altres distribucions contínues. Però és molt important perquè moltes distribucions de la vida real són aproximadament normals. El motiu és que: Si una variable aleatòria consisteix a prendre un nombre molt gran \\(n\\) de mesures independents d’una o diverses variables aleatòries i sumar-les, aleshores té distribució aproximadament normal, encara que les variables aleatòries de partida no ho siguin. Exemple 2.9 Una variable binomial \\(B(n,p)\\) s’obté prenent \\(n\\) mesures independents d’una variable Bernoulli \\(Be(p)\\) i sumant-les. Per tant, per la “regla” anterior, una \\(B(n,p)\\) hauria de ser aproximadament normal si \\(n\\) és gran. Doncs sí, si \\(n\\) és gran (posem a partir de 40, encara que si \\(p\\) és molt propera a 0 o 1, la mida de les mostres ha de ser més gran), una variable \\(X\\) binomial \\(B(n,p)\\) és aproximadament normal \\(N(np,\\sqrt{np(1-p)})\\); recordau que, si \\(X\\) és \\(B(n,p)\\), aleshores \\(\\mu_X=np\\) i \\(\\sigma_X=\\sqrt{np(1-p)}\\). Aquest “aproximadament” significa que la densitat i la distribució de \\(X\\) són aproximadament les de la normal. Per exemple, el gràfic següent compara les funcions de distribució d’una binomial \\(B(40,0.3)\\) i una normal \\(N(40\\cdot 0.3,\\sqrt{40\\cdot 0.3\\cdot 0.7})\\). En els propers temes emprarem sovint que una variable \\(B(n,p)\\) amb \\(n\\) gran és aproximadament \\(N(np,\\sqrt{np(1-p)})\\). Exemple 2.10 Si \\(X\\) és una variable aleatòria de Poisson \\(Po(\\lambda)\\) i \\(\\lambda\\) és gran, aleshores \\(X\\) també és aproximadament \\(N(\\lambda,\\sqrt{\\lambda})\\). Per exemple, el gràfic següent compara les funcions de distribució d’una Poisson \\(Po(70)\\) i una normal \\(N(70,\\sqrt{70})\\). Quan s’aproxima per mitjà d’una variable normal \\(Y\\) una variable discreta \\(X\\) que només pot prendre com a valors nombres naturals, com ara una binomial o una Poisson, és convenient aplicar alguna correcció de continuïtat. La més senzilla és, per a cada \\(n\\in \\mathbb{N}\\), aproximar: \\(P(X\\leqslant n)\\) per mitjà de \\(P(Y&lt; n+1/2)\\) \\(P(X=n)\\) per mitjà de \\(P(n-1/2&lt; Y&lt; n+1/2)\\) Vegeu l’Exemple 2.11 més a baix. 2.5.1 Amb R Per calcular probabilitats d’una \\(N(\\mu,\\sigma)\\), cal calcular les integrals a mà. O podeu emprar R, per a qui la normal és norm. Per tant, si \\(X\\sim N(\\mu,\\sigma)\\): dnorm(x,mu,sigma) dóna el valor de la densitat \\(f_X(x)\\) pnorm(x,mu,sigma) dóna el valor de la distribució \\(F_X(x)=P(X\\leqslant x)\\) qnorm(q,mu,sigma) dóna el \\(q\\)-quantil de \\(X\\) rnorm(n,mu,sigma) dóna un vector de \\(n\\) nombres aleatoris generats amb aquesta distribució Així, per exemple, si \\(X\\) és \\(N(1,2)\\) \\(P(X\\leqslant 1.5)\\) és pnorm(1.5,1,2) ## [1] 0.5987063 El 0.4-quantil de \\(X\\), és a dir, el valor \\(q\\) tal que \\(P(X\\leqslant q)=0.4\\) és qnorm(0.4,1,2) ## [1] 0.4933058 \\(P(X=1.5)\\) és dnorm(1.5,1,2) ## [1] 0.1933341 No! Com que \\(X\\) és contínua, \\(P(X=1.5)=0\\). El que us dóna dnorm(1.5,1,2) és el valor de la funció de densitat de \\(X\\) en 1.5, que no creiem que us interessi gaire. Si la normal és estàndard, no fa falta entrar la \\(\\mu=0\\) i la \\(\\sigma=1\\) (són els valors per defecte d’aquests paràmetres per a norm). Així, si \\(Z\\) és \\(N(0,1)\\): \\(P(Z\\leqslant 1.5)\\) és pnorm(1.5) ## [1] 0.9331928 El seu 0.95-quantil és qnorm(0.95) ## [1] 1.644854 Què val \\(P(-1\\leqslant Z\\leqslant 1)\\)? Com que \\(P(-1\\leqslant Z\\leqslant 1)=P(Z\\leqslant 1)-P(Z\\leqslant -1)\\), és pnorm(1)-pnorm(-1) ## [1] 0.6826895 Exemple 2.11 A la secció anterior, us hem dit que una variable binomial \\(B(n,p)\\) amb \\(n\\) gran s’aproxima per mitjà d’una variable normal \\(N(np,\\sqrt{np(1-p)})\\). Així, per exemple, una variable \\(X\\) binomial \\(B(400,0.2)\\) s’aproxima per mitjà d’una variable \\(Y\\) normal \\(N(400\\cdot 0.2,\\sqrt{400\\cdot 0.2\\cdot 0.8})=N(80,8)\\). Vegem amb alguns exemples que aquesta aproximació és millor aplicant-hi la correcció de continuïtat: \\(F_X(70)=P(X\\leqslant 70)\\): pbinom(70,400,0.2) ## [1] 0.1163917 \\(F_Y(70)=P(Y\\leqslant 70)\\): pnorm(70,80,8) ## [1] 0.1056498 La correcció de continuïtat ens diu que és millor aproximar \\(P(X\\leqslant 70)\\) per mitjà de \\(P(Y&lt; 70+1/2)\\): pnorm(70.5,80,8) ## [1] 0.1175152 \\(f_X(70)=P(X=70)\\): dbinom(70,400,0.2) ## [1] 0.02338443 \\(f_Y(70)\\) (que no és \\(P(Y=70)\\)): dnorm(70,80,8) ## [1] 0.02283114 La correcció de continuïtat ens diu que és millor aproximar \\(P(X=70)\\) per mitjà de \\(P(70-1/2&lt;Y&lt; 70+1/2)\\): pnorm(70.5,80,8)-pnorm(69.5,80,8) ## [1] 0.02283949 Exemple 2.12 La pressió sistòlica, mesurada en mm Hg, es distribueix com una variable normal amb valor mitjà i desviació típica que depenen del sexe i l’edat. Per a la franja d’edat 16-24 anys, aquests valors (s’estima que) són: Per a homes, \\(\\mu=124\\) i \\(\\sigma=13.7\\) Per a dones, \\(\\mu=117\\) i \\(\\sigma=13.7\\) El model d’hipertensió-hipotensió acceptat és el descrit en la Figura 2.7. Volem calcular els límits de cada classe per a cada sexe en aquest grup d’edat. Figura 2.7: Model d’hipertensió-hipotensió. Vegem: El límit superior del grup d’hipotensió serà el valor que deixa a l’esquerra un 5% de les tensions: el 0.05-quantil de la distribució. El límit superior del grup de risc d’hipotensió serà el valor que deixa a l’esquerra un 10% de les tensions: el 0.1-quantil de la distribució. El límit inferior del grup de risc d’hipertensió serà el valor que deixa a l’esquerra un 90% de les tensions: el 0.9-quantil de la distribució. El límit inferior del grup d’hipertensió serà el valor que deixa a l’esquerra un 95% de les tensions: el 0.95-quantil de la distribució. En els homes, la tensió sistòlica és una variable aleatòria \\(N(124,13.7)\\). Aleshores, aquests quantils són: El 0.05-quantil: round(qnorm(0.05,124,13.7),1) ## [1] 101.5 El 0.1-quantil: round(qnorm(0.1,124,13.7),1) ## [1] 106.4 El 0.9-quantil: round(qnorm(0.9,124,13.7),1) ## [1] 141.6 El 0.95-quantil: round(qnorm(0.95,124,13.7),1) ## [1] 146.5 En resum, per als homes de 16 a 24 anys tenim els límits de la Taula 2.1. Taula 2.1: Límits d’hipotensió-hipertensió en homes joves. Grup Interval Hipotens &lt;101.5 Prehipotens 101.5 a 106.4 Normotens 106.4 a 141.6 Prehipertens 141.6 a 146.5 Hipertens &gt; 146.5 Calculau els límits per a les dones. 2.5.2 Propietats bàsiques Ja hem explicat el significat dels paràmetres \\(\\mu\\) i \\(\\sigma\\), però el tornam a repetir: Si \\(X\\) és \\(N(\\mu,\\sigma)\\), aleshores \\(\\mu_X=\\mu\\) i \\(\\sigma_X=\\sigma\\). Una de les propietats clau de la distribució normal és la seva simetria: Si \\(X\\) és \\(N(\\mu,\\sigma)\\), la seva densitat \\(f_X\\) és simètrica respecte de \\(\\mu\\), és a dir, \\[ f_{X}(\\mu-x)=f_{X}(\\mu+x), \\] i pren el valor màxim a \\(x=\\mu\\). És a dir, \\(\\mu\\) és la moda de \\(X\\). Per tant, el valor al voltant del qual és més probable que una variable normal \\(N(\\mu,\\sigma)\\) caigui és justament el seu valor esperat \\(\\mu\\). En particular, si \\(Z\\) és \\(N(0,1)\\), llavors \\(f_Z\\) és simètrica al voltant de 0, és a dir, \\(f_{Z}(-x)=f_{Z}(x)\\), i la moda de \\(Z\\) és \\(x=0\\). Recordau que la funció de distribució d’una variable aleatòria contínua \\(X\\), \\[ F_X(x)=P(X\\leqslant x) \\] és l’àrea compresa entre la densitat \\(y=f_X(x)\\) i l’eix d’abscisses a l’esquerra de \\(x\\). Llavors, la simetria de \\(f_X\\) fa que, per a tot \\(x\\geqslant 0\\), les àrees davall de la densitat a l’esquerra de \\(\\mu-x\\) i a la dreta de \\(\\mu+x\\) siguin iguals. És a dir, \\[ P(X\\leqslant \\mu-x)=P(X\\geqslant \\mu+x)=1-P(X\\leqslant \\mu+x) \\] En particular (prenent \\(x=0\\)) \\[ P(X\\leqslant \\mu)=1-P(X\\leqslant \\mu)\\Rightarrow P(X\\leqslant \\mu)=0.5 \\] i per tant, \\(\\mu\\) és també la mediana de \\(X\\). Si \\(X\\) és \\(N(\\mu,\\sigma)\\), \\(\\mu\\) és la mitjana, la mediana i la moda de \\(X\\). En el cas concret de la normal estàndard \\(Z\\), per a qualsevol \\(z\\geqslant 0\\) es té que les àrees davall de la densitat a l’esquerra de \\(-z\\) i a la dreta de \\(z\\) són iguals \\[ P(Z\\leqslant -z)=P(Z\\geqslant z)=1-P(Z\\leqslant z) \\] i la mediana de \\(Z\\) és 0. Ara que sabem més coses de la normal, a l’Exemple 2.12 ens haguéssim pogut estalviar la meitat de la feina. Diguem \\(X\\) a la variable aleatòria que ens dóna la pressió arterial, en mm Hg, d’un home d’entre 16 i 24 anys. Ens diuen que \\(X\\) és \\(N(124,13.7)\\). Per la simetria de \\(X\\) al voltant de \\(\\mu=124\\), si escrivim el 0.05-quantil com \\(124-x\\), aleshores \\(P(X\\geqslant 124+x)=P(X\\leqslant 124-x)=0.05\\) i per tant \\(P(X\\leqslant 124+x)=1-P(X\\geqslant 124+x)=0.95\\), és a dir, \\(124+x\\) serà el 0.95-quantil de \\(X\\). El 0.05-quantil ha estat 101.5. Escrivint \\(101.5=124-x\\), obtenim \\(x=22.5\\). Per tant, el 0.95-quantil ha de ser \\(124+22.5=146.5\\). El mateix passa amb el 0.9-quantil i el 0.1-quantil, raonau-ho i comprovau-ho. L’argument que hem desenvolupat a la nota anterior mostra en general que si \\(X\\) és \\(N(\\mu,\\sigma)\\) i el seu \\(q\\)-quantil és \\(\\mu-x\\), aleshores el seu \\((1-q)\\)-quantil és \\(\\mu+x\\). Figura 2.8: Quantils gratis! Si \\(\\mu\\) creix, desplaça a la dreta l’eix vertical de simetria de la densitat, i amb ell tota la corba. Si \\(\\sigma\\) creix, la corba s’aplana: en augmentar la desviació típica, els valors són més variats i augmenta la probabilitat que prenguin valors més llunyans de \\(\\mu\\). El gràfic següent mostra l’efecte combinat: Indicarem amb \\(z_q\\) el \\(q\\)-quantil d’una variable normal estàndard \\(Z\\). És a dir, \\(z_q\\) és el valor tal que \\(P(Z\\leqslant z_q)=q\\). A banda del fet que \\(z_{0.5}=0\\) (la mediana de \\(Z\\) és 0), hi ha dos quantils més de la normal estàndard \\(Z\\) que hauríeu de recordar: \\(z_{0.95}=1.64\\); és a dir, \\(P(Z\\leqslant 1.64)=0.95\\) i per tant \\(P(Z\\leqslant -1.64)=P(Z\\geqslant 1.64)=0.05\\) (és a dir, \\(z_{0.05}=-1.64\\)) i \\[ P(-1.64\\leqslant Z\\leqslant 1.64)=0.9. \\] \\(z_{0.975}=1.96\\); és a dir, \\(P(Z\\leqslant 1.96)=0.975\\) i per tant \\(P(Z\\leqslant -1.96)=P(Z\\geqslant 1.96)=0.025\\) (és a dir, \\(z_{0.025}=-1.96\\)) i \\[ P(-1.96\\leqslant Z\\leqslant 1.96)=0.95. \\] Molt sovint el valor 1.96 de \\(z_{0.975}\\) s’aproxima per 2. Teniu permís per a fer-ho quan no disposeu de mitjans (R, aplis de mòbil) per a calcular quantils i us considereu incapaços de recordar “1.96”. Però només en aquest cas. Pel que hem comentat fa un moment, la simetria de la normal estàndard implica que \\(z_{1-q}=-z_{q}\\), perquè si \\(P(Z\\leqslant z_{q})=q\\), aleshores \\(P(Z\\geqslant -z_{q})=q\\) i per tant \\(P(Z\\leqslant -z_{q})=1-q\\). Una de les propietats més útils de la distribució normal és que tota combinació lineal de variables aleatòries normals independents és normal. En concret, tenim els dos resultats següents: Teorema 2.5 Sigui \\(X\\) una variable \\(N(\\mu,\\sigma)\\). Per a tots \\(a,b\\in \\mathbb{R}\\), \\(aX+b\\) és normal \\(N(a\\mu+b,|a|\\cdot\\sigma)\\). En particular, la tipificada de \\(X\\) \\[ Z=\\dfrac{X-\\mu}{\\sigma} \\] és normal estàndard. Més en general: Teorema 2.6 Si \\(X_1,\\ldots,X_n\\) són variables aleatòries normals independents i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), llavors \\(a_1X_1+\\cdots +a_nX_n+b\\) és \\(N(\\mu,\\sigma)\\) amb \\[ \\begin{array}{l} \\mu=a_1\\mu_{X_1}+\\cdots +a_n\\mu_{X_n}+b\\\\ \\sigma=\\sqrt{a_1^2\\sigma^2_{X_1}+\\cdots +a_n^2\\sigma^2_{X_n}} \\end{array} \\] Que tota combinació lineal de variables normals independents torni a ser del mateix tipus, és a dir, normal, és una propietat molt útil de les variables normals que poques famílies de distribucions comparteixen. Per exemple, si \\(X\\) és una variable binomial \\(B(n,p)\\) amb \\(p\\neq 0\\), la variable \\(2X\\) no és binomial, perquè només pren valors parells, mentre que una variable binomial \\(B(m,q)\\) ha de poder prendre tots els valors entre 0 i \\(m\\). Les probabilitats de la normal tipificada \\(Z\\) determinen les de la normal original, perquè si \\(X\\) és \\(N(\\mu,\\sigma)\\): \\[ \\begin{array}{rl} P(a\\leqslant X\\leqslant b)\\!\\!\\!\\!\\! &amp; \\displaystyle =P\\Big( \\frac{a-\\mu}{\\sigma}\\leqslant \\frac{X-\\mu}{\\sigma}\\leqslant \\frac{b-\\mu}{\\sigma}\\Big)\\\\ &amp; \\displaystyle =P\\Big(\\frac{a-\\mu}{\\sigma}\\leqslant Z\\leqslant \\frac{b-\\mu}{\\sigma}\\Big) \\end{array} \\] Això serveix per deduir fórmules o resoldre problemes com el següent, i els vostres pares ho empraven per calcular probabilitats de normals (amb taules de probabilitats de la normal estàndard), però ara és més còmode usar una apli. Exemple 2.13 Les alçades de les nordamericanes de 20 anys segueixen una distribució normal. S’ha estimat que un 10% d’elles fan manco de 1.55 m, i un 30.5% fan manco de 1.60 m. Per a quina alçada \\(h\\) es té que un 95% de les nordamericanes de 18 anys fan manco de \\(h\\) metres? Diguem \\(X\\) a la variable “Prenc una nord americana de 20 anys i mesur la seva alçada en m”. Sabem que és \\(N(\\mu,\\sigma)\\), però desconeixem \\(\\mu\\) i \\(\\sigma\\). Ens diuen que \\[ P(X&lt; 1.55)=0.1,\\ P(X&lt; 1.60)=0.305 \\] i amb això volem calcular la \\(h\\) tal que \\(P(X\\leqslant h)=0.95\\), és a dir, el 0.95-quantil de \\(X\\). El que farem serà, tipificant la \\(X\\), traduir la informació que ens han donat a quantils d’una normal estàndard \\(Z\\): \\[ \\begin{array}{l} \\displaystyle 0.1=P(X&lt; 1.55)=P\\Big(\\frac{X-\\mu}{\\sigma}&lt;\\frac{1.55-\\mu}{\\sigma}\\Big)=P\\Big(Z&lt;\\frac{1.55-\\mu}{\\sigma}\\Big)\\\\ \\displaystyle \\qquad \\Longrightarrow \\frac{1.55-\\mu}{\\sigma}=z_{0.1}\\\\ \\displaystyle 0.305=P(X&lt; 1.6)=P\\Big(\\frac{X-\\mu}{\\sigma}&lt;\\frac{1.6-\\mu}{\\sigma}\\Big)=P\\Big(Z&lt;\\frac{1.6-\\mu}{\\sigma}\\Big)\\\\ \\displaystyle \\qquad \\Longrightarrow \\frac{1.6-\\mu}{\\sigma}=z_{0.305} \\end{array} \\] Ara podem calcular aquests dos quantils \\(z_{0.1}\\) i \\(z_{0.305}\\): qnorm(0.1) ## [1] -1.281552 qnorm(0.305) ## [1] -0.5100735 Obtenim d’aquesta manera el sistema d’equacions lineals \\[ \\left. \\begin{array}{ll} 1.55-\\mu=-1.282\\sigma\\\\ 1.6-\\mu=-0.51\\sigma \\end{array}\\right\\} \\] El resolem i obtenim \\[ \\mu=1.633,\\ \\sigma=0.065 \\] I ara ja podem calcular la \\(h\\) com el 0.95-quantil d’una \\(N(1.633,0.065)\\): qnorm(0.95,1.633,0.065) ## [1] 1.739915 Concloem que un 95% de les nord americanes de 20 anys fan manco de 1.74 m. 2.5.3 Intervals de referència Un interval de referència del Q% per a una variable aleatòria contínua \\(X\\) és un interval \\([a,b]\\) tal que \\[ P(a\\leqslant X\\leqslant b)=\\frac{Q}{100}. \\] És a dir, un interval de referència del Q% per a \\(X\\) és un interval que conté els valors de \\(X\\) del Q% dels subjectes de la població. Per exemple, hem vist en la secció anterior que [-1.64,1.64] i [-1.96,1.96] són intervals de referència del 90% i del 95%, respectivament, per a una variable normal estàndard \\(Z\\). Els més comuns són els intervals de referència del 95%, que satisfan que \\[ P(a\\leqslant X\\leqslant b)=0.95 \\] i són els, que per exemple, us donen com a valors de referència en les analítiques: Quan es parla d’un interval de referència sense donar la probabilitat, se sobreentén sempre que és l’interval de referència del 95%. Quan \\(X\\) és \\(N(\\mu,\\sigma)\\), aquests intervals de referència es prenen sempre centrats en la mitjana \\(\\mu\\), és a dir, de la forma \\[ [\\mu-\\text{alguna cosa},\\mu+\\text{aquesta mateixa cosa}]. \\] Es calculen amb el resultat següent: Teorema 2.7 Si \\(X\\) és \\(N(\\mu,\\sigma)\\), un interval de referència del Q% per a \\(X\\) és \\[ [\\mu- z_{(1+q)/2}\\cdot \\sigma, \\mu+ z_{(1+q)/2}\\cdot \\sigma] \\] on \\(q=Q/100\\) i \\(z_{(1+q)/2}\\) és el \\((1+q)/2\\)-quantil de la normal estàndard \\(Z\\). Normalment escriurem aquest interval \\[ \\mu\\pm z_{(1+q)/2}\\cdot \\sigma. \\] La demostració és un exemple d’ús de la tipificació de la normal: \\[ \\begin{array}{l} P(\\mu-x\\leqslant X\\leqslant \\mu+x)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P\\Big(\\frac{\\mu-x-\\mu}{\\sigma}\\leqslant \\frac{X-\\mu}{\\sigma}\\leqslant \\frac{\\mu+x-\\mu}{\\sigma}\\Big)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(-x/{\\sigma}\\leqslant Z\\leqslant {x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant {x}/{\\sigma})-P(Z\\leqslant -{x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant {x}/{\\sigma})-(1-P(Z\\leqslant {x}/{\\sigma}))=q\\\\ \\qquad \\text{(per la simetria de $f_Z$ al voltant de 0)}\\\\ \\qquad \\Longleftrightarrow \\displaystyle 2P(Z\\leqslant {x}/{\\sigma})=q+1\\\\ \\qquad \\Longleftrightarrow P(Z\\leqslant {x}/{\\sigma})=(1+q)/2\\\\ \\qquad \\Longleftrightarrow x/\\sigma= z_{(1+q)/2}\\\\ \\qquad \\Longleftrightarrow x=z_{(1+q)/2}\\cdot \\sigma \\end{array} \\] Si \\(q=0.95\\), llavors \\((1+q)/2=0.975\\) i \\(z_{0.975}=1.96\\). Per tant, l’interval de referència del 95% per a una variable \\(X\\) normal \\(N(\\mu,\\sigma)\\) és \\[ \\mu\\pm 1.96\\sigma. \\] I com que aquest 1.96 sovint s’aproxima per 2, l’interval de referència del 95% d’una \\(N(\\mu,\\sigma)\\) se sol simplificar a \\[ \\mu\\pm 2\\sigma. \\] Això diu, bàsicament, que Si una variable aleatòria definida sobre una població segueix una distribució normal \\(N(\\mu,\\sigma)\\), un 95% dels seus individus tenen el seu valor de \\(X\\) a distància com a màxim \\(2\\sigma\\) (“a dues sigmes”) de \\(\\mu\\). Exemple 2.14 Segons l’OMS, les altures (en cm) de les dones europees de 18 anys segueixen una llei \\(N(163.1,18.53)\\). Quin és l’interval d’altures centrat en la mitjana que conté a la meitat de les europees de 18 anys? Fixau-vos que, si diem \\(X\\) a la variable aleatòria “Altura d’una dona europea de 18 anys en cm”, el que volem saber és l’interval centrat en la seva mitjana, 163.1, tal que la probabilitat que l’alçada d’una europea de 18 anys triada a l’atzar pertanyi a aquest interval sigui 0.5. És a dir, l’interval de referència del 50% per a \\(X\\). Ens diuen que \\(X\\) és \\(N(163.1,18.53)\\). Si \\(q=0.5\\), llavors \\((1+q)/2=0.75\\). El 0.75-quantil \\(z_{0.75}\\) d’una normal estàndard és qnorm(0.75) ## [1] 0.6744898 Per tant, l’interval de referència demanat és \\(163.1\\pm 0.6745\\cdot 18.53\\), és a dir, arrodonint a mm, \\([150.6, 175.6]\\). Això ens diu que la meitat de les dones europees de 18 anys fan entre 150.6 i 175.6 cm. El z-score d’un valor \\(x_0\\in \\mathbb{R}\\) respecte d’una distribució \\(N(\\mu,\\sigma)\\) és \\[ \\frac{x_0-\\mu}{\\sigma} \\] És a dir, el z-score de \\(x_0\\) és el resultat de “tipificar” \\(x_0\\) en el sentit del Teorema 2.5.2. Si la variable poblacional és normal, com més gran és el valor absolut del z-score de \\(x_0\\), més “rar” és \\(x_0\\); el signe ens diu si és més gran o més petit que el valor esperat \\(\\mu\\). Exemple 2.15 Recordau que, segons l’OMS, les altures de les dones europees de 18 anys segueixen una llei \\(N(163.1,18.53)\\). Quin seria el z-score d’una jugadora de bàsquet de 18 anys que fes 191 cm? Seria \\[ \\frac{191-163.1}{18.53}=1.5 \\] Això se sol llegir dient que l’alçada d’aquesta jugadora està 1.5 sigmes per sobre de l’alçada mitjana. 2.5.4 Variables log-normals Direm que \\(X\\) és una variable log-normal quan el seu logaritme neperià \\(\\ln(X)\\) és una variable normal. O, si ho preferiu, quan és una variable de la forma \\(e^Y\\) amb \\(Y\\) normal. Moltes concentracions d’enzims o anticossos tenen distribucions aproximadament log-normals. Si \\(a&gt;1\\), \\(\\log_a(X)=\\ln(X)/\\ln(a)\\) i per tant, pel Teorema 2.5.1, les tres afirmacions següents són equivalents: \\(X\\) és log-normal \\(\\log_a(X)\\) és normal, per a qualque base \\(a&gt;1\\). \\(\\log_a(X)\\) és normal per a tota base \\(a&gt;1\\). La densitat d’una variable log-normal és asimètrica, amb una cua a la dreta, com mostra la Figura 2.9. Figura 2.9: Densitat de \\(e^Z\\) amb \\(Z\\) normal estàndard. Recíprocament, molt sovint una variable la densitat de la qual mostri una pujada ràpida des del 0 a la moda i després una cua a la dreta, satisfà que el seu logaritme segueix una distribució aproximadament normal. Això ens serà útil més endavant. Amb R, la distribució log-normal és lnorm. Els paràmetres que s’empren per descriure-la són els de la variable normal definida pel seu logaritme: La mitjana en escala logarítmica de \\(X\\): \\(\\mu_{\\ln(X)}\\) La desviació típica en escala logarítmica de \\(X\\): \\(\\sigma_{\\ln(X)}\\) Exemple 2.16 La dosi letal \\(Y\\) de la digitalina en ratolins (és la dir, la variable aleatòria que dóna la quantitat de digitalina que cal administrar a un ratolí per matar-lo) té distribució log-normal. Se sap que una injecció de 1cc de digitalina mata un 10% dels ratolins (és a dir, que la probabilitat que una dosi de 1cc o manco mati un ratolí és de 0.1: \\(P(Y\\leqslant 1)=0.1\\)) i que una injecció de 2cc mata un 75% dels ratolins (\\(P(Y\\leqslant 2)=0.75\\)). Volem saber la dosi de digitalina (en cc) que és letal per al 95% dels ratolins. Aquest tipus d’experiments és la base de l’anomenat mètode probit per determinar la letalitat de substàncies. Així doncs, volem calcular el valor \\(a\\) tal que \\(P(Y\\leqslant a)=0.95\\), que no és res més que el 0.95-quantil de \\(Y\\). Com que el logaritme és injectiu, \\(P(Y\\leqslant x)=P(\\ln(Y)\\leqslant \\ln(x))\\). Per tant el pla és trobar el 0.95-quantil de \\(\\ln(Y)\\), diguem-li \\(b\\), i aleshores tendrem \\(a=e^b\\). Per simplificar, diguem \\(X\\) a \\(\\ln(Y)\\). Sabem que \\(X\\) és normal, per tant només ens cal saber la seva \\(\\mu\\) i la seva \\(\\sigma\\) i podrem calcular el seu 0.95-quantil. El que sabem és que \\[ \\begin{array}{l} 0.1=P(Y\\leqslant 1)=P(X\\leqslant \\ln(1))=P(X\\leqslant 0)\\\\ 0.75=P(Y\\leqslant 2)=P(X\\leqslant \\ln(2)) \\end{array} \\] Com podem determinar la \\(\\mu\\) i la \\(\\sigma\\) de \\(X\\) a partir d’aquests dos valors? Ja ens hem trobat en una situació semblant a l’Exemple 2.13. El que fem és traduir aquesta informació en termes de quantils de la normal estàndard. \\[ \\begin{array}{l} \\displaystyle 0.1=P(X\\leqslant 0)=P\\Big(\\frac{X-\\mu}{\\sigma}\\leqslant \\frac{-\\mu}{\\sigma}\\Big)=P\\Big(Z\\leqslant -\\frac{\\mu}{\\sigma}\\Big)\\\\ \\displaystyle\\qquad \\Longrightarrow -\\frac{\\mu}{\\sigma}=z_{0.1}=\\texttt{qnorm(0.1)}=-1.2816\\\\ \\displaystyle 0.75=P(X\\leqslant \\ln(2))=P\\Big(\\frac{X-\\mu}{\\sigma}\\leqslant \\frac{\\ln(2)-\\mu}{\\sigma}\\Big)=P\\Big(Z\\leqslant \\frac{\\ln(2)-\\mu}{\\sigma}\\Big)\\\\ \\displaystyle\\qquad \\Longrightarrow \\frac{\\ln(2)-\\mu}{\\sigma}=z_{0.75}=\\texttt{qnorm(0.75)}=0.6745 \\end{array} \\] Obtenim el sistema d’equacions \\[ \\left. \\begin{array}{l} \\mu=1.2816\\sigma\\\\ \\ln(2)-\\mu=0.6745\\sigma \\end{array} \\right\\} \\] i resolent-lo obtenim \\[ \\mu=0.4541,\\quad \\sigma=0.3544 \\] Ara podem calcular el 0.95-quantil de \\(X\\): qnorm(0.95,0.4541,0.3544) ## [1] 1.037036 Per tant \\(P(X\\leqslant 1.037)=0.95\\). D’aquí deduïm que \\(P(Y\\leqslant e^{1.037})=0.95\\). Com que \\(e^{1.037}=2.82\\), concloem que 2.82 cc de digitalina són suficients per matar el 95% dels ratolins. Ho podem comprovar (amb R, no escabetxant ratolins, malpensats!): plnorm(2.82,0.4541,0.3544) ## [1] 0.9499129 2.6 Test de la lliçó 2 (1) Sigui \\(X\\) una variable aleatòria de mitjana \\(\\mu\\) i desviació típica \\(\\sigma\\). Quina o quines de les afirmacions següents són sempre vertaderes? \\(E(X+2)=\\mu+2\\). \\(\\sigma(X+2)=\\sigma+2\\). \\(\\sigma(-X)=-\\sigma\\). \\(\\sigma(-X)=\\sigma\\). \\(\\sigma(X/2)=\\sigma/2\\). Cap de les altres afirmacions és vertadera. (2) La funció de distribució \\(F_X(x)\\) d’una variable aleatòria \\(X\\) ens dóna: La probabilitat d’obtenir el valor \\(x\\). La probabilitat d’obtenir un valor entre \\(-x\\) i \\(x\\), tots dos extrems inclosos. La probabilitat d’obtenir un valor entre 0 i \\(x\\), tots dos extrems inclosos. La probabilitat d’obtenir un valor més petit o igual que \\(x\\). La probabilitat d’obtenir un valor estrictament més petit que \\(x\\). (3) Quina o quines de les variables següents tenen distribució binomial? El pes d’una persona triada a l’atzar. Triam un nombre de llançaments a l’atzar, llançam aquest nombre de vegades una moneda, i comptam el nombre de cares. El nombre de glòbuls vermells en 1 mm3 de sang. La proporció d’hipertensos en una mostra aleatòria de 50 individus. Triam 10 estudiants diferents en una classe de 20, i comptam quantes dones han sortit. Triam un grup d’estudiants en una classe de 100, permetent repeticions, i comptam quantes dones han sortit. Cap d’elles. (4) Quina o quines de les variables següents tenen una distribució de Poisson? El pes d’una persona triada a l’atzar. El nombre de casos diaris de COVID-19 a Mallorca. El nombre de glòbuls vermells en 1 mm3 de sang. La proporció d’hipertensos en una mostra aleatòria de 50 individus. Triam 10 estudiants diferents en una classe de 20, i comptam quantes dones han sortit. Cap d’elles. (5) El nombre anual d’accidents laborals d’un tipus concret segueix una distribució de Poisson. Al llarg del temps s’ha observat que el 55% dels anys no es produeix cap accident d’aquests. Quin valor estimes que té el paràmetre \\(\\lambda\\) d’aquesta distribució de Poisson? 0.55 \\(e^{-0.55}\\) \\(\\ln(0.55)\\) \\(-\\ln(0.55)\\) Un valor que no és cap dels proposats en les altres respostes. (6) Sigui \\(X\\) una variable aleatòria contínua de funció de densitat: \\[ f_X(x)=\\left\\{\\begin{array}{ll} 0 &amp; \\mbox{si $x&lt;0$}\\\\ \\frac{2\\sqrt{2}}{\\sqrt{\\pi}} e^{-2x^2} &amp; \\mbox{si $x\\geqslant 0$} \\end{array} \\right. \\] És cert que \\(P(X=1)=2\\sqrt{2}e^{-2}/\\sqrt{\\pi}\\)? Sí No: en realitat \\(P(X=1)=\\int_{-\\infty}^1 \\frac{2\\sqrt{2}}{\\sqrt{\\pi}} e^{-2x^2}\\,dx\\) però no sé calcular aquesta integral, o sí que sé calcular-la, però em fa mandra fer-ho. Això no és la funció de densitat d’una variable aleatòria contínua, perquè no és una funció contínua (en el 0 bota de 0 a \\(2\\sqrt{2}/\\sqrt{\\pi}\\)) Totes les altres respostes són incorrectes (7) Sigui \\(X\\) una variable aleatòria contínua de mitjana \\(\\mu\\). Què val \\(P(X=\\mu)\\)? 0.5 \\(\\mu\\) 0 Depèn de la variable aleatòria Totes les altres respostes són falses (8) Sigui \\(X\\) una variable aleatòria contínua de moda \\(M\\). Què val \\(P(X=M)\\)? 1 0.5 0 Depèn de la variable aleatòria, però és més gran que tots els altres valors de \\(P(X=x)\\) Depèn de la variable aleatòria, però és el valor màxim de la funció de densitat de \\(X\\). Totes les altres respostes són falses (9) Sigui \\(Z\\) una variable aleatòria normal estàndard. Marca les afirmacions vertaderes. És asimètrica a l’esquerra. La seva mitjana és 1. La seva desviació típica és 0. La seva variància és 1. La seva mediana és 0. (10) Sigui \\(X\\) una variable aleatòria \\(N(\\mu,\\sigma)\\) i \\(f_X\\) la seva funció de densitat. Què val l’àrea entre la corba \\(y=f_X(x)\\) i l’eix d’abscisses? 0 \\(\\mu\\) \\(\\sigma\\) En general, no és ni \\(\\mu\\) ni \\(\\sigma\\), però sí que depèn de \\(\\mu\\) i \\(\\sigma\\) Totes les altres respostes són falses (11) Siguin \\(X\\) una variable aleatòria \\(N(\\mu,\\sigma)\\). Quina de les afirmacions següents és vertadera? \\(\\mu\\) és la mitjana de \\(X\\), però no la seva mediana \\(\\mu\\) és la mitjana i la mediana de \\(X\\), però no la seva moda \\(\\mu\\) és la mitjana, la mediana i la moda de \\(X\\), però no és veritat que \\(P(X=\\mu)&gt;P(X=a)\\) per a tot \\(a\\neq \\mu\\) \\(\\mu\\) és la mitjana, la mediana i la moda de \\(X\\) i \\(P(X=\\mu)&gt;P(X=a)\\) per a tot \\(a\\neq \\mu\\) Totes les altres respostes són falses (12) El FME (Flux Màxim d’Expiració) de les al·lotes d’11 anys segueix una distribució aproximadament normal de mitjana 300 l/min i desviació típica 20 l/min. Marca les afirmacions vertaderes: Aproximadament la meitat de les al·lotes d’11 anys tenen el FME entre 280 l/min i 320 l/min. Al voltant del 95% de les al·lotes d’11 anys tenen el FME entre 280 l/min i 320 l/min. Al voltant del 95% de les al·lotes d’11 anys tenen el FME entre 260 l/min i 340 l/min. Al voltant del 5% de les al·lotes d’11 anys tenen el FME inferior a 260 l/min. Cap al·lota d’11 anys té el FME superior a 360 l/min. (13) Se sap que una variable bioquímica té mitjana 90 i desviació típica 10. Si prenem una mostra d’individus sans, és raonable esperar que aproximadament el 95% d’ells tenguin un valor d’aquesta variable comprès entre 70 i 110? (marca totes les respostes correctes): Sí, sempre. No, mai. Si la variable té distribució normal, sí. Si la mostra és prou gran, sí. Si la variable té distribució normal i la mostra és prou gran, sí. (14) En una variable aleatòria contínua, la seva funció de densitat (marca una sola resposta): És sempre contínua Mesura com és de dens el seu domini. Aplicada a un nombre real, ens dóna la probabilitat d’obtenir-lo. Aplicada a un nombre real, ens dóna la probabilitat d’obtenir un valor menor o igual que ell. Totes les altres respostes són falses (15) Sigui \\(X\\) una variable aleatòria contínua de desviació típica \\(\\sigma\\). Què val la variància de la variable aleatòria \\(-X/2\\)? \\(\\sigma(-X/2)^2=-\\sigma^2/2\\). \\(\\sigma(-X/2)^2=\\sigma^2/2\\). \\(\\sigma(-X/2)^2=-\\sigma^2/4\\). \\(\\sigma(-X/2)^2=\\sigma^2/4\\). Totes les altres respostes són falses (16) El temps que tarda a produir-se una determinada reacció bioquímica es distribueix segons una variable normal de mitjana 17 segons i desviació típica 3 segons. Sense fer cap càlcul, què podem deduir d’aquesta afirmació? Marca totes les respostes correctes: Tots aquests temps se situen entre 8 i 26 segons. Gairebé tots aquests temps se situen entre 11 i 23 segons. És estrictament més probable que una reacció d’aquestes tardi entre 16 i 18 segons que tardi entre 18 i 20 segons. És estrictament més probable que una reacció d’aquestes tardi entre 18 i 20 segons que tardi entre 16 i 18 segons. És estrictament més probable que una reacció d’aquestes tardi entre 18 i 20 segons que tardi entre 14 i 16 segons. Cap de les afirmacions anteriors és correcta. (17) El temps que tarda a produir-se una determinada reacció bioquímica es distribueix segons una variable normal de mitjana 17 segons i desviació típica 3 segons. Quina és la probabilitat que tardi manco de 17 segons? 0 0.5 1 17/3 Cap de les afirmacions anteriors és correcta. (18) El temps que tarda a produir-se una determinada reacció bioquímica es distribueix segons una variable normal de mitjana 17 segons i desviació típica 3 segons. Quina o quines de les afirmacions següents són vertaderes? Si poguéssim mesurar els temps amb precisió infinita, observaríem que el temps que tarda més sovint és exactament 17 segons. Arrodonint a segons, el temps que tarda més sovint és 17 segons. En un 95% de les ocasions tarda aproximadament entre 14 i 20 segons. Tarda més de 20 segons amb la mateixa freqüència amb la qual tarda manco de 14 segons. Tarda més de 20 segons amb la mateixa freqüència amb la qual tarda manco de 20 segons. En un 95% de les ocasions tarda 23 segons o manco. (19) Quina de les tres afirmacions és vertadera per a les tres distribucions normals de la figura inferior? (\\(\\sigma_1\\), \\(\\sigma_2\\) i \\(\\sigma_3\\) indiquen les desviacions típiques de les corbes 1, 2 i 3, respectivament). \\(\\sigma_1&gt; \\sigma_2&gt; \\sigma_3\\) \\(\\sigma_1&lt; \\sigma_2&lt; \\sigma_3\\) \\(\\sigma_1= \\sigma_2= \\sigma_3\\) Del gràfic no es pot deduir la relació entre les tres desviacions típiques Cap de les altres afirmacions és veritable. (20) El pes mitjà d’una bossa de patates d’una determinada marca és de 150 grams amb una desviació típica de 5.6 grams. Quin és el z-score d’una bossa que pesa 147 grams (arrodonit a 2 xifres decimals)? -0.54 0.30 0.54 0.70 Cap de les respostes anteriors és correcta (21) Si una variable aleatòria normal té mitjana 18.1 i desviació típica 1.2, què val el seu 3er quartil (arrodonit a una xifra decimal)? (Empra R o una apli per calcular-lo) 18.1 18.9 19.3 20.5 Cap de les respostes anteriors és correcta (23) L’interval de referència (del 95%) de la concentració de creatinina en sèrum de les persones és 0.66-1.09 mg/dl. Què en podem deduir? (Marca només una resposta.) Que la probabilitat que la concentració mitjana de creatinina en sèrum d’una persona estigui entre 0.66 i 1.09 mg/dl és del 95%. Que si prenem una mostra aleatòria de persones i calculam la mitjana de les seves concentracions de creatinina, en un 95% de les ocasions aquesta mitjana estarà entre 0.66 i 1.09 mg/dl. Que un 5% de les persones tenen una concentració de creatinina en sèrum superior a 1.09 mg/dl. Que un 95% de les persones tenen una concentració de creatinina en sèrum entre 0.66 i 1.09 mg/dl. Que si prenem una mostra aleatòria de persones, en un 95% de les ocasions tots els valors estaran entre 0.66 i 1.09 mg/dl. Cap de les altres respostes és correcta. (24) Quin és l’efecte sobre la mitjana, la desviació típica i la mediana d’una variable aleatòria si sumam 1 al seu valor sobre tots els individus de la població? Cap d’aquests paràmetres varia. La mitjana i la mediana canvien, la desviació típica no. La mitjana varia, la resta no. La mitjana no varia, la resta sí. Tots tres paràmetres varien. Cap de les altres respostes és correcta. (25) Sigui \\(X\\) una variable aleatòria normal amb \\(\\mu=0\\) i \\(\\sigma\\) desconeguda. ¿Quina de les afirmacions següents segur que és FALSA? \\(P(X\\leqslant 0)=0.5\\) \\(P(X&lt; 0)=0.5\\) \\(P(X\\leq -1)=0.2\\) \\(P(X\\leq 1)=0.2\\) \\(P(X\\leq 1)=0.8\\) (26) Siguin \\(X\\) i \\(Y\\) dues variables aleatòries discretes. Quina o quines de les afirmacions següents són sempre vertaderes? Sempre és cert que \\(E(2X+3Y)=2E(X)+3E(Y)\\) No sempre és cert que \\(E(2X+3Y)=2E(X)+3E(Y)\\), però sí que és cert si \\(X\\) i \\(Y\\) són independents Sempre és cert que \\(\\sigma(2X+3Y)^2=2\\sigma(X)^2+3\\sigma(Y)^2\\) No sempre és cert que \\(\\sigma(2X+3Y)^2=2\\sigma(X)^2+3\\sigma(Y)^2\\), però sí que és cert si \\(X\\) i \\(Y\\) són independents Sempre és cert que \\(\\sigma(2X+3Y)^2=4\\sigma(X)^2+9\\sigma(Y)^2\\) No sempre és cert que \\(\\sigma(2X+3Y)^2=4\\sigma(X)^2+9\\sigma(Y)^2\\), però sí que és cert si \\(X\\) i \\(Y\\) són independents Sempre és cert que \\(\\sigma(2X+3Y)=2\\sigma(X)+3\\sigma(Y)\\) No sempre és cert que \\(\\sigma(2X+3Y)=2\\sigma(X)+3\\sigma(Y)\\), però sí que és cert si \\(X\\) i \\(Y\\) són independents Cap de les altres afirmacions és vertadera. (27) Teniu una població amb una proporció \\(0&lt;p&lt;1\\) d’individus que tenen una certa malaltia. Preneu mostres aleatòries de mida \\(n\\) de la població i hi comptau quants individus tenen aquesta malaltia. Quina o quines de les afirmacions següents són vertaderes? Si preneu les mostres sense permetre individus repetits, els resultats surten més variats que si les preneu permetent repeticions. Si preneu les mostres sense permetre individus repetits, els resultats surten manco variats que si les preneu permetent repeticions. Si preneu les mostres permetent que hi surtin individus repetits, com més grans preneu les mostres més variats surten els resultats. Si preneu les mostres permetent que hi surtin individus repetits, com més grans preneu les mostres manco variats surten els resultats. Si preneu les mostres sense permetre individus repetits, com més grans preneu les mostres més variats surten els resultats. Si preneu les mostres sense permetre individus repetits, com més grans preneu les mostres manco variats surten els resultats. Cap de les altres afirmacions és vertadera. "],
["chap-estim.html", "Tema 3 Estimació puntual 3.1 Estimadors 3.2 Mitjana mostral 3.3 Proporció mostral 3.4 Variància mostral 3.5 La distribució t de Student 3.6 Biaix i precisió 3.7 Estimadors màxim versemblants 3.8 Estimació de poblacions 3.9 Test de la lliçó 3", " Tema 3 Estimació puntual L’objectiu principal de la inferència estadística és obtenir informació sobre tota una població a partir de només una mostra, com quan volem saber si un brou és fat o salat tastant-ne només una cullerada. El primer tipus d’informació que ens sol interessar és què val qualque paràmetre d’alguna variable aleatòria poblacional (una proporció, una mitjana…), per exemple per poder escriure un titular com el següent: Figura 3.1: https://www.efesalud.com/miopia-estudio-universitarios Aquest 60% no s’ha obtingut fent passar a tots els universitaris espanyols un test de miopia, ni tan sols demanant-los a tots si són miops o no, sinó que simplement s’ha pres una mostra d’universitaris, s’hi ha observat un 60% de miops i s’ha extrapolat aquesta proporció a tot el col·lectiu d’universitaris espanyols. El procés d’intentar endevinar el valor d’un paràmetre d’una població a partir d’una mostra se’n diu estimació puntual, i és el que tractarem en aquest tema. En aquest curs, sempre suposarem que empram mostres aleatòries i gairebé sempre que aquestes mostres aleatòries són a més simples. Per tant, si no diem el contrari, d’ara endavant quan parlem de mostres sempre suposarem que són mostres aleatòries simples, encara que no ho diguem explícitament per no carregar massa el text. 3.1 Estimadors Per estimar el valor d’un paràmetre d’una variable aleatòria poblacional, en prenem una mostra (aleatòria simple) i calculam qualque cosa amb els valors que la formen. Què calculam? Doncs un estimador: alguna funció adequada aplicada als valors de la mostra, i que dependrà del que volguem estimar. Per exemple: Si volem estimar l’alçada mitjana dels estudiants de la UIB, prendrem una mostra d’estudiants de la UIB, els amidarem i calcularem la mitjana aritmètica de les seves alçades. Si volem estimar la proporció d’estudiants de la UIB que han passat la COVID-19, prendrem una mostra d’estudiants de la UIB, els farem un test d’anticossos i calcularem la proporció mostral de positius en la mostra. Formalment: Tenim una variable aleatòria poblacional \\(X\\), definida sobre una població. Una mostra aleatòria simple de mida \\(n\\) de \\(X\\) és un vector \\((X_1,\\ldots,X_n)\\) format per \\(n\\) còpies independents de \\(X\\). Cada variable \\(X_i\\) és una còpia de “Prenem un subjecte de la població i hi mesuram \\(X\\)”. Una realització de la mostra aleatòria simple \\((X_1,\\ldots,X_n)\\) és un vector \\((x_1,\\ldots,x_n)\\in \\mathbb{R}^n\\) de valors presos per aquestes variables aleatòries. És a dir, amb \\((X_1,\\ldots,X_n)\\) repetim \\(n\\) vegades (independents les unes de les altres) el procés de prendre un subjecte de la població i mesurar-hi \\(X\\). Cada vegada que ho fem, obtenim un vector de números, al que diem una realització de la mostra. A la lliçó anterior a aquestes realitzacions les déiem directament “mostres aleatòries simples de valors de \\(X\\)”; no passeu ànsia, en sortir d’aquest “formalment” els ho tornarem a dir. Un estimador és una variable aleatòria \\(f(X_1,\\ldots,X_n)\\) obtinguda aplicant una funció \\(f\\) a una mostra aleatòria simple \\((X_1,\\ldots,X_n)\\). Aquest estimador s’aplica a les realitzacions de la mostra i dóna nombres reals. Un estimador és una variable aleatòria, definida sobre la població formada per les mostres aleatòries simples de la població de partida. Per tant, té funció de densitat, funció de distribució (que genèricament anomenarem distribució mostral, per indicar que refereix a la probabilitat que li passi qualque cosa al valor del estimador sobre una mostra), esperança, desviació típica, etc. Com ja us hem dit, i com que no hi ha necessitat de filar tan prim, d’ara endavant cometrem l’abús de llenguatge de dir mostra (aleatòria simple) de \\(X\\) tant al vector de variables aleatòries \\((X_1,\\ldots,X_n)\\) com a una realització \\((x_1,\\ldots,x_n)\\) i hi ometrem els parèntesis. Com ja hem comentat a la Secció 1.5, si la mida \\(N\\) de la població és MOLT més gran que la mida \\(n\\) de la mostra (per fixar idees, hem dit que si \\(N\\geqslant 1000n\\)), els resultats per a mostres aleatòries simples valen (aproximadament) per a mostres aleatòries sense reposició, perquè les variables aleatòries que formen la mostra sense reposició són gairebé idèntiques i independents i les repeticions són improbables. 3.2 Mitjana mostral Quan volem estimar el valor mitjà d’una variable sobre una població, en prenem una mostra de valors i calculam la seva mitjana aritmètica, no és ver? Doncs això és la mitjana mostral. Donada una variable aleatòria \\(X\\), la seva mitjana mostral (de mostres aleatòries simples) de mida \\(n\\) és la variable aleatòria \\(\\overline{X}\\) “Prenem una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calculam la mitjana aritmètica dels seus valors”. És a dir, formalment, la mitjana mostral de mida \\(n\\) de \\(X\\) és la variable aleatòria obtinguda prenent \\(n\\) còpies independents \\(X_1,\\ldots,X_n\\) de la variable aleatòria \\(X\\) i calculant \\[ \\overline{X}=\\frac{X_1+\\cdots+X_n}{n} \\] Fixau-vos que definim la mitjana mostral només per a mostres aleatòries simples. Naturalment, té sentit definir-la per a mostres qualssevol, però llavors la seva distribució mostral deixa de complir les propietats que donarem en aquesta secció. El mateix advertiment val per als estimadors que definim en les pròximes seccions. Com a conseqüència del comportament d’esperances i variàncies de combinacions lineals, tenim el resultat següent: Teorema 3.1 Siguin \\(X\\) una variable aleatòria d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\), i \\(\\overline{X}\\) la seva mitjana mostral (de mostres aleatòries simples) de mida \\(n\\). Aleshores El valor esperat de \\(\\overline{X}\\) és \\(E(\\overline{X})=\\mu_X\\). La desviació típica de \\(\\overline{X}\\) és \\(\\sigma(\\overline{X})={\\sigma_X}/{\\sqrt{n}}\\). En efecte, com que \\[ \\overline{X}=\\frac{1}{n}X_1+\\cdots +\\frac{1}{n}X_n \\] i les variables \\(X_1,\\ldots,X_n\\) són còpies de \\(X\\), i per tant tenen totes esperança \\(\\mu_X\\) i variància \\(\\sigma^2_X\\), tenim que \\[ \\mu_{\\overline{X}}=\\overbrace{\\frac{1}{n}\\mu_X+\\cdots +\\frac{1}{n}\\mu_X}^n=\\mu_X \\] i, si \\(X_1,\\ldots,X_n\\) són independents, \\[ \\sigma_{\\overline{X}}=\\sqrt{\\overbrace{\\frac{1}{n^2}\\sigma^2_X+\\cdots+ \\frac{1}{n^2}\\sigma^2_X}^n}=\\sqrt{\\frac{n}{n^2}\\sigma^2_X}=\\frac{\\sigma_X}{\\sqrt{n}} \\] Si us hi fixau, per demostrar que \\(E(\\overline{X})=\\mu_X\\) no hem fet servir que \\(X_1,\\ldots,X_n\\) siguin independents. De fet, la igualtat \\(E(\\overline{X})=\\mu_X\\) també és vertadera per a mitjanes mostrals de mostres aleatòries sense reposició. En canvi, la igualtat \\(\\sigma_{\\overline{X}}={\\sigma_X}/{\\sqrt{n}}\\) sí que requereix que les mostres aleatòries siguin simples. Per tant: \\(\\overline{X}\\) és un estimador puntual de \\(\\mu_X\\). \\(E(\\overline{X})=\\mu_X\\), la qual cosa significa que: La mitjana de les mitjanes mostrals de totes les mostres aleatòries de mida \\(n\\) de \\(X\\) és igual a la mitjana \\(\\mu_X\\) de \\(X\\). Esperam que la mitjana mostral doni \\(\\mu_X\\): si repetíssim moltes vegades el procés de prendre una mostra aleatòria de mida \\(n\\) i calcular-ne la mitjana mostral, molt probablement el valor mitjà d’aquestes mitjanes s’acostaria molt a \\(\\mu_X\\). \\(\\sigma(\\overline{X})= \\sigma_X/\\sqrt{n}\\) indica que la dispersió de les mitjanes mostrals creix amb la dispersió de \\(X\\) i decreix amb la mida \\(n\\) de la mostra, tendint a 0 quan \\(n\\to\\infty\\). L’efecte de la mida de les mostres sobre la variabilitat de \\(\\overline{X}\\) és raonable. Quan prenem mostres aleatòries grans d’una variable i en calculam la mitjana, el més normal és que dins cada mostra els valors més petits se compensin amb els més grans, i que com a conseqüència les mitjanes siguin més homogènies que els valors de la variable. Vaja: si triam una persona a l’atzar, no és molt improbable que faci, jo què sé, 2.10 m. Però si prenem una mostra aleatòria de 50 persones, és molt més difícil que la mitjana de les seves alçades sigui 2.10 m. El que hi esperaríem és que les alçades dels més alts s’hi compensin amb les alçades dels més baixos i tot plegat doni una mitjana més… “mitjana”. A la desviació típica de \\(\\overline{X}\\) li diem l’error estàndard, o típic, de \\(\\overline{X}\\). Per tant, l’error estàndard de la mitjana mostral de mida \\(n\\) de \\(X\\) és \\(\\sigma_X/\\sqrt{n}\\). Exemple 3.1 El fitxer tests.txt que trobareu a l’url https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt conté les notes (sobre 100) de tests dels estudiants de Matemàtiques I de fa uns cursos. El guardam en un vector anomenat tests: tests=scan(&quot;https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt&quot;) Considerarem la població dels estudiants de Matemàtiques I d’aquell curs i com a variable aleatòria d’interès \\(X\\) la seva nota de tests sobre 100. Per tant, aquest vector tests conté els valors de la variable aleatòria d’interès sobre tots els individus de la població. La seva mida és N=length(tests) N ## [1] 185 La seva mitjana, que és la mitjana poblacional \\(\\mu_X\\), és mu=mean(tests) mu ## [1] 55.43243 Si en prenem una mostra aleatòria simple, per exemple de mida \\(n=40\\), la seva mitjana mostral no té per què coincidir amb la mitjana poblacional: n=40 MAS=sample(tests,n,replace=TRUE) # Una mostra aleatòria simple x.barra=mean(MAS) # La seva mitjana mostral x.barra ## [1] 53.5 Però si prenem moltes mostres aleatòries simples, la mitjana de les seves mitjanes és molt probable que sí que s’acosti a la mitjana poblacional. Vegem si tenim sort amb cent mil mostres: mitjanes=replicate(10^5,mean(sample(tests,n,replace=TRUE))) mean(mitjanes) ## [1] 55.4187 Vegem ara que la desviació típica d’aquesta mostra de mitjanes s’acosta a l’error típic de la mitjana mostral, no a la desviació típica de la població: La desviació típica poblacional: sigma=sd(tests)*sqrt((N-1)/N) sigma ## [1] 21.38241 La desviació típica de la mostra de mitjanes: sd(mitjanes) ## [1] 3.384683 L’error típic de la mitjana mostral: sigma/sqrt(n) ## [1] 3.380856 Veiem que les mitjanes mostrals presenten una dispersió molt més petita que la variable poblacional original. Gràficament, als histogrames de les Figures 3.2 i 3.3 hi podeu veure com les mitjanes estan més concentrades al voltant de 55 que les notes originals. Recordau del Teorema 2.6 que una combinació lineal de variables aleatòries normals independents torna a ser normal. Com que la mitjana mostral de mostres aleatòries simples és una combinació lineal de variables aleatòries independents, obtenim el resultat següent: Teorema 3.2 Si \\(X\\) és una variable aleatòria normal \\(N(\\mu_X,\\sigma_X)\\), la seva mitjana mostral \\(\\overline{X}\\) de mostres aleatòries simples de mida \\(n\\) és normal \\[ N\\Big(\\mu_X,\\frac{\\sigma_X}{\\sqrt{n}}\\Big). \\] El teorema següent diu que la conclusió del teorema anterior és aproximadament vertadera si la mida \\(n\\) de les mostres aleatòries simples és gran: Teorema 3.3 (Teorema Central del Límit) Siguin \\(X\\) una variable aleatòria qualsevol d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\). Quan \\(n\\to \\infty\\), la funció de distribució de la seva mitjana mostral \\(\\overline{X}\\) de mostres aleatòries simples de mida \\(n\\) tendeix a la d’una variable normal \\[ N\\Big(\\mu_X,\\frac{\\sigma_X}{\\sqrt{n}}\\Big). \\] Com us podeu imaginar, quan un resultat l’anomenen Teorema Central de qualque cosa és perquè és molt important. Normalment aplicarem el Teorema Central del Límit de la manera següent: Siguin \\(X\\) una variable aleatòria qualsevol d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\). Si la mida \\(n\\) de les mostres (aleatòries simples) és gran, la mitjana mostral \\(\\overline{X}\\) és aproximadament normal \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\). Per fixar una fita, en aquest curs entendrem que \\(n\\) és prou gran com per poder aplicar aquest “resultat” quan és més gran o igual que 40, potser menys com més se sembli \\(X\\) a una normal i potser més si la \\(X\\) és molt diferent d’una normal. A partir d’ara, sovint cometrem l’abús de llenguatge d’ometre l’adverbi “aproximadament” de l’expressió anterior, i direm simplement que si \\(n\\) és gran, \\(\\overline{X}\\) és normal. Però heu de tenir present que aquest “és normal” en realitat vol dir “la seva distribució és aproximadament la d’una variable normal”. Exemple 3.2 Suposem que tenim una variable aleatòria \\(X\\) de mitjana poblacional \\(\\mu_X=3\\) i desviació típica poblacional \\(\\sigma_X=0.2\\) i que en prenem mostres aleatòries simples de mida 100. Pel Teorema Central del Límit, la distribució de la mitjana mostral \\(\\overline{X}\\) és (aproximadament) \\[ N\\Big(3,\\frac{0.2}{\\sqrt{100}}\\Big)=N(3,0.02) \\] Exemple 3.3 Tornem a la situació de l’Exemple 3.1. Teníem les notes guardades en un vector anomenat tests. Amb l’histograma següent podem veure que aquestes notes no tenen pinta de seguir una distribució normal. fact.trans=hist(tests,plot=FALSE)$counts[1]/hist(tests,plot=FALSE)$density[1] hist(tests,col=&quot;light blue&quot;,xlab=&quot;Notes dels tests&quot;, ylab=&quot;Freqüències&quot;,main=&quot;&quot;) curve(fact.trans*dnorm(x,mean(tests),sd(tests)),col=&quot;red&quot;,lwd=2,add=TRUE) Figura 3.2: Histograma de les notes de tests A l’Exemple 3.1 també hem construït un vector anomenat mitjanes format per 105 mitjanes mostrals de mostres aleatòries simples de notes de mida 40. Pel Teorema Central del Límit, aquestes mitjanes mostrals haurien de seguir aproximadament una distribució normal, malgrat que la “població original” (les notes dels tests) no sigui normal. Vegem-ho amb un histograma, on hem afegit la densitat de la normal \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\) predita pel Teorema Central del Límit. fact.trans.m=hist(mitjanes,plot=FALSE)$counts[1]/hist(mitjanes,plot=FALSE)$density[1] hist(mitjanes,col=&quot;light blue&quot;,xlab=&quot;Mitjanes&quot;, ylab=&quot;Freqüències&quot;,main=&quot;&quot;) curve(fact.trans.m*dnorm(x,mu,sigma/sqrt(n)),col=&quot;red&quot;,lwd=2,add=TRUE) Figura 3.3: Histograma de les mitjanes de mostres de notes de tests L’exemple següent és un tipus de pregunta que més endavant ens preocuparà molt. Exemple 3.4 L’alçada d’una espècie de matolls té valor mitjà 115 cm, amb una desviació típica de 25 cm. Si prenem una mostra aleatòria simple de 100 matolls d’aquesta espècie, quina és la probabilitat que la mitjana mostral de les alçades sigui més petita que 110 cm? Diguem \\(X\\) a la variable aleatòria definida per les alçades d’aquests matolls. Pel Teorema Central del Límit, podem suposar que la mitjana mostral \\(\\overline{X}\\) de mostres aleatòries simples de 100 alçades segueix una distribució \\(N(115,25/\\sqrt{100})=N(115,2.5)\\). Llavors, la probabilitat que ens demanen és \\[ P(\\overline{X}&lt; 110) \\] que podem calcular amb round(pnorm(110,115,2.5),4) ## [1] 0.0228 Un 2.28% de les mostra aleatòries simples de 100 matolls d’aquesta espècie tenen la mitjana de les alçades més petita que 110 cm. 3.3 Proporció mostral Quan volem estimar la proporció d’individus d’una població que tenen una determinada característica, en prenem una mostra i hi calculam la proporció de membres amb aquesta característica. Aquesta serà la proporció mostral de subjectes amb aquesta característica en la nostra mostra. Sigui \\(X\\) una variable aleatòria poblacional de Bernoulli amb probabilitat d’èxit \\(p_X\\). És a dir, \\(X\\) pren els valors 1 (èxit) o 0 (fracàs) i \\(p_X\\) és la proporció de subjectes de la població en els quals val 1. Recordau que \\(E(X)=p_X\\) i \\(\\sigma_X=\\sqrt{p_X(1-p_X)}\\). La proporció mostral (de mostres aleatòries simples) de mida \\(n\\) de \\(X\\), \\(\\widehat{p}_X\\), és la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calcular-ne la proporció d’èxits: és a dir, comptar-hi el nombre total d’èxits i dividir el resultat per \\(n\\). Formalment, sigui \\(X_1,\\ldots,X_n\\) una mostra aleatòria simple de mida \\(n\\) de \\(X\\). Sigui \\(S_n=\\sum_{i=1}^n X_i\\), que és la variable aleatòria que compta el nombre d’èxits en una mostra aleatòria simple de mida \\(n\\). Aleshores, la proporció mostral de mida \\(n\\) de \\(X\\) és \\[ \\widehat{p}_X=\\frac{S_n}{n}=\\frac{X_1+\\cdots+X_n}{n}. \\] Recordau que si prenem mostres aleatòries simples, \\(S_n\\) és una variable aleatòria binomial \\(B(n,p_X)\\). Però no digueu que la proporció mostral \\(\\widehat{p}_X\\) és una variable aleatòria binomial, ni que només sigui perquè les variables aleatòries binomials prenen valors nombres naturals i els valors que pot prendre \\(\\widehat{p}_X\\) són fraccions entre 0 i 1. Fixau-vos que \\(\\widehat{p}_X\\) és un cas particular de la mitjana mostral \\(\\overline{X}\\), per tant per a les proporcions mostrals val tot el que hem dit per a mitjanes mostrals: Teorema 3.4 Sigui \\(X\\) una variable aleatòria de Bernoulli amb probabilitat d’èxit \\(p_X\\). Aleshores, la proporció mostral de mostres aleatòries simples de mida \\(n\\) de \\(X\\), \\(\\widehat{p}_X\\), satisfà que: \\(E(\\widehat{p}_X)=p_X\\) \\(\\sigma(\\widehat{p}_X)=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) Pel Teorema Central del Límit, si la mida \\(n\\) de la mostra és gran, la distribució de \\(\\widehat{p}_X\\) és aproximadament la d’una variable normal \\[ N\\left({p}_X,\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}\\right) \\] i per tant \\[ \\frac{\\widehat{p}_X-p_X}{\\sqrt{{p}_X(1-{p}_X)/n}} \\] és aproximadament \\(N(0,1)\\). Els valors de l’esperança i la desviació típica de \\(\\widehat{p}_X\\) es poden deduir dels de \\(S_n\\) sense necessitat d’invocar els de la mitjana mostral. Com que \\(S_n\\) és \\(B(n,p_X)\\), sabem que \\(E(S_n)=np_X\\) i \\(\\sigma(S_n)^2=np_X(1-p_X)\\) i per tant \\[ \\begin{array}{l} \\displaystyle E(\\widehat{p}_X)=E\\Big(\\frac{S_n}{n}\\Big)=\\frac{E(S_n)}{n}=\\frac{np_X}{n}=p_X\\\\ \\displaystyle \\sigma(\\widehat{p}_X)=\\sigma\\Big(\\frac{S_n}{n}\\Big)=\\frac{\\sigma(S_n)}{n}=\\frac{\\sqrt{np_X(1-p_X)}}{n}=\\sqrt{\\frac{p_X(1-p_X)}{n}} \\end{array} \\] Alguns comentaris: \\(E(\\widehat{p}_X)=p_X\\): Esperam que la proporció mostral sigui igual a la proporció poblacional d’èxits (si hi ha, diguem, un 20% d’èxits a la població, quin percentatge d’èxits “esperau” trobar a la mostra? Un 20%, no?). És a dir, si repetíssim moltes vegades el procés de prendre una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria de Bernoulli \\(X\\) i calcular-ne la proporció mostral d’èxits, molt probablement la mitjana d’aquestes proporcions mostrals s’acostaria molt a \\(p_X\\). En particular, \\(\\widehat{p}_X\\) és un estimador de \\(p_X\\), naturalment. \\(\\sigma(\\widehat{p}_X)= \\sqrt{{p_X(1-p_X)}/{n}}\\): la variabilitat dels resultats de \\(\\widehat{p}_X\\) decreix amb \\(n\\) i tendeix a 0 quan \\(n\\to \\infty\\). Pel que fa a la dependència de \\(\\sigma(\\widehat{p}_X)\\) respecte de \\(p_X\\) si la \\(n\\) és fixada, observau a la Figura 3.4 que \\(\\sqrt{p_X(1-p_X)}\\) creix entre 0 i 0.5 i decreix entre 0.5 i 1, assolint el valor màxim a \\(p_X=0.5\\). Figura 3.4: Gràfica de \\(\\sqrt{p(1-p)}\\) \\(\\sqrt{{p_X(1-p_X)}/{n}}\\) és l’error estándard, o típic, de \\(\\widehat{p}_X\\). L’estimam amb l’error estándard, o típic, de la mostra \\(\\sqrt{{\\widehat{p}_X(1-\\widehat{p}_X)}/{n}}\\). Sovint cometrem l’abús de llenguatge d’ometre l’adverbi “aproximadament” de l’apartat (3) del teorema anterior, i direm simplement que si \\(n\\) és gran, \\(\\widehat{p}_X\\) és normal. Però, repetim, hem de recordar que aquest “és normal” en realitat vol dir “la seva distribució és aproximadament la d’una variable normal”. Exemple 3.5 Tornem una altra vegada a la situació dels Exemples 3.1 i 3.3. Traduïm el fitxer de notes de tests en un vector binari: 0 per suspens (haver tret menys de 50) i 1 per aprovat (haver tret 50 o més): # Iniciam totes les notes a 1 aprovs=rep(1,length(tests)) # Posam 0 on la nota del test és suspesa aprovs[which(tests&lt;50)]=0 Aquest vector aprovs el podem entendre com els valors sobre la nostra població d’estudiants de la variable poblacional de Bernoulli \\(Y\\) que ens diu si un estudiant aprovà o suspengué els tests. La seva probabilitat poblacional d’èxit (aprovat) \\(p_Y\\) serà la proporció d’estudiants aprovats: p_Y=sum(aprovs)/N round(p_Y,4) ## [1] 0.5946 Ara n’extreurem 105 mostres aleatòries simples de mida \\(n=40\\), en calcularem les proporcions mostrals d’aprovats i comprovarem si es confirmen les conclusions del teorema anterior. n=40 props.mostrals=replicate(10^5,mean(sample(aprovs,n,rep=TRUE))) La mitjana d’aquest vector de proporcions hauria de ser propera a la proporció poblacional d’aprovats \\(p_Y=0.5946\\). round(mean(props.mostrals),4) ## [1] 0.5954 Vegem ara la seva desviació típica: round(sd(props.mostrals),4) ## [1] 0.0775 Pel Teorema 3.4, sabem que això hauria de ser proper a \\(\\sqrt{p_Y(1-p_Y)/n}\\) round(sqrt(p_Y*(1-p_Y)/n),4) ## [1] 0.0776 I pel Teorema Central del Límit, aquestes proporcions mostrals haurien de seguir aproximadament una distribució normal \\(N(p_Y,\\sqrt{p_Y(1-p_Y)/n})\\). Vegem-ho amb un histograma: fact.trans.p=hist(props.mostrals,plot=FALSE)$counts[1]/hist(props.mostrals,plot=FALSE)$density[1] hist(props.mostrals,col=&quot;light blue&quot;,xlab=&quot;Proporcions mostrals&quot;, ylab=&quot;Freqüències&quot;,main=&quot;Histograma de la mostra de proporcions&quot;) curve(fact.trans.p*dnorm(x,p_Y,sqrt(p_Y*(1-p_Y)/n)), col=&quot;red&quot;,lwd=2,add=TRUE) I això que la mida de les mostres, 40, no és especialment gran. Exemple 3.6 Un 59.1% dels estudiants de la UIB són dones. Hem pres una mostra més o menys aleatòria de 60 estudiants de la UIB i hi hem trobat 40 dones, dos terços. Ens demanam si 40 de 60 és una quantitat raonable de dones en una mostra aleatòria simple d’estudiants de la UIB, o si són moltes (atès que hi esperaríem al voltant d’un 59% de dones). Aquesta pregunta, que serà molt típica d’aquí a pocs temes, la traduïm en la pregunta següent: Si prenem una mostra aleatòria simple de 60 estudiants, quina és la probabilitat que la proporció mostral de dones sigui més gran o igual que 2/3? La manera més correcta de respondre aquesta qüestió és emprar que el nombre \\(S_{60}\\) de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix de manera exacta una distribució binomial \\(B(60,0.591)\\). Com que el 2/3 de la pregunta en realitat representa 40 dones, la probabilitat demanada és exactament round(1-pbinom(39,60,0.591),4) ## [1] 0.1441 Recordau que si \\(X\\) és una variable aleatòria discreta que pren valors enters, com ara la binomial, \\(P(X\\geqslant 40)=1-P(X\\leqslant 39)\\). Això ens diu que un 14.41% de les mostres aleatòries simples de 60 estudiants de la UIB contenen almenys 40 dones. Naturalment, aquesta probabilitat només és “l’exacta” si la proporció poblacional “59.1%” és exacta. Una altra opció seria aprofitar el Teorema Central del Límit, segons el qual la proporció mostral \\(\\widehat{p}_X\\) de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix una distribució aproximadament normal amb \\(\\mu=0.591\\) i \\[ \\sigma=\\sqrt{\\dfrac{0.591(1-0.591)}{60}}=0.0635 \\] Per tant, la probabilitat que \\(\\widehat{p}_X\\geqslant 2/3\\) és (ara, aproximadament) round(1-pnorm(2/3,0.591,sqrt(0.591*(1-0.591)/60)),4) ## [1] 0.1166 L’aproximació seria més bona si haguéssim efectuat la correcció de continuïtat. Diguem \\(Y\\) a la normal \\(N(0.591,0.0635)\\). Com que \\(\\widehat{p}_X=S_{60}/60\\), seria millor aproximar \\[ P(S_{60}\\geqslant 40)=1-P(S_{60}\\leqslant 39) \\] per \\[ 1-P(Y\\leqslant 39.5/60) \\] round(1-pnorm(39.5/60,0.591,sqrt(0.591*(1-0.591)/60)),4) ## [1] 0.1444 En el cas de la proporció mostral, de vegades considerarem que s’han pres mostres aleatòries sense reposició. En aquest cas, la distribució del nombre d’èxits \\(S_n\\) en una mostra segueix una distribució hipergeomètrica. D’aquí deduïm, exactament igual que en el cas de mostres aleatòries simples, que seguim tenint que \\(E(\\widehat{p}_X)=p_X\\), però ara, si \\(N\\) és la mida de la població, \\[ \\sigma({\\widehat{p}_X})=\\sqrt{\\frac{p_X(1-p_X)}{n}}\\cdot \\sqrt{\\frac{\\vphantom{(p_X}N-n}{N-1}}. \\] Recordau que al factor \\[ \\sqrt{\\frac{N-n}{N-1}} \\] que transforma \\(\\sigma({\\widehat{p}_X})\\) per a mostres aleatòries simples en la desviació típica de \\({\\widehat{p}_X}\\) per a mostres aleatòries sense reposició li diem el factor de població finita, i és el que transformava la desviació típica d’una variable binomial (que compta èxits en mostres aleatòries simples) en la desviació típica d’una variable hipergeomètrica (que compta èxits en mostres aleatòries sense reposició). Però recordau que si la mida de la població \\(N\\) és molt gran comparat amb \\(n\\), podem suposar que una mostra aleatòria sense reposició és simple. Exemple 3.7 Tornem a la situació de l’Exemple 3.5. Què passa si prenem les mostres aleatòries de notes de tests sense reposició? Prenguem ara 105 mostres aleatòries sense reposició de 40 notes de tests. props.norep=replicate(10^5,mean(sample(aprovs,n))) Un altre cop, la mitjana d’aquest vector de proporcions mostrals hauria de ser propera a la proporció poblacional d’aprovats \\(p_Y=0.5946\\). round(mean(props.norep),4) ## [1] 0.5946 Calculem ara la desviació típica d’aquest vector: round(sd(props.norep),4) ## [1] 0.069 Pel que acabam d’explicar, la desviació típica d’aquest vector de proporcions mostrals de mostres sense reposició hauria de ser molt propera a \\[ \\sqrt{\\frac{p_Y(1-p_Y)}{n}}\\cdot\\sqrt{\\frac{\\vphantom{(p_Y}N-n}{N-1}} \\] on \\(N\\) és la mida de la població, és a dir, la longitud del vector aprovs, i \\(n\\) la mida de les mostres. Vegem si és veritat: round(sqrt(p_Y*(1-p_Y)/n)*sqrt((N-n)/(N-1)),4) ## [1] 0.0689 Però si prenem mostres aleatòries sense reposició i la població no és molt més gran que les mostres, ja no es pot aplicar el Teorema Central del Límit: encara que les mostres siguin grans, la proporció mostral no té per què ser aproximadament normal. 3.4 Variància mostral Donada una variable aleatòria \\(X\\): La seva variància mostral (de mostres aleatòries simples) de mida \\(n\\), \\(\\widetilde{S}_{X}^2\\), és la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calcular la variància mostral dels seus valors. La seva desviació típica mostral (de mostres aleatòries simples) de mida \\(n\\), \\(\\widetilde{S}_{X}\\), és la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calcular la desviació típica mostral dels seus valors. Formalment, sigui \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de mida \\(n\\geqslant 2\\) d’una variable aleatòria \\(X\\). Aleshores \\[ \\widetilde{S}_{X}^2=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n-1},\\quad \\widetilde{S}_{X}=+\\sqrt{\\widetilde{S}_{X}^2} \\] A més, de tant en tant també farem servir la variància i la desviació típica “a seques”: La variància (de mostres aleatòries simples) de mida \\(n\\) de \\(X\\), \\(S_{X}^2\\), és la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calcular la variància dels seus valors: \\[ S^2_{X}=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n}=\\frac{(n-1)}{n}\\widetilde{S}^2_{X} \\] La desviació típica (de mostres aleatòries simples) de mida \\(n\\) de \\(X\\), \\({S}_{X}\\), és la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calcular la desviació típica dels seus valors: \\[ S_X=+\\sqrt{S_X^2} \\] La variància (a seques) admet la expressió senzilla següent: \\[ S^2_X=\\frac{\\sum_{i=1}^n X_{i}^2}{n}-\\overline{X}^2 \\] En efecte: \\[ \\begin{array}{l} \\displaystyle \\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n}=\\frac{1}{n}\\sum_{i=1}^n (X_{i}^2-2\\overline{X}X_i+\\overline{X}^2)\\\\ \\displaystyle\\qquad = \\frac{1}{n}\\Big(\\sum_{i=1}^n X_{i}^2-2\\overline{X}\\sum_{i=1}^n X_{i}+n\\overline{X}^2\\Big)\\\\ \\displaystyle\\qquad =\\frac{\\sum_{i=1}^n X_{i}^2}{n}-2\\overline{X}\\frac{\\sum_{i=1}^n X_{i}}{n}+\\frac{n\\overline{X}^2}{n}\\\\ \\displaystyle\\qquad =\\frac{\\sum_{i=1}^n X_{i}^2}{n}-2\\overline{X}\\cdot\\overline{X} + \\overline{X}^2=\\frac{\\sum_{i=1}^n X_{i}^2}{n}- \\overline{X}^2 \\end{array} \\] Tenim els dos resultats següents. El primer ens diu que esperam que la variància mostral d’una mostra aleatòria simple de \\(X\\) valgui la variància \\(\\sigma_{X}^2\\) de \\(X\\), en el sentit usual que si prenem mostres aleatòries simples de \\(X\\) de mida \\(n\\) gran i calculam les seves variàncies mostrals, molt probablement obtenim de mitjana un valor molt proper a \\(\\sigma_{X}^2\\). Teorema 3.5 Si \\(X\\) és una variable aleatòria de variància \\(\\sigma_X^2\\) i \\(\\widetilde{S}_{X}^2\\) és la seva variància mostral de mida \\(n\\), \\[ E(\\widetilde{S}_{X}^2)=\\sigma_{X}^2 \\] per a qualsevol \\(n\\). I per tant no esperam que la variància “a seques” d’una mostra aleatòria simple valgui \\(\\sigma_{X}^2\\). Això ho podeu comprovar fàcilment, perquè \\(S_X^2\\) s’obté a partir de \\(\\widetilde{S}_{X}^2\\) canviant el denominador, \\[ S_X^2=\\frac{n-1}{n} \\widetilde{S}_{X}^2 \\] i per tant \\[ E(S_X^2)=\\frac{n-1}{n}E(\\widetilde{S}_{X}^2)=\\frac{n-1}{n}\\sigma^2_{X} \\] El segon resultat ens diu que si la variable \\(X\\) és normal, un múltiple adequat de \\(\\widetilde{S}_{X}^2\\) té distribució mostral coneguda, la qual cosa ens permetrà calcular probabilitats d’esdeveniments relatius a \\(\\widetilde{S}_{X}^2\\). Teorema 3.6 Si \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\) i \\(\\widetilde{S}_{X}\\) és la seva variància mostral de mida \\(n\\), la variable aleatòria \\[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2} \\] té distribució coneguda: \\(\\chi_{n-1}^2\\) (es llegeix khi quadrat amb \\(n-1\\) graus de llibertat). La lletra \\(\\chi\\) en català es llegeix khi; en castellà, ji; i en anglès, chi, pronunciat xai. De la distribució \\(\\chi_\\nu^2\\), on \\(\\nu\\) són els graus de llibertat, heu de saber que: És una distribució contínua Per definició, és la distribució de la suma dels quadrats de \\(\\nu\\) variables aleatòries normals estàndard independents. És a dir, si \\(Z_{1},Z_{2},\\ldots, Z_{\\nu}\\) són variables \\(N(0,1)\\) independents, la variable \\[ Z_{1}^{2}+Z_{2}^{2}+\\cdots +Z_{\\nu}^{2} \\] té distribució \\(\\chi_\\nu^2\\). El nombre de graus de llibertat \\(\\nu\\) és el paràmetre del que depèn la seva densitat Amb R és chisq Si \\(X_\\nu\\) és una variable aleatòria amb distribució \\(\\chi_\\nu^2\\), aleshores \\(E(X_\\nu)=\\nu\\) i \\(\\sigma(X_\\nu)^2=2 \\nu\\) Per a \\(\\nu\\) petits, la distribució d’una \\(\\chi_{\\nu}^2\\) és asimètrica amb una cua a la dreta. Figura 3.5: Algunes densitats de variables \\(\\chi^2\\) A mida que \\(\\nu\\) creix, i atès que és la distribució d’una suma de \\(\\nu\\) variables aleatòries independents, pel Teorema Central del Límit es va aproximant a una distribució normal \\(N(\\nu,\\sqrt{2\\nu})\\). Figura 3.6: \\(\\chi^2\\) vs normal Per si no hi heu caigut, fixau-vos que \\[ (n-1)\\widetilde{S}_{X}^2=\\sum_{i=1}^n (X_i-\\mu_X)^2=nS_{X}^2 \\] i per tant \\[ \\frac{nS_{X}^2}{\\sigma_{X}^2}=\\frac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2}. \\] Així doncs, també podem dir que si \\(X\\) és normal, \\(nS_{X}^2/\\sigma_{X}^2\\) té distribució \\(\\chi_{n-1}^2\\). Tornem un instant a això dels graus de llibertat. Per què diem que la variància de mostres de mida \\(n\\) té \\(n-1\\) graus de llibertat? Doncs perquè si volem construir un conjunt de \\(n\\) nombres \\(x_1,\\ldots,x_n\\) que tenguin variància un valor donat, posem \\(y_0\\), en principi podem escollir com volguem \\(n-1\\) d’ells, \\(x_1,\\ldots,x_{n-1}\\), i aleshores el darrer, \\(x_n\\), queda bastant fixat. En matemàtiques això se sol expressar dient que “tenim \\(n-1\\) graus de llibertat a l’hora d’escollir \\(x_1,\\ldots,x_n\\) amb variància fixada \\(y_0\\)”. En efecte, si fixam el valor \\(y_0\\geqslant 0\\) de la variància i volem trobar \\(x_1,\\ldots,x_{n}\\) tals que \\[ y_0=\\frac{\\sum_{i=1}^n (x_i-\\overline{x})^2}{n}=\\frac{\\sum_{i=1}^n x_i^2}{n}-\\overline{x}^2 \\] vegem que per a qualssevol valors de \\(x_1,\\ldots,x_{n-1}\\), el valor de \\(x_n\\) queda fixat per una equació quadràtica: \\[ \\begin{array}{l} n y_0 &amp; =\\displaystyle \\sum_{i=1}^n x_i^2-n\\overline{x}^2= \\sum_{i=1}^n x_i^2-n\\Big(\\frac{\\sum_{i=1}^n x_i}{n}\\Big)^2\\\\ &amp; =\\displaystyle \\sum_{i=1}^n x_i^2-\\frac{(\\sum_{i=1}^n x_i)^2}{n}\\\\ &amp; \\displaystyle =\\frac{1}{n}\\left(n\\sum_{i=1}^n x_i^2-\\Big(\\sum_{i=1}^{n} x_i\\Big)^2\\right)\\\\ &amp; =\\displaystyle \\frac{1}{n}\\left(n\\sum_{i=1}^{n-1} x_i^2+n\\mathbf{x_n}^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2\\right.\\\\ &amp; \\displaystyle\\qquad\\qquad \\left. -2\\Big(\\sum_{i=1}^{n-1} x_i\\Big)\\mathbf{x_n}-\\mathbf{x_n}^2\\right)\\\\ &amp; =\\displaystyle \\frac{1}{n}\\left((n-1)\\mathbf{x_n}^2-2\\Big(\\sum_{i=1}^{n-1} x_i\\Big)\\mathbf{x_n}\\right.\\\\ &amp; \\displaystyle\\qquad\\qquad \\left.+n\\sum_{i=1}^{n-1} x_i^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2 \\right) \\end{array} \\] d’on (multiplicant els dos costats de la igualtat per \\(n\\) i dividint-los per \\(n-1\\)) obtenim, finalment, l’equació de segon grau en \\(\\mathbf{x_n}\\) \\[ \\mathbf{x_n}^2-\\frac{2\\sum_{i=1}^{n-1} x_i}{n-1}\\mathbf{x_n}+\\frac{n\\sum_{i=1}^{n-1} x_i^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2-n^2y_0^2}{n-1}=0 \\] Per tant, fixat \\(y_0\\) i un cop escollits \\(x_1,\\ldots,x_{n-1}\\), el darrer valor \\(x_n\\) ha de ser per força una solució d’aquesta equació de segon grau. Fixau-vos que aquesta equació no sempre té solució real, perquè pot tenir el discriminant negatiu. Per tant exageràvem un poc dient que podíem triar \\(x_1,\\ldots,x_{n-1}\\) “com volguem”. Per exemple, si voleu que la variància sigui 0 i preneu \\(x_1,\\ldots,x_{n-1}\\) no tots iguals, podeu estar ben segurs que no trobareu cap \\(x_n\\) que satisfaci aquesta equació: per tenir variància 0, els nombres \\(x_1,\\ldots,x_n\\) han de ser tots iguals. Però el que ha de quedar clar és que un cop escollits \\(x_1,\\ldots,x_{n-1}\\), el valor de \\(x_n\\) ja no pot ser qualsevol, pot prendre com a màxim dos valors diferents. Anau alerta: Si la variable poblacional \\(X\\) no és normal, la conclusió del Teorema 3.6 no és vertadera. Encara que \\(X\\) sigui normal, \\(E(\\widetilde{S}_{X})\\neq \\sigma_{X}\\). Ja ho hem comentat abans, però ho repetim: si \\(S^2_{X}\\) és la variància “a seques” (dividint per \\(n\\) en comptes de per \\(n-1\\)), \\(E(S^2_{X})\\neq \\sigma^2_{X}\\). Exemple 3.8 Suposem que el pes en néixer dels nadons segueix una distribució normal, i s’estima que la seva desviació típica (en g) és 800. Hem anotat els pesos de tots els recent nats amb SIDA d’una ciutat durant 2 anys. El teniu al vector pesos.SIDA següent: pesos.SIDA=c(2466,3941,2807,3118,2098,3175,3515,3317,3742,3062, 3033,2353,2013,3515,3260,2892,1616,4423,3572,2750, 2807,2807,3005,3374,2722,2495,3459,3374,1984,2495, 3062,3005,2608,2353,4394,3232,2013,2551,2977,3118, 2637,1503,2438,2722,2863,2013,3232,2863) Quina és la probabilitat que una mostra (aleatòria simple) de pesos de recent nats de la mateixa mida que aquesta tengui una desviació típica mostral tan petita o més que la d’aquesta mostra? La variable d’interès és \\(X\\): “Prenem un recent nat i pesam el seu pes en g”. Ens diuen que és normal amb \\(\\sigma=800\\). Pel que fa a la nostra mostra de pesos, la seva mida \\(n\\) és n=length(pesos.SIDA) n ## [1] 48 i la seva desviació típica mostral és s.tilda=round(sd(pesos.SIDA),1) s.tilda ## [1] 623.4 Sigui \\(\\widetilde{S}_X\\) la desviació típica mostral de mida 48 de la variable \\(X\\). Ens demanen \\(P(\\widetilde{S}_X \\leqslant 623.4)\\). Això tal qual no ho sabem calcular, perquè no sabem la funció de distribució de \\(\\widetilde{S}_X\\). Però sí que sabem la de \\[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2}= \\frac{47\\widetilde{S}_{X}^2}{800^2} \\] Aquesta variable té distribució \\(\\chi_{47}^2\\). Per tant el que hem de fer és traduir la probabilitat que volem calcular en termes d’aquesta variable: \\[ P(\\widetilde{S}_X\\leqslant 623.4)=P\\Big(\\frac{47\\widetilde{S}_{X}^2}{800^2}\\leqslant \\frac{47\\cdot 623.4^2}{800^2}\\Big)=P(\\chi_{47}^2\\leqslant 28.54) \\] i això val round(pchisq(round((n-1)*s.tilda^2/800^2,2),n-1),4) ## [1] 0.0153 Per tant, només un 1.5% de les mostres aleatòries simples de 47 recent nats tenen una desviació típica mostral més petita o igual que la de la nostra mostra de recent nats amb SIDA. 3.5 La distribució t de Student Recordau que si la variable poblacional \\(X\\) és \\(N(\\mu_X,\\sigma_X)\\) i prenem mostres aleatòries simples de mida \\(n\\), la variable \\[ \\frac{\\overline{X}-\\mu_X}{\\sigma_{X}/\\sqrt{n}} \\] és normal estàndard. Des del punt de vista teòric això és útil per obtenir fórmules, però normalment no ens serveix per calcular la probabilitat que a \\(\\overline{X}\\) li passi qualque cosa, perquè gairebé mai sabrem la desviació típica poblacional \\(\\sigma_{X}\\). Què passa si l’estimam per mitjà de \\(\\widetilde{S}_{X}\\) amb la mateixa mostra amb la qual calculam \\(\\overline{X}\\)? Doncs que el resultat següent ens salva el dia, perquè la variable que obtenim té distribució coneguda. Teorema 3.7 Sigui \\(X\\) una variable \\(N(\\mu_X, \\sigma_X)\\). Siguin \\(\\overline{X}\\) i \\(\\widetilde{S}_{X}\\) les seves mitjana mostral i desviació típica mostral de mostres aleatòries simples de mida \\(n\\), respectivament. Aleshores, la variable aleatòria \\[ T=\\frac{\\overline{X}-\\mu_X}{\\widetilde{S}_{X}/\\sqrt{n}} \\] té una distribució coneguda, anomenada t de Student amb \\(n-1\\) graus de llibertat, \\(t_{n-1}\\). Al denominador \\(\\widetilde{S}_{X}/\\sqrt{n}\\) li diem l’error estàndard, o típic, de la mostra: estima l’error estàndard \\(\\sigma_X/\\sqrt{n}\\) de \\(\\overline{X}\\). De la distribució t de Student amb \\(\\nu\\) graus de llibertat, \\(t_{\\nu}\\), heu de saber que: És contínua Amb R és t El nombre de graus de llibertat \\(\\nu\\) és el paràmetre del que depèn la seva densitat Si \\(T_{\\nu}\\) és una variable amb distribució \\(t_{\\nu}\\), aleshores \\(E(T_{\\nu})=0\\) i \\(\\sigma(T_{\\nu})^2=\\nu/(\\nu-2)\\) (en realitat aquestes dues igualtats només són veritat si \\(\\nu\\geqslant 3\\), però no fa falta recordar-ho). La funció de densitat d’una variable \\(t_{\\nu}\\) és simètrica al voltant de 0 (com la d’una \\(N(0,1)\\)): \\[ P(T_{\\nu}\\leqslant -x)=P(T_{\\nu}\\geqslant x)=1-P(T_{\\nu}\\leqslant x) \\] Per tant 0 també és la seva mediana. Figura 3.7: Densitats d’algunes t de Student Si \\(\\nu\\) és gran, la distribució d’una variable \\(t_{\\nu}\\) és aproximadament la d’una \\(N(0,1)\\) però amb una mica més de variància, perquè \\(\\nu/(\\nu-2)&gt;1\\), i per tant un poc més aplatada. Figura 3.8: t amb molts graus de llibertat vs Normal estàndard El fet que una t de Student sigui més aplatada que una normal estàndard \\(Z\\) implica que les cues de la t tenen major probabilitat que les de \\(Z\\) (fixau-vos que als gràfics anteriors els extrems de les densitats de les t estan per damunt dels de la de \\(Z\\)), la qual cosa es tradueix en el fet que és més probable obtenir valors lluny del 0 amb una t de Student que amb una \\(N(0,1)\\). Indicarem amb \\(t_{\\nu,q}\\) el \\(q\\)-quantil d’una variable aleatòria \\(T_{\\nu}\\) que segueix una distribució \\(t_\\nu\\). És a dir, \\(t_{\\nu,q}\\) és el valor tal que \\[ P(T_{\\nu}\\leqslant t_{\\nu,q})=q \\] Per la simetria de la distribució \\(t_\\nu\\), \\[ t_{\\nu,q}=-t_{\\nu,1-q}. \\] Hi ha algunes propietats dels quantils de la t de Student que heu de saber, per poder aplicar-les quan no tengueu a l’abast R o una apli per calcular quantils: \\(t_{\\nu ,q}\\approx z_{q}\\) si \\(\\nu\\) és molt gran, posem \\(\\nu \\geqslant 200\\). Per exemple qt(0.975,200) # t_{200,0.975} ## [1] 1.971896 qnorm(0.975) # z_0.975 ## [1] 1.959964 \\(t_{\\nu,0.95}\\) (per a \\(10\\leqslant \\nu\\leqslant 200\\)) està entre 1.65 i 1.8; ho podeu aproximar \\(t_{n,0.95}\\approx 1.7\\) \\(t_{n,0.975}\\) (per a \\(10\\leqslant n\\leqslant 200\\)) està entre 1.97 i 2.2; ho podeu aproximar \\(t_{n,0.975}\\approx 2\\) Comprovau amb R les afirmacions sobr els quantils de la t de Student dels darrers dos punts. Abans de tancar aquesta secció, recordau que, donada una variable aleatòria \\(X\\), no heu de confondre: Desviació típica (o estàndard) de la variable aleatòria, \\(\\sigma_X\\): El paràmetre poblacional, normalment desconegut Desviació típica (o estàndard) (sigui mostral, \\(\\widetilde{S}_X\\), o a seques, \\(S_X\\)) d’una mostra: L’estadístic que calculam sobre la mostra i que quantifica la dispersió de la mostra Error típic (o estàndard) d’un estimador: La desviació típica de la variable aleatòria que defineix l’estimador, normalment desconeguda Error típic (o estàndard) d’una mostra: Estimació de l’error típic de la mitjana mostral (o de la proporció mostral) a partir d’una mostra; servirà per calcular intervals de confiança. És \\(\\widetilde{S}_X/\\sqrt{n}\\) (o \\(\\sqrt{\\widehat{p}_X(1-\\widehat{p}_X)/n}\\) si es tracta de proporcions). 3.6 Biaix i precisió En una primera aproximació, la bondat d’un estimador es descriu en termes de dues propietats: la seva exactitud i la seva precisió. L’exactitud d’un estimador refereix al fet que el seu valor esperat sigui el valor real del paràmetre que es vol estimar. La precisió d’un estimador refereix al fet que els seus valors estiguin molt concentrats. Per tant, un estimador és exacte i precís quan els seus valors es concentren molt al voltant del valor real del paràmetre. La combinació d’exactitud i precisió disminueix la probabilitat que una estimació caigui enfora del valor real que volem estimar. Aquests dos conceptes se solen il·lustrar amb una diana, així que nosaltres també ho farem: 3.6.1 Estimadors no esbiaixats Un estimador puntual \\(\\widehat{\\theta}\\) d’un paràmetre poblacional \\(\\theta\\) és exacte, o no esbiaixat (insesgado, en castellà), quan el seu valor esperat és el valor poblacional del paràmetre, és a dir, quan \\[ E(\\widehat{\\theta})=\\theta \\] El biaix d’un estimador \\(\\widehat{\\theta}\\) d’un paràmetre \\(\\theta\\) és la diferència \\(E(\\widehat{\\theta})-\\theta\\). L’exactitud de l’estimador també es mesura amb aquesta diferència \\(E(\\widehat{\\theta})-\\theta\\), però hem de tenir en compte a l’hora d’expressar-nos que, com més petit sigui el valor absolut d’aquesta diferència, \\(|E(\\widehat{\\theta})-\\theta|\\), menys esbiaixat i més exacte és l’estimador. Per tant, “augmentar l’exactitud” és reduir el valor absolut del biaix. Exemples: Ja hem vist a les seccions anteriors que \\(E(\\overline{X})=\\mu_X\\). Per tant, \\(\\overline{X}\\) és un estimador no esbiaixat de \\(\\mu_X\\). \\(E(\\widehat{p}_X)=p_X\\). Per tant, \\(\\widehat{p}_X\\) és un estimador no esbiaixat de \\(p_X\\). \\(E(\\widetilde{S}_{X}^2)=\\sigma_X^2\\). Per tant, \\(\\widetilde{S}_{X}^2\\) és un estimador no esbiaixat de \\(\\sigma_X^2\\). Com que \\({S}_{X}^2=\\dfrac{n-1}{n}\\widetilde{S}_{X}^2\\), tenim que \\(E({S}_{X}^2)=\\dfrac{n-1}{n}\\sigma_X^2\\). Per tant, en aquest cas, \\({S}_{X}^2\\) és un estimador esbiaixat de \\(\\sigma_X^2\\), amb biaix \\[ \\mu_{{S}_{X}^2}-\\sigma_X^2=\\dfrac{n-1}{n}\\sigma_X^2-\\sigma_X^2=-\\dfrac{\\sigma_X^2}{n}\\ \\mathop{\\longrightarrow}_{\\scriptscriptstyle n\\to\\infty}\\ 0 \\] En aquest cas diem que el seu biaix tendeix a 0. \\(E(\\widetilde{S}_{X}), E({S}_{X})\\neq \\sigma_X\\) ni tan sols quan \\(X\\) és normal. Per tant, \\(\\widetilde{S}_{X}\\) i \\({S}_{X}\\) són estimadors esbiaixats de \\(\\sigma_X\\). Quan \\(X\\) és normal, el seu biaix tendeix a 0. Recordau que, en general, \\(E(X^2)\\neq E(X)^2\\). Per tant, no hauríem d’esperar que \\(E(\\widetilde{S}_{X})=\\sqrt{E(\\widetilde{S}_{X}^2)}\\). Per si qualque dia us cal saber-ho, si \\(X\\) és normal \\[ E(\\widetilde{S}_X)=\\left\\{\\begin{array}{ll} \\sigma_X\\sqrt{\\dfrac{2}{(n-1)\\pi}}\\cdot \\dfrac{2^{n-2}(\\frac{n}{2}-1)!^2}{(n-2)!} &amp; \\text{ si $n$ és parell}\\\\ \\sigma_X\\sqrt{\\dfrac{2\\pi}{n-1}}\\cdot \\dfrac{(n-2)!}{2^{n-2}(\\frac{n-1}{2}-1)!^2} &amp; \\text{ si $n$ és imparell} \\end{array}\\right. \\] Per tant, per obtenir un estimador no esbiaixat per a la desviació típica \\(\\sigma_X\\) d’una variable normal, només heu de dividir \\(\\widetilde{S}_X\\) pel factor que acompanyi la \\(\\sigma_X\\) a la dreta d’aquesta fórmula, segons quina sigui la mida \\(n\\) de les mostres. 3.6.2 Estimadors precisos Donats dos estimadors \\(\\widehat{\\theta}_1\\), \\(\\widehat{\\theta}_2\\) del mateix paràmetre \\(\\theta\\), direm que \\(\\widehat{\\theta}_1\\) és més eficient, o més precís, que \\(\\widehat{\\theta}_2\\) quan la desviació típica de \\(\\widehat{\\theta}_1\\) és més petita que la de \\(\\widehat{\\theta}_2\\): \\[ \\sigma(\\widehat{\\theta}_1)&lt; \\sigma(\\widehat{\\theta}_2). \\] Quan \\(\\widehat{\\theta}_1\\) i \\(\\widehat{\\theta}_2\\) són no esbiaixats, que \\(\\widehat{\\theta}_1\\) sigui més eficient que \\(\\widehat{\\theta}_2\\) significa que els seus valors es concentren més al voltant del paràmetre \\(\\theta\\) que volem estimar. Normalment, només comparam l’eficiència de dos estimadors quan són no esbiaixats o amb el biaix que tendeixi a 0. De res ens serveix tenir un estimador molt precís però que sistemàticament dóna un valor llunyà del valor real del paràmetre. Exemples: Si \\(X\\) és normal, \\(\\overline{X}\\) és l’estimador no esbiaixat més eficient de la mitjana poblacional \\(\\mu_X\\). Si \\(X\\) és Bernoulli, \\(\\widehat{p}_X\\) és l’estimador no esbiaixat més eficient de la proporció poblacional \\(p_X\\). Si \\(X\\) és normal, \\(\\widetilde{S}_X^2\\) és l’estimador no esbiaixat més eficient de la variància poblacional \\(\\sigma_X^2\\). Exemple 3.9 Sigui \\(X\\) una variable aleatòria normal \\(N(\\mu_X,\\sigma_X)\\). Per la simetria de les variables normals, sabem que \\(\\mu_X\\) és també la seva mediana. Se’ns podria ocórrer llavors emprar la mediana \\(\\mathit{Me}=Q_{0.5}\\) d’una mostra aleatòria simple de mida \\(n\\) de \\(X\\) per estimar \\(\\mu_X\\). Resulta que \\(E(\\mathit{Me})=\\mu_X\\) però \\[ \\sigma^2(\\mathit{Me})\\approx \\dfrac{\\pi}{2}\\cdot \\dfrac{\\sigma_{X}^2}{n}\\approx 1.57 \\cdot \\frac{\\sigma_{X}^2}{n}=1.57\\sigma^2_{\\overline{X}} \\] Per tant, si \\(X\\) és normal, la mediana \\(\\mathit{Me}\\) també és un estimador no esbiaixat de \\(\\mu_X\\), però és menys eficient que \\(\\overline{X}\\). Per això preferim emprar la mitjana mostral per estimar \\(\\mu_X\\). Hem dit que si la població és normal, \\(\\widetilde{S}_X^2\\) és l’estimador no esbiaixat més eficient de la variància poblacional \\(\\sigma_X^2\\). La variància a seques \\[ S_X^2=\\frac{(n-1)}{n} \\widetilde{S}_X^2 \\] és més eficient, perquè \\[ \\sigma(S_X^2)=\\sqrt{\\frac{(n-1)}{n}}\\sigma(\\widetilde{S}_X^2)&lt;\\sigma(\\widetilde{S}_X^2), \\] però és un estimador esbiaixat de \\(\\sigma_X^2\\), amb biaix que tendeix a 0. Si \\(n\\) és petit, és millor fer servir la variància mostral \\(\\widetilde{S}_X^2\\) per estimar la variància, ja que el biaix pot desplaçar substancialment l’estimació, però si \\(n\\) és gran, el biaix de \\(S_X^2\\) ja és petit i es pot fer servir \\(S_X^2\\). De totes formes, si \\(n\\) és molt gran, dividir per \\(n\\) o per \\(n-1\\) no varia gaire el resultat i per tant \\(\\widetilde{S}_X^2\\) i \\(S_X^2\\) donen valors molt semblants. 3.7 Estimadors màxim versemblants Un estimador d’un paràmetre és màxim versemblant quan, aplicat a una mostra aleatòria simple, dóna el valor del paràmetre que fa màxima la probabilitat d’obtenir aquesta mostra. En realitat, l’estimació màxim versemblant d’un paràmetre el que fa màxim és el producte dels valors de la funció densitat de la variable aleatòria poblacional aplicada als elements de la mostra. Quan la variable aleatòria és discreta, això coincideix amb el que hem dit, perquè la probabilitat d’obtenir un valor concret és la funció densitat aplicada a aquest valor. Però quan la variable aleatòria poblacional és contínua, la probabilitat d’obtenir una mostra concreta és sempre 0 i no té sentit parlar de maximitzar aquest 0. Per això es pren la funció densitat. Aquí no ens complicarem la vida i entendrem que el que maximitzam és la probabilitat d’obtenir la mostra. Exemple 3.10 Suposem que tenim una variable aleatòria Bernoulli \\(X\\) de probabilitat d’èxit \\(p_X\\) desconeguda. Donada una mostra aleatòria simple \\(x_1,\\ldots,x_n\\) de \\(X\\), siguin \\(\\widehat{p}_x\\) la seva proporció mostral i \\[ P(x_1,\\ldots,x_n\\mid p_X=p) \\] la probabilitat d’obtenir la mostra quan la probabilitat poblacional \\(p_X\\) és igual \\(p\\). Un estimador per a \\(p_X\\) és màxim versemblant quan, aplicat a cada mostra aleatòria simple \\(x_1,\\ldots,x_n\\) de \\(X\\), ens dóna el valor de \\(p\\) que fa que \\[ P(x_1,\\ldots,x_n\\mid p_X=p) \\] sigui el màxim possible. Quin creieu que és l’estimador màxim versemblant de \\(p_X\\)? Vegem un exemple concret. Suposau en 20 llançaments d’una moneda obtenim 5 cares. Quina creieu que és la probabilitat d’obtenir cara amb aquesta moneda que fa màxima la probabilitat que en 20 llançaments obtinguem 5 cares? La intuïció ens diu que hauria de ser la proporció mostral \\(\\widehat{p}_X=5/20=0.25\\), no? Confirmem-ho amb el gràfic de la probabilitat que una binomial \\(B(20,p)\\) doni 5 en funció de \\(p\\): plot((0:200)/200,dbinom(5,20,(0:200)/200),type=&quot;h&quot;,xlab=&quot;p&quot;,ylab=&quot;&quot;,xaxp=c(0,1,20)) points(0.25,dbinom(5,20,0.25),type=&quot;h&quot;,col=&quot;red&quot;) Figura 3.9: Probabilitat que una B(20,p) valgui 5 El resultat següent mostra que això sempre és així. Teorema 3.8 El valor de \\(p\\) per al qual \\(P(x_1,\\ldots,x_n\\mid p_X=p)\\) és màxim és \\(\\widehat{p}_x\\). La demostració és senzilla. Suposau que dins \\(x_1,\\ldots,x_n\\) hi ha \\(m\\) 1s i \\(n-m\\) 0s, de manera que \\(\\widehat{p}_X=m/n\\). Aleshores, la probabilitat d’obtenir \\(x_1,\\ldots,x_n\\) és \\[ P(x_1,\\ldots,x_n\\mid p_X=p)=p^m(1-p)^{n-m} \\] Per trobar el valor de \\(p\\) que fa aquest probabilitat màxima, derivau respecte de \\(p\\) i estudiau el signe de la derivada, i concloureu que el màxim es dóna efectivament a \\(p=m/n\\). La proporció \\(\\widehat{p}_x\\) és el valor de \\(p_X\\) que fa màxima la probabilitat d’obtenir la nostra mostra, no a l’enrevés: No és el valor més probable de \\(p_X\\) condicionat a la nostra mostra. Vaja, no confongueu \\[ P(x_1,\\ldots,x_n\\mid p_X=p)\\text{ amb }P(p_X=p\\mid x_1,\\ldots,x_n). \\] D’això darrer no en sabem trobar el màxim sense alguna hipòtesi sobre la distribució de probabilitat dels valors possibles de \\(p_X\\). Si la proporció \\(\\widehat{p}_x\\) fos el valor més probable de \\(p_X\\) condicionat a la nostra mostra, en díríem un estimador màxim probable, no un estimador màxim versemblant, no ho trobau? Alguns altres estimadors màxim versemblants: \\(\\overline{X}\\) és l’estimador màxim versemblant del paràmetre \\(\\lambda\\) d’una variable aleatòria Poisson \\(\\overline{X}\\) és l’estimador màxim versemblant de la mitjana \\(\\mu_X\\) d’una variable aleatòria normal \\(S_X^2\\) i \\(S_X\\) (la variància i desviació típica a seques, no les mostrals!) són els estimadors màxim versemblants de la variància \\(\\sigma_X^2\\) i la desviació típica \\(\\sigma_X\\) d’una variable aleatòria normal 3.8 Estimació de poblacions 3.8.1 Estimació de poblacions numerades Exemple 3.11 Un dia vaig voler estimar quants taxis hi havia a Palma. Per fer-ho, assegut en un bar del Passeig Marítim vaig apuntar les llicències dels 40 primers taxis que passaren. Els entraré directament en un vector de R. taxis=c(1217,600,883,1026,150,715,297,137,508,134,38,961,538,1154, 314,1121,823,158,940,99,977,286,1006,1207,264,1183,1120, 498,606,566,1239,860,114,701,381,836,561,494,858,187) sort(taxis) ## [1] 38 99 114 134 137 150 158 187 264 286 297 314 381 494 498 ## [16] 508 538 561 566 600 606 701 715 823 836 858 860 883 940 961 ## [31] 977 1006 1026 1120 1121 1154 1183 1207 1217 1239 Puc estimar quants taxis hi ha a Palma a partir d’aquesta mostra? Us pot semblar una beneitura de pregunta, però aquest és un problema de rellevància històrica, com podeu consultar en aquest article. La solució d’aquest problema és donada pel resultat següent: Teorema 3.9 Sigui \\(X\\) una variable aleatòria uniforme sobre \\(\\{1,2,\\ldots,N\\}\\) (és a dir, \\(X\\) pot prendre tots els valors entre 1 i N, tots amb la mateixa probabilitat 1/N), i sigui \\(x_1,\\ldots,x_n\\) una mostra aleatòria sense reposició de \\(X\\). Sigui \\(m=\\max(x_1,\\ldots,x_n)\\). Aleshores, l’estimador no esbiaixat més eficient de \\(N\\) és \\[ \\widehat{N}=m+\\frac{m-n}{n} \\] Vegem la idea intuïtiva que hi ha al darrere d’aquesta fórmula. Suposau que teniu \\(x_1,\\ldots,x_n\\) ordenats en ordre creixent, \\(x_1&lt;\\cdots&lt;x_n\\), de manera que \\(x_n=m\\). Calculem la longitud mitjana dels “forats” a l’esquerra de cada valor \\(x_i\\). A l’esquerra de \\(x_1\\) hi “falten” els nombres \\(1,2,\\ldots,x_1-1\\), per tant hi ha un forat de \\(x_1-1\\) nombres. Entre \\(x_1\\) i \\(x_2\\) hi “falten” els nombres \\(x_1+1,\\ldots,x_2-1\\), per tant hi ha un forat de \\(x_2-x_1-1\\) nombres. En general, entre cada \\(x_{i-1}\\) i \\(x_{i}\\) hi ha un forat de \\(x_{i}-x_{i-1}-1\\) nombres (hi “falten” els nombres \\(x_{i-1}+1,\\ldots,x_i-1\\)). Per tant, la mitjana de les longituds d’aquests “forats” és \\[ \\begin{array}{l} \\displaystyle \\frac{(x_1-1)+(x_2-x_1-1)+\\cdots+(x_{n}-x_{n-1}-1)}{n}\\\\ \\displaystyle \\qquad\\quad =\\frac{x_n-n}{n}=\\frac{m-n}{n} \\end{array} \\] El que fa l’estimador \\(\\widehat{N}\\) és sumar al màxim de la mostra, \\(m\\), aquesta longitud mitjana dels forats entre membres de la mostra. És a dir, estimam que la mida de la població és tal que a la dreta del màxim de la nostra mostra hi ha un “forat” de mida la mitjana dels forats de la mostra. Exemple 3.12 Continuem amb l’Exemple 3.11. Emprant la fórmula anterior, obtenim max(taxis)+(max(taxis)-length(taxis))/length(taxis) ## [1] 1268.975 la qual cosa em permeté estimar que hi havia 1269 taxis a Palma. En realitat, consultant la web de l’Ajuntament, després vaig saber que en aquell moment n’hi havia 1246. Exemple 3.13 Fem un experiment. Generarem a l’atzar una mida N d’una població grandeta, i suposarem que els individus de la població estan numerats de l’1 al N. A continuació, prendrem 100 mostres aleaòries sense reposició de la nostra població i amb cada una d’aquestes mostres estimarem la N emprant la fórmula que hem donat. Al final, calcularem la mitjana d’aquestes estimacions i la compararem amb el valor real de N, que no descobrirem fins el final. Perquè l’experiment sigui reproduïble, fixarem la llavor d’aleatorietat, però perquè no cregueu que fem trampes amb aquesta llavor, el que farem serà generar a l’atzar la llavor d’aleatorietat amb la funció sample. Llavor=sample(1000,1) Llavor ## [1] 580 set.seed(Llavor) Ara generam la mida N de la població com un nombre a l’atzar entre 5000 i 10000. N=sample(5000:10000,1) Suposarem per tant que hi ha N individus a la nostra població, numerats de l’1 al N. Ara generarem 100 mostres aleatòries sense reposició d’aquesta població, i ens quedarem amb la mida i el valor màxim de cada una d’elles, que és l’únic que necessitam saber. Les mides les generarem a l’atzar entre, posem, 25 i 75: Mostra=function(a,b,P){ # a i b: mides màxima i mínima de la mostra; P: mida de la població n=sample(a:b,1) # Mida de la mostra X=sample(P,n) # Mostra aleatòria de mida n c(n,max(X)) # Parell (mida, màxim) } Mostres=replicate(100,Mostra(25,75,N)) Mostres ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] ## [1,] 43 53 53 40 67 44 40 73 67 67 61 26 37 30 ## [2,] 6682 6684 6684 6652 6673 6623 6607 6540 6670 6657 6657 6455 6528 6667 ## [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] ## [1,] 75 29 56 29 33 74 51 64 42 61 39 68 ## [2,] 6686 6651 6632 6617 6671 6470 6379 6565 6637 6684 6423 6522 ## [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] ## [1,] 48 28 57 28 63 46 32 31 44 69 31 31 ## [2,] 6105 6522 6293 6327 6691 6498 6464 6522 6652 6606 6298 6262 ## [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] ## [1,] 27 65 70 30 42 56 53 40 33 25 61 63 ## [2,] 6562 6676 6509 5655 6370 6641 6653 6674 6341 6612 6641 6693 ## [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62] ## [1,] 59 42 60 52 64 38 26 71 75 48 39 47 ## [2,] 6657 6596 6545 6681 6528 6583 6656 6692 6588 6603 6569 6583 ## [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74] ## [1,] 41 37 57 70 51 29 69 46 52 64 56 54 ## [2,] 6480 6535 6693 6694 6422 6665 6630 6654 6679 6414 6609 6672 ## [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] [,85] [,86] ## [1,] 59 57 56 69 39 70 58 59 48 50 37 68 ## [2,] 6675 6624 6223 6618 6480 6664 6681 6536 6525 6671 6669 6686 ## [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98] ## [1,] 70 44 39 47 56 65 43 32 60 57 42 55 ## [2,] 6697 6490 6677 6619 6492 6609 6587 6653 6564 6674 6152 6585 ## [,99] [,100] ## [1,] 75 36 ## [2,] 6398 6623 En aquesta matriu Mostres, cada columna correspon a una mostra aleatòria: la primera filera és la seva mida \\(n\\) i la segona filera el màxim \\(m\\). Ara, amb cada una d’aquestes mostres, podem estimar la mida N de la població per mitjà de la fórmula \\(m+(m-n)/n\\). Dibuixarem un histograma d’aquestes estimacions, per veure què ens ha sortit. Estimacions=Mostres[2,]+(Mostres[2,]-Mostres[1,])/Mostres[1,] round(range(Estimacions),1) # Estimacions mínima i màxima ## [1] 5842.5 6911.0 hist(Estimacions, breaks=20,col=&quot;light blue&quot;, xlab=&quot;Estimacions de N&quot;,ylab=&quot;Freqüències&quot;,main=&quot;&quot;) Com veieu, obtenim estimacions que van de 5842.5 a 6911. La mitjana d’aquestes estimacions és round(mean(Estimacions),1) ## [1] 6704.5 És hora de descobrir el valor de N, per veure si hi hem fet a prop: N ## [1] 6701 No hem fet molt enfora, com veieu. 3.8.2 Marca-recaptura Suposem que en una població hi ha \\(N\\) individus, en capturam \\(K\\) (tots diferents), els marcam i els tornam a amollar. Al cap de poc temps, en capturam \\(n\\), dels quals resulta que \\(k\\) estan marcats. A partir d’aquestes dades, volem estimar el valor de \\(N\\). Si suposam que \\(N\\) i \\(K\\) no han canviat de la primera a la segona captura (cap individu no ha abandonat la població ni se n’hi ha incorporat cap de nou), aleshores la variable aleatòria \\(X\\) definida per “Capturam un individu i miram si està marcat” és Bernoulli \\(Be(p)\\) amb \\(p=K/N\\), on coneixem la \\(K\\) i volem estimar la \\(N\\). Sigui ara \\(x_1,\\ldots,x_n\\) la mostra capturada en segon lloc. La seva proporció mostral d’individus marcats és \\(\\widehat{p}_X=k/n\\). Com que \\(\\widehat{p}_X\\) és l’estimador màxim versemblant de \\(p\\), estimam que \\[ \\dfrac{K}{N}=\\dfrac{k}{n} \\] d’on, aïllant la \\(N\\), estimam que \\[ N=\\frac{n\\cdot K}{k}. \\] En resum, l’estimador \\[ \\widehat{N}=\\frac{n\\cdot K}{k} \\] maximitza la probabilitat d’obtenir \\(k\\) individus marcats en una mostra aleatòria de \\(n\\) individus. És l’estimador màxim versemblant de \\(N\\) a partir de \\(K\\), \\(k\\) i \\(n\\); també se li diu estimador de Lincoln-Petersen. Fixau-vos que aquest estimador no fa res més que traduir la proporció “Si he trobat \\(k\\) individus marcats en un conjunt de \\(n\\) individus, què ha de valer el nombre total \\(N\\) de individus perquè hi hagi en total \\(K\\) individus marcats?” Exemple 3.14 Suposem que hem marcat 15 peixos d’un llac, i que en una captura posterior de 10 peixos, n’hi ha 4 de marcats. Quants peixos conté el llac? Ho estimarem amb l’estimador de Lincoln-Petersen: \\[ \\widehat{N}=\\frac{15\\cdot 10}{4}=37.5 \\] Per tant, estimam que hi haurà entre 37 i 38 peixos al llac. En aquest cas podem comprovar la màxima versemblança d’aquesta estimació, calculant la probabilitat d’obtenir 4 individus marcats en una mostra aleatòria de 10 individus d’una població de \\(N\\) individus on n’hi ha 15 de marcats i trobant la \\(N\\) que maximitza aquesta probabilitat. Per fer-ho, recordem que si una població està formada per \\(K\\) subjectes marcats i \\(N-K\\) subjectes no marcats, el nombre de subjectes marcats en mostres aleatòries sense reposició de mida \\(n\\) segueix una distribució hipergeomètrica \\(H(K, N-K,n)\\). Per tant, per a cada possible \\(N\\), la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats serà dhyper(4,15,N-15,10). N=15:1000 # Rang de possibles valors de N p=dhyper(4,15,N-15,10) # Probabilitats de 4 marcats en 10 Nmax=N[which(p==max(p))] # N que maximitza la probabilitat Nmax ## [1] 37 Aquest Nmax és la \\(N\\) que fa màxima la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats. Vegem-ho amb un gràfic: plot(N[1:86],p[1:86],type=&quot;h&quot;,xaxp=c(15,100,17),xlab=&quot;N&quot;,ylab=&quot;p&quot;) points(Nmax,dhyper(4,15,Nmax-15,10),type=&quot;h&quot;,col=&quot;red&quot;,lwd=1.5) I què hagués passat si no haguéssim trobat cap peix marcat a la mostra? Quan la mida de la mostra és petita, és més convenient emprar l’estimador de Chapman: \\[ \\widehat{N}=\\frac{(n+1)\\cdot (K+1)}{k+1}-1 \\] La idea és que afegim a la població un individu extra i marcat, que suposam que també capturam a la segona mostra. Llavors, aplicam l’estimador de Lincoln-Petersen i finalment restam 1, per descomptar l’individu marcat extra que realment no pertany a la població que volem estimar. D’aquesta manera ja no tenim el problema de dividir per 0 si \\(k\\) ens dóna 0. En la situació de l’Exemple 3.14, aquest estimador dóna \\[ \\widehat{N}=\\frac{16\\cdot 11}{5}-1=34.2 \\] i ens fa estimar una població total d’uns 34 peixos. Abans hem obtingut entre 37 i 38 peixos. Quina de les dues estimacions s’acosta més a la realitat? Ni idea, no ho podem saber. Amb una altra recaptura segurament haguéssim obtingut resultats diferents. L’estimador de Lincoln-Petersen \\[ \\widehat{N}=\\frac{n\\cdot K}{k} \\] és esbiaixat, amb biaix que tendeix a 0. L’estimador de Chapman és menys esbiaixat però no és màxim versemblant. Exemple 3.15 Fem un experiment similar al de l’Exemple 3.13. Generarem a l’atzar una mida N d’una població grandeta i en marcarem una certa quantitat K. A continuació, prendrem 50 mostres aleaòries sense reposició de la nostra població i amb cada una d’aquestes mostres estimarem la N emprant els dos estimadors que hem explicat en aquesta subsecció. Al final, calcularem les mitjanes d’aquestes estimacions i les compararem amb el valor real de N, que no descobrirem fins el final. Com a l’Exemple 3.13, fixarem la llavor d’aleatorietat a l’atzar. Llavor2=sample(1000,1) Llavor2 ## [1] 206 set.seed(Llavor2) Ara generam la mida N de la població com un nombre a l’atzar entre 5000 i 10000. N=sample(5000:10000,1) Ara en capturam i marcam K; per fixar idees, prendrem K=200. K=200 Per simplificar, suposarem que els N individus de la nostra població estan numerats de l’1 a l’N i que els marcats són els K primers. Ara generarem 100 mostres aleatòries sense reposició d’aquesta població, i ens quedarem amb la mida de la mostra i el nombre d’individus marcats (és a dir, el nombre de valors \\(\\leqslant K=200\\) en la mostra). Les mides les generarem a l’atzar entre, posem, 100 i 150: Mostra=function(a,b,P,M){ # a i b: mides màxima i mínima de la mostra; P: mida de la població; # M: nombre de marcats n=sample(a:b,1) # Mida de la mostra X=sample(P,n,rep=FALSE) # Mostra aleatòria c(n,length(which(X&lt;=M))) # Parell (mida, nombre de marcats) } Mostres=replicate(100, Mostra(100,150,N,K)) Mostres ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] ## [1,] 119 101 101 109 130 121 129 107 136 108 120 146 124 134 ## [2,] 5 2 5 1 5 4 6 3 4 3 2 5 3 4 ## [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] ## [1,] 106 131 120 149 113 143 117 125 132 101 109 108 ## [2,] 1 3 4 5 2 3 4 5 1 4 3 2 ## [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] ## [1,] 138 143 109 105 141 110 125 150 109 103 141 115 ## [2,] 4 3 8 2 3 1 5 3 2 6 8 3 ## [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] ## [1,] 107 132 135 118 131 117 110 115 135 138 127 121 ## [2,] 2 4 3 4 3 5 1 3 6 2 6 5 ## [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62] ## [1,] 124 144 134 115 129 102 111 130 102 107 111 123 ## [2,] 2 4 4 1 5 6 5 5 2 1 4 4 ## [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74] ## [1,] 119 131 115 150 145 125 119 149 129 112 146 135 ## [2,] 4 3 2 1 7 1 3 1 5 4 7 4 ## [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] [,85] [,86] ## [1,] 119 128 124 147 148 135 139 150 123 142 108 138 ## [2,] 2 5 4 4 5 6 4 6 5 8 2 2 ## [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98] ## [1,] 112 141 131 144 111 112 147 103 112 108 107 133 ## [2,] 2 7 5 4 1 6 3 4 4 1 2 5 ## [,99] [,100] ## [1,] 139 149 ## [2,] 1 5 En aquesta matriu Mostres, cada columna correspon a una mostra aleatòria: la primera filera és la seva mida \\(n\\) i la segona filera el nombre d’individus marcats a la mostra. Ara, amb cada una d’aquestes mostres, podem estimar la mida N de la població per mitjà de l’estimador de Lincoln-Petersen. EstimacionsLP=Mostres[1,]*K/Mostres[2,] round(range(EstimacionsLP),1) ## [1] 2725 30000 hist(EstimacionsLP, breaks=20,col=&quot;light blue&quot;, xlab=&quot;Estimacions de N&quot;,ylab=&quot;Freqüències&quot;, main=&quot;Estimador de Lincoln-Petersen&quot;) Com veieu, obtenim estimacions que van de 2725 a 30000. La mitjana de les estimacions és round(mean(EstimacionsLP),1) ## [1] 9246 També podem emprar l’estimador de Chapman: EstimacionsCh=(Mostres[1,]+1)*(K+1)/(Mostres[2,]+1)-1 round(range(EstimacionsCh),1) ## [1] 2455.7 15174.5 hist(EstimacionsCh, breaks=20,col=&quot;light blue&quot;,xlab=&quot;Estimacions de N&quot;,ylab=&quot;Freqüències&quot;,main=&quot;Estimador de Chapman&quot;) Com veieu, obtenim estimacions que van de 2455.7 a 15174.5. La mitjana d’aquestes estimacions és round(mean(EstimacionsCh),1) ## [1] 6292.7 És hora de descobrir el valor de N, per veure si hi hem fet a prop: N ## [1] 7225 Com veieu, amb l’estimador de Chapman ens hem fet més a prop del valor real de \\(N\\) que amb el màxim versemblant. Però amb cap d’ells ens hi hem fet molt a prop. 3.9 Test de la lliçó 3 (1) Tenim una variable aleatòria \\(X\\) normal de mitjana \\(\\mu\\) i desviació típica \\(\\sigma\\). Prenem mostres aleatòries simples de mida \\(n\\), i indicam amb \\(\\widetilde{S}_X\\) la seva desviació típica mostral. Quina o quines de les afirmacions següents són vertaderes? \\(E(\\widetilde{S}_X^2)=\\sigma^2\\). \\(E(\\widetilde{S}_X)=\\sigma\\). \\(\\widetilde{S}_X^2\\) segueix una distribució \\(\\chi^2\\) amb \\(n-1\\) graus de llibertat. \\((n-1)\\widetilde{S}_X^2/\\sigma^2\\) segueix una distribució \\(\\chi^2\\) amb \\(n-1\\) graus de llibertat. Totes les altres respostes són falses. (2) Quina o quines de les afirmacions següents sobre la mitjana mostral són vertaderes? Si la distribució poblacional és normal, sempre coincideix amb la mediana de la mostra. Sempre serveix per estimar la mitjana poblacional. Sempre serveix per estimar la mediana poblacional. Si la distribució poblacional és normal, serveix per estimar la mediana poblacional. Cap de les altres respostes és correcta. (3) L’error estàndard de la mitjana mostral de mida \\(n\\geqslant 2\\) (marca totes les continuacions correctes): Mesura la variabilitat de les observacions que formen la mostra. És l’exactitud amb què es mesura cada observació de la mostra. Mesura la variabilitat de les mitjanes mostrals de mostres aleatòries simples. Mesura la precisió amb què les mitjanes mostrals de mostres aleatòries simples estimen la mitjana poblacional. És proporcional a la mitjana mostral. És més gran que la desviació típica de la població. Sobre cada mostra val la desviació típica de la mostra. Cap de les altres respostes és correcta. (4) La proporció d’afectats per una determinada malaltia en una població és del 10%. Si estimam aquesta proporció poblacional repetidament a partir de mostres de mida 1000, aquestes estimacions segueixen una distribució que (marca totes les afirmacions correctes): És una distribució mostral. És aproximadament normal. Té mitjana 0.1. Té variància 90. És binomial. Cap de les altres respostes és correcta. (5) Què hem de fer per disminuir a la meitat l’error estàndard d’una proporció? Hem d’augmentar en un 50% la mida de la mostra Hem de doblar la mida de la mostra. Hem de quadruplicar la mida de la mostra. Hem de dividir per 2 la mida de la mostra. Hem de dividir per 4 la mida de la mostra. Cap de les altres respostes és correcta. (6) La probabilitat que els individus d’una determinada població tenguin una determinada característica \\(C\\) és \\(p\\). Prenem mostres aleatòries simples de mida \\(n\\) d’aquesta població, i indicam amb \\(\\widehat{p}_X\\) la seva proporció mostral. Quina o quines de les afirmacions següents són vertaderes? \\(\\widehat{p}_X\\) té sempre distribució binomial \\(B(n,p)\\). \\(\\widehat{p}_X\\) té sempre distribució normal. Si \\(n\\) és gran, \\(\\widehat{p}_X\\) té distribució aproximadament binomial \\(B(n,p)\\). Si \\(n\\) és gran, \\(\\widehat{p}_X\\) té distribució aproximadament normal. L’error estàndard de \\(\\widehat{p}_X\\) és \\(\\sqrt{p(1-p)/n}\\). (7) Sigui \\(X\\) una variable aleatòria que no és constant. Si en prenem mostres aleatòries simples més grans (marca totes les continuacions correctes): La mitjana mostral sempre disminueix. L’error estàndard de la mitjana sempre disminueix. L’error estàndard de la mitjana sempre augmenta. La variància mostral sempre augmenta. El nombre de graus de llibertat de l’estimador \\(\\chi^2\\) associat a la variància mostral sempre augmenta. Cap de les altres respostes és correcta. (8) La longitud d’una determinada espècie d’animalons té un valor mitjà de \\(\\mu\\) cm. Si prenem mostres aleatòries simples de 20 exemplars, calculam la seva mitjana mostral \\(\\overline{X}\\) i la seva desviació típica mostral \\(\\widetilde{S}_X\\) (marca la continuació més correcta): L’estadístic \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) segueix sempre una llei normal. L’estadístic \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) segueix sempre una llei t de Student. L’estadístic \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) segueix una llei normal si la longitud segueix una llei normal. L’estadístic \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) segueix una llei t de Student si la longitud segueix una llei normal. L’estadístic \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) no segueix mai ni una llei normal ni una llei t de Student, perquè les mostres no són prou grans. (9) En una mostra de 100 dones es va obtenir una concentració mitjana d’hemoglobina en sang de 10 amb una desviació típica de 2. Quin és l’error típic de la mostra? 0.02 0.04 0.2 0.4 1 Cap dels valors anteriors (10) Què significa que un estimador d’un paràmetre d’una variable aleatòria sigui no esbiaixat? Que la distribució mostral de l’estimador és normal. Que aplicat a una mostra aleatòria simple sempre dóna el valor poblacional del paràmetre. Que el seu valor esperat és igual al valor poblacional del paràmetre. Que aplicat a una mostra aleatòria simple sempre dóna el valor esperat del paràmetre. Que el seu error típic és petit. (11) La concentració en sang a les persones d’un determinat metabolit (en mg/ml) té una distribució \\(N(23,3)\\). Quina de les afirmacions següents és vertadera? Aproximadament un 90% de les mostres aleatòries de 100 individus tendran la seva mitjana entre 22.4 i 23.6 mg/ml. Aproximadament un 95% de les mostres aleatòries de 100 individus tendran la seva mitjana entre 22.4 i 23.6 mg/ml. Aproximadament un 99% de les mostres aleatòries de 100 individus tendran la seva mitjana entre 22.4 i 23.6 mg/ml. Més d’un 99% de les mostres aleatòries de 100 individus tendran mitjana igual a 23. Cap de les afirmacions anteriors és vertadera. (12) Sigui \\(X\\) una variable aleatòria \\(N(\\mu_X,2)\\) i sigui \\(\\overline{X}\\) la mitjana mostral de mida \\(10\\) de \\(X\\). Quina de les afirmacions següents és vertadera? La desviació típica de \\(\\overline{X}\\) és igual a 2. La desviació típica de \\(\\overline{X}\\) és menor que 2. La desviació típica de \\(\\overline{X}\\) és major que 2. Que la desviació típica de \\(\\overline{X}\\) sigui major, menor o igual que 2 depèn de \\(\\mu_X\\). Cap de les afirmacions anteriors és vertadera. (13) Quan un estimador és màxim versemblant? Quan, aplicat a una mostra, sempre dóna el valor real del paràmetre. Quan tots els estadístics el consideren versemblant Quan, aplicat a una mostra, dóna el valor que fa màxima la probabilitat del paràmetre. Quan, aplicat a una mostra, dóna el valor del paràmetre que fa màxima la probabilitat de la mostra. Quan el seu valor esperat és el valor real del paràmetre. "],
["chap-IC.html", "Tema 4 Intervals de confiança 4.1 Definició d’interval de confiança 4.2 Exemple: Interval de confiança del 95% per a la mitjana d’una variable aleatòria normal 4.3 Interval de confiança per a la mitjana basat en la t de Student 4.4 Intervals de confiança per a proporcions 4.5 Intervals de confiança per a la variància i la desviació típica d’una variable normal 4.6 “Poblacions finites” 4.7 Test de la lliçó 4", " Tema 4 Intervals de confiança Amb l’estimació puntual intentam endevinar el valor d’un paràmetre d’una variable poblacional. Però, és clar, és molt difícil que amb una mostra poguem encertar exactament el valor del paràmetre. Les tècniques de l’estadística inferencial ens permeten aleshores quantificar la precisió d’aquesta estimació. Això es fa complementant l’estimació puntual amb un interval al voltant d’aquesta estimació “on estam molt segurs que cau el valor real del paràmetre”. Figura 4.1: elEconomista.es, 27/5/2019 Naturalment, no fa falta saber estadística per donar un interval on estiguem molt segurs que cau el valor real del paràmetre. Basta donar un interval prou ample com per contenir tots els valors raonables del paràmetre. Del que es tracta és de donar un interval el més estret possible on estiguem molt segurs que cau el valor real del paràmetre. Aleshores, l’amplada d’aquest interval dependrà: De la variabilitat de l’estimador: com ja hem comentat a la lliçó anterior, com manco variabilitat tingui, més precisa serà l’estimació. Normalment, la variabilitat de l’estimador creix amb la desviació típica de la variable poblacional i decreix amb la mida de les mostres. Del nivell de confiança, o seguretat, de l’estimació: com de segurs volem estar que el valor real del paràmetre cau dins l’interval que donem. Quant més segurs volguem estar, segurament més ample haurà de ser l’interval. 4.1 Definició d’interval de confiança Un interval de confiança del Q% (abreujadament, un IC Q%) d’un paràmetre poblacional és un interval obtingut aplicant a una mostra aleatòria simple de mida \\(n\\) una fórmula que satisfà la propietat següent: El Q% dels intervals obtinguts aplicant aquesta fórmula a mostres aleatòries simples de mida \\(n\\) contenen el valor real del paràmetre poblacional que es vol estimar. És a dir: Un Q% dels IC Q% contenen el valor real del paràmetre poblacional. Tenir una confiança del Q% significa doncs que hem calculat l’interval amb una fórmula que encerta el Q% de les vegades, en el sentit que en Q de cada 100 vegades que aplicàssim aquesta fórmula a mostres aleatòries simples, els intervals que obtendríem contendrien el valor real del paràmetre que volem estimar. Però aquesta fórmula s’equivoca el (100-Q)% de les vegades, és a dir, 100-Q de cada 100 intervals obtinguts aplicant aquesta fórmula a mostres aleatòries simples no contenen el valor real del paràmetre que volem estimar. I no sabem quin és el nostre cas. Nosaltres només podem confiar que hagi encertat amb la nostra mostra. Exemple 4.1 En un experiment hem mesurat el percentatge d’augment d’alcohol en sang a 40 persones després de prendre 4 canyes de cervesa. La mitjana i la desviació típica mostral d’aquests percentatges d’increment han estat \\(\\overline{X}=41.2\\) i \\(\\widetilde{S}_X=2.1\\). Com veurem a l’Exemple 4.4, un IC 95% per al percentatge d’augment mitjà d’alcohol en sang d’una persona després de beure 4 canyes de cervesa és [40.53, 41.87]. Això significa que estam “molt segurs” que l’augment mitjà d’alcohol en sang d’una persona després de beure 4 canyes de cervesa està entre el 40.53% i el 41.87%, perquè aquest interval l’haurem calculat amb una fórmula que el 95% de les vegades que l’aplicàssim a una mostra aleatòria simple de mida 40 donaria un interval que conté la mitjana poblacional que volem estimar. Nosaltres som optimistes i “confiam” que el nostre interval pertany a aquest 95% d’intervals que l’encerten. Sovint això ho trobareu expressat com : Hi ha un 95% de probabilitat que l’interval [40.53, 41.87] contengui el valor real de l’augment mitjà d’alcohol en sang d’una persona després de beure 4 canyes de cervesa. Però cal entendre el que diu aquesta frase: Per definició, un 95% dels intervals de confiança del 95% per a l’augment mitjà d’alcohol etc. contenen el valor real d’aquest augment mitjà. [40.53, 41.87] és un interval de confiança del 95% per a l’augment mitjà d’alcohol etc. Aleshores, [40.53, 41.87] té una probabilitat del 95% de contenir el valor real de l’augment mitjà d’alcohol etc. en el mateix sentit que si un 95% de les persones tenen una determinada característica, i prenc una persona a l’atzar, aquesta persona té un 95% de probabilitat de tenir aquesta característica. No confongueu: Interval de referència del Q% per a una variable aleatòria: Interval que conté el valor de la variable aleatòria en un individu amb probabilitat Q%. Interval de confiança del Q% per a un paràmetre: Interval que conté el valor poblacional del paràmetre de la variable aleatòria “amb probabilitat” Q%, en el sentit que l’hem calculat amb una fórmula que dóna un interval que conté el paràmetre el Q% de les vegades que l’aplicam a una mostra aleatòria simple. Interval de referència del Q% per a un estimador: Interval que conté el valor de l’estimador sobre una mostra amb probabilitat Q%. Per exemple: Si diem que un interval de referència del 95% per a la concentració d’una proteïna en sèrum en individus sans mesurada en g/dl és [11,16], això significa que un 95% dels individus sans tenen una concentració d’aquesta proteïna en sèrum d’entre 11 i 16 g/dl, és a dir, que un individu sa escollit a l’atzar té un 95% de probabilitat que la seva concentració d’aquesta proteïna en sèrum estigui entre 11 i 16 g/dl. Si diem que un interval de confiança del 95% per a la concentració mitjana d’una proteïna en sèrum en individus sans mesurada en g/dl és [11,16], això significa que hem pres una mostra aleatòria simple de concentracions d’aquesta proteïna en sèrum en individus sans i a partir d’aquesta mostra: Hem estimat que la concentració mitjana d’aquesta proteïna en sèrum en individus sans està entre 11 i 16 g/dl I tenim un “95% de confiança” en aquest interval perquè el 95% dels intervals que s’obtenen en aplicar aquesta fórmula a mostres aleatòries simples de la mateixa mida que la nostra contenen la mitjana poblacional. Si diem que el 95% de les mostres de 100 concentracions d’una determinada proteïna en sèrum en individus sans tenen la mitjana mostral entre 11 i 16, això és un interval de referència del 95% per a la mitjana mostral de mostres de mida 100, no un interval de confiança per a la concentració mitjana poblacional ni un interval de referència per al valor de la concentració en un individu. Sovint calculareu un interval de confiança del Q% per a un cert paràmetre \\(\\theta\\) d’una població, us donarà \\([a,b]\\), i amb el poc rigor amb què us soleu expressar, us serà igual dir “el valor real de \\(\\theta\\) té una probabilitat del Q% de pertànyer a \\([a,b]\\)” que “\\([a,b]\\) té una probabilitat del Q% de contenir el valor real de \\(\\theta\\)” Però aquestes dues frases no diuen exactament el mateix. I de fet, la primera és falsa i la segona la interpretam com a vertadera. Fixau-vos que a la primera frase parlam de la probabilitat que a \\(\\theta\\) li passi qualque cosa, i a la segona que sigui a \\([a,b]\\) a qui li passi qualque cosa. La primera frase diu que \\(\\theta\\) varia i un Q% dels seus valors pertanyen a \\([a,b]\\). Això és fals. “El valor real de \\(\\theta\\)” és un número que no varia. Per a la nostra població val una cosa concreta, desconeguda però concreta, que pertany o no a l’interval \\([a,b]\\). La segona frase en canvi es pot interpretar de la manera següent. L’interval \\([a,b]\\) forma part de tota la població d’intervals de confiança del Q% per a \\(\\theta\\) calculats a partir de mostres aleatòries simples d’una mida concreta de la nostra població. Un Q% d’aquests intervals conté el valor real de \\(\\theta\\). Per tant, podem dir que el nostre interval \\([a,b]\\) té una probabilitat del Q% de contenir el valor real de \\(\\theta\\). Aquesta interpretació és correcta. Encara que el millor que podeu fer és no mesclar probabilitat amb confiança, i dir simplement que teniu un 95% de confiança, o un 95% de seguretat, que \\([a,b]\\) conté el valor real de \\(\\theta\\). Així no us enganxau els dits. Que un IC Q% per a un paràmetre \\(\\theta\\) sigui \\([a,b]\\) serveix: Per estimar \\(\\theta\\) amb aquest marge de confiança: Estam bastant segurs que el valor poblacional de \\(\\theta\\) està entre \\(a\\) i \\(b\\). Per poder comparar el valor poblacional de \\(\\theta\\) amb un valor concret amb aquest marge de confiança: Estam bastant segurs que el valor real de \\(\\theta\\) no està ni per sota de \\(a\\) ni per sobre de \\(b\\) i per tant que és diferent de tots aquests valors. Exemple 4.2 Si un IC 95% per a la prevalença \\(p\\) d’una determinada característica en una població (la fracció d’individus que tenen aquesta característica) va de 0.025 a 0.047: Estam molt (“un 95%”) segurs que \\(p\\in [0.025,0.047]\\) (perquè un 95% dels intervals calculats amb la fórmula que hem emprat contendrien \\(p\\)) Estam molt segurs que \\(p&gt;0.02\\) (perquè tot l’interval on estam molt segurs que cau el valor real de \\(p\\) està a la dreta de 0.02) Estam molt segurs que \\(p\\neq 0.05\\) (perquè 0.05 no pertany a l’interval on estam molt segurs que sí que cau el valor real de \\(p\\)) Però no estam molt segurs que \\(p=0.03\\), per molt que \\(0.03\\in [0.025,0.047]\\): estam molt segurs que \\(p\\) està entre 0.025 i 0.047, però no tenim cap seguretat que valgui un valor concret entre aquests límits, només que està entre aquests límits. En tot cas, com que 0.03 pertany a l’interval on creiem que cau el valor real de \\(p\\), podem dir que, amb un nivell de confiança del 95%, \\(p\\) podria ser 0.03. O també que, amb un nivell de confiança del 95%, no podem rebutjar que \\(p\\) sigui 0.03. Hi ha dos tipus de mètodes bàsics de càlcul d’intervals de confiança a partir de mostres aleatòries: Paramètrics: Usant alguna fórmula basada en la distribució mostral de l’estimador. Es basen en teoremes i només serveixen si la variable aleatòria \\(X\\) i la mostra aleatòria satisfan (aproximadament) les hipòtesis del teorema. No paramètrics: Tots els altres. El nostre preferit és el bootstrap: Es prenen a l’atzar moltes mostres aleatòries amb reposició de la mostra, totes de la mateixa mida que la mostra. Es calcula l’estimador amb cada una d’aquestes mostres. S’usa el vector de resultats per estimar un interval de confiança. Per exemple, podem prendre com a IC 95% l’interval amb extrems els quantils 0.025 i 0.975 d’aquest vector. El bootstrap es pot usar sempre i funciona bé si la mostra és aleatòria, però es basa en un procés aleatori i per tant cada execució sobre una mateixa mostra pot donar un interval diferent. El bootstrap és una eina molt poderosa per calcular intervals de confiança i, en general, per estimar la distribució mostral d’un estadístic. Tant, que a la pràctica ja comença a substituir els mètodes paramètrics. Emperò no fa miracles: si la mostra és petita o molt poc representativa de la població, un IC calculat amb el bootstrap serveix de tan poc com un de calculat amb un mètode paramètric. Figura 4.2: En anglès, la bootstrap és la cingla de la bota, i el mètode del bootstrap refereix a la frase feta anglesa “elevar-se estirant-se de les cingles” 4.2 Exemple: Interval de confiança del 95% per a la mitjana d’una variable aleatòria normal Una de les fórmules més conegudes per a intervals de confiança és la següent: Si \\(X\\) és normal i en tenim una mostra aleatòria simple de mida \\(n\\), mitjana mostral \\(\\overline{X}\\) i desviació típica mostral \\(\\widetilde{S}_X\\), un IC 95% per a la seva mitjana \\(\\mu\\) és \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] on \\(t_{n-1,0.975}\\) indica el 0.975-quantil de la distribució \\(t_{n-1}\\). A alguns de vosaltres us hauran explicat a Batxillerat, o trobareu a llibres que consulteu, una fórmula per a l’IC 95% per a \\(\\mu\\) similar a aquesta, però canviant-hi la \\(\\widetilde{S}_X\\) per la desviació típica de \\(X\\), \\(\\sigma\\), i el \\(t_{n-1,0.975}\\) per \\(z_{0.975}\\). Aquesta altra fórmula només es pot fer servir si sabeu què val \\(\\sigma\\), que a la pràctica, mai serà el cas. Per tant, per favor, oblidau-la. Vegem d’on surt aquesta fórmula, ja que és un paradigma de com s’obtenen la majoria de les fórmules paramètriques per a intervals de confiança. Suposem doncs que \\(X\\) és normal de mitjana \\(\\mu\\) i que en tenim una mostra aleatòria simple de mida \\(n\\), mitjana mostral \\(\\overline{X}\\) i desviació típica mostral \\(\\widetilde{S}_X\\). En aquesta situació, sabem que \\[ T=\\frac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}} \\] té distribució t de Student amb \\(n-1\\) graus de llibertat, \\(t_{n-1}\\). Si podem trobar \\(A,B\\in \\mathbb{R}\\) tals que \\[ P(A\\leqslant T\\leqslant B)=0.95, \\] llavors: \\[ \\begin{array}{rl} 0.95 &amp;\\!\\!\\!\\! =P\\Bigg(A\\leqslant \\dfrac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}}\\leqslant B\\Bigg)\\\\[2ex] &amp;\\!\\!\\!\\! =P\\Bigg(A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant \\overline{X}-\\mu \\leqslant B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp;\\!\\!\\!\\! =P\\Bigg(-\\overline{X}+A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant -\\mu \\leqslant -\\overline{X}+B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp;\\!\\!\\!\\! =P\\Bigg(\\overline{X}-B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant \\mu \\leqslant \\overline{X}-A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg) \\end{array} \\] Com que \\(P(A\\leqslant T\\leqslant B)=0.95\\) significa que, per al 95% de les mostres aleatòries simples de mida \\(n\\), el valor de \\(T\\) està entre \\(A\\) i \\(B\\), \\[ P\\Bigg(\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant \\mu \\leqslant \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)=0.95 \\] significa que, per al 95% de les mostres aleatòries simples de mida \\(n\\), la \\(\\mu\\) cau dins l’interval \\[ \\Bigg[\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Per tant, això serà un IC 95% per a \\(\\mu\\). Ens falta trobar els \\(A,B\\) tals que \\(P(A\\leqslant T\\leqslant B)=0.95\\). Per trobar-los, emprarem quantils de la distribució de \\(T\\). Recordem que si indicam amb \\(t_{n-1,0.975}\\) el 0.975-quantil d’una \\(t_{n-1}\\), per definició tenim que \\[ P(T\\leqslant t_{n-1,0.975})=0.975 \\] i per la simetria de la \\(t\\), \\[ P(T\\leqslant -t_{n-1,0.975})=P(T\\geqslant t_{n-1,0.975})=0.025 \\] Per tant: \\[ \\begin{array}{l} P(-t_{n-1,0.975}\\leqslant T\\leqslant t_{n-1,0.975})\\\\ \\quad =P(T\\leqslant t_{n-1,0.975})-P(T\\leqslant -t_{n-1,0.975})\\\\ \\quad =0.975-0.025=0.95 \\end{array} \\] Així doncs, podem prendre \\[ A=-t_{n-1,0.975},\\quad B=t_{n-1,0.975} \\] i obtenim l’IC 95% per a \\(\\mu\\) anunciat: \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] L’escriurem \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Exemple 4.3 Fem un experiment per veure que, efectivament, aquesta fórmula “encerta”, en el sentit que conté la \\(\\mu\\), al voltant del 95% de les vegades. Al bloc de codi següent, hi generam una Població de 107 “individus” que segueixen una llei normal estàndard i en calculam la mitjana mu. A continuació, definim una funció IC que calcula l’IC 95% per a la mitjana \\(\\mu\\) amb la fórmula anterior. Llavors, prenem 200 mostres aleatòries simples de mida 50 de la nostra població i les aplicam aquesta funció, obtenint una matriu M de 200 columnes formades pels dos extrems dels intervals (l’inferior a la primera filera i el superior a la segona filera). Finalment, comptam quantes vegades hem encertat, és a dir, a quantes columnes de M la mitjana poblacional mu està entre l’entrada de la primera filera i la de la segona. set.seed(42) Poblacio=rnorm(10^7) mu=mean(Poblacio) IC=function(x){ n=length(x) mean(x)+qt(0.975,n-1)*sd(x)/sqrt(n)*c(-1,1)} M=replicate(200,IC(sample(Poblacio,50,replace=TRUE))) Encerts=length(which(mu&gt;=M[1,] &amp; mu&lt;=M[2,])) Encerts ## [1] 189 Hem encertat 189 vegades, és a dir, un 94.5% de les vegades. És aproximadament el que esperàvem. Si ho provau amb altres llavors d’aleatorietat obtendreu altres resultats, de vegades millors, de vegades pitjors. Per veure millor els encerts, dibuixam els intervals en un gràfic, on apareixeran en gris els que contenen la mu i en vermell els que no. plot(1,type=&quot;n&quot;,xlim=c(-0.8,0.8),ylim=c(0,200), xlab=&quot;Valors&quot;,ylab=&quot;Repeticions&quot;, main=&quot;200 IC 95%&quot;) seg.int=function(i){color=&quot;grey&quot;; if((mu&lt;M[1,i]) | (mu&gt;M[2,i])){color=&quot;red&quot;} segments(M[1,i],i,M[2,i],i,col=color,lwd=2)} sapply(1:200,FUN=seg.int) abline(v=mu,lwd=2) Com veieu, de mitjana, un (100-Q)% dels IC Q% NO contenen el valor real del paràmetre. Per exemple, de mitjana, un 5% de les vegades que calculam un IC 95%, el paràmetre poblacional no pertany a l’interval obtingut. Per tant, si calculam \\(n\\) IC 95% sobre mostres aleatòries simples independents, el nombre de vegades que l’interval resultant no contendrà el paràmetre poblacional seguirà una distribució binomial \\(B(n,0.05)\\). El gràfic següent dóna el valor de \\(P(X\\geqslant 1)\\) per a una variable aleatòria \\(X\\) de tipus \\(B(n,0.05)\\), per a \\(n=0,...,100\\), i per tant la probabilitat que si calculam \\(n\\) IC 95% sobre mostres aleatòries simples independents, almanco un d’ells no contengui el paràmetre poblacional desitjat. Figura 4.3: Probabilitat d’algun èxit amb una B(n,0.05) Tornant a l’IC 95% per a \\(\\mu\\) d’una variable normal donat per la fórmula \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] fixau-vos que: Està centrat en \\(\\overline{X}\\), per tant en cada càlcul estarà centrat en la mitjana mostral. Tal i com l’hem calculat, la probabilitat que l’interval no contengui la \\(\\mu\\) es reparteix per igual als dos costats: en un 2.5% dels intervals la \\(\\mu\\) poblacional estarà a l’esquerra de l’extrem inferior i en un altre 2.5% estarà a la dreta de l’extrem superior. Per exemple, \\[ \\begin{array}{l} 0.025\\!\\!\\!\\!\\! &amp; =P(T&gt; t_{n-1,0.975})\\\\ &amp;\\displaystyle =P\\Big(\\dfrac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}} &gt; t_{n-1,0.975}\\Big)\\\\ &amp;\\displaystyle =P\\Big(\\mu&lt;\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Big) \\end{array} \\] Exemple 4.4 En un experiment hem mesurat el percentatge d’augment d’alcohol en sang a 40 persones després de prendre 4 canyes de cervesa. La mitjana i la desviació típica mostral d’aquests percentatges d’increment han estat \\[ \\overline{X}=41.2,\\quad \\widetilde{S}_X=2.1 \\] Per calcular un IC 95% per al percentatge mitjà d’augment, suposarem que la variable aleatòria d’interès (de la que volem estimar la mitjana), que és \\(X\\): “Prenem una persona i li mesuram el percentatge d’augment d’alcohol en sang després de prendre 4 canyes de cervesa” és normal i que la mostra que hem pres d’aquesta variable és aleatòria simple. Llavors, com que \\(t_{n-1,0.975}\\)=qt(0.975,39)=2.0227, un IC 95% és \\[ 41.2\\pm 2.0227\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67\\Rightarrow [40.53, 41.87] \\] Per tant, estimam amb un 95% de confiança que el percentatge mitjà d’augment d’alcohol en sang després de prendre 4 canyes de cervesa està entre el 40.53% i el 41.87%. Per calcular l’interval anterior hem suposat que la variable poblacional “Percentatge d’augment d’alcohol en sang després de prendre 4 canyes de cervesa” segueix una distribució normal. I si no és normal? En aquest cas, com que \\(n=40\\) és “gran”, pel Teorema 4.2 de la propera secció l’interval obtingut segueix essent (aproximadament) un interval de confiança del 95% per a \\(\\mu\\) Si \\(n\\) fos petit i \\(X\\) molt diferent d’una normal, no es podria usar aquesta fórmula i caldria cercar-se la vida (per exemple, emprar el mètode de bootstrap) També hem suposat que era una mostra aleatòria simple. I si no ho fos? Si fos aleatòria, com que el nombre de persones que poden prendre 4 canyes de cervesa és pràcticament la població mundial, molt gran, a efectes pràctics la podríem considerar simple. Però segur que no és aleatòria, sinó oportunista. No hem tret per sorteig 40 persones de la llista de tota la població mundial, ni tan sols de la de Mallorca, i les hem convidat a 4 cerveses, sinó que hem cercat voluntaris. En aquest cas no podem fer res per salvar la fórmula, i la seva validesa depèn de si la mostra de persones presa pot passar per aleatòria o no. 4.3 Interval de confiança per a la mitjana basat en la t de Student A partir d’ara, per tal d’evitar ambigüitats, a les fórmules hi expressarem el nivell de confiança dels intervals en tant per u, no en tant per cent; és a dir, com una proporció en comptes de com un percentatge. Per tant, en lloc d’intervals de confiança del \\(Q\\%\\), parlarem d’intervals de confiança de nivell de confiança \\(q\\), amb \\(q=Q/100\\) entre 0 i 1. Amb aquestes notacions, per exemple, els intervals de confiança del 95% seran intervals de confiança de nivell de confiança 0.95. La fórmula El mateix argument que abans, canviant 0.95 per \\(q\\) dóna: Teorema 4.1 Si \\(X\\) és normal i en prenem una mostra aleatòria simple de mida \\(n\\), un interval de confiança de nivell de confiança \\(q\\) (en tant per u) per a la seva mitjana \\(\\mu\\) és \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Fixau-vos que als IC 95%, \\(q=0.95\\) i per tant \\((1+q)/2=1.95/2=0.975\\). Usant el Teorema Central del Límit i algunes aproximacions, tenim el següent resultat: Teorema 4.2 Sigui \\(X\\) una variable aleatòria qualsevol de mitjana poblacional \\(\\mu\\). Suposem que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) gran (diguem, de 40 o més elements). Llavors, un interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu\\) és aproximadament \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] L’aproximació del teorema anterior és millor com més gran sigui \\(n\\) o com més propera a una normal sigui la variable poblacional \\(X\\). En resum: Podem emprar la fórmula per a l’interval de confiança de nivell de confiança \\(q\\) per a la mitjana poblacional basada en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] quan la variable poblacional és normal o quan la mostra aleatòria simple és gran. Exemple 4.5 L’empresa RX-print ofereix una impressora de radiografies d’altíssima qualitat. En la seva publicitat afirma que els seus cartutxos imprimeixen una mitjana de 500 radiografies amb l’especificació: Dades tècniques: Mostra de mida \\(n=25\\), població suposada normal, nivell de confiança del 90% Uns radiòlegs desitgen comprovar aquestes afirmacions i prenen una mostra de 25 cartutxos, obtenint una mitjana de 518 radiografies amb una desviació típica mostral de 39.9. Amb aquesta mostra, la mitjana poblacional anunciada pel fabricant cau dins l’interval de confiança del 90%? La variable aleatòria d’interès és \\(X\\) és “Prenem un cartutx d’aquesta empresa i miram el nombre de radiografies que permet imprimir”, de mitjana \\(\\mu\\) per a la qual volem calcular un IC 90%. Suposarem que la variable \\(X\\) és normal, perquè l’empresa ho suposa a les dades tècniques, i que la mostra és aleatòria simple. Per tant podem emprar la fórmula \\[ \\overline{X}\\pm t_{n-1,(q+1)/2} \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] on \\(n=25\\), \\(\\overline{X}=518\\), \\(\\widetilde{S}_X=39.9\\), \\(q=0.9\\), \\((q+1)/2=0.95\\) i \\(t_{24,0.95}\\)=qt(0.95,24)\\(=1.71\\). Operant: \\[ 518\\pm 1.71\\times \\frac{39.9}{\\sqrt{25}}\\Rightarrow 518\\pm 13.65\\Rightarrow [504.35,531.65] \\] Tenim, doncs, un 90% de confiança que el nombre mitjà de radiografies per cartutx està entre 504.35 i 531.65, i en particular que és més gran que 500. Exemple 4.6 A l’exemple anterior hem suposat que la variable aleatòria era normal. Què passaria si fos molt diferent d’una normal? Com que \\(n=25\\) no és prou gran, en principi no podríem aplicar la fórmula de l’interval de confiança basada en la t de Student. Emprarem el mètode del bootstrap, per a la qual cosa necessitam tenir les dades originals, i no només els seus estadístics. Tenim aquestes dades en el vector Radios següent: Radios=c(485,511,509,509,561,529,458,532,545,546,503,577, 547,477,507,548,480,444,461,573,513,604,542,501,488) mean(Radios) ## [1] 518 sd(Radios) ## [1] 39.89987 Prenem 5000 mostres aleatòries simples de mida 25 (la mateixa mida que el conjunt de dades original) de les dades i calculam la mitjana de cada mostra; fixam la llavor d’aleatorietat perquè el càlcul sigui reproduïble: set.seed(100) Simulacions=replicate(5000,mean(sample(Radios,25,rep=TRUE))) Ara prenem com a IC 90% l’interval que tanca el 90% de valors centrals d’aquest vector de mitjanes mostrals, és a dir, l’interval que va del quantil 0.05 al quantil 0.95 d’aquest vector de mitjanes: quantile(Simulacions,c(0.05,0.95)) ## 5% 95% ## 504.96 530.92 Obtenim l’interval [504.96,530.92]: amb la fórmula basada en la t de Student, havíem obtingut l’interval [504.35,531.65]. Algunes consideracions Observau que l’estructura de l’interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu\\) donat al Teorema 4.2 és \\[\\begin{align} &amp; \\text{estimador}\\nonumber\\\\ &amp; \\qquad \\pm \\frac{1+q}{2}\\text{-quantil de la distr. mostral}\\times \\text{error típic de l&#39;estimació} \\tag{4.1} \\end{align}\\] Aquesta estructura és bastant típica (tot i que no universal: no tots els intervals de confiança paramètrics tenen aquesta forma) i satisfà que: L’interval de confiança està centrat en el valor de l’estimador La probabilitat que l’interval no contengui la \\(\\mu\\) es reparteix per igual als dos costats: en una fracció \\(q/2\\) dels intervals la \\(\\mu\\) poblacional estarà a l’esquerra de l’extrem inferior i en una fracció \\(q/2\\) dels intervals estarà a la dreta de l’extrem superior. A més, tenim que: Per a una mateixa mostra i una mateixa fórmula (paramètrica) per calcular l’interval de confiança, si el nivell de confiança creix, l’interval s’eixampla. Això és general, per a tots els intervals de confiança paramètrics. La idea intuïtiva és que, per augmentar la probabilitat que un interval contengui el valor del paràmetre, hem de prendre un interval més ample. A un interval de confiança amb l’estructura (4.1), el motiu matemàtic és que si \\(q\\) creix, el quantil d’ordre (1+\\(q\\))/2 de la distribució mostral es fa més gran. Per exemple, a l’Exemple 4.4, teníem \\(n=40\\), \\(\\overline{X}=41.2\\) i \\(\\widetilde{S}_X=2.1\\): L’IC 95% té \\(q=0.95\\), per tant \\(t_{n-1,(1+q)/2}=t_{39,0.975}=2.02\\), i donava \\[ 41.2\\pm 2.02\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67 \\] L’IC 99% té \\(q=0.99\\), per tant \\(t_{n-1,(1+q)/2}=t_{39,0.995}=2.71\\), i dóna \\[ 41.2\\pm 2.71\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.9 \\] més ample Però si canviam de mostra (o de fórmula, si n’hi ha més d’una) per calcular l’interval de confiança, pot passar qualsevol cosa. Amb R La funció t.test(X,conf.level=...)$conf.int calcula l’interval de confiança basat en la t de Student per a la \\(\\mu\\) de la variable aleatòria de la que el vector X n’és una mostra. El paràmetre conf.level permet especificar el nivell de confiança (en tant per u). El seu valor per defecte és 0.95, així que per calcular un IC 95% no cal especificar-lo. Per exemple, l’IC 90% per al nombre mitjà de radiografies per cartutx de l’Exemple 4.5 es calcularia amb t.test(Radios,conf.level=0.9)$conf.int ## [1] 504.3472 531.6528 ## attr(,&quot;conf.level&quot;) ## [1] 0.9 Càlcul de la mida de la mostra per fixar l’error Recordem que l’interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu\\) basat en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] és simètric i centrat en \\(\\overline{X}\\). La seva amplada és la diferència entre els seus extrems \\[ 2t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] El marge d’error (error, precisió) \\(M\\) en l’estimació de \\(\\mu\\) per mitjà d’aquest interval de confiança és el que sumam i restam a \\(\\overline{X}\\) per obtenir l’interval, és a dir, la meitat de la seva amplada: \\[ M=t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Anau alerta amb el llenguatge. Un interval és més precís quan és més estret. Per tant, si dieu precisió, en lloc d’error o marge d’error, a la meitat de l’amplada de l’interval, l’interval serà més precís quant més petita sigui la seva precisió. Sona molt malament. Una pregunta típica a l’hora de planejar un experiment és quina ha de ser la mida de la mostra que hem de prendre perquè el marge d’error en estimar \\(\\mu\\) amb un nivell de confiança donat sigui com a màxim un cert valor desitjat \\(M_{max}\\). És a dir, volem trobar la \\(n\\) més petita tal que \\[ t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant M_{max}. \\] Però fixau-vos que en aquesta desigualtat la \\(n\\) hi apareix al quantil i a l’error típic, i a més la \\(\\widetilde{S}_X\\) depèn de la mostra. El que farem per respondre la pregunta serà fer algunes trampes: Aproximarem la t de Student per una normal estàndard (ja que segurament la \\(n\\) haurà de ser gran): \\[ t_{n-1,(1+q)/2}\\rightsquigarrow z_{(1+q)/2} \\] Estimarem el valor de \\(\\widetilde{S}_X\\) mitjançant la desviació típica mostral \\(\\widetilde{S}_0\\) d’una prova pilot (un experiment anterior, realitzat per nosaltres o publicat per qualcú altre a qualque lloc de confiança) D’aquesta manera, aproximam l’error \\(M\\) per mitjà de \\[ M\\approx z_{(1+q)/2}\\times \\frac{\\widetilde{S}_0}{\\sqrt{n}} \\] I ara si imposam que \\(M\\leqslant M_{max}\\), ja podem aïllar la \\(n\\): \\[ z_{(1+q)/2}\\times \\frac{\\widetilde{S}_0}{\\sqrt{n}}\\leqslant M_{max}\\Longrightarrow n\\geqslant \\left(\\frac{ z_{(1+q)/2}\\cdot \\widetilde{S}_0}{M_{max}} \\right)^2 \\] En resum: Per estimar la \\(\\mu\\) amb nivell de confiança \\(q\\) amb un marge d’error com a màxim \\(M_{max}\\) mitjançant la fórmula basada en la t de Student, prendrem una mostra de mida \\[ n\\geqslant \\left(\\frac{ z_{(1+q)/2}\\cdot \\widetilde{S}_0}{M_{max}} \\right)^2, \\] on \\(\\widetilde{S}_0\\) és la desviació típica mostral d’una mostra anterior (d’una prova pilot). Naturalment, quan després prenguem una mostra de mida \\(n\\) que satisfaci aquesta condició, pot passar qualsevol cosa, ja que hem emprat els resultats d’una mostra per estimar la desviació típica d’una altra mostra i a més hem aproximat els quantils de la t de Student per els d’una normal estàndard, que són més petits. Però almanco haurem fet tot el que haurem pogut per fitar l’error dins el marge desitjat. Exemple 4.7 A l’Exemple 4.4, hem emprat una mostra de \\(n=40\\) persones, amb \\(\\overline{X}=41.2\\) i \\(\\widetilde{S}_X=2.1\\), i l’error ha estat \\[ t_{0.975,39}\\cdot \\frac{2.1}{\\sqrt{40}}=0.67 \\] Quin és el nombre mínim de persones que hauríem hagut d’emprar per estimar la mitjana amb un nivell de confiança del 95% i un error de (com a màxim) 0.5? És a dir, quin el nombre mínim de persones que hauríem hagut d’emprar per obtenir un IC 95% d’amplada (com a màxim) 1? Emprarem la mostra d’aquell exemple com a prova pilot, i per tant prendrem \\(\\widetilde{S}_0=2.1\\): \\[ n\\geqslant \\left(\\frac{ z_{(1+q)/2}\\cdot \\widetilde{S}_0}{M_{max}} \\right)^2= \\left(\\frac{1.96\\cdot 2.1}{0.5} \\right)^2=67.77 \\] El valor de \\(n\\) més petit que satisfà aquesta condició és 68, per tant aquest és el nombre mínim de persones que hauríem hagut d’emprar per esperar obtenir un IC 95% d’amplada (com a màxim) 1. 4.4 Intervals de confiança per a proporcions Suposem que tenim una variable de Bernoulli \\(X\\) amb probabilitat d’èxit \\(p_X\\) desconeguda. Volem calcular un interval de confiança per a \\(p_X\\). Per fer-ho, prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\), amb nombre d’èxits \\(S_n\\) i per tant proporció mostral d’èxits \\(\\widehat{p}_{X}=S_n/n\\) Explicarem tres mètodes per calcular aquest interval de confiança: El mètode exacte de Clopper-Pearson, que es pot aplicar sempre però sol donar intervals de confiança més amples del necessari. El mètode aproximat de Wilson, que es pot emprar quan la mostra és gran, posem de mida 40 o més, i es basa en el fet que, pel Teorema Central del Límit, la proporció mostral de mostres aleatòries simples grans segueix una distribució aproximadament normal. El mètode aproximat de Laplace, que és una simplificació del mètode de Wilson, però només es pot emprar quan la mostra és bastant més gran, posem de mida 100 o més, i la proporció mostral \\(\\widehat{p}_{X}\\) no és molt propera a 0 o a 1. És el mètode més clàssic i conegut. Tots tres mètodes només valen per a mostres aleatòries simples, o almanco que puguin passar per aleatòries simples. Mètode “exacte” de Clopper-Pearson Aquest mètode es basa en el fet que el nombre d’èxits \\(S_n\\) en mostres aleatòries simples de mida \\(n\\) de \\(X\\) segueix una distribució binomial \\(B(n,p_X)\\). Raonant de manera similar a com obteníem l’interval per a \\(\\mu\\) basat en la t de Student (us estalviarem els detalls) arribam a la fórmula següent, que no fa falta ni que llegiu si no ho voleu: Teorema 4.3 Amb les notacions anteriors, un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) és \\([p_0,p_1]\\), on \\(p_0\\) és la solució de l’equació \\[ \\sum_{k=S_n}^n\\binom{n}{k}p_0^k(1-p_0)^{n-k}= \\frac{1-q}{2} \\] \\(p_1\\) és la solució de l’equació \\[ \\sum_{k=0}^{S_n}\\binom{n}{k}p_1^k(1-p_1)^{n-k}= \\frac{1-q}{2} \\] Calcular amb la calculadora aquest interval sol ser impossible, i normalment dóna més ample del necessari (degut a la natura discreta de la distribució binomial, que només pren valors nombres naturals), però es pot emprar amb mostres aleatòries simples de qualsevol mida ja que empra que el nombre d’èxits \\(S_n\\) en mostres aleatòries simples de mida \\(n\\) de \\(X\\) segueix una distribució binomial i això sempre és veritat. Per calcular-lo amb R, podeu emprar la funció del paquet epitools binom.exact(S,n,conf.level=...) on S és el nombre d’èxits, n la mida de la mostra, i conf.level el nivell de confiança en tant per u, que per defecte val 0.95. Exemple 4.8 De 10 pacients tractats amb un medicament, 2 s’han curat. Quin seria un IC 95% per a la proporció p de pacients que aquest medicament cura? Emprarem el mètode de Clopper-Pearson: library(epitools) round(binom.exact(2,10),3) ## x n proportion lower upper conf.level ## 1 2 10 0.2 0.025 0.556 0.95 La columna lower dóna l’extrem inferior de l’interval de confiança i la columna upper l’extrem superior. Obtenim, per tant, l’interval [0.025,0.556]. Estimam per tant amb una confiança del 95% que aquest medicament cura entre el 2.5% i el 55.6% dels pacients. Sí, aquest interval és molt ample. La culpa no és del mètode de Clopper-Pearson, és de la mida petita de la mostra. Un inconvenient de l’interval de Clopper-Pearson és que, en principi, no està centrat en \\(\\widehat{p}_{X}\\). Per exemple, el centre de l’interval anterior és \\((0.025+0.556)/2= 0.29\\), diferent de \\(\\widehat{p}_X=0.2\\) Mètode de Wilson Suposem ara que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) gran (posem, de 40 o més subjectes) i proporció mostral d’èxits \\(\\widehat{p}_{X}\\). En aquestes condicions, pel Teorema Central del Límit, \\[ \\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}} \\] és aproximadament \\(N(0,1)\\). Per tant \\[ P\\Big(-z_{(1+q)/2}\\leqslant \\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\leqslant z_{(1+q)/2}\\Big)\\approx q \\] Aïllant \\(p_X\\) amb una mica de paciència obtenim: Teorema 4.4 Si la mida \\(n\\) de la mostra és gran, un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) és (aproximadament): \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/{2}}^2}{2n}\\pm z_{(1+q)/{2}}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(1+q)/{2}}^2}{4n^2}}}{1+\\frac{z_{(1+q)/{2}}^2}{n}} \\] Amb R es calcula amb la funció binom.wilson(x,n,conf.level=...) del paquet epitools, amb la mateixa sintaxi que binom.exact. Aquest interval tampoc està centrat en \\(\\widehat{p}_{X}\\): el seu centre és \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/{2}}^2}{2n}}{1+\\frac{z_{(1+q)/{2}}^2}{n}} \\] Mètode de Laplace Suposem finalment que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) encara més gran i \\(\\widehat{p}_{X}\\) enfora de 0 i 1. Per fixar idees, suposem que \\[ n\\geqslant 100,\\ n\\widehat{p}_{X}\\geqslant 10,\\ n(1-\\widehat{p}_{X})\\geqslant 10 \\] Fixau-vos que \\(n\\widehat{p}_{X}\\) és el nombre d’èxits a la mostra i \\(n(1-\\widehat{p}_{X})=n-n\\widehat{p}_{X}\\) és el nombre de fracassos. En aquest cas, a la fórmula de l’interval de Wilson els termes \\(z_{(1+q)/{2}}^2/n\\) són molt petits per comparació amb els altres i els podem menysprear, igualant-los a 0. Obtenim la fórmula següent: Teorema 4.5 En les condicions explicades, un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) és (aproximadament): \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Amb R es calcula amb la funció binom.approx(x,n,conf.level=...) del paquet epitools, amb la mateixa sintaxi que binom.exact. Aquesta fórmula és la més popular, amb més de 200 anys de rodatge. Us heu de saber la fórmula de Laplace, no cal saber les fórmules dels altres dos intervals. Però sí que heu de saber quan es pot aplicar cadascuna. Exemple 4.9 En una mostra aleatòria de 500 famílies amb nins en edat escolar es va trobar que 340 introduïen fruita diàriament en la dieta dels seus fills. A partir d’aquestes dades, volem calcular un interval de confiança del 95% per a la proporció real de famílies d’aquesta ciutat amb nins en edat escolar que incorporen fruita fresca cada dia en la dieta dels seus fills. Diguem \\(X\\) a la variable aleatòria “Prenem una família amb nins en edat escolar i miram si inclou diàriament fruita a la dieta dels fills”. És Bernoulli, diguem \\(p_X\\) a la seva probabilitat d’èxit: la probabilitat que una família amb nins en edat escolar inclogui diàriament fruita a la dieta dels fills. Cercam un interval de confiança del 95% per a \\(p_X\\). Suposarem que la nostra mostra és aleatòria simple. Com que \\(n=500\\geqslant 100\\), \\(n\\widehat{p}_X=340\\geqslant 10\\) i \\(n(1-\\widehat{p}_X)=160\\geqslant 10\\), podem emprar la fórmula de Laplace \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] amb \\(n=500\\), \\(\\widehat{p}_{X}=340/500=0.68\\) i \\(z_{(q+1)/2}=z_{0.975}=1.96\\). Dóna \\[ 0.68\\pm 1.96\\sqrt{\\frac{0.68(1-0.68)}{500}}\\Rightarrow [0.639,0.721] \\] Amb R: round(binom.approx(340,500), 3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.639 0.721 0.95 Amb els altres mètodes, que també podríem aplicar en aquest cas, obtenim els intervals: round(binom.exact(340,500),3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.637 0.721 0.95 round(binom.wilson(340,500),3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.638 0.719 0.95 En resum, estimam que entre aproximadament un 64% i un 72% de les famílies d’aquesta ciutat amb nins en edat escolar inclouen diàriament fruita fresca en la dieta dels seus fills. Quan podem calcular més d’un interval per a \\(p_X\\), quin calculam? D’entrada cal dir que si podem calcular més d’un interval, segurament donaran molt similars, com heu pogut comprovar a l’exemple anterior. A més, recordau que les tres fórmules només ens donen “un nivell de confiança q” si s’apliquen a mostres aleatòries simples, i les nostres mostres gairebé sempre seran oportunistes, cas en el qual, si ens posam perepunyetes, no en podem aplicar cap. Però en tot cas, si no filam molt prim i podem triar, hem de tenir en compte que: L’interval de Clopper-Pearson és exacte, no empra cap aproximació, i el podem emprar sempre, però: Tendeix a donar un interval més ample del necessari No està centrat en la proporció mostral Només és un interval “exacte” si la mostra és aleatòria simple, la qual cosa sol ser falsa (com a molt, serà “aproximadament” aleatòria simple) Com que no es pot calcular “a mà”, no és molt popular L’interval de Wilson és aproximat, fa servir l’aproximació a la normal donada pel Teorema Central del Límit. Això no és un gran emperò, perquè tanmateix segurament la mostra serà com a molt “aproximadament” aleatòria simple. Ara bé, tampoc no està centrat en la proporció mostral, i ens agrada poder donar els intervals en la forma “estimació més manco qualque cosa” perquè d’aquesta manera donam l’estimació puntual i el marge d’error. L’interval de Laplace és molt aproximat, però: Forma part de la cultura general del científic, tothom el coneix És l’únic dels tres que està centrat en la proporció mostral Exemple 4.10 En un assaig d’un nou tractament de quimioteràpia, en una mostra de \\(n\\) malalts tractats, cap desenvolupà càncer testicular com a efecte secundari. Quin seria un interval de confiança al 95% per a la proporció de malalts tractats amb aquesta quimio que desenvolupen càncer testicular? Per calcular-lo podem emprar el mètode de Clopper-Pearson i, si \\(n\\) és gran, el de Wilson. No podem emprar la fórmula de Laplace, perquè \\(\\widehat{p}_X=0\\). Pel que fa a Clopper-Pearson, aquest és un dels pocs casos que admeten solució analítica senzilla: dóna l’interval \\[ \\Big[0,1-\\Big(\\frac{1-q}{2}\\Big)^{1/n}\\Big] \\] que, si \\(q=0.95\\), queda \\[ [0,1-0.025^{1/n}]. \\] Per exemple, si \\(n=40\\) binom.exact(0,40) ## x n proportion lower upper conf.level ## 1 0 40 0 0 0.0880973 0.95 1-0.025^(1/40) ## [1] 0.0880973 Si podem emprar el mètode de Wilson, la fórmula \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(q+1)/2}^2}{2n}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(q+1)/2}^2}{4n^2}}}{1+\\frac{z_{(q+1)/2}^2}{n}} \\] amb \\(\\widehat{p}_{X}=0\\) i \\(z_{(1+q)/2}=1.96\\) dóna \\[ \\frac{\\frac{1.96^2}{2n}\\pm 1.96\\sqrt{\\frac{1.96^2}{4n^2}}}{1+\\frac{1.96^2}{n}}\\Longrightarrow \\Big[0,\\frac{1.96^2}{n+1.96^2}\\Big] \\] Per exemple, un altre cop amb \\(n=40\\) binom.wilson(0,40) ## x n proportion lower upper conf.level ## 1 0 40 0 6.330897e-18 0.0876216 0.95 qnorm(0.975)^2/(40+qnorm(0.975)^2) ## [1] 0.0876216 Quan s’ha de calcular “a ull” un interval de confiança del 95% per a una probabilitat \\(p_X\\) a partir d’una mostra on no hi ha hagut cap èxit, sovint es fa servir la regla següent: Regla del 3: Quan en una mostra de mida \\(n\\) d’una variable aleatòria de Bernoulli de paràmetre \\(p_X\\) no hi trobam cap èxit, un IC 95% per a \\(p_X\\) va, aproximadament, de 0 a \\(3/n\\). Amb aquesta regla, en el nostre exemple amb \\(n=40\\) obtendríem l’interval [0,3/40]=[0,0.075], no molt enfora del [0,0.088] que hem obtingut amb els altres dos mètodes. Per veure com la regla del 3 aproxima l’interval de Clopper-Pearson, el gràfic següent mostra els valors \\(3/n\\) i l’extrem superior de l’IC 95% de Clopper-Pearson a partir d’una mostra de mida \\(n\\) amb 0 èxits: El gràfic següent mostra els valors \\(3/n\\) i els extrems superiors dels IC 95% de Clopper-Pearson i de Wilson a partir d’una mostra de mida \\(n\\) (\\(n\\geqslant 40\\) per als intervals de confiança de Wilson) amb 0 èxits: Els extrems superiors dels intervals de Clopper-Pearson i Wilson se superposen en aquest darrer gràfic. Exemple 4.11 En un assaig d’un tractament de quimioteràpia, en una mostra de 100 pacients tractats, 25 desenvoluparen càncer testicular secundari. Volem calcular un IC 95% per a la proporció de pacients tractats amb aquesta quimioteràpia que desenvolupen càncer testicular. En aquest cas podem emprar els tres mètodes: round(binom.exact(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1688 0.3466 0.95 round(binom.wilson(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1755 0.343 0.95 round(binom.approx(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1651 0.3349 0.95 Concloem, amb un nivell de confiança del 95%, que entre aproximadament un 17% i un 34% dels pacients tractats amb aquesta quimioteràpia desenvolupen càncer testicular. Càlcul de la mida de la mostra per a fixar l’error L’error (marge d’error, precisió…) de l’interval de confiança de Laplace és \\[ M= z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Com al cas de la mitjana, quan estimam una proporció ens pot sorgir el problema de determinar la mida mínima de la mostra que hem d’emprar a fi que aquest error no sigui més gran que un cert valor. En el cas de l’interval de Laplace per a una proporció, podem donar un \\(n\\) que garanteixi, valgui el que valgui \\(\\widehat{p}_{X}\\in [0,1]\\), un marge d’error màxim donat. Fixau-vos que la funció \\(y=p (1-p)\\), amb \\(p\\in [0,1]\\), és una paràbola còncava amb vèrtex al punt \\(p=0.5\\): Figura 4.4: Gràfic de la funció \\(y=p(1-p)\\) Per tant, el seu màxim s’assoleix a \\(p=0.5\\). Així, doncs \\[ \\widehat{p}_{X} (1-\\widehat{p}_{X})\\leqslant 0.5(1-0.5)=0.5^2\\text{ per a tot $\\widehat{p}_X\\in[0,1]$} \\] i per tant \\[ \\begin{array}{l} \\displaystyle M=z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\\\ \\qquad\\displaystyle \\leqslant z_{(q+1)/2}\\sqrt{\\frac{0.5^2}{n}}=\\frac{0.5z_{(q+1)/2}}{\\sqrt{n}}=\\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\end{array} \\] D’aquesta manera, si prenem \\(n\\) tal que \\[ \\frac{z_{(q+1)/2}}{2\\sqrt{n}}\\leqslant M_{max} \\] aleshores segur que \\(M\\leqslant M_{max}\\), valgui el que valgui \\(\\widehat{p}_{X}\\). Per tant, el que farem serà calcular la \\(n\\) per obtenir un error com a màxim \\(M_{max}\\) en el cas més desfavorable: quan l’interval és el més ample possible, és a dir, suposant que \\(\\widehat{p}_{X}=0.5\\): \\[ M_{max}\\geqslant \\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\Longrightarrow n\\geqslant \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2 \\] En resum: Teorema 4.6 Si \\[ n\\geqslant \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2, \\] el marge d’error de l’interval de Laplace de nivell de confiança \\(q\\) calculat amb una mostra de mida \\(n\\) sempre serà com a molt \\(M_{max}\\). Exemple 4.12 Quina és la mida més petita d’una mostra que ens garanteix un error de com a màxim 0.05 en estimar una proporció \\(p_X\\) emprant un interval de confiança de Laplace del 95%? Pel teorema anterior, per garantir un error de 0.05 en calcular un IC 95% per una proporció \\(p_X\\) emprant la fórmula de Laplace, hem d’emprar una mostra de mida \\(n\\) tal que \\[ n\\geqslant \\Bigg(\\frac{z_{(1+q)/2}}{2M_{max}}\\Bigg)^2=\\Bigg(\\frac{1.96}{0.1}\\Bigg)^2=384.16 \\] La mida més petita que satisfà aquesta condició és \\(n=385\\). La resposta correcta no és 384, per molt que 384.16 s’arrodoneixi a 384. Fixau-vos que 384 no és més gran que 384.16. Observau tres coses: El valor de \\(n\\) només depèn de la precisió i del nivell de confiança, no de la natura de l’estudi ni de la mida de la població ni de proves pilot. Tal i com hem trobat la \\(n\\), estam segurs que si prenem una mostra com a mínim d’aquesta mida, el marge d’error de l’interval de confiança de Laplace serà com a màxim \\(M_{max}\\), sigui quina sigui la mostra. És de les poques vegades que podem estar segurs de qualque cosa en estadística. El teorema anterior és per a l’amplada de l’interval de Laplace, però la \\(n\\) segurament us sortirà molt gran i en aquest cas l’interval de Laplace aproxima molt bé els altres dos intervals. 4.5 Intervals de confiança per a la variància i la desviació típica d’una variable normal Suposem que tenim una variable normal \\(X\\). Volem trobar un IC 95% per a la seva variància \\(\\sigma^2\\) (o la seva desviació típica \\(\\sigma\\)). Per calcular-lo, prenem una mostra aleatòria simple de mida \\(n\\), de variància mostral \\(\\widetilde{S}^2_X\\). Recordau que, en aquestes condicions, \\[ \\frac{(n-1) \\widetilde{S}_{X}^2}{\\sigma^2} \\] té distribució \\(\\chi^2_{n-1}\\). Podem aprofitar aquest fet per obtenir intervals de confiança per a \\(\\sigma^2\\): Teorema 4.7 Si la variable \\(X\\) és normal, un interval de confiança de nivell de confiança \\(q\\) per a \\(\\sigma^2\\) és \\[ \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}, \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right], \\] on \\(\\chi_{n-1,r}^2\\) és el \\(r\\)-quantil de la distribució \\(\\chi_{n-1}^2\\). La justificació d’aquesta fórmula és la usual: com que \\[ \\begin{array}{l} \\displaystyle P(\\chi_{n-1}^2\\leqslant \\chi_{n-1,(1-q)/2}^2)=\\frac{1-q}{2}\\\\ \\displaystyle P(\\chi_{n-1}^2\\geqslant \\chi_{n-1,(1+q)/2}^2)=1-\\frac{1+q}{2}=\\frac{1-q}{2}, \\end{array} \\] tenim que \\[ \\begin{array}{l} q=P\\left(\\chi_{n-1,(1-q)/2}^2\\leqslant \\chi_{n-1}^2\\leq \\chi_{n-1,(1+q)/2}^2\\right)\\\\[2ex] \\quad\\displaystyle =P\\left(\\chi_{n-1,(1-q)/2}^2\\leqslant \\frac{(n-1) \\widetilde{S}_{X}^2}{\\sigma^2}\\leq \\chi_{n-1,(1+q)/2}^2 \\right)\\\\[2ex] \\quad\\displaystyle = P\\left(\\frac{(n-1) \\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}\\leq\\sigma^2\\leq\\frac{ (n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right) \\end{array} \\] Aquest interval de confiança per \\(\\sigma^2\\) no està centrat en \\(\\widetilde{S}_{X}^2\\) ni en \\({S}_{X}^2\\). A més, com que \\(\\chi_{n-1}^2\\) no és simètrica, s’han de calcular els dos quantils \\(\\chi_{n-1,(1-q)/2}^2\\) i \\(\\chi_{n-1,(1+q)/2}^2\\), perquè no hi ha cap relació entre ells que doni el valor d’un a partir del de l’altre. Exemple 4.13 Un índex de qualitat d’un reactiu químic és la variabilitat en el temps que tarda en actuar: es demana que aquest temps sigui aproximadament constant, és a dir, que tengui una desviació típica molt petita. Hem realitzat 30 proves en les quals hem mesurat el temps d’actuació d’un determinat reactiu, i a partir dels resultats volem calcular un IC 95% per a la desviació típica del seu temps d’actuació. Tenim els resultats guardats en el vector següent: Temps=c(12,13,13,14,14,14,15,15,16,17,17,18,18,19,19, 25,25,26,27,30,33,34,35,40,40,51,51,58,59,83) Per ara suposarem que la distribució del temps d’actuació d’aquest reactiu és (aproximadament) normal. Més endavant estudiarem tècniques per determinar (amb un cert nivell de confiança) si podem acceptar que una mostra prové d’una variable normal. Continuem. Com que la variable que ens dóna el temps és (aproximadament) normal, podem emprar la fórmula per a l’IC 95% per a \\(\\sigma^2\\) anterior: \\[ \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}, \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right] \\] on: \\(n=\\)length(Temps)\\(=30\\) \\(\\widetilde{S}_X^2=\\)var(Temps)\\(=301.55\\) \\(q=0.95\\), per tant \\(\\chi_{n-1,(1+q)/2}^2=\\)qchisq(0.975,29)\\(=45.72\\) i \\(\\chi_{n-1,(1-q)/2}^2=\\)qchisq(0.025,29)\\(=16.05\\) Obtenim l’interval: \\[ \\left[ \\frac{29\\cdot 301.55}{45.72}, \\frac{29\\cdot 301.55}{16.05}\\right]= [191.26, 544.96] \\] Aquest interval és per a la variància! Per obtenir un interval de confiança per a la desviació típica, prenem arrels quadrades dels extrems: \\[ [\\sqrt{191.26}, \\sqrt{544.96}]=[13.83,23.34] \\] Estimam doncs (amb un 95% de confiança) que la variabilitat dels temps d’actuació d’aquest reactiu és molt gran. Comparau aquest interval amb l’IC 95% per al seu temps mitjà d’actuació: round(t.test(Temps)$conf.int,2) ## [1] 21.88 34.85 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 L’extrem superior de l’IC 95% per a la desviació típica és més gran que l’extrem inferior d’aquest IC 95% per a la mitjana. Amb R, aquest interval de confiança amb nivell de confiança \\(q\\) per a la variància es pot calcular amb la funció varTest(X,conf.level=...)$conf.int del paquet EnvStats, on X és el vector que conté la mostra i conf.level indica el nivell de confiança en tant per u, que per defecte és igual a 0.95. Així, l’interval de confiança que ens demanàvem a l’exemple anterior es calcularia amb library(EnvStats) varTest(Temps)$conf.int ## LCL UCL ## 191.2627 544.9572 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 Que no, que aquest és el de la variància! L’IC 95% per a la desviació típica és: sqrt(varTest(Temps)$conf.int) ## LCL UCL ## 13.82977 23.34432 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 L’interval per a la variància basat en la distribució \\(\\chi^2\\) només és vàlid si la variable poblacional és (aproximadament) normal. En cas que no poguem acceptar que ho és, el millor és emprar un mètode no paramètric, com per exemple el bootstrap. Exemple 4.14 Anem a calcular un IC 95% per a la desviació típica del temps de reacció de l’Exemple anterior amb el mètode del bootstrap. Prenem 5000 mostres aleatòries simples de mida 30 del vector Temps i calculam la desviació típica mostral de cada mostra: Simulacions.sd=replicate(5000,sd(sample(Temps,30,rep=TRUE))) Ara prenem com a IC 95% l’interval que va del quantil 0.025 al quantil 0.975 d’aquest vector de desviacions típiques: quantile(Simulacions.sd,c(0.025,0.975)) ## 2.5% 97.5% ## 11.00926 22.69609 No ha sortit molt diferent de l’obtingut amb la fórmula basada en la distribució \\(\\chi^2\\). 4.6 “Poblacions finites” Fins ara hem emprat mostres aleatòries simples. Què passa si prenem mostres aleatòries sense reposició? Si la mida \\(N\\) de la població és molt més gran que la mida \\(n\\) de la mostra (posem \\(N\\geqslant 1000n\\)), les fórmules donades fins ara funcionen (aproximadament) bé. Quan la mida \\(N\\) de la població no és molt més gran que la mida \\(n\\) de la mostra, el que es fa és, a les fórmules que hem donat per als intervals de confiança per a \\(\\mu\\) o \\(p_X\\), multiplicar-hi l’error estàndard pel factor de població finita \\[ \\sqrt{\\frac{N-n}{N-1}} \\] Així: Si \\(X\\) és una variable definida sobre una població de mida \\(N\\) i prenem una mostra aleatòria sense reposició de \\(X\\), amb mitjana \\(\\overline{X}\\) i desviació típica mostral \\(\\widetilde{S}_X\\), i si \\(X\\) és normal o si \\(n\\) és gran, es recomana prendre com a interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu_X\\) \\[ \\overline{X}\\pm t_{n-1,(q+1)/2}\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] Si \\(X\\) és una variable de Bernoulli definida sobre una població de mida \\(N\\) i prenem una mostra aleatòria sense reposició de \\(X\\), amb \\(n\\) molt gran i nombres d’èxits i fracassos com a mínim 10, es recomana prendre com a interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] En les condicions del punt anterior, per obtenir un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) amb un marge d’error \\(M_{max}\\) en el cas més desfavorable (\\(\\widehat{p}_X=0.5\\)) cal prendre una mostra de mida \\[ n\\geqslant \\frac{Nz_{(q+1)/2}^2}{4M_{max}^2(N-1)+z_{(q+1)/2}^2} \\] Exemple 4.15 En una mostra aleatòria de 727 estudiants (diferents) de la UIB (\\(N=12000\\)), 557 afirmàrem haver comès plagi en algun treball durant els seus estudis. Quin seria un interval de confiança del 95% per a la proporció \\(p_X\\) d’estudiants de la UIB que han comès plagi en algun treball? Una mostra de 727 estudiants diferents és molt gran respecte del total d’estudiants de la UIB, per la qual cosa convé emprar la fórmula de Laplace amb el factor de població finita \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] on \\(\\widehat{p}_{X}=557/727=0.766\\), \\(z_{(q+1)/2}=1.96\\), \\(n=727\\) i \\(N=12000\\): dóna \\[ 0.766\\pm 1.96\\sqrt{\\frac{0.766(1-0.766)}{727}}\\sqrt{\\frac{\\vphantom{(}12000-727}{12000-1}}\\Rightarrow [0.736,0.796] \\] Estimam amb un nivell de confiança del 95% que entre un 75.1 i un 78.1 dels estudiants de la UIB han comès plagi en algun treball. Exemple 4.16 De quina mida hem de prendre una mostra aleatòria sense reposició d’estudiants de la UIB per estimar una proporció amb nivell de confiança del 95% i un marge d’error màxim de 0.05? Per la fórmula anterior (prenent \\(N=12000\\) i \\(z_{(1+q)/2}=1.96\\)), per garantir un marge d’error màxim de 0.05 en el cas més desfavorable cal prendre una mostra de mida \\[ n\\geqslant \\frac{12000\\cdot 1.96^2}{4\\cdot 0.05^2(12000-1)+1.96^2}=372.3 \\] Per tant, ens calen 373 estudiants. 4.7 Test de la lliçó 4 (1) En un estudi transversal sobre una mostra de 500 subjectes representatius d’una comunitat, s’ha observat una prevalença d’una certa malaltia del 20% (IC 95%: 16.5%-23.5%). Quina de les afirmacions següents és correcta? Si prenem una altra mostra de 500 subjectes de la mateixa comunitat, tenim un 95% de confiança que l’interval 16.5%-23.5% contendrà el percentatge de subjectes de la mostra que tenen aquesta malaltia. Un 95% dels individus de la comunitat tenen entre el 16.5% i el 23.5% de probabilitat de tenir aquesta malaltia. La fórmula amb la qual hem obtingut l’interval 16.5%-23.5% produeix intervals que contenen la proporció poblacional de malalts en un 95% de les ocasions. La fórmula amb la qual hem obtingut l’interval 16.5%-23.5% produeix intervals que contenen la proporció de malalts en la mostra en un 95% de les ocasions. Totes les altres respostes són falses. (2) Prenem una mostra aleatòria simple de mida 50 d’una variable aleatòria. Calculam un interval de confiança del 90% per a la mitjana de la variable aleatòria a partir d’aquesta mostra, dóna [11.8,12.8]. Què significa això? Que l’hem obtingut amb una fórmula que el 90% de les vegades dóna un interval que conté el valor real de la variable. Que l’hem obtingut amb una fórmula que el 90% de les vegades dóna un interval que conté el valor de la mitjana de la mostra emprada per calcular-lo. Que l’hem obtingut amb una fórmula que el 90% de les vegades dóna un interval que conté el valor de la mitjana mostral de qualsevol mostra. Que l’hem obtingut amb una fórmula que el 90% de les vegades dóna un interval que conté el valor real de la mitjana de la variable aleatòria. Cap de les respostes anteriors és correcta. (3) En un estudi transversal sobre una mostra de subjectes representatius d’una comunitat, s’ha observat una prevalença d’hipertensió arterial (HTA) del 20% (interval de confiança del 95%: 15%-25%). Quina de les afirmacions següents és vertadera? Es té un 95% de seguretat que entre un 15% i un 25% dels subjectes de la mostra són hipertensos. Es té un 95% de seguretat que entre un 15% i un 25% dels subjectes de la comunitat són hipertensos. Es té un 95% de seguretat que la prevalença de la HTA en la comunitat és del 20%. La prevalença real de HTA en la comunitat se situa entre el 15% i el 25%. Cap de les respostes anteriors és correcta. (4) Un interval de confiança del 99% per a la concentració d’un determinat metabòlit a la sang dels individus d’una determinada espècie és [10,12]. D’acord amb això, esperam trobar fora d’aquest interval: Un 1% de les concentracions mitjanes de totes les mostres de qualsevol mida d’individus d’aquesta espècie. Un 1% de les concentracions mitjanes de les mostres grans (\\(\\geqslant 40\\)) d’individus d’aquesta espècie. Un 99% de les concentracions mitjanes de les mostres de qualsevol mida d’individus d’aquesta espècie. Un 1% de les concentracions dels individus d’aquesta espècie. Un 99% de les concentracions dels individus d’aquesta espècie. Cap de les anteriors respostes és correcta (5) Quina de les situacions següents ens permet una estimació més precisa d’una mitjana poblacional \\(\\mu\\) amb la fórmula basada en la t de Student? \\(\\overline{X}=10\\), \\(\\widetilde{S}_X=0.2\\), \\(n=30\\). \\(\\overline{X}=20\\), \\(\\widetilde{S}_X=0.2\\), \\(n=30\\). \\(\\overline{X}=10\\), \\(\\widetilde{S}_X=0.2\\), \\(n=50\\). \\(\\overline{X}=40\\), \\(\\widetilde{S}_X=0.1\\), \\(n=50\\). (6) Prenem una mostra aleatòria simple de mida 100 d’una variable aleatòria i calculam un interval de confiança del 95% per a \\(\\mu\\) amb la fórmula basada en la t de Student. Obtenim [11.8,12.8]. Què ha valgut, aproximadament, la desviació típica mostral de la mostra? 12.3 2.5 3 6.5 No ho podem saber a partir de les dades donades (7) Per calcular un interval de confiança al 95% per al valor mitjà \\(\\mu\\) d’una certa variable, hem pres una mostra aleatòria simple de mida 100. Si ara prenguéssim una altra mostra aleatòria simple de mida 100 i amb aquesta calculàssim un interval de confiança del 99% per a \\(\\mu\\), com seria aquest interval? Més ample que l’anterior Més estret que l’anterior Exactament igual d’ample que l’anterior Pot passar qualsevol cosa (8) Per estimar una certa mitjana poblacional amb un nivell de confiança 0.95, hem emprat la fórmula basada en la t de Student sobre una mostra de 100 individus i hem obtingut un IC 95% amb un marge d’error de 0.02. Si empram la mateixa fórmula per a calcular aquest IC sobre una mostra de 200 individus, estam segurs que (marcau totes les afirmacions correctes): L’IC 95% obtingut tindrà un marge d’error &lt;0.02 L’IC 95% obtingut tindrà un marge d’error &gt;0.02 Si calculam un IC 99%, el seu marge d’error serà &gt;0.02 Si calculam un IC 90%, el seu marge d’error serà &gt;0.02 Cap de les altres afirmacions és correcta (9) En una mostra de 88 estudiants, es trobà que un 8% consumien begudes energètiques (IC 95%: 2% a 14%, mètode de Laplace). Quina o quines de les afirmacions següents són certes? Una altra mostra de la mateixa mida sempre mostraria una taxa d’estudiants consumidors de begudes energètiques entre el 2% i el 14%. El 95% del estudiants té una probabilitat d’entre el 2% i el 14% de consumir begudes energètiques. Estam molt segurs que entre el 2% i el 14% dels estudiants consumeixin begudes energètiques. Si la mostra hagués estat de 880 estudiants i també hagués tingut un 8% de consumidors de begudes energètiques, l’interval de confiança del 95% hagués estat més estret. Seria impossible obtenir aquest IC 95% si la taxa de consum de begudes energètiques entre els estudiants fos del 20%. (10) Prenem una mostra aleatòria de 200 residents de Santa Margalida (població, 12000 habitants) per calcular un interval de confiança de la proporció dels margalidans que presenten una determinada condició. Quina o quines de les afirmacions següents són vertaderes? Si la mostra és simple, no cal tenir en compte el factor de població finita. Encara que la mostra sigui simple, cal tenir en compte el factor de població finita. Si la mostra no és simple, cal tenir en compte el factor de població finita. Una mostra aleatòria sense reposició de mida 200 d’una població de mida 12000 sempre podem entendre que és simple, a efectes de calcular intervals de confiança de proporcions. Totes les altres respostes són falses. (11) Estam calculant intervals de confiança per a la probabilitat d’èxit d’una variable de Bernoulli a partir de mostres aleatòries simples de la mateixa mida emprant la fórmula de Laplace. Sobre una mostra hem obtingut una proporció mostral d’èxits \\(\\widehat{p}_X=0.5\\) i sobre una altra mostra una proporció mostral d’èxits \\(\\widehat{p}_X=0.7\\). Quin dels dos intervals de confiança és més ample? El calculat amb la mostra amb \\(\\widehat{p}_X=0.5\\) El calculat amb la mostra amb \\(\\widehat{p}_X=0.7\\) Com que les dues mostres són de la mateixa mida, els dos intervals tenen la mateixa amplitud Com que les dues mostres són diferents, no ho podem saber Cap de les respostes anteriors és correcta (12) Quina o quines de les afirmacions següents sobre l’interval de confiança per a la variància poblacional basat en la distribució \\(\\chi^2\\) són vertaderes? Sempre està centrat en la variància mostral de la mostra emprada Sempre està centrat en la variància “a seques” de la mostra emprada Si es tracta d’un interval de confiança del 95%, la fórmula donada satisfà que el 95% de les vegades que l’aplicam a una mostra aleatòria simple dóna un interval que conté la variància mostral de la mostra. Si canviam de mostra, però mantenim la mida de la mostra i el nivell de confiança, l’interval és més ample com més gran sigui la variància mostral de la mostra Si no canviam de mostra i augmentam el nivell de confiança, disminueix la seva amplada. Si dues mostres són de la mateixa mida i tenen la mateixa variància mostral, donen lloc al mateix interval de confiança del 95% per a la variància poblacional Si dues mostres tenen la mateixa variància mostral, donen lloc al mateix interval de confiança del 95% per a la variància poblacional encara que siguin de mides diferents (13) Volem estimar el nivell mitjà de potassi en sang en un poble de Mallorca, mesurant-lo sobre una mostra aleatòria d’habitants del poble i emprant la fórmula basada en la t de Student. L’exactitud de l’estimació pot dependre de (marcau totes les respostes correctes): El valor real del nivell mitjà de potassi en sang en el poble objecte d’estudi. El nombre d’habitants del poble. La mida de la mostra. La variància del nivell de potassi en sang en aquest poble. Cap de les altres respostes és correcta. (14) En una mostra aleatòria d’individus d’una comunitat s’ha obtingut una valor mitjà de la tensió arterial diastòlica (TAD) de 85 mmHg, amb un error estàndard de 2.5 mmHg. Quina o quines de les afirmacions següents són vertaderes? El 95% dels subjectes de la mostra tenien valors de TAD entre 80 i 90 mmHg. El 90% dels subjectes de la mostra tenien valors de TAD entre 82.5 i 87.5 mmHg. Es té un 95% de confiança que l’interval 80-90 mmHg inclourà el valor mitjà vertader de la TAD de la comunitat. Es té un 90% de confiança que l’interval 82.5-87.5 mmHg inclogui el valor mitjà vertader de la TAD de la comunitat. Com que la mostra és aleatòria, el valor mitjà vertader de la TAD en la comunitat és de 85 mmHg. (15) Per calcular un interval de confiança al 95% per al valor mitjà \\(\\mu\\) d’una certa variable, hem pres una mostra aleatòria simple de mida 100. Si, amb la mateixa mostra, calculàssim un interval de confiança del 99% per a \\(\\mu\\), com seria aquest interval? Més ample que l’anterior Més estret que l’anterior Com que la mostra és la mateixa, l’interval serà el mateix Pot passar qualsevol cosa Cap de les altres respostes és correcta (16) Per calcular un interval de confiança al 95% per el valor mitjà d’una certa variable, havíem decidit prendre una mostra aleatòria simple de mida 200, però resulta massa costós, i hem decidit reduir la mida a 100. Té aquesta decisió qualque efecte sobre l’amplada de l’interval de confiança? Amb 100 l’interval de confiança serà més ample que amb 200 Amb 100 l’interval de confiança serà més estret que amb 200 Com que el nivell de confiança és el mateix, els intervals de confiança tendran la mateixa amplada Pot passar qualsevol cosa (17) Calculam un interval de confiança al 95% per a la mitjana poblacional d’una variable aleatòria, a partir d’una mostra aleatòria simple de 100 individus. Si calculam el mateix interval de confiança amb una altra mostra aleatòria simple de 100 individus que té una variància més gran, quina de les tres coses següents passarà? El segon interval serà més ample El segon interval serà més estret Els dos intervals tendran la mateixa amplada Pot passar qualsevol cosa (18) Amb la finalitat de disminuir el marge d’error en l’estimació de la mitjana d’una certa variable aleatòria per mitjà de la mitjana aritmètica d’una mostra, el millor que podem fer és (marcau una única resposta): Disminuir la variància de la variable aleatòria poblacional. Augmentar el nivell de confiança. Disminuir el nivell de confiança. Augmentar la mida de la mostra. Eliminar els valors dubtosos de la mostra. (19) Un article d’una revista científica informa que l’interval de confiança al 95% del nivell mitjà de colesterol en sang en els adults d’una certa població és 192-208. Es va acceptar que la variable tenia una distribució normal, per la qual cosa s’emprà la fórmula basada en la t de Student, i la mostra que s’usà per calcular aquest interval de confiança va ser de 100 individus. Quina o quines de les següents afirmacions són vertaderes? És molt probable que el nivell mitjà poblacional estigui comprès entre 192 i 208. Si se repetís l’estudi molts pics, en un 95% de les vegades s’obtindria una mitjana mostral compresa entre 192 i 208. El 95% dels adults de la població té un nivell de colesterol comprès entre 192 i 208. La mitjana mostral trobada en l’estudi és de 200. La desviació típica mostral trobada en l’estudi ha estat aproximadament 40 o 41. (20) Estam planejant fer un assaig clínic per estudiar l’eficàcia d’un nou tipus de medicament per al tractament de la hipercolesterolèmia (colesterol alt). Volem estimar la reducció mitjana del nivell de colesterol en plasma als 15 dies de començar a prendre el medicament. Quina o quines de les dades següents NO són útils per calcular la mida de la mostra de pacients als quals administrarem el nou medicament per estimar-la? La reducció mitjana del nivell de colesterol en plasma als 15 dies obtinguda en una petita prova pilot prèvia, que va ser de 8 mg/dl. La desviació típica en la reducció del nivell de colesterol en plasma als 15 dies obtinguda en una petita prova pilot prèvia, que va ser d’1.2 mg/dl. El nivell de confiança, que fixarem en un 5%. La proporció esperada de pacients que no completaran l’estudi, que en altres estudis similars de la literatura ha estat d’un 10%. L’error màxim que ens volem permetre en l’estimació de la reducció mitjana del nivell de colesterol en plasma, que fixarem en 1 mg/dl. (21) Un investigador vol determinar la proporció d’estudiants de secundària d’una determinada comunitat que consumeixen begudes energètiques passant una enquesta a una mostra d’estudiants. Per calcular la mida mostral que necessita per al seu estudi ja disposa de les dades següents: mida de la població objectiu; percentatge esperat d’estudiants que no contestaran l’enquesta; la precisió amb la qual desitja donar l’estimació de la proporció (5 punts percentuals); el nivell de confiança (95%). Vol calcular aquesta mida mostral en el cas més desfavorable (proporció mostral 0.5). Quina o quines altres dades li falten? (marcau totes les respostes correctes): Saber l’error estàndard de la proporció mostral d’estudiants consumidors de begudes energètiques. Estimar la desviació típica de la proporció de consumidors de begudes energètiques. Conèixer la proporció de consumidors de begudes energètiques en el total de la població de la zona d’interès. Estimar la proporció d’estudiants consumidors de begudes energètiques amb una petita prova pilot. Com que vol calcular l’interval de confiança en el cas més desfavorable, ja no li fa falta cap altra dada. (22) A Espanya hi ha aproximadament 80000 estudiants universitaris de ciències. Suposem que es va passar una enquesta a una mostra aleatòria simple de 200 estudiants d’aquests i que 198 van respondre que la matèria que manco els havia agradat havia estat l’Estadística. Si volgués calcular un interval de confiança per a la proporció d’estudiants de ciències per als quals la matèria manco preferida és l’Estadística emprant aquestes dades, quin, o quins, mètodes podria emprar? Només el de Clopper-Pearson Només el de Clopper-Pearson i el de Wilson El de Clopper-Pearson, el de Wilson i el de Laplace Només el mètode de Laplace amb el factor de població finita Cap de les altres respostes és correcta. (23) Els EEUU tenen aproximadament 330 milions d’habitants. Imaginau que volem estimar amb un 95% de confiança la proporció d’ells que tenen qualque tatuatge. Quants nord americans triats a l’atzar hauríem d’entrevistar com a mínim per garantir un marge d’error inferior a 0.05 (5 punts percentuals)? Triau d’entre els nombres següents el que creguis que més s’hi acosta. Uns 50 Uns 500 Uns 5000 Uns 50,000 Uns 500,000 "],
["chap-chgen.html", "Tema 5 Contrastos d’hipòtesis: Generalitats 5.1 Les hipòtesis nul·la i alternativa 5.2 Un exemple 5.3 El p-valor 5.4 Tipus d’errors 5.5 Exemple: El test t 5.6 Recapitulació 5.7 Test de la lliçó 5", " Tema 5 Contrastos d’hipòtesis: Generalitats En moltes situacions, hem de prendre una decisió sobre si es pot acceptar o rebutjar una hipòtesi relativa al valor d’un paràmetre d’una població o diverses poblacions. Per prendre aquesta decisió, prenem una mostra de la població i hi mesuram qualque cosa. Per exemple: Volem saber si una moneda està trucada a favor de cara. Per decidir-ho, la llançam una sèrie de vegades, i comptam quantes cares surten. Volem decidir si un tractament nou A és més efectiu que el tractament vell B en la curació d’una malaltia X. Per decidir-ho, portam a terme un assaig clínic, tractant amb A un grup de malalts i amb B un altre grup de malalts, i comparam la taxa de curació dels tractaments sobre aquests dos grups. El mètode estadístic que s’empra per acceptar o rebutjar una hipòtesi rep el nom de contrast d’hipòtesis. 5.1 Les hipòtesis nul·la i alternativa En un contrast d’hipòtesis, es comparen sempre dues hipòtesis alternatives: la hipòtesi nul·la H0 i la hipòtesi alternativa H1. Se sol plantejar formalment \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{hipòtesi nul·la}\\\\ H_{1}:\\text{hipòtesi alternativa} \\end{array} \\right. \\] Típicament, la hipòtesi nul·la H0 és “no hi ha diferència”, “no passa res”, “no hi ha res d’estrany” o l’equivalent en el context del contrast: La moneda és equilibrada (50% de probabilitat de cara) Els tractaments A i B són igual d’efectius en la curació de la malaltia X La hipòtesi alternativa H1 planteja la diferència de la qual cercam evidència: La moneda està trucada a favor de cara (més del 50% de probabilitat de cara) A és més efectiu que B en la curació de la malaltia X Per defecte, estam disposats a acceptar H0: que no hi ha diferència, que no passa res. Per defecte, estam disposats a acceptar que la moneda és equilibrada (la majoria ho són, no?) Per defecte, estam disposats a acceptar que els dos tractaments són igual d’efectius (en general, si preneu dos tractaments qualssevol, a l’atzar, i els aplicau a malalts de X, els dos seran igual de (in)efectius) Si obtenim evidència suficient que H0 és falsa, rebutjarem H0 a favor de H1 i conclourem que H1 és vertadera. Què vol dir “obtenir evidència suficient que H0 és falsa”? Doncs que les dades obtengudes fan que H0 sigui inversemblant (mala de creure) per comparació amb H1: Tendrem evidència que la moneda està trucada a favor de cara si a la nostra sèrie de llançaments la proporció de cares és tan i tan gran que fa mal de creure que la probabilitat de cara sigui del 50% Tendrem evidència que el tractament A és més efectiu que B en la curació de la malaltia X si en el nostre assaig la taxa de curació de la malaltia X amb el tractament A és tan i tan més gran que la de B que fa mal de creure que els dos tractaments siguin igual d’efectius Si no obtenim evidència suficient que H0 és falsa, és a dir, si les nostres dades són raonablement compatibles amb H0, no podrem rebutjar-la. En aquest cas direm que acceptam la hipòtesi nul·la com a sinònim de no rebutjam la hipòtesi nul·la. Acceptarem que la moneda no està trucada a favor de cara si a la nostra sèrie de llançaments la proporció de cares no és prou gran com per fer mal de creure que sigui equilibrada Acceptarem que el tractament A és igual d’efectiu que B en la curació de la malaltia X si en el nostre assaig la taxa de curació de la malaltia X amb el tractament A no és prou més gran que la de B com per fer mal de creure que els dos tractaments siguin igual d’efectius Si rebutjam H0 en favor de H1 no serà perquè hàgim demostrat que H0 sigui impossible, ni tan sols que sigui improbable: tan sols haurem observat que és mala de creure vists els resultats del nostre experiment Per exemple, si en una seqüència de 30 llançaments d’una moneda obtenim totes les vegades cara, segurament ho considerarem evidència que la moneda està trucada, però no demostrarà que la moneda estigui trucada. Sí, farà mal de creure que sigui equilibrada, però no és impossible: la moneda podria ser equilibrada i per pur atzar nosaltres haver tengut aquesta ratxa de cares. Feu els comptes. La probabilitat de treure 30 cares en 30 llançaments d’una moneda equilibrada és 0.530=9.3· 10-10. Per tant, de mitjana, aproximadament en un de cada mil milions de pics que s’efectuen 30 llançaments seguits d’una moneda equilibrada, s’obtenen 30 cares. Al món hi ha actualment més de 7700 milions de persones. És a dir que, si tots ens posàssim d’acord i llançàssim una moneda equilibrada 30 vegades, esperaríem que entre 7 i 8 treguessin 30 cares. I tampoc podem dir que sigui improbable que la moneda sigui equilibrada, ja que nosaltres sabem calcular \\[ P(\\text{30 cares en 30 llançaments}\\mid \\text{La moneda és equilibrada}) \\] però no sabem calcular \\[ P(\\text{La moneda és equilibrada}\\mid\\text{30 cares en 30 llançaments}). \\] Si acceptam la hipòtesi nul·la és perquè no la podem rebutjar ja que no trobam motius per dubtar d’ella, però no haurem trobat evidència que sigui vertadera ni haurem demostrat que sigui probable (i possible en principi ho és sempre). Per exemple, si en una seqüència de 4 llançaments d’una moneda obtenim 2 cares, no tendrem motiu per dubtar que la probabilitat de cara sigui 0.5: no podrem rebutjar que aquesta probabilitat sigui 0.5. Però tampoc no tendrem motiu per dubtar que la probabilitat de cara sigui, jo què sé, 0.5001: no podrem rebutjar que aquesta probabilitat sigui 0.5001. Però el que no pot ser és que diguem que hem obtingut evidència que la probabilitat de cara és 0.5 i que hem obtingut evidència que la probabilitat de cara és 0.5001. No es pot obtenir evidència simultàniament de dues coses que s’excloguin una a l’altra. La millor manera de no entendre malament el resultat d’un contrast d’hipòtesis és sempre redactar la conclusió en la forma Hem trobat evidència de la hipòtesi alternativa No hem trobat evidència de la hipòtesi alternativa segons quin sigui el cas. Exemple 5.1 En un judici (on l’acusat és innocent si no es demostra el contrari, i per tant estam disposats a acceptar per defecte que és innocent), se cerca evidència que l’acusat és culpable, per tant aquesta és la hipòtesi alternativa: El contrast és \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;acusat és innocent}\\\\ H_{1}:\\text{L&#39;acusat és culpable} \\end{array} \\right. \\] S’aporten proves Si el jurat les troba prou incriminatòries, “més enllà de tot dubte raonable”, declara culpable l’acusat (rebutja H0 en favor de H1) Si el jurat no les troba prou incriminatòries, el considera no culpable (no rebutja H0) Fixau-vos que considerar no culpable no és el mateix que demostrar que és innocent: pot ser que es consideri que l’acusat no és culpable simplement perquè no s’hagi trobat prou evidència per declarar-lo culpable. Exemple 5.2 Un examen és un contrast d’hipòtesis. En aquest cas, “no passa res” significa que l’estudiant és com si no hagués anat al curs, no ha après res, i per tant aquesta és la hipòtesi nul·la. Amb l’examen cercam evidència que l’estudiant ha après la matèria, per tant aquesta serà la hipòtesi alternativa: El contrast és: \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;estudiant no sap la matèria}\\\\ H_{1}:\\text{L&#39;estudiant sap la matèria} \\end{array} \\right. \\] Prenem una mostra del coneixement de l’estudiant (l’estudiant fa l’examen) Si hi ha prou evidència a favor de H1 (si l’examen li surt prou bé), rebutjam H0: decidim que l’estudiant sap la matèria, aprova l’assignatura Si no hi ha prou evidència a favor de H1 (si l’examen no li surt prou bé), ens quedam amb H0: concloem que l’estudiant no ha après la matèria, suspèn l’assignatura Exemple 5.3 Ens trobam amb la notícia següent al diari, i ens demanam si les dones practiquen realment menys esport que els homes. Aquesta pregunta la podem plantejar de moltes maneres: Totes les dones fan cada dia menys hores d’esport que tots els homes? Si prenc una dona i un home a l’atzar, hi ha més d’un 50% de probabilitat que ella practiqui menys esport que ell? La majoria de les dones fan cada dia menys hores d’esport que la majoria dels homes? La proporció de practicants d’esport entre les dones és més petita que entre els homes? La mitjana setmanal de vegades que les dones practiquen esport és més petita que la dels homes? La mitjana setmanal d’hores que les dones practiquen esport és més petita que la dels homes? … Cada una d’aquestes preguntes es traduiria en un contrast d’hipòtesis diferent. Com que aquí estam tractant contrastos sobre paràmetres poblacionals (mitjanes, proporcions, etc.), podríem plantejar algun dels quatre darrers. Anem a centrar-nos en la darrera qüestió, sobre mitjanes setmanals d’hores d’esport. Aquí, les variables poblacionals d’interès són: \\(X_d\\): “Prenc una dona i anot el seu nombre mitjà d’hores setmanals d’esport”, amb mitjana \\(\\mu_d\\): la mitjana d’hores setmanals d’esport de les dones (la mitjana de les mitjanes d’hores setmanals d’esport de totes les dones és la mitjana d’hores setmanals d’esport de les dones). \\(X_h\\): “Prenc un home i anot el seu nombre mitjà d’hores setmanals d’esport”, amb mitjana \\(\\mu_h\\): la mitjana d’hores setmanals d’esport dels homes El contrast que volem realitzar és Hipòtesi nul·la: no hi ha diferència entre les mitjanes d’hores setmanals d’esport d’homes i dones Hipòtesi alternativa: la mitjana d’hores setmanals d’esport de les dones és més petita que la dels homes És a dir \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&lt;\\mu_h \\end{array} \\right. \\] El procediment per realitzar-lo serà: Prenem mostres aleatòries de dones i d’homes i els demanam pels seus hàbits de pràctica d’esport Calculam la mitjana mostral \\(\\overline{X}_d\\) d’hores setmanals d’esport de les dones de la mostra Calculam la mitjana mostral \\(\\overline{X}_h\\) d’hores setmanals d’esport dels homes de la mostra Si \\(\\overline{X}_d\\) és molt més petita que \\(\\overline{X}_h\\), ho prendrem com a evidència que \\(\\mu_d&lt;\\mu_h\\) Si \\(\\overline{X}_d\\) no és molt més petita que \\(\\overline{X}_h\\), no haurem trobat evidència que \\(\\mu_d&lt;\\mu_h\\) i per tant acceptarem que \\(\\mu_d=\\mu_h\\) Què significa “\\(\\overline{X}_d\\) molt més petita que \\(\\overline{X}_h\\)”? Una opció, que podríem importar del tema anterior, seria calcular un interval de confiança del 95% per a \\(\\mu_d-\\mu_h\\) a partir de la mostra: Si estigués totalment a l’esquerra del 0, amb un 95% de confiança podríem concloure que \\(\\mu_d&lt;\\mu_h\\) (perquè tendríem un 95% de seguretat que el valor real de la diferència \\(\\mu_d-\\mu_h\\) pertany a un interval de nombres estrictament negatius). En cas contrari, és a dir, si contengués el 0 o si estigués totalment a la dreta del 0, amb un 95% de confiança no podríem concloure que \\(\\mu_d&lt;\\mu_h\\) (perquè l’interval on estam molt segurs que cau el valor real de la diferència \\(\\mu_d-\\mu_h\\) contendria valors \\(\\geqslant 0\\) i per tant podria ser, dins el nostre marge de seguretat, que \\(\\mu_d-\\mu_h\\geqslant 0\\)). Com que aquí voldrem filar més prim que això del “nivell de confiança”, el procediment serà una mica més complicat (bàsicament, emprarem diferents fórmules per calcular els intervals de confiança segons la forma que tengui la hipòtesi alternativa). Abans de tancar aquesta secció, volem emfatitzar algunes advertències. Les hipòtesis dels contrastos són sobre paràmetres de les poblacions, NO sobre estadístics de les mostres. A l’exemple anterior les hipòtesis del contrast comparaven les mitjanes poblacionals d’hores setmanals d’esport de les dones i els homes, no les mitjanes mostrals d’hores setmanals d’esport de les dones i els homes de la nostra mostra. Per comparar les mitjanes mostrals no ens fa falta un contrast d’hipòtesis: les calculam i punt. En canvi, com que no podem calcular les mitjanes d’hores setmanals d’esport de totes les dones i de tots els homes, ens veiem obligats a emprar estadística i fer un contrast d’hipòtesis. Recordau que la falta d’evidència a favor de H1 no és evidència a favor de H0. Si no podem concloure que les dones practiquin menys esport que els homes (perquè no hàgim trobat evidència a favor d’aquesta hipòtesi), això no significarà que hàgim trobat evidència que els homes i les dones practiquin la mateixa quantitat d’esport o que les dones en practiquin més. Simplement, significarà que l’evidència a favor de H1 no ha estat prou forta com per poder afirmar que és vertadera i per tant acceptam que tothom practica la mateixa quantitat d’esport. En general, mai no podrem trobar evidència de la hipòtesi nul·la. Si per exemple al nostre estudi haguéssim trobat que \\(\\overline{X}_d=\\overline{X}_h\\), això seria compatible amb la hipòtesi nul·la \\(\\mu_d=\\mu_h\\), naturalment, i per això no la podríem rebutjar. Però no podem dir que aporti evidència que \\(\\mu_d=\\mu_h\\), perquè \\(\\overline{X}_d=\\overline{X}_h\\) segurament també seria compatible, per exemple, amb \\(\\mu_d=\\mu_h+0.0007\\) (les dones fan, de mitjana, un minut més d’esport a la setmana que els homes), per tant tampoc no podríem rebutjar com a hipòtesi nul·la que \\(\\mu_d=\\mu_h+0.0007\\). I el que no podem dir és que un mateix conjunt de dades aporti simultàniament evidència que \\(\\mu_d=\\mu_h\\) i que \\(\\mu_d=\\mu_h+0.0007\\). La pregunta (el contrast) us la plantejau a priori a partir d’hipòtesis o suposicions prèvies. No val canviar de contrast a la vista de les dades. La pregunta la plantejam abans d’obtenir la mostra. Si estam interessats en el contrast \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&lt;\\mu_h \\end{array} \\right. \\] i obtenim que \\(\\overline{X}_d\\) és molt més gran que \\(\\overline{X}_h\\) en la nostra mostra, concloem que no tenim evidència que \\(\\mu_d&lt;\\mu_h\\) i punt. És fer trampes dir: “No hem trobat evidència que les dones practiquin menys esport que els homes, però si amb aquestes mateixes dades realitzam el contrast \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&gt;\\mu_h \\end{array} \\right. \\] sí que obtenim evidència que elles practiquen més esport que ells.” D’això se’n diu “anar a pescar” o també “torturar les dades”: obtenir unes dades i cercar de què donen evidència. És mala praxis científica. Qualsevol conjunt de dades, si el torturam prou, acaba donant evidència de qualque cosa. Triau la hipòtesi alternativa en funció d’allò que cercau evidència. No confongueu \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&lt;\\mu_h \\end{array} \\right. \\] amb \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d\\neq \\mu_h \\end{array} \\right. \\] que tradueix la pregunta \"Els homes i les dones, de mitjana, practiquen esport un nombre diferent d’hores a la setmana?’’ Regles per triar H0 i H1 en aquest curs: H0 sempre ha de significar “no hi ha diferència” i s’ha de definir formalment mitjançant una igualtat H1 és la hipòtesi de la que cercam evidència, i s’ha de definir formalment mitjançant alguna cosa “estricta”: Hipòtesi unilateral (one-sided; també d’una cua, one-tailed): definida amb &lt; o amb &gt; Hipòtesi bilateral (two-sided; també de dues cues, two-tailed): definida amb \\(\\neq\\) Els contrastos prenen el nom del tipus d’hipòtesi alternativa: contrast unilateral, de dues cues, etc. 5.2 Un exemple Tenc una moneda, i crec que està trucada a favor de cara. Vull contrastar-ho. Aquí la variable aleatòria \\(X\\) que ens interessa és “Llanç la moneda i anot 1 si surt cara”, que és de Bernoulli amb probabilitat d’èxit (és a dir, probabilitat de treure cara amb la meva moneda) \\(p_{\\mathit{Cara}}\\). La hipòtesi nul·la serà que la moneda no està trucada (no li passa res a la meva moneda), i l’alternativa (de la que cerc evidència) que la moneda està trucada a favor de cara. En termes de \\(p_{\\mathit{Cara}}\\), el contrast és \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Exemple 5.4 Suposem que llanç la moneda 3 vegades i obtenc 3 cares. És evidència suficient que està trucada? Diguem \\(S_3\\) a la variable aleatòria “Nombre de cares en 3 llançaments d’aquesta moneda.” Si la moneda no està trucada, \\(S_3\\) és binomial B(3,0.5) i per tant \\[ P(S_3=3)=0.5^{3}=0.125 \\] El resultat obtengut no és molt improbable amb una moneda equilibrada: passaria en 1 de cada 8 seqüències de 3 llançaments. Per tant, no és evidència suficient que estigui trucada. No podem rebutjar que sigui equilibrada. D’aquest tipus de procediment, emprant la distribució binomial del nombre d’èxits en una mostra aleatòria simple per contrastar un valor de la probabilitat poblacional d’èxit, en direm un test binomial. Exemple 5.5 Suposem que ara llanç la moneda 10 vegades i obtenc 10 cares. És evidència suficient que està trucada? Diguem ara \\(S_{10}\\) a la variable aleatòria “Nombre de cares en 10 llançaments.” Si la moneda no està trucada, \\(S_{10}\\) és B(10,0.5) i per tant \\[ P(S_{10}=10)=0.5^{10}=0.001 \\] El resultat obtengut és molt improbable si la moneda no està trucada: si la moneda fos equilibrada, només en 1 de cada 1000 seqüències de 10 llançaments obtendríem 10 cares. És a dir: El resultat del nostre experiment seria molt estrany si la moneda fos equilibrada, per tant és inversemblant que sigui equilibrada. Ho consideram evidència que està trucada. Fixau-vos en el raonament. Tenim la hipòtesi nul·la i realitzam un experiment per a contrastar-la. Si obtenim un resultat que sembla que la contradiu, una de dues: O la hipòtesi nul·la és falsa. O la hipòtesi nul·la és vertadera i ha passat una cosa molt rara. Què és el més assenyat concloure? Tenint en compte que les coses molt rares no solen passar, el més assenyat és concloure que la hipòtesi nul·la és falsa. Fixau-vos en el procediment: Hem plantejat el contrast: \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Hem recollit una mostra aleatòria: la seqüència de llançaments Hem triat un estadístic de contrast amb distribució mostral coneguda quan H0 és vertadera: al nostre cas, el nombre de cares Hem calculat el valor d’aquest estadístic sobre la nostra mostra Hem calculat la probabilitat que l’estadístic prengui el valor observat si H0 és vertadera Si aquesta probabilitat és molt petita, ho consideram evidència que H1 és vertadera Si no és prou petita, no podem rebutjar que H0 sigui la vertadera Bé, això és el que hem fet, però no és del tot correcte. Als punts (5) i (6) diem que: “Calculam la probabilitat que l’estadístic prengui el valor observat si H0 és vertadera; si és molt petita, ho consideram evidència que H1 és vertadera.” Segur que això està bé? Suposem que, al contrast anterior, llançam la moneda 10 vegades i ara obtenim 10 creus. És evidència suficient que està trucada a favor de cara? Òbviament no ho pot ser, però la probabilitat que passi si H0 és vertadera és la mateixa que abans: \\[ P(S_{10}=0)=0.5^{10}=0.001 \\] En molts casos, la probabilitat d’obtenir exactament el que hem obtengut pot ser molt petita, independentment del que hàgim obtengut. Per exemple, suposem que llançam la moneda 10000 vegades i obtenim 5000 cares. Si la moneda és equilibrada, el nombre de cares seguirà una distribució binomial B(10000,0.5) i la probabilitat d’obtenir 5000 cares serà dbinom(5000,10000,0.5)=0.008, ben petita, però clarament si la meitat de llançaments donen cara, no podem tenir mai evidència que la moneda estigui trucada. O, encara més exagerat, si l’estadístic de contrast té distribució contínua, la probabilitat que prengui un valor concret és 0. Més petit impossible, però no sempre rebutjarem la hipòtesi nu·la. Figura 5.1: “Null hypothesis” (https://xkcd.com/892/ (CC-BI-NC 2.5)) Així que: En realitat, el que es calcula a (5) és la probabilitat que, si H0 és vertadera, l’estadístic prengui un valor tan extrem o més (en el sentit de H1) que l’obtengut. A aquesta probabiitat li diem el p-valor. Al nostre exemple de la moneda, com que la hipòtesi nul·la és \\(p_{\\mathit{Cara}}= 0.5\\) i la hipòtesi alternativa és \\(p_{\\mathit{Cara}}&gt; 0.5\\), el p-valor és la probabilitat que, si \\(p_{\\mathit{Cara}}= 0.5\\), el nombre de cares sigui més gran o igual que l’obtengut a la nostra mostra. En els dos exemples anteriors concrets, on obteníem 3 cares en 3 llançaments i 10 cares en 10 llançaments, és el mateix demanar que el nombre de cares sigui igual a l’obtengut i demanar que el nombre de cares sigui més gran o igual que l’obtengut, perquè en els dos experiments hem obtengut el nombre màxim possible de cares; per exemple, treure 3 o més cares en 3 llançaments és exactament el mateix que treure 3 cares en 3 llançaments. Però en general aquest no serà el cas. Exemple 5.6 Tornem al nostre contrast \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Suposem que llanç la moneda 10 vegades i obtenc 7 cares. És evidència suficient que està trucada? Seguim dient \\(S_{10}\\) a la variable aleatòria “Nombre de cares en 10 llançaments”, que, si la moneda no està trucada, és B(10,0.5). Com que la hipòtesi alternativa és \\(p_{\\mathit{Cara}}&gt; 0.5\\), “obtenir un nombre de cares tan extrem o més que el que hem obtengut en el sentit de la hipòtesi alternativa” és treure tantes cares com les que hem obtengut o més, és a dir treure 7 o més cares. Per tant \\[ \\text{p-valor}=P(S_{10}\\geqslant 7)=\\texttt{1-pbinom(6,10,0.5)}=0.172 \\] Un resultat tan extrem o més que l’obtengut no és molt improbable si la moneda no està trucada: passaria al voltant d’1 de cada 6 ocasions. Per tant, com que és bastant compatible amb el fet que la moneda sigui equilibrada, no ho podem considerar evidència que estigui trucada a favor de cara. Exemple 5.7 Tenc una moneda, i ara crec que està trucada a favor de creu. Vull contrastar-ho. Plantejat en termes de \\(p_{\\mathit{Cara}}\\), el contrast que vull realitzar és \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}: p_{\\mathit{Cara}}&lt; 0.5 \\end{array} \\right. \\] Suposem que llanç la moneda 10 vegades i obtenc 1 cara. És evidència suficient que \\(p_{\\mathit{Cara}}&lt; 0.5\\)? Seguim dient \\(S_{10}\\) a la variable aleatòria “Nombre de cares en 10 llançaments d’aquesta moneda”, que, si H0 és vertadera, és B(10,0.5). Ara, com que H1 és \\(p_{\\mathit{Cara}}&lt; 0.5\\), “obtenir un nombre de cares tan extrem o més que el que hem obtengut en el sentit de la hipòtesi alternativa” és treure tantes cares com les que hem obtengut o menys, és a dir treure 1 cara o cap. Per tant \\[ \\text{p-valor}=P(S_{10}\\leqslant 1)=\\texttt{pbinom(1,10,0.5)}=0.01 \\] Un resultat tan extrem o més que l’obtengut és bastant improbable si \\(p_{\\mathit{Cara}}= 0.5\\): passaria en 1 de cada 100 seqüències de 10 llançaments. Ho podem considerar evidència que la moneda està trucada a favor de creu. 5.3 El p-valor El p-valor d’un contrast és la probabilitat que, si la hipòtesi nul·la és vertadera, l’estadístic de contrast prengui en una mostra aleatòria simple de la mateixa mida que la nostra un valor tan o més extrem, en el sentit de la hipòtesi alternativa, que l’obtengut amb la nostra mostra. Ho tornarem a repetir, posant èmfasi en els components fonamentals de la definició. El p-valor és: La probabilitat que, si la hipòtesi nul·la és vertadera, l’estadístic de contrast prengui en una mostra aleatòria simple de la mateixa mida que la nostra un valor tan o més extrem, en el sentit de la hipòtesi alternativa, que l’obtengut amb la nostra mostra. Exemple 5.8 Suposem que al contrast de les mitjanes d’hores setmanals d’esport d’homes i dones de l’Exemple 5.3 hi empram com a estadístic de contrast la diferència entre les mitjanes mostrals \\(\\overline{X}_d-\\overline{X}_h\\) (que no serà el cas: només és com a exemple!) i que hem pres mostres de 50 dones i de 50 homes, i que la diferència de mitjanes mostrals ha estat -1.2. Aleshores, el p-valor del contrast és La probabilitat que, si la hipòtesi nul·la és vertadera, si \\(\\mu_d=\\mu_h\\), és a dir, si els homes i les dones practiquen de mitjana el mateix nombre d’hores d’esport a la setmana, l’estadístic de contrast prengui en una mostra aleatòria simple de la mateixa mida que la nostra el valor de \\(\\overline{X}_d-\\overline{X}_h\\), és a dir, de la mitjana mostral d’hores setmanals d’esport en les dones menys la mitjana mostral d’hores setmanals d’esport en els homes, d’una mostra aleatòria formada per 50 dones i 50 homes, sigui un valor tan o més extrem, en el sentit de la hipòtesi alternativa, més petit o igual (perquè la hipòtesi alternativa és \\(\\mu_d&lt;\\mu_h\\), és a dir \\(\\mu_d-\\mu_h&lt;0\\)) que l’obtengut amb la nostra mostra. que el de la nostra mostra, -1.2 En resum, el p-valor seria en aquest cas La probabilitat, si \\(\\mu_d=\\mu_h\\), que, si prenem una mostra aleatòria de 50 dones i 50 homes, el valor de \\(\\overline{X}_d-\\overline{X}_h\\) que obtenguem sigui més petit o igual que -1.2: \\[ P(\\overline{X}_d-\\overline{X}_h\\leqslant -1.2\\mid \\mu_d=\\mu_h) \\] Si aquesta probabilitat és molt petita, la mostra obtenguda és poc consistent amb la hipòtesi nul·la i per tant conclourem que la hipòtesi alternativa és vertadera. Si, en canvi, aquesta probabilitat no és molt petita, la mostra obtenguda és consistent amb la hipòtesi nul·la i per tant no podrem rebutjar que H0 sigui vertadera. El p-valor no és: La probabilitat que H0 sigui vertadera condicionada al nostre resultat La probabilitat que H1 sigui falsa condicionada al nostre resultat És a l’inrevés: El p-valor és la probabilitat del nostre resultat (o quelcom més extrem en el sentit del qual cercam evidència) condicionada al fet que H0 sigui vertadera. Per tant, el p-valor és una evidencia indirecta inversa de H1: Com més petit sigui el p-valor, més rar seria el que hem obtengut si H0 fos vertadera i H1 falsa, i per tant més evidència tenim que H0 no pot ser vertadera i que la vertadera és H1. Per exemple, que el p-valor d’un contrast doni 0.03 Significa que, si H0 és vertadera, la probabilitat que l’estadístic de contrast prengui sobre una mostra un valor tan extrem o més que el que hem obtengut és 0.03 La trobau petita? Ho preneu com a evidència que H0 és falsa i H1 vertadera No la trobau petita? No teniu evidència per rebutjar que H0 sigui vertadera No significa que: La probabilitat que H0 sigui vertadera és 0.03 H0 és vertadera un 3% de les vegades En un contrast d’hipòtesis no obtenim cap informació directa sobre la probabilitat de H0 o de H1. Exemple 5.9 Tenc una moneda i vull saber si està trucada; a favor de cara o a favor de creu, m’és igual, només vull saber si està trucada. Ho decidiré amb un contrast. Plantejat en termes de la probabilitat de treure cara \\(p_{\\mathit{Cara}}\\), el contrast que vull realitzar ara és \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}\\neq 0.5 \\end{array} \\right. \\] Suposem que la llanç 10 vegades i obtenc 8 cares. És evidència suficient que està trucada? Com a la secció anterior, diguem \\(S_{10}\\) a la variable “Nombre de cares en 10 llançaments”. Si \\(p_{\\mathit{Cara}}= 0.5\\), \\(S_{10}\\) és B(10,0.5). Si la hipòtesi nul·la fos vertadera, esperaríem treure 5 cares i 5 creus. Com que la hipòtesi alternativa és \\(H_{1}:p_{\\mathit{Cara}}\\neq 0.5\\), ara “obtenir un resultat tan o més extrem, en el sentit de la hipòtesi alternativa, que l’obtengut” és treure un resultat tant o més diferent de 5 cares i 5 creus que l’obtengut: és a dir, treure almenys 8 cares o almenys 8 creus, o el que és el mateix, treure com a mínim 8 cares o com a màxim 2 cares. Per tant, el p-valor és \\[ \\begin{array}{l} P(S_{10}\\geqslant 8\\text{ o }S_{10}\\leqslant 2) =P(S_{10}\\geqslant 8) + P(S_{10}\\leqslant 2)\\\\ \\qquad =1-P(S_{10}\\leqslant 7) + P(S_{10}\\leqslant 2)\\\\ \\qquad =\\texttt{1-pbinom(7,10,0.5)+pbinom(2,10,0.5)}\\\\ \\qquad =0.11 \\end{array} \\] Per tant, si la moneda no està trucada, un resultat com l’obtengut o més llunyà de “meitat cares, meitat creus” és improbable, però no gaire (1 de cada 9 vegades passaria). És evidència suficient que estigui trucada? Quin p-valor marca el llindar de l’inversemblança de H0? Figura 5.2: No adorareu falsos déus. La resposta és que depèn de quant estiguem disposats a equivocar-nos. 5.4 Tipus d’errors La comparació entre la realitat i la decisió resultant d’un contrast dóna lloc a quatre situacions possibles, resumides en la taula següent: H0 és la vertadera a la realitat i nosaltres decidim que H1 és vertadera*. La conclusió del contrast és errònia. En diem error de tipus I o positiu fals. Indicarem amb \\(\\alpha\\) la probabilitat de cometre un error de tipus I, és a dir, de rebutjar H0 si és vertadera, i en direm el nivell de significació: \\[ \\alpha=P(\\text{Rebutjar } H_0| H_0\\text{ vertadera}). \\] H1 és vertadera a la realitat i nosaltres acceptam H0*. La conclusió del contrast és errònia. En diem error de tipus II o negatiu fals. Indicarem amb \\(\\beta\\) la probabilitat de cometre un error de tipus II, és a dir, d’acceptar H0 si H1 és vertadera,: \\[ \\beta=P(\\text{Acceptar } H_0| H_1\\text{ vertadera}). \\] H1 és vertadera a la realitat i nosaltres decidim que H1 és vertadera*. La conclusió del contrast és correcta. En diem un positiu vertader. La probabilitat d’encertar amb un positiu vertader és \\(1-\\beta\\) i en direm la potència: \\[ 1-\\beta=P(\\text{Rebutjar } H_0| H_1\\text{ vertadera}). \\] H0 és la vertadera a la realitat i nosaltres l’acceptam*. La conclusió del contrast és correcta. En diem un negatiu vertader. La probabilitat d’encertar amb un negatiu vertader és \\(1-\\alpha\\) i en direm el nivell de confiança: \\[ 1-\\alpha=P(\\text{Acceptar } H_0| H_0\\text{ vertadera}). \\] En el context d’un contrast d’hipòtesis, un resultat positiu és rebutjar la hipòtesi nul·la i decidir que l’alternativa és la vertadera (hem trobat qualque cosa) un resultat negatiu és acceptar la hipòtesi nul·la (no hem trobat res i ens hem de conformar amb la hipòtesi nul·la) Ho tornam a repetir: El nivell de significació, \\(\\alpha\\), d’un contrast és la probabilitat que, si la hipòtesi nul·la és vertadera, nosaltres ens equivoquem i la rebutgem a favor de l’alternativa: \\[ \\alpha=P(\\text{Rebutjar } H_0| H_0\\text{ vertadera}). \\] Per tant, és una probabilitat d’error. La potència, \\(1-\\beta\\), d’un contrast és la probabilitat que, si la hipòtesi alternativa és vertadera, nosaltres ho detectem i rebutgem la hipòtesi nul·la a favor de l’alternativa: \\[ 1-\\beta=P(\\text{Rebutjar } H_0| H_1\\text{ vertadera}). \\] Per tant, és una probabilitat d’encert. Exemple 5.10 En un test d’embaràs, el contrast que es realitza és: \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{No estàs embarassada}\\\\ H_{1}:\\text{Estàs embarassada} \\end{array} \\right. \\] Exemple 5.11 En un judici, on s’ha de declarar un acusat innocent o culpable, el contrast era \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;acusat és innocent}\\\\ H_{1}:\\text{L&#39;acusat és culpable} \\end{array} \\right. \\] Es poden cometre dos errors: Error de tipus I: Declarar culpable un innocent Error de tipus II: Declarar no culpable un culpable És pitjor l’error de tipus I, convé minimitzar-lo. Per això només es declara qualcú culpable quan les proves ho demostren més enllà de qualsevol dubte raonable. Exemple 5.12 En un examen, el contrast era \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;estudiant no sap la matèria}\\\\ H_{1}:\\text{L&#39;estudiant sap la matèria} \\end{array} \\right. \\] Es poden donar dos errors: Que l’estudiant aprovi sense saber la matèria Que l’estudiant suspengui sabent la matèria Quin és el de tipus I i quin el de tipus II? Quin creieu que és pitjor? Normalment, es considera pitjor cometre un error de tipus I que cometre un error de tipus II. Per tant, l’objectiu primari en un contrast és trobar una regla de rebuig de H0 que tengui poca probabilitat \\(\\alpha\\) d’error de tipus I. Però també voldríem minimitzar la probabilitat \\(\\beta\\) d’error de tipus II. El problema és que quan fem disminuir \\(\\alpha\\), sol augmentar \\(\\beta\\). Per disminuir \\(\\alpha\\), fem més difícil rebutjar la hipòtesi nul·la, i això fa que augmenti la probabilitat d’acceptar-la encara que sigui falsa. Què se sol fer? Donar una regla de decisió per a un \\(\\alpha\\) màxim fixat. És costum prendre \\(\\alpha=0.05\\): una mica menys que la probabilitat de treure 4 cares seguides amb una moneda equilibrada. Després, augmentar la mida \\(n\\) de la mostra per arribar a la \\(\\beta\\) desitjada. Abans d’acabar amb els errors, fixau-vos que si efectuam \\(M\\) contrastos (independents) emprant una regla de decisió que garanteixi un nivell de significació \\(\\alpha\\) fixat, i a tots aquests contrastos la H0 és vertadera, el nombre de contrastos d’aquests on ens equivocarem i rebutjarem H0 té distribució binomial B(M,\\(\\alpha\\)). En concret, prenent el nivell de significació usual \\(\\alpha=0.05\\), acceptam una probabilitat d’equivocar-nos rebutjant H0 a favor de H1 de 0.05. És a dir, assumim que, de mitjana, la nostra conclusió serà equivocada en 1 de cada 20 pics que la hipòtesi nul·la sigui vertadera. Si efectuam molts contrastos, augmenta la probabilitat de “trobar qualque cosa” encara que no hi hagi res que trobar, i acabar dient que les gominoles verdes curen l’acné: Figura 5.3: “Significant” (https://xkcd.com/882/ (CC-BY-NC 2.5)) 5.5 Exemple: El test t La concentració mitjana de calci en plasma en homes sans de 22 a 44 anys és de 2.5 mmol/l. Ens demanam si els homes joves amb diabetis tenen una concentració de calci en plasma superior a la dels homes joves sans. Ho traduirem en un contrast d’hipòtesis sobre la concentració mitjana de calci en plasma en els homes joves diabètics, diguem-li \\(\\mu\\): La hipòtesi nul·la serà que no hi ha diferència entre \\(\\mu\\) i la concentració mitjana de calci en plasma en els homes joves sans, és a dir, que \\(\\mu=2.5\\). La hipòtesi alternativa és d’allò que cercam evidència: que \\(\\mu\\) és més gran que la concentració mitjana de calci en plasma en els homes joves sans, és a dir, que \\(\\mu&gt;2.5\\). Per tant, el contrast que volem realitzar és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=2.5\\\\ H_{1}:\\mu &gt;2.5 \\end{array} \\right. \\] Diguem \\(X\\) a la variable aleatòria “Prenem un home diabètic de 22 a 44 anys i li mesuram la concentració de calci en plasma en mmol/l”. Se sap que la concentració de calci en plasma en homes sans segueix una llei aproximadament normal, així que suposarem que la nostra \\(X\\) també és normal. En una mostra de 20 diabètics d’aquesta franja d’edat, es va obtenir una concentració mitjana de calci \\(\\overline{X}=3.2\\) mmol/l amb una desviació típica mostral \\(\\widetilde{S}_X=1.5\\). Suposem que aquesta mostra de diabètics joves és representativa i que la podem considerar aleatòria. La nostra situació, doncs, és un cas particular del cas general següent. Tenim una variable aleatòria poblacional \\(X\\) normal de mitjana \\(\\mu\\) i plantejam el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt;\\mu_0 \\end{array} \\right. \\] per a un valor concret \\(\\mu_0\\). Volem prendre una decisió a partir d’una mostra aleatòria simple. En aquesta situació, si H0 és vertadera, és a dir, si la mitjana de \\(X\\) és \\(\\mu_0\\), sabem que \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] té distribució \\(t_{n-1}\\). La idea que guiarà el procediment per prendre una decisió en aquest contrast serà: Rebutjarem H0 a favor de H1 si aquest estadístic de contrast \\(T\\) pren un valor “molt gran” sobre la mostra, és a dir, si \\(\\overline{X}\\) és “molts errors típics” més gran que \\(\\mu_0\\). La definició precisa de “molt gran” dependrà del valor d’\\(\\alpha\\) que volguem prendre, és a dir, de la probabilitat de cometre un error de tipus I que estiguem disposats a assumir: quant més petit volguem que sigui \\(\\alpha\\), més gran haurà de ser l’evidència a favor de \\(\\mu&gt;\\mu_0\\), és a dir, més gran haurà de ser \\(T\\). Aquí prendrem el valor usual \\(\\alpha=0.05\\): acceptam que tenim una probabilitat del 5% que, si la hipòtesi nul·la és vertadera, la nostra conclusió sigui que és falsa. Sigui \\(T_0\\) el valor que pren l’estadístic de contrast \\(T\\) en la nostra mostra. Rebutjarem H0 si \\(T_0\\) és més gran que un cert llindar \\(L_0\\), que determinam a partir de \\(\\alpha\\). Per fer-ho, igualarem a \\(\\alpha\\) la probabilitat que \\(T&gt; L_0\\) si la hipòtesi nul·la és vertadera, cas en el qual \\(T\\) té distribució \\(t_{n-1}\\), i aïllarem \\(L_0\\). \\[ \\begin{array}{l} \\alpha = P(\\text{Rebutjar } H_{0}| H_{0} \\text{ certa})=P(T&gt; L_0)\\\\ \\qquad\\quad \\Longleftrightarrow 1-\\alpha= P(T\\leqslant L_0)\\Longleftrightarrow L_0= t_{n-1,1-\\alpha} \\end{array} \\] Per tant, a fi que el nivell de significació del contrast sigui \\(\\alpha\\), Rebutjarem H0 si \\(T_0&gt;t_{n-1,1-\\alpha}\\) En direm una regla de rebuig per aquest tipus de contrast. Tornem al nostre exemple dels diabètics \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=2.5\\\\ H_{1}:\\mu &gt; 2.5 \\end{array} \\right. \\] Si \\(\\alpha=0.05\\) i \\(n=20\\), el llindar a partir del qual rebutjam H0 és \\(t_{n-1,1-\\alpha}=t_{19,0.95}=\\texttt{qt(0.95,19)}=1.73\\). A la nostra mostra hi tenim que \\(\\overline{X}=3.2\\), \\(\\widetilde{S}_X=1.5\\) i \\(n=20\\), per tant l’estadístic de contrast val \\[ T_0=\\frac{3.2-2.5}{1.5/\\sqrt{20}}=2.09 \\] Com que \\(2.09&gt;1.73\\), concloem amb un nivell de significació de 0.05 que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els joves sans. Vegem ara com entra en joc el p-valor. Recordem que rebutjarem H0 quan \\(T_0&gt;t_{n-1,1-\\alpha}\\): \\[ \\begin{array}{l} \\text{Rebutjarem } H_0 \\Longleftrightarrow T_0&gt; t_{n-1,1-\\alpha}\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt; P(T\\geqslant t_{n-1,1-\\alpha})\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt; 1-P(T\\leqslant t_{n-1,1-\\alpha})=1-(1-\\alpha)=\\alpha\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt;\\alpha \\end{array} \\] I ara observau que \\(P(T\\geqslant T_0)\\) és la probabilitat que, si H0 és vertadera, l’estadístic de contrast \\(T\\) prengui un valor tan extrem o més, en el sentit de \\(H_1: \\mu&gt;2.5\\), que l’obtengut en la nostra mostra, \\(T_0\\): és el p-valor del contrast. Per tant, tenim una altra regla de rebuig (equivalent a l’anterior): Rebutjarem H0 quan el p-valor sigui més petit que \\(\\alpha\\) En el nostre exemple, ja hem calculat \\(T_0=2.09\\). Llavors, \\[ \\text{p-valor} =P(T\\geqslant 2.09)=\\texttt{1-pt(2.09,19)} =0.025 \\] Com que el p-valor és més petit que 0.05, Concloem amb un nivell de significació de 0.05 que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els sans. Això se sol expressar dient que: Hem obtengut evidència estadísticament significativa que el nivell mitjà de calci en plasma en els joves diabètics és més gran que en els joves sans. D’aquest tipus de procediment per comparar la \\(\\mu\\) d’una variable amb un valor donat \\(\\mu_0\\), emprant que \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] té distribució t de Student amb \\(n-1\\) graus de llibertat, \\(t_{n-1}\\), se’n diu un test t. Com explicarem al pròxim tema, podem emprar un test t per contrastar una mitjana quan la variable poblacional és normal i també quan la variable poblacional no és normal però la mostra és prou gran (posem, \\(n\\geqslant 40\\)). Fixau-vos que la nostra conclusió ha estat que “concloem amb un nivell de significació de 0.05 que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els joves sans.” Per tant, reconeixem una probabilitat d’haver-nos equivocat del 5%: Si en realitat el nivell mitjà de calci en sang en els joves diabètics és el mateix que en els sans, la probabilitat que teníem d’equivocar-nos i concloure que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els sans és del 5%. Exemple 5.13 Anem a estudiar aquesta taxa d’encerts per mitjà d’una simulació. Primer suposarem que el nivell mitjà real és 2.5, i simularem la probabilitat d’error de tipus I. Com que estam fent el contrast amb nivell de significació 0.05, esperam al voltant d’un 5% d’errors de tipus I. Per fixar idees, modelarem la població de joves diabètics per mitjà d’una variable aleatòria \\(N(2.5,0.5)\\). La \\(\\sigma=0.5\\) ens l’hem inventada. Aprofitam per fixar la llavor d’aleatorietat. set.seed(42) mu0=2.5 sigma0=0.5 El llindar \\(L_0\\) per \\(n=20\\) i \\(\\alpha=0.05\\) és L0=qt(0.95,19) L0 ## [1] 1.729133 La funció estadístic següent pren una mostra aleatòria de mida \\(n\\) d’una variable \\(N(\\mu, \\sigma)\\) i en calcula l’estadístic de contrast \\(T\\): estadístic=function(n,mu,sigma){ mostra=rnorm(n,mu,sigma) (mean(mostra)-mu0)/(sd(mostra)/sqrt(n)) } Ara, repetim 200 vegades el procés de prendre una mostra aleatòria de mida 20 de la nostra població i calcular la \\(T\\) corresponent. Després miram la proporció de vegades que això ha donat més gran que el llindar \\(L_0\\), és a dir, la proporció de vegades que rebutjam la hipòtesi nul·la \\(\\mu=2.5\\) i que per tant cometem un error de tipus I. Tes=replicate(200,estadístic(20,mu0,sigma0)) p.error.Tipus.I=length(Tes[Tes&gt;L0])/200 p.error.Tipus.I ## [1] 0.05 Hem comès exactament un 5% d’errors de tipus I! Ara suposarem que el nivell mitjà real és estrictament més gran que 2.5, i anam a simular els errors de tipus II, per veure amb quina freqüència els cometem. Per començar, generam un vector de 100 \\(\\mu\\)’s entre 2.6 i 3, de manera que tots els valors tenguin la mateixa probabilitat de sortir. mus=runif(100,2.6,3) I ara el que farem serà el següent. Per a cada \\(\\mu_i\\) d’aquest vector, prendrem com a “població de diabètics” una variable \\(N(\\mu_i,0.5)\\). A continuació, per a cada una d’aquestes poblacions, repetirem 200 vegades el procés de prendre una mostra aleatòria simple de mida 20 d’aquesta població i calcular la \\(T\\) corresponent. Després, per a cada població, calcularem la proporció de vegades que això ha donat més petit o igual que el llindar, és a dir, la proporció de vegades que acceptam la hipòtesi nul·la \\(\\mu=2.5\\) i que per tant cometem un error de tipus II. Organitzarem totes aquestes proporcions en un vector p.error.Tipus.II. p.error.Tipus.II=rep(1,100) for (j in 1:100){ Tes=replicate(200,estadístic(20,mus[j],sigma0)) p.error.Tipus.II[j]=round(length(Tes[Tes&lt;=L0])/200,2) } p.error.Tipus.II ## [1] 0.24 0.36 0.52 0.53 0.31 0.04 0.08 0.09 0.78 0.68 0.62 0.00 0.10 0.12 0.65 ## [16] 0.01 0.04 0.62 0.57 0.10 0.58 0.25 0.30 0.00 0.29 0.48 0.26 0.00 0.09 0.66 ## [31] 0.07 0.08 0.79 0.03 0.03 0.00 0.00 0.56 0.52 0.23 0.72 0.04 0.70 0.77 0.74 ## [46] 0.70 0.06 0.15 0.06 0.48 0.00 0.04 0.10 0.01 0.01 0.00 0.35 0.60 0.58 0.64 ## [61] 0.08 0.38 0.09 0.40 0.78 0.02 0.03 0.66 0.47 0.27 0.18 0.05 0.59 0.01 0.04 ## [76] 0.44 0.33 0.34 0.66 0.01 0.10 0.68 0.73 0.74 0.21 0.07 0.18 0.69 0.01 0.32 ## [91] 0.06 0.64 0.66 0.27 0.08 0.49 0.20 0.01 0.10 0.42 En alguns casos no hem comès cap error, i en uns altres la majoria de conclusions han estat errònies. La proporció mitjana d’errors de tipus II ha estat: mean(p.error.Tipus.II) ## [1] 0.3092 Si prenem mostres més grans, la probabilitat d’error de tipus II disminueix. Comprovem-ho repetint aquest segon experiment amb mostres de mida 200. p.error.Tipus.II.200=rep(1,100) for (j in 1:100){ Tes=replicate(200,estadístic(200,mus[j],sigma0)) p.error.Tipus.II.200[j]=round(length(which((Tes&lt;=L0)==TRUE))/200,2) } mean(p.error.Tipus.II.200) ## [1] 0.0078 Multiplicant per 10 la mida de les mostres, hem baixat d’una taxa d’errors de tipus II del 30.92% al 0.78%. Recordau que la potència d’un contrast és la probabilitat de no cometre un error de tipus II. Hem vist que prenent mostres més grans, la proporció d’errors de tipus II ha disminuït. Això és general: Si fixam el nivell de significació, com més grans són les mostres, més gran és la potència del contrast. Tornem a la situació general en la que tenim una variable aleatòria \\(X\\) normal i volem comparar la seva mitjana \\(\\mu\\) amb un cert valor \\(\\mu_0\\) i suposem que ara cercam evidència que \\(\\mu&lt;\\mu_0\\), de manera que el contrast és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &lt; \\mu_0 \\end{array} \\right. \\] En aquest cas, el p-valor és \\(P(T\\leqslant T_0)\\) i, raonant exactament igual com abans, obtenim les dues regles de rebuig equivalents següents: Rebutjarem H0 si \\(T_0&lt; t_{n-1,\\alpha}\\) Rebutjarem H0 si el p-valor és més petit que \\(\\alpha\\) I què passa si ara cercam evidència que \\(\\mu\\) és diferent de \\(\\mu_0\\)? És a dir, si tenim el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu\\ \\neq \\mu_0 \\end{array} \\right. \\] En aquest cas, rebutjarem H0 quan \\(\\overline{X}\\) és prou diferent de \\(\\mu_0\\), per damunt o per davall de \\(\\mu_0\\), i això ho traduïm en que rebutjarem H0 quan \\(|T_0|\\) (el valor absolut de \\(T_0\\)) sigui més gran que un cert llindar \\(L_0\\), que determinam a partir de \\(\\alpha\\) com abans: \\[ \\begin{array}{l} \\alpha = P(\\text{Rebutjar } H_{0}| H_{0} \\text{ certa})=P(|T|&gt; L_0)\\\\ \\hphantom{\\alpha} = P(T&lt; -L_0\\text{ o } T&gt;L_0)= P(T&lt; -L_0)+P(T&gt;L_0)\\\\ \\hphantom{\\alpha} =2P(T&gt;L_0) \\text{ (per la simetria de $t_{n-1}$)}\\\\ \\Longleftrightarrow \\alpha/2=P(T&gt;L_0)= 1-P(T\\leqslant L_0) \\\\ \\Longleftrightarrow P(T\\leqslant L_0)=1-\\alpha/2\\Longleftrightarrow L_0= t_{n-1,1-\\alpha/2} \\end{array} \\] Per tant, en un contrast bilateral amb nivell de significació \\(\\alpha\\), tenim la regla de rebuig següent: Rebutjarem H0 si \\(|T_0|&gt;t_{n-1,1-\\alpha/2}\\) En aquest cas, el p-valor serà la probabilitat que \\(T\\) prengui un valor tant o més extrem que \\(T_0\\), en el sentit de la hipòtesi alternativa, és a dir, més enfora de 0 que \\(T_0\\): més gran que \\(|T_0|\\) o més petit que \\(-|T_0|\\): \\[ \\text{p-valor} =P(T\\leqslant -|T_0|)+P(T\\geqslant |T_0|)=2 P(T\\geqslant |T_0|). \\] Observau que tornam a emprar que, per la simetria de les variables t de Student, \\(P(T\\leqslant -|T_0|)=P(T\\geqslant |T_0|)\\). Per tant, \\[ \\begin{array}{l} \\text{Rebutjam }H_0 \\Longleftrightarrow |T_0|&gt;t_{n-1,1-\\alpha/2}\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant |T_0|)&lt;{\\alpha}/{2}\\\\ \\qquad\\Longleftrightarrow 2 P(T\\geqslant |T_0|)&lt;\\alpha\\\\ \\qquad \\Longleftrightarrow \\text{p-valor} &lt; \\alpha \\end{array} \\] Per tant, en un contrast bilateral amb nivell de significació \\(\\alpha\\) també tenim la regla de rebuig: Rebutjarem H0 si el p-valor és més petit que \\(\\alpha\\) En resum, en un contrast d’una mitjana \\(\\mu\\) emprant un test t i nivell de significació \\(\\alpha\\): Si \\(H_1:\\mu&gt; \\mu_0\\): Rebutjam H0 si \\(T_0&gt;t_{n-1,1-\\alpha}\\) El p-valor és \\(P(T\\geqslant T_0)\\) i rebutjam H0 si aquest p-valor és més petit que \\(\\alpha\\) Si \\(H_1:\\mu&lt; \\mu_0\\): Rebutjam H0 si \\(T_0&lt; t_{n-1,\\alpha}\\) El p-valor és \\(P(T\\leqslant T_0)\\) i rebutjam H0 si aquest p-valor és més petit que \\(\\alpha\\) Si \\(H_1:\\mu\\neq \\mu_0\\): Rebutjam H0 si \\(|T_0|&gt;t_{n-1,1-\\alpha/2}\\) El p-valor és \\(2P(T\\geqslant |T_0|)\\) i rebutjam H0 si aquest p-valor és més petit que \\(\\alpha\\) Exemple 5.14 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&gt;20 \\end{array} \\right. \\] amb un nivell de significació de 0.05. Prenem una mostra aleatòria simple de \\(n=25\\) observacions i obtenim \\(\\overline{X}=20.7\\) i \\(\\widetilde{S}_X=1.8\\). Què decidim? Estadístic de contrast: \\(T=\\dfrac{\\overline{X}-\\mu_0}{\\widetilde{S}_X/\\sqrt{n}}\\) Pren el valor \\[ T_0=\\dfrac{20.7-20}{{1.8}/{\\sqrt{25}}}=1.944 \\] p-valor \\[ P(T\\geqslant 1.944)=\\texttt{1-pt(1.944,24)}=0.032 \\] Decisió: Com que el p-valor és més petit que 0.05, rebutjam H0 i concloem (amb \\(\\alpha=0.05\\)) que \\(\\mu&gt;20\\). Exemple 5.15 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&gt;20 \\end{array} \\right. \\] amb un nivell de significació de 0.01. Amb la mateixa mostra aleatòria simple de l’exemple anterior, què decidim? El p-valor és el mateix que abans, 0.032, perquè el contrast i la mostra són els mateixos. Com que aquest p-valor és més gran que 0.01, amb \\(\\alpha=0.01\\) no podem rebutjar que \\(\\mu=20\\). Exemple 5.16 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&lt; 20 \\end{array} \\right. \\] amb un nivell de significació de 0.05. Amb la mateixa mostra aleatòria simple dels exemples anteriors (\\(n=25\\), \\(\\overline{X}=20.7\\), \\(\\widetilde{S}_X=1.8\\)), què decidim? L’estadístic de contrast i el seu valor \\(T_0\\) són el mateixos que abans. p-valor \\[ P(T\\leqslant 1.944)=\\texttt{pt(1.944,24)}=0.968 \\] Decisió: Com que el p-valor és més gran que 0.05, amb \\(\\alpha=0.05\\) no podem rebutjar que \\(\\mu=20\\). Vegem, com volíeu que concloguéssim que \\(\\mu&lt;20\\) si ens ha sortit una mitjana mostral 20.7, més gran que 20? No feia falta fer cap càlcul (i exposar-nos a equivocar-nos), bastava raonar una mica. Exemple 5.17 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu\\neq 20 \\end{array} \\right. \\] amb un nivell de significació de 0.05. Amb la mateixa mostra aleatòria simple dels exemples anteriors, què decidim? Recordem que \\(n=25\\), \\(\\overline{X}=20.7\\) i \\(\\widetilde{S}_X=1.8\\). L’estadístic de contrast prenia el valor \\(T_0=1.944\\). Ara el p-valor és \\[ 2\\cdot P(T\\geqslant 1.944)=\\texttt{2*(1-pt(1.944,24))}=0.064 \\] Com que el p-valor és més gran que 0.05, amb \\(\\alpha=0.05\\) no podem rebutjar que \\(\\mu=20\\), i per tant no podem concloure que \\(\\mu\\neq 20\\). Com pot ser que amb la mateixa mostra i mateix nivell de significació poguem concloure que \\(\\mu&gt; 20\\) però no poguem concloure que \\(\\mu\\neq 20\\)? O és que \\(\\mu&gt; 20\\) no implica que \\(\\mu\\neq 20\\)? Vegem, si haguéssim demostrat que segur que \\(\\mu&gt; 20\\), està clar que això implicaria que \\(\\mu\\neq 20\\). Però hem arribat a la conclusió \\(\\mu&gt; 20\\) assumint un cert marge d’error, una probabilitat d’error de tipus I de 0.05, i ens demanam si \\(\\mu\\neq 20\\) assumint el mateix marge d’error. En aquesta situació les regles de la lògica aristotèlica ja no funcionen. Fixau-vos que, en realitat, el que passa és que trobarem evidència que \\(\\mu\\neq 20\\) si \\(T\\) és molt gran o molt petit, i per tant al contrast bilateral hi tenim dues fonts d’error de tipus I: que per pur atzar \\(T\\) ens surti molt gran o que ens surti molt petit. En canvi, només trobarem evidència que \\(\\mu&gt; 20\\) si \\(T\\) és molt gran, i per tant hi tenim una sola font d’error de tipus I. Aleshores, per garantir una mateixa probabilitat d’error de tipus I, hem de ser molt més exigents al contrast bilateral, on ens podem equivocar de dues maneres diferents, que a l’unilateral. Exemple 5.18 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu\\neq 20 \\end{array} \\right. \\] amb un nivell de significació de 0.05. Prenem una mostra aleatòria simple de \\(n=25\\) observacions i obtenim \\(\\overline{X}=19\\) i \\(\\widetilde{S}_X=1.8\\). Què decidim? Estadístic de contrast: \\(T=\\dfrac{\\overline{X}-\\mu_0}{\\widetilde{S}_X/\\sqrt{n}}\\) Pren el valor \\[ T_0=\\dfrac{19-20}{{1.8}/{\\sqrt{25}}}=-2.778 \\] p-valor \\[ 2P(T\\geqslant -2.778)=\\texttt{2*(1-pt(-2.778,24))}=1.99 \\] Decisió: com que el p-valor és més gran que \\(\\alpha\\), no podem rebutjar H0. El p-valor és una probabiitat. Com voleu que doni 1.99? NO! El p-valor no és \\(2\\cdot P(T\\geqslant T_0)\\), sinó \\(2\\cdot P(T\\geqslant |T_0|)\\). Per tant, el p-valor és \\[ 2\\cdot P(T\\geqslant 2.778)=\\texttt{2*(1-pt(2.778,24))}=0.01 \\] i com que p-valor és més petit que \\(\\alpha\\), podem rebutjar H0 i concloure, amb nivell de significació 0.05, que \\(\\mu\\neq 20\\). 5.6 Recapitulació Repassem els conceptes introduïts fins ara, i posem nom a alguns altres: Nivell de significació, \\(\\alpha\\): probabilitat de rebutjar H0 si aquesta és vertadera (probabilitat d’error de tipus I, de positiu fals). Nivell de confiança, \\(1-\\alpha\\): probabilitat d’acceptar H0 si aquesta és vertadera (probabilitat de negatiu vertader). Potència, \\(1-\\beta\\): probabilitat de rebutjar H0 si H1 és vertadera (probabilitat de positiu vertader). Estadístic de contrast: el que calculam sobre una mostra aleatòria simple i del qual coneixem la distribució de probabilitat si H0 és vertadera. Regió crítica o de rebuig: el rang de valors de l’estadístic de contrast per als quals rebutjam H0 amb un nivell de significació \\(\\alpha\\) donat. Regió d’acceptació: el complementari de la regió de rebuig, és a dir, el rang de valors de l’estadístic de contrast per als quals acceptam H0 amb un nivell de significació \\(\\alpha\\) donat. p-valor: la probabilitat que, si H0 és vertadera, l’estadístic de contrast prengui sobre una mostra aleatòria simple de la mateixa mida que la nostra un valor tan o més extrem (en el sentit de H1) que l’obtengut sobre la nostra mostra. L’estadístic de contrast pertany a la regió de rebuig si, i només si, el p-valor és més petit que el nivell de significació. Exemple 5.19 Si realitzam un test t per efectuar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt; \\mu_0 \\end{array} \\right. \\] rebutjam H0 amb nivell de significació \\(\\alpha\\) quan \\[ T=\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}&gt;t_{n-1,1-\\alpha} \\] Per tant: Estadístic de contrast: aquest \\(T\\) Regió de rebuig per aquest \\(\\alpha\\): l’interval \\((t_{n-1,1-\\alpha},\\infty)\\) Regió d’acceptació per aquest \\(\\alpha\\): l’interval \\((-\\infty,t_{n-1,1-\\alpha}]\\) p-valor: \\(P(T\\geqslant T_0)\\), on \\(T_0\\) indica el valor de \\(T\\) sobre la nostra mostra Si en canvi el contrast que volem efectuar és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &lt; \\mu_0 \\end{array} \\right. \\] rebutjam H0 amb nivell de significació \\(\\alpha\\) quan \\[ T=\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}&lt;t_{n-1,\\alpha} \\] Per tant: Estadístic de contrast: el mateix \\(T\\) que abans Regió de rebuig per aquest \\(\\alpha\\): l’interval \\((-\\infty,t_{n-1,\\alpha})\\) Regió d’acceptació per aquest \\(\\alpha\\): l’interval \\([t_{n-1,\\alpha},\\infty)\\) p-valor: \\(P(T\\leqslant T_0)\\) Finalment, si el contrast que volem realitzar és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq \\mu_0 \\end{array} \\right. \\] rebutjam H0 amb nivell de significació \\(\\alpha\\) quan \\[ |T|=\\left|\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\right|&gt;t_{n-1,1-\\alpha/2} \\] Per tant: Estadístic de contrast: el mateix \\(T\\) que abans Regió de rebuig per aquest \\(\\alpha\\): la unió d’intervals \\((-\\infty,-t_{n-1,1-\\alpha/2})\\cup (t_{n-1,1-\\alpha/2},\\infty)\\) Regió d’acceptació per aquest \\(\\alpha\\): l’interval \\([-t_{n-1,1-\\alpha/2},t_{n-1,1-\\alpha/2}]\\) p-valor: \\(2P(T\\geqslant |T_0|)\\) Interval de confiança d’un contrast L’interval de confiança de nivell de confiança \\(1-\\alpha\\) d’un contrast és un interval que té probabilitat \\(1-\\alpha\\) de contenir el valor real del paràmetre poblacional que contrastam, en el sentit dels intervals de confiança del tema anterior: es calcula amb una fórmula que en una fracció \\(1-\\alpha\\) de les ocasions que l’aplicam a una mostra aleatòria simple, dóna un interval que conté el paràmetre d’interès. Aquest interval de confiança s’obté imposant que l’estadístic de contrast pertanyi a la regió d’acceptació per al nivell de significació \\(\\alpha\\) i aïllant el paràmetre poblacional. Quan H1 és bilateral, coincideix amb l’interval de confiança donat en el tema anterior. Quan H1 és unilateral, dóna un interval infinit al costat definit per la hipòtesi alternativa. Per exemple, considerem el cas de un test t per efectuar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt; \\mu_0 \\end{array} \\right. \\] Acceptam H0 amb nivell de significació \\(\\alpha\\) quan \\[ \\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\leqslant t_{n-1,1-\\alpha} \\] Aïllant \\(\\mu_0\\), obtenim \\[ \\overline{X}- t_{n-1,1-\\alpha}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant \\mu_0 \\] Per tant, l’interval de confiança de nivell de confiança \\(1-\\alpha\\) per a aquest contrast és \\[ \\Bigg[\\overline{X}- t_{n-1,1-\\alpha}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}},\\infty\\Bigg) \\] Si la \\(\\mu_0\\) que contrastam pertany a aquest interval, no podem concloure que la \\(\\mu\\) poblacional sigui més gran que \\(\\mu_0\\), i per tant no podem rebutjar que \\(\\mu=\\mu_0\\). Els valors de \\(\\mu_0\\) en aquest interval són tan grans que amb la nostra mostra no hem obtengut evidència que la \\(\\mu\\) real sigui encara més gran que ells. En l’exemple dels diabètics de la Secció 5.5, dóna l’interval \\[ \\Bigg[3.2- 1.73\\cdot \\dfrac{1.5}{\\sqrt{20}},\\infty\\Bigg)=[2.62,\\infty) \\] Concloem que, amb un nivell de confiança del 95%, la concentració mitjana de calci en sang en els joves diabètics és com a mínim 2.62, i que per tant, amb aquest nivell de confiança, és més gran que 2.5, encara que per poc. Si efectuam un contrast bilateral amb un test t \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu\\neq \\mu_0 \\end{array} \\right. \\] acceptam H0 amb nivell de significació \\(\\alpha\\) quan \\[ -t_{n-1,1-\\alpha/2}\\leqslant \\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\leqslant t_{n-1,1-\\alpha/2} \\] Aïllant \\(\\mu_0\\), obtenim: \\[ \\overline{X}- t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant \\mu_0 \\leqslant \\overline{X}+ t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}} \\] Per tant, l’interval de confiança de nivell de confiança \\(1-\\alpha\\) per a aquest contrast és \\[ \\Bigg[\\overline{X}- t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}},\\overline{X}+ t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Us sona? Fent \\(q=1-\\alpha\\), de manera que \\(1-\\alpha/2=(1+q)/2\\), és el del tema anterior. Donat un contrast d’hipòtesis, podem decidir si rebutjam H0 a favor de H1 amb nivell de significació \\(\\alpha\\) emprant: La regió de rebuig: Si l’estadístic de contrast cau dins la regió de rebuig per al nivell de significació \\(\\alpha\\), rebutjam H0 El p-valor: Si el p-valor és més petit que el nivell de significació \\(\\alpha\\), rebutjam H0 L’interval de confiança: Si el valor que contrastam del paràmetre poblacional no pertany a l’interval de confiança de nivell de confiança \\(1-\\alpha\\), rebutjam H0 Els tres mètodes són equivalents. El més adequat és donar el p-valor i l’interval de confiança: el p-valor perquè el lector el pugui comparar amb el nivell de significació que consideri oportú i l’interval de confiança perquè mostra el marge amb el qual hem acceptat o rebutjat la hipòtesi nul·la amb el nostre nivell de significació. Si no establim un nivell de significació \\(\\alpha\\), el que és habitual en Biologia i Bioquímica és: Acceptar H0 si el p-valor és més gran que 0.1: es diu que el p-valor no és estadísticament significatiu. Rebutjar H0 si el p-valor és més petit que 0.05: es diu que el p-valor és estadísticament significatiu. Si el p-valor està entre 0.05 i 0.1 i no s’ha fixat nivell de significació, el millor que podeu fer és no concloure res. Figura 5.4: “P-values” (https://xkcd.com/1478/ (CC-BI-NC 2.5)) Quan el p-valor és més petit que 0.05, se solen distingir tres franges: Significatiu si està entre 0.01 i 0.05 Fortament significatiu si està entre 0.001 i 0.01 Molt significatiu si és més petit que 0.001 R marca aquestes franges amb un codi d’asteriscs Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Figura 5.5: Emoticones per representar els nivells de significació estadística (BMJ 2018; 363, doi: https://doi.org/10.1136/bmj.k5033) Per favor, acostumau-vos a donar el p-valor, i no la franja de significació on cau. D’aquesta manera el lector el pot comparar amb el nivell de significació que ell consideri l’adient. Atès que rebutjam H0 si, i només si, el p-valor és més petit que \\(\\alpha\\), el p-valor d’un contrast és el nivell de significació més petit per al qual rebutjaríem la hipòtesi nul·la. És a dir: El p-valor obtengut en un contrast és la probabilitat mínima que assumim d’equivocar-nos rebutjant la hipòtesi nul·la si és vertadera. La potència Recordau que la potència \\(1-\\beta\\) és la probabilitat de rebutjar H0 quan H1 és vertadera. Per exemple, en l’exemple del calci en diabètics de la Secció 5.5, la regla de rebuig era \\[ T=\\frac{\\overline{X}-2.5}{\\widetilde{S}_X/\\sqrt{n}}&gt;1.73, \\] per tant la potència era \\[ 1-\\beta=P(\\text{Rebutjar } H_0| H_1\\text{ vertadera})=P(T&gt;1.73| \\mu&gt;2.5). \\] Aquesta probabilitat és impossible de calcular, però hi ha paquets de R que la saben estimar. Per a cada tipus de contrast es té una relació numèrica entre: La potència \\(1-\\beta\\) La mida de la mostra \\(n\\): la potència creix amb \\(n\\) El nivell de significació \\(\\alpha\\): la potència decreix amb \\(\\alpha\\) La mida de l’efecte, un valor que quantifica la diferència entre el valor de l’estimador del paràmetre sobre la mostra i el valor que contrastam del paràmetre poblacional. La potència creix amb el valor absolut de la mida de l’efecte (ja que, quant més gran és la diferència entre l’estimació i el valor contrastat, més fàcil és que sigui estadísticament significativa i per tant rebutgem la hipòtesi nul·la). Aquesta relació permet calcular qualsevol dels quatre valors a partir dels altres tres; amb R, el paquet pwr permet fer-ho amb els contrastos més usuals. Al pròxim tema en veurem alguns exemples. A l’hora de planejar un experiment per realitzar un contrast, el que s’ha de fer és: Fixar el nivell de significació desitjat Fixar la potència desitjada Estimar la mida de l’efecte esperat (a partir de la nostra teoria, de la nostra experiència, dels resultats d’altres estudis…) o que volguem detectar (per rebutjar la hipòtesi nul·la ens bastarà una mida de l’efecte petita o la requerirem grossa?) i emprar la relació anterior per calcular la mida de la mostra necessària per assolir la potència desitjada. Desconfiau dels treballs on això no es faci. Podria ser que la potència fos molt baixa i hi hagués un biaix de infrapotència (underpower): es necessitava un efecte molt gran per poder rebutjar la hipòtesi nul·la i publicar l’article. El risc de positiu fals (Opcional) El paquet statcheck de R permet revisar de manera automàtica tots els càlculs d’un article escrit en un format concret en psicologia i comprovar-ne els p-valors. Els autors analitzaren 30,000 articles i varen concloure que (Behavior research methods 48 (2016), 1205-1226): “Hem trobat que la meitat dels articles contenen almenys un p-valor erroni. I un de cada vuit articles conté un p-valor erroni que a més afecta la conclusió estadística.” Per tant, Qualsevol article pot donar un p-valor petit que estigui equivocat No us en refieu. A més, teniu present que: Qualsevol estudi mal dissenyat o mal realitzat pot donar un p-valor petit… que no signifiqui absolutament res Qualsevol estudi perfectament dissenyat i realitzat pot donar per pur atzar un p-valor petit… que impliqui un positiu fals En resum, a qualsevol estudi us podeu trobar amb un fals positiu. Sigau escèptics. El risc de positiu fals, FPR, en un contrast és \\[ P(H_0\\text{ vertadera}|H_0\\text{ rebutjada}). \\] Pel teorema de Bayes (notau que interpretam \\(H_1= \\text{no }H_0\\)) \\[ \\begin{array}{rl} FPR&amp;=\\dfrac{P(H_0)\\cdot P(H_0\\text{ reb.}|H_0)}{P(H_0)\\cdot P(H_0\\text{ reb.}|H_0)+P(H_1)\\cdot P(H_0\\text{ reb.}|H_1)}\\\\ &amp; =\\dfrac{P(H_0)\\cdot \\alpha}{P(H_0)\\cdot \\alpha+(1-P(H_0))\\cdot (1-\\beta)}\\\\ &amp; =\\dfrac{(1-P(H_1))\\cdot \\alpha}{(1-P(H_1))\\cdot \\alpha+ P(H_1)\\cdot (1-\\beta)} \\end{array} \\] Per calcular-lo, hem de saber el nivell de significació i la potència i hem de decidir a priori quina probabilitat assignam al fet que H1 sigui vertadera. Exemple 5.20 En un estudi (publicat a Psychological Science 22 (2011), pp. 1011-1018) es repartiren 66 participants en dos grups de 33, als que direm grup Bandera i grup Control, i els mostraren les mateixes 4 fotos d’edificis. En les del grup Bandera, dues mostraven una bandera dels EUA, i en les del grup Control, aquestes banderes havien estat eliminades digitalment. Un exemple d’aquestes fotos es mostra a la Figura 5.6. Per emmascarar l’estudi, se’ls demanà que endevinassin l’hora del dia en què varen ser preses les fotos. Figura 5.6: Una de les fotos emprades a l’experiment de les banderes Després de mirar les fotos, els participants emplenaren un qüestionari sobre idees polítiques, a partir del qual es pot calcular un cert “índex de republicanisme” (en el sentit nord americà del terme) \\(M\\). Resulta que \\(M\\) va ser significativament més gran en el grup Bandera que en el grup Control, i amb un nivell de significació \\(\\alpha=0.05\\) els autors de l’estudi conclogueren que mirar fotos amb banderes estatals et “dretitza” (almenys a curt termini) les idees polítiques. Vaig a estimar el risc que aquest positiu sigui fals. Com que a priori, trob molt improbable que la conclusió sigui certa, li assignaré \\(P(H_1)=0.1\\) i gràcies. Emprarem el seu \\(\\alpha=0.05\\), i si es calcula la potència del contrast publicat, dóna 0.5. Llavors \\[ FPR =\\dfrac{0.9\\cdot 0.05}{0.9\\cdot 0.05+0.1\\cdot 0.5}=0.47 \\] Per tant, a posteriori, crec que hi ha un 47% de probabilitats que H1 sigui falsa i un 53% de probabilitats que H1 sigui vertadera. 5.7 Test de la lliçó 5 (1) Quan escrivim formalment un contrast d’hipòtesis, què significa H1? És la primera hipòtesi que fem i que després ja modificarem en funció de les dades obtingudes És la hipòtesi nul·la És la hipòtesi alternativa És la variable aleatòria poblacional d’interès Cap de les altres respostes és la correcta (2) Tenc un dau cúbic de 6 cares i sospit que està trucat a favor de 1. Amb un experiment cercaré evidència que confirmi la meva sospita. Sigui \\(p\\) la probabilitat de treure un 1 amb el meu dau. Quin dels contrastos d’hipòtesis següents tradueix la pregunta que vull resoldre amb aquest experiment? \\(H_0: p=1/6; H_1: p \\neq 1/6\\) \\(H_0: p=1/6; H_1: p &gt; 1/6\\) \\(H_0: p=1/6; H_1: p \\geqslant 1/6\\) \\(H_0: p=1/6; H_1: p&lt;1/6\\) \\(H_0: p&gt;1/6; H_1: p=1/6\\) \\(H_0: p&gt;1/6; H_1: p \\leqslant 1/6\\) \\(H_0: p \\leqslant 1/6; H_1: p &gt; 1/6\\) \\(H_0: p = 1/2; H_1: p &gt; 1/2\\) Cap dels anteriors (3) Tenc un dau cúbic de 6 cares i sospit que està trucat a favor de 1. Sigui \\(p\\) la probabilitat de treure un 1 amb el meu dau. He llançat el dau 100 vegades, he obtengut 28 uns. Això m’ha donat un p-valor de 0.0015. Quina és la conclusió correcta d’aquest contrast? Es confirma la meva sospita, perquè la probabilitat que el meu dau no estigui trucat a favor d’1 és 0.0015 No es confirma la meva sospita, perquè la probabilitat que el meu dau estigui trucat a favor d’1 és 0.0015 Es confirma la meva sospita, perquè la probabilitat d’obtenir, si el dau fos equilibrat, exactament 28 uns en 100 llançaments és molt improbable (0.0015), i això fa difícil de creure que el dau sigui equilibrat No es confirma la meva sospita, perquè la probabilitat d’obtenir, si el dau estigués trucat a favor d’1, exactament 28 uns en 100 llançaments és molt improbable (0.0015), i això fa difícil de creure que el dau estigui trucat Es confirma la meva sospita, perquè la probabilitat d’obtenir, si el dau fos equilibrat, 28 o més uns en 100 llançaments és molt improbable (0.0015), i això fa difícil de creure que el dau sigui equilibrat Es confirma la meva sospita, perquè la probabilitat d’obtenir, si el dau fos equilibrat, 28 o menys uns en 100 llançaments és molt improbable (0.0015), i això fa difícil de creure que el dau sigui equilibrat No es confirma la meva sospita, perquè la probabilitat d’obtenir, si el dau estigués trucat a favor de 1, 28 o menys uns en 100 llançaments és molt improbable (0.0015), i això fa difícil de creure que el dau estigui trucat Cap de les altres respostes és correcta (4) Volem contrastar si la proporció d’estudiants universitaris que rebutjaran la vacuna de la COVID-19 és inferior al 5.6% (la proporció estimada de la població espanyola que pensa rebutjar-la). Per a això, prenem una mostra raonablement aleatòria de 100 estudiants i els ho demanam. Quina és la hipòtesi nul·la d’aquest contrast? La proporció poblacional d’estudiants universitaris que rebutjaran la vacuna de la COVID-19 és més petita que el 5.6% La proporció poblacional d’estudiants universitaris que rebutjaran la vacuna de la COVID-19 és més petita o igual que el 5.6% La proporció poblacional d’estudiants universitaris que rebutjaran la vacuna de la COVID-19 és del 5.6% La proporció poblacional d’estudiants universitaris que rebutjaran la vacuna de la COVID-19 és més gran o igual que el 5.6% La proporció d’estudiants de la nostra mostra que rebutjaran la vacuna de la COVID-19 és més petita que el 5.6% La proporció d’estudiants de la nostra mostra que rebutjaran la vacuna de la COVID-19 és més petita o igual que el 5.6% La proporció d’estudiants de la nostra mostra que rebutjaran la vacuna de la COVID-19 és del 5.6% La proporció d’estudiants de la nostra mostra que rebutjaran la vacuna de la COVID-19 és més gran o igual que el 5.6% (5) Un test del COVID-19 no és res més que un contrast d’hipòtesis: prens una mostra de l’individu i decideixes si està malalt o no. Quin contrast és? H0: L’individu està infectat; H1: L’individu no està infectat H0: L’individu no està infectat; H1: L’individu està infectat H0: L’individu no està infectat; H1: L’individu podria estar infectat H0: No sé si l’individu està infectat; H1: L’individu està infectat (6) Quan en un contrast d’hipòtesis rebutjam la hipòtesi nul·la i decidim que l’alternativa és la vertadera (marcau la resposta correcta) És perquè els resultats de la nostra mostra demostren que la hipòtesi alternativa és vertadera És perquè els resultats de la nostra mostra demostren que la hipòtesi nul·la és falsa És perquè els resultats de la nostra mostra demostren que la hipòtesi alternativa és més probable que la nul·la És perquè els resultats de la nostra mostra demostren que la hipòtesi nul·la és impossible És perquè els resultats de la nostra mostra ens fan dubtar que la hipòtesi nul·la sigui vertadera (7) Volem investigar si prendre un suplement diari de vitamina B fa que les ungles de les mans creixin més ràpid que si no es pren. Quina és la hipòtesi nul·la? Prendre un suplement de vitamina B accelera el creixement de les ungles. No se sap si prendre un suplement de vitamina B accelera o retarda el creixement de les ungles. Prendre un suplement de vitamina B retarda el creixement de les ungles. Prendre un suplement de vitamina B no té cap efecte en el creixement de les ungles. (8) Suposem que en un contrast d’hipòtesis NO s’ha rebutjat la hipòtesi nul·la. Quina de les següents afirmacions és la més correcta? S’ha demostrat que la hipòtesi nul·la és vertadera. S’ha demostrat que la hipòtesi alternativa és falsa. S’ha trobat evidència que la hipòtesi nul·la és vertadera. S’ha trobat evidència que la hipòtesi alternativa és falsa. Totes les altres afirmacions són uns dois. (9) En un estudi on es va contrastar si la proporció d’adolescents mallorquins que són miops és més gran que el 40%, es va prendre una mostra de 50 adolescents i s’hi observaren 22 miops. El p-valor del contrast va ser 0.33. Què vol dir això? Marcau una sola resposta. La probabilitat que un adolescent mallorquí sigui miop és 0.33 La probabilitat que la proporció d’adolescents mallorquins que són miops sigui més gran que el 50% és 0.67 La probabilitat que la proporció d’adolescents mallorquins que són miops sigui més gran que el 50% és 0.33 És un error, perquè 22 de 50 no és un 33% Si la proporció d’adolescents mallorquins que són miops fos més gran que el 40%, la probabilitat d’obtenir 22 miops en una mostra aleatòria de 50 adolescents mallorquins és 0.33 Si la proporció d’adolescents mallorquins que són miops fos més gran que el 40%, la probabilitat d’obtenir 22 o més miops en una mostra aleatòria de 50 adolescents mallorquins és 0.33 Si la proporció d’adolescents mallorquins que són miops fos del 40%, la probabilitat d’obtenir 22 miops en una mostra aleatòria de 50 adolescents mallorquins és 0.33 Si la proporció d’adolescents mallorquins que són miops fos del 40%, la probabilitat d’obtenir 22 o més miops en una mostra aleatòria de 50 adolescents mallorquins és 0.33 Si la proporció d’adolescents mallorquins que són miops fos més petita o igual que el 40%, la probabilitat d’obtenir 22 miops en una mostra aleatòria de 50 adolescents mallorquins és 0.33 Si la proporció d’adolescents mallorquins que són miops fos més petita o igual que el 40%, la probabilitat d’obtenir 22 o més miops en una mostra aleatòria de 50 adolescents mallorquins és 0.33 Cap de les altres respostes és correcta (10) En una assaig clínic d’una vacuna de la COVID-19 se cerca evidència que la vacuna redueix la probabilitat d’infecció. Digau \\(p_v\\) a la probabilitat d’infectar-se si s’ha rebut la vacuna i \\(p_n\\) a la probabilitat d’infectar-se si no s’ha rebut la vacuna. Quin contrast tradueix la pregunta que es pretén resoldre amb aquest assaig? \\(H_0:p_v&lt;p_n\\); \\(H_1: p_v&gt;p_n\\) \\(H_0:p_v&lt;p_n\\); \\(H_1: p_v \\leqslant p_n\\) \\(H_0:p_v&lt;p_n\\); \\(H_1: p_v =p_n\\) \\(H_0:p_v=p_n\\); \\(H_1: p_v \\leqslant p_n\\) \\(H_0:p_v=p_n\\); \\(H_1: p_v &lt; p_n\\) \\(H_0:p_v=p_n\\); \\(H_1: p_v &gt; p_n\\) \\(H_0:p_v&gt;p_n\\); \\(H_1: p_v = p_n\\) \\(H_0:p_v \\geqslant p_n\\); \\(H_1: p_v &lt; p_n\\) \\(H_0:p_v &gt; p_n\\); \\(H_1: p_v \\leqslant p_n\\) Cap dels anteriors (11) Suposem que, un cop s’hagi realitzat l’assaig anterior, en analitzar les dades recollides, s’obtengui evidència que \\(p_v\\) és més petita que \\(p_n\\), amb un p-valor 0.034. Quina de les interpretacions següents d’aquest valor és la més correcta? Que hi ha un 3.4% de probabilitat que, si es repeteix l’estudi, no es trobin diferències significatives entre les proporcions d’infectats entre els vacunats i els no vacunats Que hi ha un 3.4% de probabilitat que la probabilitat d’infectar-se dels vacunats i dels no vacunats sigui la mateixa Que hi ha un 3.4% de diferència, o més, entre la probabilitat que un no vacunat s’infecti i la probabilitat que un vacunat s’infecti Que a la mostra considerada, hi ha hagut almenys un 3.4% de diferència entre la proporció dels no vacunats que s’han infectat i la proporció dels vacunats que s’han infectat Que si la vacuna no redueix la probabilitat d’infectar-se, hi ha un 3.4% de probabilitat que, si es repeteix l’estudi, la diferència que s’obtengui entre les proporcions d’infectats entre els vacunats i els no vacunats sigui com l’obtenguda en aquest assaig, o més gran. Que hi ha un 3.4% de probabilitat que, si es repeteix l’estudi, la diferència que s’obtengui entre les proporcions d’infectats entre els vacunats i els no vacunats sigui com l’obtenguda en aquest assaig, o més gran. (12) Un científic publica un article on afirma que les persones que consumeixen un determinat medicament tenen una major probabilitat de formació de càlculs renals. Més tard es descobreix que en realitat aquesta associació no existeix. Quin tipus d’error va cometre el científic i per què? Tipus I, perquè va afirmar que la hipòtesi nul·la és certa quan en realitat és falsa. Tipus I, perquè va afirmar que la hipòtesi nul·la és falsa quan en realitat és certa. Tipus II, perquè va afirmar que la hipòtesi nul·la és certa quan en realitat és falsa. Tipus II, perquè va afirmar que la hipòtesi nul·la és falsa quan en realitat és certa. (13) Què significa que en un contrast d’hipòtesis prenguem un nivell de significació del 1%? Que si la hipòtesi nul·la és falsa, hi ha un 1% de probabilitats que la rebutgem a favor de l’alternativa. Que si la hipòtesi nul·la és falsa, hi ha un 1% de probabilitats que l’acceptem. Que si la hipòtesi nul·la és vertadera, hi ha un 1% de probabilitats que la rebutgem a favor de l’alternativa. Que si la hipòtesi nul·la és vertadera, hi ha un 1% de probabilitats que l’acceptem. Que hi ha un 1% de probabilitats que rebutgem la hipòtesi nul·la. Que hi ha un 1% de probabilitats que acceptem la hipòtesi nul·la. Cap de les altres respostes és correcta. (14) En un estudi no es va obtenir evidència estadísticament significativa que la proporció de rosses naturals entre les estudiants de ciències de la UIB fos més petita que la proporció d’espanyoles rosses. Quina o quines de les afirmacions següents sobre el contrast d’hipòtesis que es va realitzar són vertaderes? El contrast va ser unilateral. És segur que la proporció de rosses naturals entre les estudiants de ciències de la UIB és més gran o igual que la proporció d’espanyoles rosses. Es va obtenir evidència estadísticament significativa que la proporció de rosses naturals entre les estudiants de ciències de la UIB és més gran o igual que la proporció d’espanyoles rosses. Pot ser que la conclusió es degués a un error de tipus I. Pot ser que la conclusió es degués a un error de tipus II. Totes les altres respostes són falses. (15) En un examen considerat com un contrast (marcau totes les respostes correctes) Que l’estudiant aprovi sense saber la matèria és un error de tipus I Que l’estudiant aprovi sense saber la matèria és un error de tipus II Que l’estudiant aprovi sense saber la matèria és simultàniament un error de tipus I i de tipus II El nivell de significació és la probabilitat que l’estudiant aprovi sense saber la matèria El nivell de significació és la probabilitat que l’estudiant suspengui si no sap la matèria (16) En un estudi on es va contrastar si els individus amb hipertensió arterial tenen un major risc de sofrir un infart de miocardi que els individus normotensos, es va obtenir un p-valor de 0.02. Què vol dir això? La probabilitat que els hipertensos tenguin més risc de sofrir un infart de miocardi que els normotensos és 0.02 La probabilitat que els hipertensos tenguin més risc de sofrir un infart de miocardi que els normotensos és 0.98 Un hipertens té una probabilitat de sofrir un infart de miocardi un 2% major que un normotens. En les mostres que hem emprat en l’estudi, la proporció d’hipertensos que han sofert un infart de miocardi és un 2% major que la de normotensos que han sofert un infart de miocardi Cap de les altres respostes és correcta. (17) En un contrast amb \\(\\alpha=0.05\\) rebutjam la hipòtesi nul·la. Què passaria si, amb la mateixa mostra, prenguéssim \\(\\alpha=0.1\\)? Segur que també rebutjaríem la hipòtesi nul·la Segur que no rebutjaríem la hipòtesi nul·la Pot passar qualsevol cosa (18) En un contrast amb \\(\\alpha=0.05\\) no rebutjam la hipòtesi nul·la. Què passaria si, amb la mateixa mostra, prenguéssim \\(\\alpha=0.1\\)? Segur que tampoc rebutjaríem la hipòtesi nul·la Segur que sí que rebutjaríem la hipòtesi nul·la Pot passar qualsevol cosa (19) Suposem que hem realitzat un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_{0}\\\\ H_{1}:\\mu&gt;\\mu_{0} \\end{array} \\right. \\] amb \\(\\alpha=0.05\\) amb un test t sobre una mostra de mida 50 i el resultat ha estat que no podem rebutjar la hipòtesi nul·la. Quina seria la conclusió si, amb la mateixa mostra, canviàssim H1 per \\(\\mu\\neq \\mu_0\\)? Segur que tampoc rebutjaríem la hipòtesi nul·la Segur que sí que rebutjaríem la hipòtesi nul·la Pot passar qualsevol cosa (20) Suposem que hem realitzat un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_{0}\\\\ H_{1}:\\mu&gt;\\mu_{0} \\end{array} \\right. \\] amb \\(\\alpha=0.05\\) amb un test t sobre una mostra de mida 50 i el resultat ha estat que podem rebutjar la hipòtesi nul·la. Quina seria la conclusió si, amb la mateixa mostra, canviàssim H1 per \\(\\mu\\neq \\mu_0\\)? Segur que tampoc rebutjaríem la hipòtesi nul·la Segur que sí que rebutjaríem la hipòtesi nul·la Pot passar qualsevol cosa (21) Suposem que hem realitzat un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_{0}\\\\ H_{1}:\\mu\\neq \\mu_{0} \\end{array} \\right. \\] amb \\(\\alpha=0.05\\) amb un test t sobre una mostra de mida 50 i el resultat ha estat que no podem rebutjar la hipòtesi nul·la. Quina seria la conclusió si, amb la mateixa mostra, canviàssim H1 per \\(\\mu&gt; \\mu_0\\)? Segur que tampoc rebutjaríem la hipòtesi nul·la Segur que sí que rebutjaríem la hipòtesi nul·la Pot passar qualsevol cosa (22) Suposem que hem realitzat un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_{0}\\\\ H_{1}:\\mu\\neq\\mu_{0} \\end{array} \\right. \\] amb \\(\\alpha=0.05\\) amb un test t sobre una mostra de mida 50 i el resultat ha estat que podem rebutjar la hipòtesi nul·la. Quina seria la conclusió si, amb la mateixa mostra, canviàssim H1 per \\(\\mu&gt; \\mu_0\\)? Segur que tampoc rebutjaríem la hipòtesi nul·la Segur que sí que rebutjaríem la hipòtesi nul·la Pot passar qualsevol cosa (23) Hem realitzat un contrast d’hipòtesis per determinar si hi ha evidència que el temps mitjà d’eliminació \\(\\mu\\) d’un cert compost en les persones amb funció renal normal és superior a les 5 hores. Sobre una mostra de 100 persones, hem emprat un test t i hem obtengut un valor per a l’estadístic de contrast \\(T\\) d’1.4 i un p-valor 0.01. Què significa això? Marcau la resposta correcta. Si \\(\\mu=5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T\\leqslant 1.4\\) és 0.01. Si \\(\\mu=5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T\\geqslant 1.4\\) és 0.01. Si \\(\\mu=5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T= 1.4\\) és 0.01. Si \\(\\mu&gt; 5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T\\leqslant 1.4\\) és 0.01. Si \\(\\mu&gt; 5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T\\geqslant 1.4\\) és 0.01. Si \\(\\mu&gt; 5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T= 1.4\\) és 0.01. Totes les altres respostes són incorrectes. (24) Hem realitzat un contrast d’hipòtesis per determinar si hi ha evidència que el temps mitjà d’eliminació \\(\\mu\\) d’un cert compost en les persones amb funció renal normal és diferent de 5 hores. Sobre una mostra de 100 persones, hem emprat un test t i hem obtengut un valor per a l’estadístic de contrast d’1.4 i un p-valor 0.01. Què significa això? Marcau la resposta correcta. Si \\(\\mu=5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T\\leqslant 1.4\\) és 0.01. Si \\(\\mu=5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T\\geqslant 1.4\\) és 0.01. Si \\(\\mu=5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T= 1.4\\) és 0.01. Si \\(\\mu\\neq 5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T\\leqslant 1.4\\) és 0.01. Si \\(\\mu\\neq 5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T\\geqslant 1.4\\) és 0.01. Si \\(\\mu\\neq 5\\), la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem \\(T= 1.4\\) és 0.01. Totes les altres respostes són incorrectes. (25) En un contrast d’una mitjana emprant un test t, l’augment de la mida d’aquesta mostra (marcau totes les respostes correctes): Millora l’aproximació de l’estadístic de contrast a una distribució normal. Esperam que disminueixi la probabilitat d’error de tipus I. Esperam que disminueixi la probabilitat d’error de tipus II. Esperam que disminueixi la potència del contrast. Fa menys probable que la hipòtesi nul·la sigui vertadera. Totes les altres respostes són incorrectes. (26) En un contrast d’hipòtesis en el qual la hipòtesi nul·la és vertadera (marcau una sola resposta): Només podem cometre un error de tipus I. Només podem cometre un error de tipus II. Podem cometre tant un error de tipus I com un error de tipus II, però no tots dos. Podem cometre tant un error de tipus I com un error de tipus II, i podem cometre’ls tots dos. Com que la hipòtesi nul·la és vertadera, no podem cometre ni un error de tipus I ni un error de tipus II. Totes les altres respostes són falses. (27) Hem realitzat un contrast d’hipòtesis per determinar si hi ha evidència que la concentració mitjana d’un cert metabòlit en sang és diferent en pacients amb dues malalties diferents. Sobre dues mostres de 100 subjectes, hem obtengut un valor per a l’estadístic de contrast de -3.2 i un p-valor \\(0.0015\\). Què significa això? Marcau la resposta correcta. Si les concentracions mitjanes són iguals, la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem un valor per a l’estadístic de contrast menor que -3.2 és 0.0015. Si les concentracions mitjanes són iguals, la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem un valor per a l’estadístic de contrast major que -3.2 és 0.0015. Si les concentracions mitjanes són iguals, la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem un valor per a l’estadístic de contrast major que 3.2 és 0.0015. Si les concentracions mitjanes són iguals, la probabilitat que en un altre estudi per realitzar aquest contrast obtenguem un valor per a l’estadístic de contrast menor que -3.2 o major que 3.2 és 0.0015. La probabilitat que les concentracions mitjanes siguin iguals quan s’obté aquest valor de l’estadístic de contrast és 0.0015. Cap de les altres afirmacions és correcta. (28) Hem realitzat dos contrastos d’hipòtesis diferents amb dues mostres diferents, al primer hem obtengut un p-valor 0.02 i al segon un p-valor 0.01. Quina de les conclusions següents és la correcta? És més probable que sigui vertadera la hipòtesi alternativa del primer contrast que la del segon És més probable que sigui vertadera la hipòtesi alternativa del segon contrast que la del primer Cap de les conclusions anteriors és correcta. (29) En un contrast d’hipòtesis sobre la mitjana \\(\\mu\\) d’una variable aleatòria normal \\(X\\) amb hipòtesi alternativa \\(H_1: \\mu&lt;2\\) hem pres una mostra aleatòria simple de \\(X\\) de mida 25 i hem obtengut una mitjana mostral de 1.6 amb una desviació típica mostral de 1.1. Volem realitzar el contrast amb nivell de significació 0.05. Quina de les regles següents genèriques hem d’aplicar? Acceptarem la hipòtesi nul·la si l’estadístic de contrast és més petit que un cert llindar \\(L_0\\) Rebutjarem la hipòtesi nul·la si l’estadístic de contrast és més petit que un cert llindar \\(L_0\\) Rebutjarem la hipòtesi nul·la si l’estadístic de contrast és igual a un cert llindar \\(L_0\\) (30) Què és la regió d’acceptació d’un contrast sobre un paràmetre poblacional? El conjunt dels valors del paràmetre poblacional pels quals hem d’acceptar la hipòtesi nul·la El conjunt dels valors del paràmetre poblacional pels quals hem d’acceptar la hipòtesi alternativa El conjunt dels valors de l’estadístic de contrast pels quals hem d’acceptar la hipòtesi nul·la El conjunt dels valors de l’estadístic de contrast pels quals hem d’acceptar la hipòtesi alternativa El conjunt de les estimacions acceptables del paràmetre poblacional a partir de la mostra (31) Si efectuam un mateix contrast amb el mateix nivell de significació dues vegades amb dues mostres diferents de la mateixa mida (marcau les continuacions correctes) La regió d’acceptació del contrast serà les dues vegades la mateixa La regió d’acceptació del contrast pot donar diferent amb cada mostra L’interval de confiança del contrast serà les dues vegades el mateix L’interval de confiança del contrast pot donar diferent amb cada mostra (32) En un contrast d’hipòtesis hem rebutjat la hipòtesi nul·la a favor de l’alternativa amb nivell de significació del 10%. El contrast ha tengut una potència del 60%. Quina de les afirmacions següents és correcta en aquesta situació? La probabilitat que la hipòtesi nul·la sigui vertadera és 0.1 La probabilitat que la hipòtesi nul·la sigui vertadera és 0.4 La probabilitat que la hipòtesi alternativa sigui vertadera és 0.1 La probabilitat que la hipòtesi alternativa sigui vertadera és 0.4 Cap de les altres respostes és correcta. (33) Hem efectuat el mateix contrast amb dues mostres: amb la primera hem obtengut un p-valor de 0.1 i amb la segona un p-valor de 0.01. Quina o quines de les afirmacions següents són correctes? És més probable que sigui vertadera la hipòtesi nul·la del contrast amb la primera mostra que la hipòtesi nul·la del contrast amb la segona mostra És més probable que sigui vertadera la hipòtesi nul·la del contrast amb la segona mostra que la hipòtesi nul·la del contrast amb la primera mostra No hi ha manera de saber si la hipòtesi nul·la del contrast amb la primera mostra és més probable o menys probable que la hipòtesi nul·la del contrast amb la primera mostra Cap de les altres respostes és correcta (34) Suposem que hem realitzat un contrast \\(H_0: \\mu=\\mu_0\\) contra \\(H_1: \\mu\\neq\\mu_0\\) amb \\(\\alpha=0.05\\) amb un test t sobre una determinada mostra. Què li passaria a l’interval de confiança del contrast si canviàssim H1 per \\(\\mu&lt;\\mu_0\\)? Seria el mateix, perquè no hem canviat de mostra Seria més ample Seria més estret Pot passar qualsevol cosa (35) Suposem que hem realitzat un contrast \\(H_0: \\mu=\\mu_0\\) contra \\(H_1: \\mu\\neq \\mu_0\\) amb \\(\\alpha=0.05\\) amb un test t sobre una determinada mostra. Què li passaria a l’interval de confiança del contrast obtengut amb aquesta mateixa mostra si augmentàssim el nivell de significació a \\(\\alpha=0.1\\)? Seria més ample Seria més estret Seria exactament igual, perquè no hem canviat de mostra Pot passar qualsevol cosa (36) Hem efectuat un test t d’una mitjana, amb hipòtesi alternativa \\(\\mu\\neq 2\\). És possible que hàgim obtengut (amb la mateixa mostra) un interval de confiança del contrast del 95% [2.1,3.2] i un p-valor 0.13? Sí No (37) Hem efectuat un test t d’una mitjana, amb hipòtesi alternativa \\(\\mu\\neq 2\\). És possible que hàgim obtengut (amb la mateixa mostra) un interval de confiança del contrast del 95% [1.8,3.2] i un p-valor 0.13? Sí No (38) Hem efectuat un test t d’una mitjana, amb hipòtesi alternativa \\(\\mu&lt;2\\). És possible que hàgim obtengut (amb la mateixa mostra) un interval de confiança del contrast del 95% [1.8,3.2] i un p-valor 0.13? Sí No (39) Hem efectuat un test t de dues mitjanes, amb hipòtesi alternativa \\(\\mu_1\\neq \\mu_2\\). És possible que hàgim obtengut (amb la mateixa mostra) un interval de confiança del contrast del 95% [2.1,3.2] i un p-valor 0.13? Sí No (40) Hem efectuat dues vegades, amb dues mostres diferents, un mateix test t d’una mitjana, amb hipòtesi alternativa \\(\\mu\\neq 2\\). És possible que amb una mostra hàgim obtengut un interval de confiança del contrast del 95% [2.1,3.2] i amb l’altra mostra un p-valor 0.13? Sí No "],
["contrastos-dhipòtesis-dun-i-dos-paràmetres.html", "Tema 6 Contrastos d’hipòtesis d’un i dos paràmetres 6.1 Contrastos de mitjanes 6.2 Contrastos de variàncies 6.3 Contrastos per a proporcions 6.4 Test de la lliçó 6", " Tema 6 Contrastos d’hipòtesis d’un i dos paràmetres Per adquirir un poc de disciplina en la realització de contrastos d’hipòtesis, procurau, almenys per ara, dividir-los en els apartats següents: Variables aleatòries d’interès, incloent les seves unitats de mesura si en tenen, i els paràmetres poblacionals involucrats en el contrast Contrast \\[ \\left\\{\\begin{array}{l} H_{0}: ...\\\\ H_{1}: ... \\end{array} \\right. \\] i nivell de significació \\(\\alpha\\); si no l’indicam, entendrem que \\(\\alpha=0.05\\). I a partir d’aquí, si el feu “a mà”: Estadístic de contrast i distribució si la hipòtesi nul·la és vertadera Valor de l’estadístic sobre la mostra p-valor i, si pot ser, interval de confiança del nivell de confiança \\(1-\\alpha\\) (per defecte, 0.95) Conclusió I si el feu amb R: L’efectuau amb R Conclusió Per a la conclusió, emprau la plantilla següent Hem obtingut evidència estadísticament significativa que passa tal cosa (test realitzat, p-valor …, IC 95% …). No hem obtingut evidència estadísticament significativa que passi tal cosa (test realitzat, p-valor …, IC 95% …). 6.1 Contrastos de mitjanes 6.1.1 Test t per a una mitjana Si estam en una de les dues situacions següents: \\(X\\) és una variable aleatòria normal amb mitjana \\(\\mu\\) i en prenem una mostra aleatòria simple de mida \\(n\\) qualsevol \\(X\\) és una variable aleatòria qualsevol amb mitjana \\(\\mu\\) i en prenem una mostra aleatòria simple de mida \\(n\\) gran (diguem que de mida com a mínim 40) i volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq\\mu_0\\text{ o }\\mu &gt;\\mu_0\\text{ o }\\mu&lt;\\mu_0 \\end{array} \\right. \\] podem emprar el test t que ja hem explicat a la Secció 5.5, basat en l’estadístic de contrast \\[ T= \\frac{\\overline{X}-\\mu_{0}}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] que, en les condicions donades i si \\(\\mu=\\mu_0\\), té una distribució (aproximadament, si \\(X\\) no és normal però \\(n\\) és gran) \\(t_{n-1}\\). Exemple 6.1 Una organització ecologista afirma que el pes mitjà dels individus adults d’una espècie d’animals ha disminuït dràsticament. Se sap per les dades històriques que el pes mitjà poblacional era de 460 g. Una mostra aleatòria de 50 individus d’aquesta espècie ha donat una mitjana mostral de 428 g i una desviació típica mostral de 119 g. Amb aquestes dades, podem afirmar amb un nivell de significació del 5% que el pes mitjà és inferior a 460 g? Variable aleatòria d’interès: \\(X\\): “Prenem un animaló d’aquests i anotam el seu pes, en grams”, amb mitjana \\(\\mu\\) Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=460\\\\ H_{1}:\\mu&lt;460 \\end{array} \\right. \\] Prenem nivell de significació \\(\\alpha=0.05\\). Estadístic de contrast: Com que \\(n=50\\) és gran, emprarem \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] que sí H0 és vertadera serà (aproximadament) t de Student amb \\(n-1=49\\) graus de llibertat Valor de l’estadístic: \\[ \\dfrac{428-460}{{119}/{\\sqrt{50}}}=-1.9 \\] p-valor: \\[ P(T\\leqslant -1.9)=\\texttt{pt(-1.9,49)}=0.032 \\] Interval de confiança del 95%: \\[ \\left(-\\infty, \\overline{X}+t_{n-1,1-\\alpha}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\right]=(-\\infty, 456.2] \\] Conclusió: Com que el p-valor és més petit que 0.05, concloem (amb \\(\\alpha=0.05\\)) que el pes mitjà actual és més petit que 460 g. De fet, amb un 95% de confiança podem afirmar que el pes mitjà actual és inferior a 456.2 g, que està per davall dels 460 g. Amb la plantilla que us hem donat: Hem obtingut evidència estadísticament significativa que el pes mitjà actual és menor que 460 g (test t, p-valor 0.03, IC 95% de \\(-\\infty\\) a 456.2) i que per tant ha minvat en els darrers anys. 6.1.2 Test t per a dues mitjanes Si estam en una de les situacions següents: \\(X_1,X_2\\) són dues variables aleatòries normals de mitjanes \\(\\mu_1\\), \\(\\mu_2\\) i en prenem mostres aleatòries simples de mides \\(n_1\\), \\(n_2\\) qualssevol \\(X_1,X_2\\) són dues variables aleatòries qualssevol de mitjanes \\(\\mu_1\\), \\(\\mu_2\\) i en prenem mostres aleatòries simples de mides \\(n_1\\), \\(n_2\\) grans (diguem que totes dues de mida com a mínim 40) i volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1=\\mu_2\\\\ H_{1}:\\mu_1 \\neq\\mu_2\\text{ o }\\mu_1 &gt;\\mu_2\\text{ o }\\mu_1&lt;\\mu_2 \\end{array} \\right. \\] podem emprar un test t, basat en un estadístic de contrast \\(T\\) adequat que segueix una llei t de Student. L’estadístic de contrast concret i els graus de llibertat de la seva distribució t de Student depenen de dues coses. En primer lloc, de si les dues mostres són independents o aparellades: Independents: Hem mesurat \\(X_1\\) i \\(X_2\\) sobre dues mostres obtingudes de manera independent una de l’altra. Aparellades: Hem mesurat \\(X_1\\) i \\(X_2\\) sobre els subjectes d’una mateixa mostra, o hi ha un aparellament natural entre els subjectes de les dues mostres de tal manera que poguem entendre que en realitat hem pres una mostra de parelles de subjectes. Exemple 6.2 Vegem alguns exemples de mostres aparellades i independents: Per mirar si els estudiants dediquen més hores setmanals a Matemàtiques I que a Matemàtiques II, hem escollit a l’atzar un grup de 50 estudiants i els hem demanat el primer semestre quantes hores setmanals dediquen a Matemàtiques I i el segon semestre quantes hores setmanals dediquen a Matemàtiques II. Hem mesurat les dues variables d’interès (hores setmanals de Matemàtiques I i de Matemàtiques II) sobre els mateixos estudiants: les dues mostres són aparellades. Per mirar si els estudiants dediquen més hores setmanals a Matemàtiques I que a Matemàtiques II, el primer semestre hem pres a l’atzar un grup de 50 estudiants i els hem demanat quantes hores setmanals dediquen a Matemàtiques I, i el segon semestre hem pres a l’atzar un altre grup de 50 estudiants i els hem demanat quantes hores setmanals dediquen a Matemàtiques II. Són mostres independents: cada mostra ha estat presa a l’atzar independentment de l’altra. Per mirar si els estudiants dediquen més hores setmanals a Matemàtiques I que a Matemàtiques II, el primer semestre hem pres a l’atzar un grup de 50 estudiants i els hem demanat quantes hores setmanals dediquen a Matemàtiques I. Però ara, és clar, alguns d’aquests poden no estar matriculats a Matemàtiques II o matriculats però només de cos present. Aleshores, el que fem el segon semestre és, per a cada un dels 50 estudiants triats el primer semestre, escollim un estudiant de Matemàtiques II que a Matemàtiques I hagi tret una nota similar. Als 50 estudiants així triats els demanam quantes hores setmanals dediquen a Matemàtiques II. Observau que és com si haguéssim triat parelles formades per un estudiant de Matemàtiques I i un estudiant de Matemàtiques II amb notes similars de Matemàtiques I. Per tant, les mostres són aparellades. Per esbrinar si l’estatus socioeconòmic de les famílies afecta el QI (quocient d’intel·ligència) dels fills, es prengué una mostra de 50 nins i nines de famílies d’estatus socioeconòmic alt i una de 50 nins i nines de famílies d’estatus socioeconòmic baix i se’ls mesurà el QI. Com que no diuen res sobre haver triat els infants d’un grup aparellats amb els de l’altre, entenem que són dues mostres independents. Per poder considerar-les aparellades, hauríem de poder deduir quines parelles es formaren. Per esbrinar si el QI té component genètic o ambiental, es prengueren 10 parelles de bessons monozigòtics que s’havien criat en famílies d’estatus socioeconòmic diferent. Es formà una mostra amb els 10 bessons que s’havien criat en una família d’estatus socioeconòmic alt i una altra amb els 10 bessons que s’havien criat en una d’estatus socioeconòmic baix. A tots ells se’ls mesurà el QI. Aquí directament es prengué la mostra formada per parelles (les parelles de bessons) i la separaren en dues mostres de persones. Per tant, són mostres aparellades. Tornem al test t per a dues mitjanes. Quan les mostres són independents, l’estadístic de contrast concret i els graus de llibertat de la seva distribució t de Student també depenen de si \\(X_1\\) i \\(X_2\\) tenen la mateixa variància o no (la qual cosa es pot decidir amb un altre contrast: vegeu la Secció 6.2); per a mostres de la mateixa mida de variables normals, la conclusió sol ser la mateixa Quan les mostres són aparellades, podem entendre que tenim una sola mostra, formada per les parelles, sobre les quals mesuram la diferència \\(X_1-X_2\\). En aquest cas, traduïm \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1=\\mu_2\\\\ H_{1}:\\mu_1 \\neq\\mu_2\\text{ o }\\mu_1 &gt;\\mu_2\\text{ o }\\mu_1&lt;\\mu_2 \\end{array} \\right. \\] en \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1-\\mu_2=0\\\\ H_{1}:\\mu_1-\\mu_2 \\neq0\\text{ o }\\mu_1-\\mu_2 &gt;0\\text{ o }\\mu_1-\\mu_2&lt;0 \\end{array} \\right. \\] on \\(\\mu_1-\\mu_2\\) és la mitjana de \\(X_1-X_2\\), i el consideram un contrast d’una sola mitjana, emprant com a mostra les diferències \\(X_1-X_2\\) a les parelles. Per tant, quan les mostres són aparellades, si diem \\(D\\) a \\(X_1-X_2\\), \\(\\overline{D}\\) a la mitjana mostral de \\(D\\) i \\(\\widetilde{S}_D\\) a la desviació típica mostral de \\(D\\) sobre la mostra de parelles i diem \\(n\\) a la mida de la mostra de parelles, l’estadístic de contrast és \\[ T=\\frac{\\overline{D}}{\\widetilde{S}_D/\\sqrt{n}} \\] que, quan \\(\\mu_D=(\\mu_1-\\mu_2)=0\\), té distribució t de Student amb \\(n-1\\) graus de llibertat, \\(t_{n-1}\\), (aproximadament, si \\(X_1,X_2\\) no són normals però la \\(n\\) és gran). Un test t de mostres aparellades és en realitat un test t de la mitjana de \\(X_1-X_2\\). Per tant, si la mida \\(n\\) de les mostres no és gran, no cal que les dues variables poblacionals \\(X_1\\) i \\(X_2\\) siguin totes dues normals per poder-lo fer servir. Basta que la seva diferència \\(X_1-X_2\\) sigui normal. Quan les mostres són independents, siguin \\(\\overline{X}_1\\) i \\(\\widetilde{S}_{X_1}^2\\) la mitjana mostral i la variància mostral de la mostra de \\(X_1\\) i \\(\\overline{X}_2\\) i \\(\\widetilde{S}_{X_2}^2\\) la mitjana mostral i la variància mostral de la mostra de \\(X_2\\). Diguem, a més, \\(\\sigma_1^2\\) i \\(\\sigma_2^2\\) a les variàncies (poblacionals) de \\(X_1\\) i \\(X_2\\). Aleshores: Si \\(\\sigma_1^2=\\sigma_2^2\\), l’estadístic de contrast és \\[ T=\\frac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{(\\frac{1}{n_1}+\\frac{1}{n_2})\\cdot \\frac{(n_1-1)\\widetilde{S}_{X_1}^2+(n_2-1)\\widetilde{S}_{X_2}^2}{n_1+n_2-2}}} \\] que, quan \\(\\mu_1=\\mu_2\\), té distribució t de Student amb \\(n_1+n_2-2\\) graus de llibertat, \\(t_{n_1+n_2-2}\\) (aproximadament, si \\(X_1,X_2\\) no són normals però \\(n_1\\) i \\(n_2\\) són totes dues grans). Si \\(\\sigma_1^2\\neq \\sigma_2^2\\), l’estadístic de contrast és \\[ T=\\frac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{\\frac{\\widetilde{S}_{X_1}^2}{n_1}+\\frac{\\widetilde{S}_{X_2}^2}{n_2}}} \\] que, quan \\(\\mu_1=\\mu_2\\), té distribució t de Student amb \\[ \\nu=\\frac{\\displaystyle \\left( \\frac{\\widetilde{S}_{X_1}^2}{n_1}+\\frac{\\widetilde{S}_{X_2}^2}{n_2}\\right)^2} {\\displaystyle \\frac{1}{n_1-1}\\left(\\frac{\\widetilde{S}_{X_1}^2}{n_1}\\right)^2+\\frac{1}{n_2-1}\\left(\\frac{\\widetilde{S}_{X_2}^2}{n_2}\\right)^2} \\] graus de llibertat, \\(t_{\\nu}\\) (aproximadament, si \\(X_1,X_2\\) no són normals però \\(n_1\\) i \\(n_2\\) són totes dues grans). No cal que sapigueu aquestes fórmules per a mostres independents, només que l’estadístic de contrast i la seva distribució depenen de si les variàncies poblacionals són iguals o diferents. El nombre de graus de llibertat de la distribució t de Student emprada en un contrast sobre dues mostres de mida \\(n\\): Si les mostres són aparellades, és \\(n-1\\) Si les mostres són independents, és aproximadament \\(2(n-1)\\) Això fa que amb dues mostres aparellades de \\(n\\) individus cadascuna sigui necessari un efecte més gran per poder rebutjar la hipòtesi nul·la que si fossin independents. Això disminueix el risc de cometre un error de tipus I. Per exemple, suposem que volem realitzar el contrast \\[ \\left\\{ \\begin{array}{l} H_0: \\mu_1=\\mu_2\\\\ H_1: \\mu_1&gt;\\mu_2 \\end{array} \\right. \\] i que l’estadístic de contrast \\(T\\) sobre dues mostres de mides \\(n_1=n_2=20\\) dóna 1.7. Aleshores Si les mostres són independents, \\[ \\text{p-valor}=P(T&gt;1.7)\\approx \\texttt{1-pt(1.7,38)}=0.0487 \\] Si les mostres són aparellades, \\[ \\text{p-valor}=P(T&gt;1.7)=\\texttt{1-pt(1.7,19)}=0.0527 \\] Per tant, amb nivell de significació \\(\\alpha=0.05\\), rebutjaríem la hipòtesi nul·la amb les mostres independents i l’acceptaríem amb les mostres aparellades. 6.1.3 Tests t amb R Tots aquests tests t estan implementats en la funció de R t.test(x, y, mu=..., alternative=..., paired=..., var.equal=..., conf.level=...) on: Entram com a x una mostra i a mu el valor amb el qual volem contrastar \\(\\mu\\), o entram com a x i y les mostres de \\(X_1\\) i de \\(X_2\\) A alternative hi hem d’indicar el tipus de contrast segons la hipòtesi alternativa: alternative=\"two.sided\" (\\(\\neq\\), el valor per defecte) alternative=\"less\" (\\(&lt;\\)) alternative=\"greater\" (\\(&gt;\\)) En el cas d’un contrast de dues mitjanes, a paired hi hem d’indicar si les mostres són independents, amb paired=FALSE (el valor per defecte), o aparellades, amb paired=TRUE En el cas d’un contrast de dues mitjanes amb mostres independents, a var.equal hi hem d’indicar si les variàncies són iguals, amb var.equal=TRUE, o diferents, amb var.equal=FALSE (el valor per defecte) A conf.level hi hem d’especificar el nivell de confiança \\(1-\\alpha\\): el seu valor per defecte és 0.95, que correspon al nivell de significació \\(\\alpha=0.05\\) usual 6.1.4 Exemples Exemple 6.3 La temperatura mitjana del cos humà, és el valor usualment acceptat de 98.6o F (37o C)? Per contrastar-ho, emprarem la taula de dades Body_Temperature.txt, construïda per P.A. Mackowiak, S. S. Wasserman i M.M. Levine en 1992 precisament per realitzar aquest contrast i que trobareu a l’Aula Digital. Variable aleatòria d’interès: \\(X\\): “Prenem una persona i n’anotam la temperatura, en graus F”, amb mitjana \\(\\mu\\) Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=98.6\\\\ H_{1}:\\mu \\neq 98.6 \\end{array} \\right. \\] Realitzarem aquest contrast amb R. Carregam la taula de temperatures, que prèviament hem guardat en el directori de treball de R, en un dataframe que anomenarem BT. BT=read.table(&quot;Body_Temperature.txt&quot;) head(BT) ## Gender HeartRate Temperature ## 1 M 69 97.0 ## 2 M 72 98.8 ## 3 M 68 96.2 ## 4 F 75 97.8 ## 5 F 68 98.8 ## 6 M 79 101.3 str(BT) ## &#39;data.frame&#39;:\t230 obs. of 3 variables: ## $ Gender : chr &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;F&quot; ... ## $ HeartRate : int 69 72 68 75 68 79 71 73 77 81 ... ## $ Temperature: num 97 98.8 96.2 97.8 98.8 ... Veiem que la taula BT consta de 230 individus i 3 variables mesurades sobre cadascun d’ells: el sexe (variable Gender, amb nivells F per a dona i M per a home), les pulsacions per minut (variable HeartRate) i la temperatura en graus F (variable Temperature). Com que la mostra és gran, \\(n=230\\), podem emprar un test t. Emprarem la funció t.test, aplicant-la al vector de temperatures i al valor que contrastam, 98.6, entrat amb el paràmetre mu. Indicarem amb el paràmetre alternative=\"two.sided\" que el test és bilateral. No faria falta fer-ho, perquè és el seu valor per defecte. Igualment, indicarem amb el paràmetre conf.level=0.95 que volem emprar un nivell de significació de 0.05, i tampoc faria falta emprar-lo. t.test(BT$Temperature, mu=98.6, alternative=&quot;two.sided&quot;, conf.level=0.95) ## ## One Sample t-test ## ## data: BT$Temperature ## t = -5.7205, df = 229, p-value = 3.301e-08 ## alternative hypothesis: true mean is not equal to 98.6 ## 95 percent confidence interval: ## 98.17563 98.39307 ## sample estimates: ## mean of x ## 98.28435 Del resultat cal destacar: El p-valor, p-value, en el nostre cas 3.301·10-8 (R l’ha escrit en notació científica: 3.301e-08). L’IC 95%, 95 percent confidence interval, per al valor que contrastam (aquí, la temperatura mitjana poblacional), en el nostre cas [98.17563, 98.39307]. La mitjana mostral de la mostra, sample of x, en el nostre cas 98.28435. Per tant: El p-valor és 3·10-8, per la qual cosa amb les dades d’aquesta taula obtenim evidència estadísticament significativa que la temperatura mitjana del cos humà no és de 98.6o F (37o C) A més, com que l’IC 95% per a la temperatura mitjana del cos humà que hem obtingut va de 98.2 a 98.4 (36.78 a 36.89o C), hem trobat evidència amb aquest nivell de confiança que aquesta temperatura mitjana és de fet (lleugerament) inferior a 98.6o F Conclusió: Hem obtingut evidència estadísticament significativa que la temperatura mitjana del cos humà no és de 98.6o F (test t, p-valor 3·10-8, IC 95% de 98.2 a 98.4). Exemple 6.4 La temperatura mitjana dels homes, és diferent de la de les dones? Per resoldre aquesta qüestió, emprarem la mateixa taula de dades que abans. Variables aleatòries d’interès: \\(X_d\\): “Prenem una dona i anotam la seva temperatura, en graus F”, amb mitjana \\(\\mu_d\\) \\(X_h\\): “Prenem un home i anotam la seva la temperatura, en graus F”, amb mitjana \\(\\mu_h\\) Contrast: Plantejarem el contrast en termes de temperatures mitjanes: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_d=\\mu_h\\\\ H_{1}:\\mu_d\\neq \\mu_h \\end{array} \\right. \\] Per poder emprar un test t, primer ens cal saber si hi ha nombres suficientment grans d’homes i dones a la nostra mostra per emprar-lo sense haver-nos de preocupar per si les variables poblacionals són normals o no. Per això calcularem la taula de freqüències dels sexes, aplicant la funció table al vector BT$Gender dels sexes: table(BT$Gender) ## ## F M ## 116 114 Són prou grans. Anam a crear uns vectors amb les temperatures d’homes i de dones. Recordau que hi ha diverses maneres d’extreure d’un dataframe el vector de valors d’una variable V1 per als individus que prenen un valor concret X en una altra variable V2: per exemple dataframe$V1[V2==X] o dataframe[V2==X,V1]. Així, les temperatures dels homes (individus on la variable Gender és igual a M) són BT$Temperature[BT$Gender==&quot;M&quot;] ## [1] 97.0 98.8 96.2 101.3 99.2 97.5 97.3 98.6 99.0 98.0 97.0 97.6 ## [13] 99.0 97.1 98.9 98.6 98.9 97.2 98.0 99.4 98.8 98.5 99.6 97.3 ## [25] 96.5 97.8 98.3 98.1 98.8 97.7 98.3 97.7 99.1 98.8 97.4 96.9 ## [37] 98.0 98.4 100.3 97.0 99.0 100.6 98.0 98.5 97.0 97.0 98.6 97.8 ## [49] 97.3 96.3 96.7 96.9 97.0 97.1 97.1 97.1 97.2 97.3 97.4 97.4 ## [61] 97.4 97.4 97.5 97.5 97.6 97.6 97.6 97.7 97.8 97.8 97.8 97.8 ## [73] 97.9 97.9 98.0 98.0 98.0 98.0 98.0 98.0 98.1 98.1 98.2 98.2 ## [85] 98.2 98.2 98.3 98.3 98.4 98.4 98.4 98.4 98.5 98.5 98.6 98.6 ## [97] 98.6 98.6 98.6 98.6 98.7 98.7 98.8 98.8 98.8 98.9 99.0 99.0 ## [109] 99.0 99.1 99.2 99.3 99.4 99.5 Bé, cream els vectors \\(X_d\\) (dones) i \\(X_h\\) (homes) X_d=BT$Temperature[BT$Gender==&quot;F&quot;] # Temperatures de dones X_h=BT$Temperature[BT$Gender==&quot;M&quot;] # Temperatures d&#39;homes Per portar a terme un test t per comparar dues mitjanes, aplicam la funció t.test als vectors X_di X_h. Ja no afegirem els paràmetres alternative=\"two.sided\" i conf.level=0.95 perquè són els valors per defecte. En aquest exemple, a més, especificarem que les mostres són independents amb paired=FALSE (no caldria, ja que també n’és el valor per defecte) i a més hem d’especificar si les variàncies poblacionals són iguals (var.equal=TRUE) o diferents (var.equal=FALSE). El que farem aquí serà provar els dos casos: amb les variàncies iguals i amb les variàncies diferents. Si les dues conclusions són la mateixa, aquesta serà la conclusió que prendrem. Si dóna diferent, haurem de realitzar un contrast previ per decidir si hem de suposar que les variàncies són iguals o diferents. t.test(X_d, X_h, paired=FALSE, var.equal=TRUE) ## ## Two Sample t-test ## ## data: X_d and X_h ## t = 2.5379, df = 228, p-value = 0.01182 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.06189412 0.49173564 ## sample estimates: ## mean of x mean of y ## 98.42155 98.14474 t.test(X_d, X_h, paired=FALSE, var.equal=FALSE) ## ## Welch Two Sample t-test ## ## data: X_d and X_h ## t = 2.5358, df = 225.32, p-value = 0.0119 ## alternative hypothesis: true difference in means is not equal to 0 ## 95 percent confidence interval: ## 0.06170851 0.49192125 ## sample estimates: ## mean of x mean of y ## 98.42155 98.14474 En tots dos casos obtenim un p-valor (p-value) de l’ordre de 0.012. L’IC 95 % (95 percent confidence interval) que ens dóna és per a la diferència de les mitjanes poblacionals, \\(\\mu_d-\\mu_h\\). Com que no conté el 0, podem rebutjar que les dues mitjanes siguin iguals (que \\(\\mu_d-\\mu_h=0\\)). Conclusió: Hem obtingut evidència estadísticament significativa que la temperatura mitjana de les dones és diferent de la dels homes (test t, p-valor 0.012, IC 95% per a la diferència de les mitjanes de 0.062 a 0.492). Exemple 6.5 Desdijunar segó de civada (oat bran) en lloc de flocs de blat de moro (corn flakes), ajuda a reduir el nivell de colesterol? Per resoldre aquesta qüestió, emprarem la taula de dades oatbran.txt, que trobareu a l’Aula Digital. Aquestes dades es recolliren en un assaig creuat sobre 14 individus. A cada un d’ells se li assignà un dels dos desdejunis de manera aleatòria i el prengueren durant 15 dies. Al final d’aquest període, se’ls mesurà el nivell de colesterol en sang. Passat un mes de descans, cada participant va desdejunar durant 15 dies l’altre producte, i al final se’ls tornà a mesurar el nivell de colesterol en sang. En aquesta taula, aquests nivells de colesterol estan mesurats en milimols per litre. Fixau-vos que les mostres obtengudes d’aquesta manera són aparellades, perquè es mesuraren les dues variables aleatòries sobre els mateixos individus en dos moments diferents. Variables aleatòries d’interès: \\(X_{ob}\\): “Prenem una persona que desdejuna oat bran i li mesuram el nivell de colesterol en mmol/l”, amb mitjana \\(\\mu_{ob}\\) \\(X_{cf}\\): “Prenem una persona que desdejuna corn flakes i li mesuram el nivell de colesterol en mmol/l”, amb mitjana \\(\\mu_{cf}\\) Contrast: El plantejarem en termes de nivells mitjans de colesterol: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{ob}=\\mu_{cf}\\\\ H_{1}:\\mu_{ob}&lt; \\mu_{cf} \\end{array} \\right. \\] Carregam la taula de dades, que prèviament hem guardat en el directori de treball de R, en un dataframe al que anomenam OBR i consultam la seva estructura: OBR=read.table(&quot;oatbran.txt&quot;,header=TRUE) head(OBR) ## CORNFLK OATBRAN ## 1 4.61 3.94 ## 2 6.42 5.57 ## 3 5.40 5.85 ## 4 4.54 4.80 ## 5 3.98 3.68 ## 6 3.82 2.96 str(OBR) ## &#39;data.frame&#39;:\t14 obs. of 2 variables: ## $ CORNFLK: num 4.61 6.42 5.4 4.54 3.98 3.82 5.01 4.34 3.8 4.56 ... ## $ OATBRAN: num 3.94 5.57 5.85 4.8 3.68 2.96 4.41 3.72 3.49 3.94 ... N’extraiem les dues variables en forma de vectors: OAT=OBR$OATBRAN CFL=OBR$CORNFLK Com que mostres de mida 14 són petites, si volem aplicar un test t necessitam que les diferències OAT-CFL provenguin d’una distribució normal. Per decidir si és veritat o no, més endavant explicarem contrastos de bondat d’ajust, amb hipòtesi nul·la “Aquesta mostra prové d’una variable aleatòria amb tal distribució” i hipòtesi alternativa “No és veritat que aquesta mostra provengui d’una variable aleatòria amb tal distribució”. Per ara ens conformarem amb decidir-ho a partir d’un gràfic. A Matemàtiques I us explicàvem que podeu dibuixar un histograma d’una mostra afegint-hi la densitat estimada, a partir de la mostra, de la variable poblacional i la densitat d’una distribució normal amb mitjana i desviació típica les de la mostra, i mirar si sembla que les dades segueixen aquesta distribució normal. Però amb poques dades això és mal de veure: hist(OAT-CFL,freq=FALSE, breaks=4,col=&quot;light blue&quot;,xlab=&quot;Colesterol&quot;, ylab=&quot;Densitat&quot;, main=&quot;Histograma de les diferències&quot;,ylim=c(0,1)) lines(density(OAT-CFL),lty=2,lwd=2) curve(dnorm(x,mean(OAT-CFL),sd(OAT-CFL)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;), col=c(&quot;black&quot;,&quot;red&quot;),lty=c(2,1),cex=0.75) En aquest cas, una opció millor és dibuixar un q-q-plot. Un q-q-plot d’una mostra i una distribució teòrica és el gràfic dels q-q-punts: els punts de la forma (q-quantil de la distribució, q-quantil de la mostra), per a tots els valors de q que tengui sentit donada la mida de la mostra. Quan la distribució amb la que comparam la mostra és una normal, se’n sol dir un normal-plot. Si la mostra prové de la distribució emprada en el q-q-plot, és d’esperar que el q-quantil de la mostra sigui aproximadament igual al q-quantil de la distribució i per tant que aquests q-q-punts estiguin prop de la diagonal principal \\(y=x\\). La funció qqPlot del paquet car produeix uns q-q-plots que contenen una regió de confiança del 95% que especifica què vol dir això que “els q-q-punts estiguin prop de la diagonal principal \\(y=x\\)”, amb el significat usual de nivell de confiança. En particular, si tots els q-q-punts cauen aquesta regió de confiança, amb un 95% de confiança podem acceptar que la mostra prové de la distribució representada a l’eix d’abscisses. L’explicam amb detall a la lliçó de R sobre Contrastos de Bondat d’Ajust. Vegem el q-q-plot de la nostra mostra de diferències: car::qqPlot(OAT-CFL, distribution=&quot;norm&quot;, mean=mean(OAT-CFL), sd=sd(OAT-CFL), ylab=&quot;Quantils de OAT-CFL&quot;, xlab=&quot;Quantils de normal&quot;, main=&quot;q-q-plot de les diferències&quot;, pch=20, id=FALSE,) Veiem que podem acceptar que les diferències provenen d’una distribució normal: podem fer servir un test t. En aquest cas, el test t és de mostres aparellades. Per tant, a t.test hi hem d’especificar paired=TRUE i no hi hem d’especificar el paràmetre var.equal (la igualtat o no de variàncies només s’ha de tenir en compte en els tests amb mostres independents). Emprarem el paràmetre alternative=\"less\" per indicar que el test és unilateral: la hipòtesi alternativa és que la mitjana de la població corresponent a la primera mostra, OAT, és més petita que la de la corresponent a la segona mostra, CFL. t.test(OAT,CFL,alternative=&quot;less&quot;, paired=TRUE) ## ## Paired t-test ## ## data: OAT and CFL ## t = -3.3195, df = 13, p-value = 0.002768 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.1626132 ## sample estimates: ## mean of the differences ## -0.3485714 Com abans, el resultat inclou el p-valor, l’IC 95% per a la mitjana de les diferències (que és igual a la diferència de les mitjanes: recordau que \\(E(X-Y)=E(X)-E(Y)\\)) i ara, com a novetat, la mitjana de les diferències (mean of the differences) en comptes de les dues mitjanes. Conclusió: Hem obtingut evidència estadísticament significativa que desdejunar oatbran redueix el nivell mitjà de colesterol respecte de desdejunar corn flakes (test t, p-valor 0.003, IC 95% per a la diferència de les mitjanes de \\(-\\infty\\) a -0.163). Exemple 6.6 Volem contrastar si el nivell de triglicèrids als nadons de 2 setmanes és més alt que el del seu cordó umbilical en néixer. Per fer-ho, emprarem les dades d’una mostra de 25 nadons als quals els mesuraren els nivells de triglicèrids en plasma a la sang del seu cordó umbilical i a la seva sang al cap de 2 setmanes de néixer (les dues en ng/dl). Tenim les dades a la taula trignadons.txt que trobareu a l’Aula Digital. Les seves variables són CU, les mesures del cordó umbilical, DS, les mesures al cap de dues setmanes, i Nin, que identifica el nadó. Les mostres obtengudes d’aquesta manera tornen a ser aparellades, perquè es mesuraren les dues variables aleatòries sobre els mateixos nadons en dos moments diferents. Variables aleatòries d’interès: \\(X_{cu}\\): “Prenem un recent nat i mesuram el nivell de triglicèrids en plasma a la sang del seu cordó umbilical en ng/dl”, amb mitjana \\(\\mu_{cu}\\) \\(X_{ds}\\): “Prenem un nadó de 2 setmanes i mesuram el seu nivell de triglicèrids en plasma en ng/dl”, amb mitjana \\(\\mu_{ds}\\) Contrast: Plantejarem el contrast en termes dels nivells mitjans de triglicèrids: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{cu}=\\mu_{ds}\\\\ H_{1}:\\mu_{cu}&lt; \\mu_{ds} \\end{array} \\right. \\] Carregam la taula de dades, que prèviament hem guardat en el directori de treball de R, en un dataframe al que anomenam TGN i consultam la seva estructura: TGN=read.table(&quot;trignadons.txt&quot;,header=TRUE) head(TGN) ## Nin CU DS ## 1 1 45 80 ## 2 2 30 68 ## 3 3 30 83 ## 4 4 30 78 ## 5 5 31 79 ## 6 6 27 78 str(TGN) ## &#39;data.frame&#39;:\t25 obs. of 3 variables: ## $ Nin: int 1 2 3 4 5 6 7 8 9 10 ... ## $ CU : int 45 30 30 30 31 27 27 30 33 32 ... ## $ DS : int 80 68 83 78 79 78 89 78 72 75 ... Com que 25 dades per mostra són poques, miram si les diferències segueixen una distribució normal amb un normal-plot. Diffs=TGN$CU-TGN$DS car::qqPlot(Diffs, distribution=&quot;norm&quot;, mean=mean(Diffs), sd=sd(Diffs), ylab=&quot;Quantils de les diferències&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) Podem acceptar que les diferències provenen d’una distribució normal, així que podem tirar endavant amb un test t. Però abans de continuar, volem fer-vos observar que, en aquest exemple, les mostres de triglicèrids per separat no semblen venir de variables normals. car::qqPlot(TGN$CU, distribution=&quot;norm&quot;, mean=mean(TGN$CU), sd=sd(TGN$CU), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, main=&quot;q-q-plot de CU&quot;, pch=20, id=FALSE) car::qqPlot(TGN$DS, distribution=&quot;norm&quot;, mean=mean(TGN$DS), sd=sd(TGN$DS), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, main=&quot;q-q-plot de DS&quot;, pch=20, id=FALSE) Hi ha q-q-punts fora de la regió de confiança. Vegem els seus histogrames hist(TGN$CU, freq=FALSE, main=&quot;Histograma de TGN$CU&quot;, xlab=&quot;&quot;,ylab=&quot;&quot;,col=&quot;light blue&quot;) lines(density(TGN$CU),lty=2,lwd=2) curve(dnorm(x,mean(TGN$CU),sd(TGN$CU)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;),col=c(&quot;black&quot;,&quot;red&quot;), lty=c(2,1),cex=0.5) # hist(TGN$DS, freq=FALSE, main=&quot;Histograma de TGN$DS&quot;, xlab=&quot;&quot;,ylab=&quot;&quot;,col=&quot;light blue&quot;) lines(density(TGN$DS),lty=2,lwd=2) curve(dnorm(x,mean(TGN$DS),sd(TGN$DS)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;),col=c(&quot;black&quot;,&quot;red&quot;), lty=c(2,1),cex=0.5) Les dues mostres presenten una cua a la dreta. Per sort, com que les mostres són aparellades, bastava que les diferències seguissin una llei normal. Efectuem el test t: t.test(TGN$CU, TGN$DS, paired=TRUE, alternative=&quot;less&quot;) ## ## Paired t-test ## ## data: TGN$CU and TGN$DS ## t = -21.988, df = 24, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -41.8674 ## sample estimates: ## mean of the differences ## -45.4 Conclusió: Hem obtingut evidència estadísticament significativa que el nivell mitjà de triglicèrids a la sang del cordó umbilical d’un nadó és més petit que el nivell mitjà de triglicèrids a la sang d’un nadó de 2 setmanes (test t, p-valor&lt;2.2·10-16, IC 95% per a la diferència de les mitjanes de \\(-\\infty\\) a -41.8674). Exemple 6.7 Imaginau ara que les mostres TGN$CU i TGN$DS haguessin estat independents. En aquest cas, com que, com hem vist, no podríem acceptar que provenen de variables normals, no podríem fer servir un test t. En aquesta situació, tenim dues opcions. Una és emprar un test no paramètric: serà el que farem a la pròxima secció (Exemple 6.9). Una altra és recordar de la Secció 2.5.4 que quan tenim una variable amb una cua a la dreta, pot ser que els logaritmes segueixin aproximadament una distribució normal. Vegem si hi ha sort. LogCU=log(TGN$CU) qqPlot(LogCU, distribution=&quot;norm&quot;, mean=mean(LogCU), sd=sd(LogCU), ylab=&quot;Quantils dels logaritmes&quot;, xlab=&quot;Quantils de normal&quot;, main=&quot;q-q-plot de LogCU&quot;, pch=20, id=FALSE) # LogDS=log(TGN$DS) qqPlot(LogDS, distribution=&quot;norm&quot;, mean=mean(LogDS), sd=sd(LogDS), ylab=&quot;Quantils dels logaritmes&quot;, xlab=&quot;Quantils de normal&quot;, main=&quot;q-q-plot de LogDS&quot;, pch=20, id=FALSE) Aquests logaritmes ja poden passar per normals. Per tant, el que faríem seria, en lloc de comparar les mitjanes dels nivells de triglicèrids, comparar les mitjanes dels seus logaritmes. Aquest tipus de transformació és molt usual en Bioestadística. No són contrastos equivalents, perquè el logaritme de la mitjana no és la mitjana del logaritme. Però en realitat la pregunta que originava aquesta investigació era si el nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons, i ho plantejàvem en termes de si és veritat que el nivell mitjà de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons. Ara, demanar-nos si “el nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons” sí que és equivalent a demanar-nos si “el logaritme del nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons”. I el que fem és plantejar aquesta pregunta en termes de si és veritat que el valor mitjà del logaritme del nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons Per tant, les noves variables aleatòries d’interès són: \\(\\ln(X_{cu})\\): “Prenem un recent nat i calculam el logaritme del nivell de triglicèrids en plasma a la sang del seu cordó umbilical”, amb mitjana \\(\\mu_{logcu}\\) \\(\\ln(X_{ds})\\): “Prenem un nadó de 2 setmanes i calculam el logaritme del seu nivell de triglicèrids en plasma”, amb mitjana \\(\\mu_{logds}\\) Nou contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{logcu}=\\mu_{logds}\\\\ H_{1}:\\mu_{logcu}&lt; \\mu_{logds} \\end{array} \\right. \\] Prenem com a mostres de \\(\\ln(X_{cu})\\) i \\(\\ln(X_{ds})\\) els vectors de logaritmes LogCU i LogDS de la nostra mostra original, que podem acceptar que provenen de distribucions normals, i els aplicam la funció t.test amb alternative=\"less\", paired=FALSE (recordau que en aquest exemple estam suposant que les mostres són independents), i els dos valors de var.equal. t.test(LogCU, LogDS, var.equal=TRUE, paired=FALSE, alternative=&quot;less&quot;) ## ## Two Sample t-test ## ## data: LogCU and LogDS ## t = -22.766, df = 48, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.8280214 ## sample estimates: ## mean of x mean of y ## 3.440296 4.334172 t.test(LogCU, LogDS, var.equal=FALSE, paired=FALSE, alternative=&quot;less&quot;) ## ## Welch Two Sample t-test ## ## data: LogCU and LogDS ## t = -22.766, df = 47.642, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.8280117 ## sample estimates: ## mean of x mean of y ## 3.440296 4.334172 Conclusió: Hem obtingut evidència estadísticament significativa que el valor mitjà del logaritme del nivell de triglicèrids a la sang del cordó umbilical d’un nadó és més petit que el valor mitjà del logaritme del nivell de triglicèrids a la sang d’un nadó de 2 setmanes (test t, p-valor&lt;2.2·10-16, IC 95% per a la diferència de les mitjanes dels logaritmes de \\(-\\infty\\) a -0.828). Concloem, per tant, que tenim evidència estadísticament significativa que el nivell de triglicèrids als nadons de 2 setmanes és més alt que el del seu cordó umbilical. 6.1.5 Tests no paramètrics Si les variables aleatòries d’interès no són (aproximadament) normals i alguna mostra és petita, no podem emprar un test t per comparar mitjanes. En aquest cas, una possibilitat és provar de transformar les dades com a l’Exemple 6.6 per veure si la transformació esdevé normal, i si és el cas, plantejar el contrast en termes de mitjanes de les dades transformades Una altra possibilitat és emprar un test no paramètric, que no necessiti que les variables aleatòries siguin normals perquè la conclusió sigui vàlida. La majoria de tests no paramètrics per comparar mitjanes en realitat comparen medianes, però normalment cometem l’abús de llenguatge de dir que són per contrastar mitjanes. A més, si les variables aleatòries són simètriques, les mitjanes coincideixen amb les medianes. Els més populars són: Test de Wilcoxon per a una mitjana o dues mitjanes emprant mostres aparellades Test de Mann-Whitney per a dues mitjanes emprant mostres independents Tots tres es calculen amb R amb la funció wilcox.test(x, y, mu=..., alternative=..., paired=..., conf.level=...) amb sintaxi idèntica a la de t.test (excepte que no s’hi empra el var.equal). Els millors tests no paramètrics solen tenir potència inferior als millors tests paramètrics. A més, no tots els tests no paramètrics produeixen intervals de confiança. Per tant, sempre que sigui possible és més convenient emprar un test paramètric. Però només si és possible. Emprar un test paramètric quan no és adequat pot portar a conclusions equivocades. Emprau tests paramètrics sempre que pogueu, però només quan pogueu. Com a exemple, vegem com funciona (una versió simplificada) del test de Wilcoxon d’una mitjana. Sigui \\(X\\) una variable aleatòria contínua simètrica al voltant de la seva mitjana \\(\\mu\\) desconeguda. Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq \\mu_0 \\text{ o }\\mu &gt;\\mu_0\\text{ o }\\mu&lt;\\mu_0 \\end{array} \\right. \\] Prenem una mostra aleatòria simple \\(x_1,\\ldots, x_n\\) de \\(X\\). El procediment d’aquest test es basa aleshores en els següents passos, que després il·lustram a l’Exemple 6.8: Per a cada \\(i=1,\\ldots,n\\), sigui \\(d_i=x_i-\\mu_0\\). Als passos següents no es tenen en compte els \\(d_i=0\\). Enumeram els valors \\(d_i\\neq 0\\) de menor a major valor absolut; en cas d’empats, a cada un dels valors empatats li assignam la mitjana de les posicions que ocuparien. A l’índex assignat d’aquesta manera a cada \\(d_i\\) li diem el seu rang. Per exemple, a l’Exemple 6.8 hi ha quatre \\(i\\) amb valors \\(d_i=\\pm 1\\), i els tocarien les posicions 1, 2, 3 i 4: aleshores el rang de cada un d’aquests quatre \\(d_i\\) és 2.5. Diem \\(T_+\\) a la suma dels rangs dels \\(d_i&gt;0\\) i \\(T_{-}\\) a la suma dels rangs dels \\(d_i&lt;0\\) Si H0 vertadera, és a dir, si \\(\\mu=\\mu_0\\), per la simetria de \\(X\\) al voltant de \\(\\mu\\) esperam que \\(T_+\\approx T_-\\). Per tant: Si \\(T_+\\) és molt petit, és evidència que \\(\\mu &lt;\\mu_0\\) En efecte, si \\(T_+\\) és molt més petit que \\(T_-\\), bàsicament significa que hi ha molts més valors a l’esquerra de \\(\\mu_0\\) que a la seva dreta. Això ens dóna evidència que la mediana poblacional (que és el valor que deixa la meitat de la població a l’esquerra i l’altra meitat a la dreta) ha d’estar a l’esquerra de \\(\\mu_0\\). Si \\(T_+\\) és molt gran, és evidència que \\(\\mu &gt;\\mu_0\\) En efecte, si \\(T_+\\) és molt més gran que \\(T_-\\), bàsicament significa que hi ha més valors a la dreta de \\(\\mu_0\\) que a l’esquerra. Això és evidència que més de la meitat dels valors estan a la dreta de \\(\\mu_0\\), és a dir, que la mediana està a la dreta de \\(\\mu_0\\). Si \\(T_+\\) és molt petit o molt gran, és evidència que \\(\\mu\\neq \\mu_0\\) I resulta que, quan \\(X\\) és simètrica i H0 vertadera, la distribució de \\(T_+\\), per a cada \\(n\\), és coneguda, la qual cosa es pot emprar per calcular el p-valor. Això ho fa la funció wilcox.test. Exemple 6.8 Alimentàrem amb una dieta especial 13 ratolins des del naixement fins a la setmana 12. Els augments de pes (en grams) varen ser els del vector següent pesos=c(69,61,69,65,70,68,69,68,72,67,74,69,76) Podem concloure que l’augment mitjà de pes en aquestes condicions és de menys de 70 g? Variable aleatòria d’interès: \\(X\\): “Prenem un ratolí alimentat amb aquesta dieta especial i mesuram el seu augment de pes en grams durant les seves primeres 12 setmanes de vida”, amb mitjana \\(\\mu\\). Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=70\\\\ H_{1}:\\mu &lt;70 \\end{array} \\right. \\] Si miram la mostra, veurem que no té pinta de venir d’una distribució normal però sí simètrica: qqPlot(pesos, distribution=&quot;norm&quot;, mean=mean(pesos), sd=sd(pesos), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) stripchart(pesos,method=&quot;stack&quot;,vertical=TRUE,pch=20) Per tant, emprarem un test de Wilcoxon. Vegem com aniria a mà. Calculam els \\(d_i=x_i-70\\) \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\hline \\end{array} \\] Assignam índexos als \\(d_i\\neq 0\\) en ordre creixent al seu valor absolut. En cas d’empat, per ara els assignam els índexos ordenats d’esquerra a dreta. \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\textrm{Rang fals} &amp; 1 &amp; 12 &amp; 2 &amp; 10 &amp; &amp; 5 &amp; 3 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 4 &amp; 11 \\\\ \\hline \\end{array} \\] A continuació, assignam com a rang de cada \\(d_i\\) la mitjana de tots els “rangs falsos” dels \\(d_i\\) amb el seu mateix valor absolut. Així, el rang de tots els \\(d_i=-1\\) és \\((1+2+3+4)/4=2.5\\) i el rang dels \\(d_i=-2\\) o 2 és \\((5+6+7)/3=6\\). \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\textrm{Rang fals} &amp; 1 &amp; 12 &amp; 2 &amp; 10 &amp; &amp; 5 &amp; 3 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 4 &amp; 11 \\\\ \\textrm{Rang} &amp; 2.5 &amp; 12 &amp; 2.5 &amp; 10 &amp; &amp; 6 &amp; 2.5 &amp; 6 &amp; 6 &amp; 8 &amp; 9 &amp; 2.5 &amp; 11 \\\\ \\hline \\end{array} \\] Anotam quins \\(d_i\\) són positius i quins negatius: \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\textrm{Rang fals} &amp; 1 &amp; 12 &amp; 2 &amp; 10 &amp; &amp; 5 &amp; 3 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 4 &amp; 11 \\\\ \\textrm{Rang} &amp; 2.5 &amp; 12 &amp; 2.5 &amp; 10 &amp; &amp; 6 &amp; 2.5 &amp; 6 &amp; 6 &amp; 8 &amp; 9 &amp; 2.5 &amp; 11 \\\\ \\textrm{Signe} &amp; - &amp; - &amp; - &amp; - &amp; &amp; - &amp; - &amp; - &amp; + &amp; - &amp; + &amp; - &amp; +\\\\ \\hline \\end{array} \\] Sumam, d’una banda, els rangs dels \\(d_i\\) positius i de l’altra, els dels negatius: \\[ \\begin{array}{l} T_+=6+9+11=26\\\\ T_-=2.5+ 12 + 2.5 + 10 + 6 + 2.5 + 6 + 8 + 2.5=52 \\end{array} \\] I ara miraríem si \\(T_+\\) és prou més petit que \\(T_-\\) perquè sigui evidència estadísticament significativa de que \\(\\mu &lt;\\mu_0\\). Això ja no ho podem fer a mà. Amb R, simplement entraríem wilcox.test(pesos,mu=70,alternative=&quot;less&quot;) ## ## Wilcoxon signed rank test with continuity correction ## ## data: pesos ## V = 26, p-value = 0.1621 ## alternative hypothesis: true location is less than 70 Conclusió: No hem obtingut evidència estadísticament significativa que l’augment mitjà de pes en aquestes condicions sigui més petit que 70 g (test de Wilcoxon, p-valor 0.16). El test de Wilcoxon per a dues mitjanes emprant mostres aparellades és bàsicament el test anterior aplicat a la diferència dels valors de les dues variables a les parelles. Exemple 6.9 Una alternativa a la transformació logarítmica portada a terme a l’Exemple 6.7 hagués estat emprar el test de Wilcoxon per a mostres independents. El contrast ara seria \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{cu}-\\mu_{ds}=0\\\\ H_{1}:\\mu_{cu}- \\mu_{ds}&lt;0 \\end{array} \\right. \\] que clarament correspon al contrast original \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{cu}=\\mu_{ds}\\\\ H_{1}:\\mu_{cu}&lt; \\mu_{ds} \\end{array} \\right. \\] però hem de tenir present que la hipòtesi nul·la en realitat significa que la mediana de les diferències dels nivells de triglicèrids en el cordó umbilical menys els nivells de triglicèrids al cap de dues setmanes és 0, és a dir Si restam del nivell de triglicèrids en la sang del cordó umbilical d’un nadó el seu nivell de triglicèrids en sang al cap de dues setmanes, la meitat de les vegades obtenim un valor \\(\\geqslant 0\\) i l’altra meitat de les vegades un valor \\(\\leqslant 0\\), o, equivalentment, La meitat dels nadons tenen el nivell de triglicèrids en la sang del cordó umbilical més alt o igual que el seu nivell de triglicèrids en sang al cap de dues setmanes, i l’altra meitat tenen el nivell de triglicèrids en la sang del cordó umbilical més petit o igual que el seu nivell de triglicèrids en sang al cap de dues setmanes. La hipòtesi alternativa és que aquesta mediana és negativa. És a dir, la hipòtesi alternativa és Si restam el nivell de triglicèrids en la sang del cordó umbilical d’un nadó menys el nivell de triglicèrids en sang al cap de dues setmanes, més de la meitat de les vegades obtendríem un valor \\(&lt;0\\) o, equivalentment, Més de la meitat dels nadons tenen el nivell de triglicèrids en la sang del cordó umbilical més petit que el seu nivell de triglicèrids en sang al cap de dues setmanes. wilcox.test(TGN$CU,TGN$DS,alternative=&quot;less&quot;,paired=FALSE) ## ## Wilcoxon rank sum test with continuity correction ## ## data: TGN$CU and TGN$DS ## W = 0, p-value = 6.771e-10 ## alternative hypothesis: true location shift is less than 0 Com que el p-valor és de l’ordre de 10-10, rebutjam la hipòtesi nul·la en favor de la alternativa; abusarem del llenguatge i ho expressarem en termes de mitjanes: Conclusió: Hem obtingut evidència estadísticament significativa que el nivell mitjà de triglicèrids a la sang del cordó umbilical dels nadons és més petit que al cap de dues setmanes (test de Wilcoxon, p-valor 6.7·10-10). I no podríem haver emprat bootstrap? I tant! L’únic que cal tenir-hi en compte és que en el contrast de dues mitjanes que s’efectua amb un bootstrap la hipòtesi nul·la no és només \\(\\mu_1=\\mu_2\\), sinó Les dues mostres provenen de la mateixa variable poblacional És a dir, el contrast que resoldrem serà \\[ \\left\\{\\begin{array}{l} H_0:\\ \\text{$X_{cu}$ i $X_{ds}$ tenen la mateixa distribució}\\\\ H_1:\\ \\text{$\\mu_{cu}&lt;\\mu_{ds}$} \\end{array}\\right. \\] Diguem \\(A\\) a la mostra TGN$CU i \\(B\\) a la mostra TGN$DS. Siguin \\(n_A\\) i \\(n_B\\) les seves mides, que en el nostre cas son totes dues 25. El que farem és el següent: Concatenam en un únic vector les mostres \\(A\\) i \\(B\\). Obtenim un vector de \\(n_A+n_B\\) dades, les primeres \\(n_A\\) d’una mostra i les altres \\(n_B\\) de l’altra mostra. A=TGN$CU B=TGN$DS nA=length(A) nB=length(B) Global=c(A,B) Repetim 5000 vegades el procés següent: Prenem una m.a.s. de Global de la seva mateixa mida, \\(n_A+n_B\\) Calculam la mitjana de les primeres \\(n_A\\) entrades Calculam la mitjana de les darreres \\(n_B\\) entrades Calculam la diferència d’aquestes mitjanes Organitzam totes aquestes diferències de mitjanes en un vector. Fixarem la llavor d’aleatorietat, perquè el resultat sigui reproduïble. set.seed(1234) DifM=function(x,n,m){mean(x[1:n])-mean(x[(n+1):(n+m)])} Remostreig=replicate(5000,DifM(sample(Global, nA+nB, rep=TRUE),nA,nB)) Prendrem com a p-valor la proporció d’aquestes diferències de mitjanes que són més petites o iguals que \\(\\overline{A}-\\overline{B}\\). p.valor=length(which(Remostreig&lt;=mean(A)-mean(B)))/length(Remostreig) p.valor ## [1] 0 Vaja! mean(A)-mean(B) ## [1] -45.4 min(Remostreig) ## [1] -27.76 Què significa això? Si les dues mostres de triglicèrids provinguessin de la mateixa variable, el vector Global seria una mostra d’aquesta variable. Llavors, la diferència \\(\\overline{A}-\\overline{B}\\) entre la mitjana de les seves primeres 25 entrades i la de les seves darreres 25 entrades no hauria de ser molt diferent de la diferència entre la mitjana d’una mostra genèrica de 25 entrades i una altra mostra genèrica de 25 entrades. Què fem? Estimam la distribució d’aquestes diferències de mitjanes amb el remostreig, i comparam la nostra diferència \\(\\overline{A}-\\overline{B}\\) amb aquesta distribució. Resulta que és més petita que totes aquestes mitjanes. Per tant, seria “molt rara” per a aquesta distribució. Aleshores, això ho entenem com a senyal que la nostra premissa és falsa, és a dir, que les dues mostres de triglicèrids no provenen de la mateixa variable. Conclusió: Hem obtingut evidència estadísticament significativa que el nivell mitjà de triglicèrids a la sang del cordó umbilical dels nadons és més petit que al cap de dues setmanes (bootstrap, p-valor 0). 6.2 Contrastos de variàncies 6.2.1 Test \\(\\chi^2\\) d’una variància Siguin \\(X\\) una variable aleatòria normal amb desviació típica \\(\\sigma\\). Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma=\\sigma_0\\\\ H_{1}:\\sigma \\neq\\sigma_0\\text{ o }\\sigma &gt;\\sigma_0\\text{ o }\\sigma&lt;\\sigma_0 \\end{array} \\right. \\] o equivalentment \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma^2=\\sigma_0^2\\\\ H_{1}:\\sigma^2 \\neq\\sigma_0^2\\text{ o }\\sigma^2 &gt;\\sigma_0^2\\text{ o }\\sigma^2&lt;\\sigma_0^2 \\end{array} \\right. \\] Prenem una mostra aleatòria simple de mida \\(n\\) de \\(X\\). Recordem, aleshores, que \\[ \\frac{(n-1) \\widetilde{S}_X^2}{\\sigma^2} \\] té distribució khi quadrat amb \\(n-1\\) graus de llibertat, \\(\\chi_{n-1}^2\\). Per tant, si H0 és vertadera (si \\(\\sigma=\\sigma_0\\)), l’estadístic de contrast \\[ \\chi^2=\\frac{(n-1) \\widetilde{S}_X^2}{\\sigma_{0}^2} \\] té distribució \\(\\chi_{n-1}^2\\). Això ho podem emprar per calcular p-valors, regions crítiques etc. En concret, si el valor d’aquest estadístic de contrast sobre la mostra és \\(\\chi_0^2\\), aleshores: Si \\(H_{1}:\\sigma&gt;\\sigma_{0}\\), el p-valor és \\(P(\\chi^2\\geqslant \\chi_0^2)\\) Si \\(H_{1}:\\sigma&lt;\\sigma_{0}\\), el p-valor és \\(P(\\chi^2\\leqslant \\chi^2_0)\\) Si \\(H_{1}:\\sigma\\neq \\sigma_{0}\\), el p-valor es pren, per conveni, igual a \\(2\\text{min}\\big\\{P(\\chi^2\\geqslant \\chi^2_0), P(\\chi^2\\leqslant\\chi^2_0)\\big\\}\\) Alerta amb els p-valors dels contrastos bilaterals que no siguin ni tests t ni binomials, ja que per motius històrics no es calculen com “la probabilitat d’obtenir un valor de l’estadístic de contrast tant o més extrem que l’obtingut”, sinó per mitjà d’una fórmula de l’estil de la que hem donat aquí dalt. Exemple 6.10 Suposem que tenim una mostra aleatòria simple d’una variable \\(X\\) normal de mida 25, i ha donat \\(\\widetilde{S}_X^2=1.25\\). Volem realitzar alguns contrastos amb hipòtesi nul·la \\(\\sigma_X^2=0.8\\), i per tant tendrem \\[ \\chi_0^2=\\frac{(25-1)\\cdot 1.25}{0.8}=37.5 \\] Si volem realitzar el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_X^2=0.8 \\\\ H_{1}:\\sigma_X^2&gt; 0.8 \\end{array} \\right. \\] el p-valor és \\[ P(\\chi^2_{24} \\geqslant 37.5)=\\texttt{1-pchisq(37.5,24)}=0.039 \\] Amb nivell de confiança \\(\\alpha=0.05\\) rebutjam H0 en favor de H1 Si volem realitzar el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_X^2=0.8 \\\\ H_{1}:\\sigma_X^2\\neq 0.8 \\end{array} \\right. \\] el p-valor és \\[ \\begin{array}{l} 2\\min\\big\\{P(\\chi^2_{24}\\geqslant 37.5),P(\\chi^2_{24}\\leqslant 37.5)\\big\\}\\\\ \\qquad=2\\min\\{\\texttt{1-pchisq(37.5,24)},\\texttt{pchisq(37.5,24)}\\}\\\\ \\qquad=2\\min\\{0.039,0.961\\}= 0.078 \\end{array} \\] Amb nivell de confiança \\(\\alpha=0.05\\), no podem rebutjar H0 . En resum: amb la nostra mostra trobam evidència estadísticament significativa que \\(\\sigma_X&gt;\\sigma_0\\), però no trobam evidència estadísticament significativa que \\(\\sigma_X\\neq \\sigma_0\\). No us ha de venir de nou, ja ens hi hem trobat en altres ocasions (recordau els Exemples 5.14 i 5.17): per rebutjar la hipòtesi nul·la en un contrast bilateral cal més evidència que en un contrast unilateral, perquè al contrast bilateral tenim dues fonts d’error de tipus I i al contrast unilateral només una. Exemple 6.11 S’ha analitzat el líquid amniòtic d’una mostra aleatòria de 15 embarassades de 3er trimestre, i s’han obtingut les mesures següents de proteïnes totals (en grams per 100 ml): amnio=c(0.69,1.04,0.39,0.37,0.64,0.73,0.69,1.04,0.83,1.01, 0.19,0.61,0.42,0.25,0.79) Podem concloure a partir d’aquestes dades, amb un nivell de significació del 5%, que la desviació típica poblacional (és a dir, la desviació típica de la quantitat de proteïna total en el líquid amniòtic de les embarassades de 3er trimestre expressada en grams per 100 ml) és diferent de 0.25? Variable aleatòria d’interès: \\(X\\): “Prenem una embarassada i li mesuram la quantitat de proteïna total en …”, amb desviació típica \\(\\sigma\\). Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma=0.25 \\\\ H_{1}:\\sigma\\neq 0.25 \\end{array} \\right. \\] amb \\(\\alpha=0.05\\) Per poder aplicar el test \\(\\chi^2\\), cal que \\(X\\) sigui normal. Vegem el normal-plot: qqPlot(amnio, distribution=&quot;norm&quot;, mean=mean(amnio), sd=sd(amnio), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) Podem acceptar que \\(X\\) és normal. Estadístic de contrast: \\[ \\chi^2=\\frac{(n-1) \\widetilde{S}_X^2}{\\sigma_{0}^2} \\] que segueix una llei \\(\\chi^2_{n-1}\\) si H0 és certa. Valor de l’estadístic de contrast, \\(\\chi^2_0\\): n=length(amnio) khi0=(n-1)*var(amnio)/0.25^2 round(khi0,2) ## [1] 17.08 p-valor: \\[ \\begin{array}{l} 2\\min\\big\\{P(\\chi_{n-1}^2\\geqslant \\chi^2_0), P(\\chi_{n-1}^2\\leqslant \\chi^2_0)\\big\\}\\\\ \\qquad=2\\min\\{\\texttt{1-pchisq(17.08,14)},\\texttt{pchisq(17.08,14)}\\}\\\\ \\qquad=2\\min\\{0.252,0.748\\}= 0.504 \\end{array} \\] En aquest exemple, com que el contrast és bilateral, l’IC 95% seria el del tema anterior (amb \\(q=1-\\alpha=0.95\\)). El de la variància seria \\[ \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,0.975}^2}, \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,0.025}^2} \\right] \\] on \\(\\chi_{n-1,0.975}^2\\)=qchisq(0.975,14)=26.11895 i \\(\\chi_{n-1,0.025}^2\\)=qchisq(0.025,14)=26.11895. Dóna, per tant, \\[ \\left[ \\frac{14\\cdot 0.07624}{26.11895}, \\frac{14\\cdot 0.07624}{5.62873}\\right]=[0.0409, 0.1896] \\] L’interval de confiança del 95% per a la desviació típica serà aleshores \\[ [\\sqrt{0.0408}, \\sqrt{0.1895}]= [0.202,0.435] \\] i conté el valor 0.25 que contrastàvem. Conclusió: No hem obtingut evidència estadísticament significativa que la desviació típica (de la quantitat de proteïna total …) sigui diferent de 0.25 (test \\(\\chi^2\\), p-valor 0.504, IC 95% de 0.202 a 0.435). Aquest test \\(\\chi^2\\) d’una variància està implementat en la funció sigma.test del paquet TeachingDemos. La seva sintaxi és similar a la de t.test per a una mitjana, canviant la mu per sigma si contrastam la desviació típica o sigmasq si contrastam la variància. Per exemple, per realitzar aquest darrer contrast, simplement entraríem library(TeachingDemos) sigma.test(amnio,sigma=0.25,alternative=&quot;two.sided&quot;) ## ## One sample Chi-squared test for variance ## ## data: amnio ## X-squared = 17.078, df = 14, p-value = 0.5041 ## alternative hypothesis: true variance is not equal to 0.0625 ## 95 percent confidence interval: ## 0.04086535 0.18962728 ## sample estimates: ## var of amnio ## 0.07624 Ups, què ha passat amb l’interval de confiança? No res: fixau-vos que és el de la variància. L’interval de confiança que dóna la funció sigma.test és el de la variància, tant si contrastam la desviació típica (amb el paràmetre sigma) com si contrastam la variància (amb el paràmetre sigmasq). 6.2.2 Test F per a dues variàncies Siguin \\(X_1,X_2\\) dues variables aleatòries normals de desviacions típiques \\(\\sigma_1\\) i \\(\\sigma_2\\), respectivament. En prenem dues mostres aleatòries simples independents de mides \\(n_1\\) i \\(n_2\\) i variàncies mostrals \\(\\widetilde{S}_{X_1}^2\\) i \\(\\widetilde{S}_{X_2}^2\\). Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_1^2=\\sigma_2^2\\\\[1ex] H_{1}:\\sigma_1^2\\neq \\sigma_2^2\\text{ o }\\sigma_1^2&gt; \\sigma_2^2\\text{ o }\\sigma_1^2&lt; \\sigma_2^2 \\end{array} \\right. \\] L’interpretarem \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_1^2/\\sigma_2^2=1\\\\[1ex] H_{1}:\\sigma_1^2/\\sigma_2^2\\neq 1\\text{ o }\\sigma_1^2/\\sigma_2^2&gt;1 \\text{ o }\\sigma_1^2/\\sigma_2^2&lt; 1 \\end{array} \\right. \\] Per realitzar-lo, s’empra l’estadístic de contrast \\[ F={\\widetilde{S}_{X_1}^2}/{\\widetilde{S}_{X_2}^2} \\] que, si les dues poblacions són normals i \\[ H_0: \\sigma_1=\\sigma_2 \\] és vertadera, té distribució coneguda: la F de Fisher-Snedecor \\(F_{n_1-1,n_2-1}\\) amb \\(n_1-1\\) i \\(n_2-1\\) graus de llibertat. Per aquest motiu a aquest contrast se li diu un test F. De la distribució \\(F_{n,m}\\), on \\(n,m\\) són els seus graus de llibertat, heu de saber que: Els graus de llibertat \\(n,m\\) són els paràmetres dels quals depèn la funció de distribució, i l’ordre és important: si \\(n\\neq m\\), la distribució \\(F_{n,m}\\) i la distribució \\(F_{m,n}\\) són diferents. Amb R és f No és simètrica, té cua a la dreta i per tant, com explicam d’aquí a una estona, els p-valors dels contrastos bilaterals es calculen com al test \\(\\chi^2\\) d’una variància. El gràfic següent mostra les gràfiques de les densitats de les distribucions \\(F_{n,m}\\) per a \\(n=3,4\\) i \\(m=3,4,5\\). Es pot observar a cada una d’elles una cua a la dreta ben marcada, i també hi podeu observar que les distribucions \\(F_{3,4}\\) i \\(F_{4,3}\\) tenen densitats diferents. Per tant, si diem \\(F_0\\) al valor que pren l’estadístic \\(F\\) sobre la nostra mostra Si \\(H_{1}:\\sigma_1^2&gt;\\sigma_2^2\\), el p-valor del contrast és \\(P(F\\geqslant F_0)\\) Si \\(H_{1}:\\sigma_1^2&lt;\\sigma_2^2\\), el p-valor del contrast és \\(P(F\\leqslant F_0)\\) Si \\(H_{1}:\\sigma_1^2\\neq \\sigma_2^2\\), el p-valor es pren, per conveni, igual a \\(2\\text{min}\\big\\{P(F\\geqslant F_0), P(F\\leqslant F_0)\\big\\}\\) El test F està implementat en la funció var.test de R: s’aplica a les dues mostres, amb sintaxi similar a la de t.test. En particular, alternative=\"two.sided\", que correspon al contrast bilateral (el més comú), i conf.level=0.95, que correspon a \\(\\alpha=0.05\\), són els valors per defecte d’aquests paràmetres. Exemple 6.12 Les variables \\(X_d\\) i \\(X_h\\) de l’Exemple 6.4, tenen la mateixa variància? Suposarem que totes dues són normals (les temperatures ho solen ser) i diguem \\(\\sigma_d^2\\) i \\(\\sigma_h^2\\) a les seves variàncies. Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_d^2=\\sigma_h^2\\\\ H_{1}:\\sigma_d^2\\neq \\sigma_h^2 \\end{array} \\right. \\] Estadístic de contrast: \\[ F=\\widetilde{S}_d^2/\\widetilde{S}_h^2 \\] Valor de l’estadístic de contrast a la nostra mostra, \\(F_0\\): F0=var(X_d)/var(X_h) round(F0,4) ## [1] 0.8322 Recordem que les mides de les nostres mostres eren \\(n_d=116\\) i \\(n_h=114\\) p-valor: \\[ \\begin{array}{l} 2\\min\\big\\{P(F_{n_d-1,n_h-1} \\geqslant F_0), P(F_{n_d-1,n_h-1}\\leqslant F_0)\\big\\}\\\\ \\qquad =2\\min\\big\\{P(F_{115,113} \\geqslant 0.8322), P(F_{115,113} \\leqslant 0.8322)\\big\\}\\\\ \\qquad =2\\min\\{\\texttt{1-pf(0.8322,115,113)},\\texttt{pf(0.8322,115,113)}\\} \\\\ \\qquad =2\\min\\{0.836,0.164\\}= 0.328 \\end{array} \\] Conclusió: No hem trobat evidència estadísticament significativa que les variables \\(X_h\\) i \\(X_d\\) tenguin variància diferent (test F, p-valor 0.33). Amb R entraríem: var.test(X_d, X_h) ## ## F test to compare two variances ## ## data: X_d and X_h ## F = 0.8322, num df = 115, denom df = 113, p-value = 0.3278 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.575234 1.203224 ## sample estimates: ## ratio of variances ## 0.8321984 Obtenim el mateix p-valor que abans. L’interval de confiança que dóna aquesta funció és per al quocient de les variàncies \\(\\sigma_d^2/\\sigma_h^2\\). Aleshores, com que l’IC 95% conté l’1, no podem rebutjar amb un nivell de significació del 5% que \\(\\sigma_d^2/\\sigma_h^2=1\\), és a dir, que \\(\\sigma_d^2=\\sigma_h^2\\). Podem ampliar la conclusió: Conclusió: No hem trobat evidència estadísticament significativa que les variables \\(X_h\\) i \\(X_d\\) tenguin variància diferent (test F, p-valor 0.33, IC 95% per al quocient de les variàncies de 0.57 a 1.2). Acceptarem que tenen la mateixa variància. Per tant, si els tests t amb var.equal=TRUE i var.equal=FALSE de l’Exemple 6.4 haguessin donat conclusions diferents, prendríem la corresponent a variàncies iguals. Hem emprat un test F per comparar aquestes variàncies, i perquè la conclusió sigui fiable, cal que les variables poblacionals siguin normals, no és suficient que les mostres siguin grans; de fet, la seva validesa no depèn per res de la mida de les mostres. Podem suposar que efectivament les variables \\(X_d\\) i \\(X_h\\) són normals? Vegem els histogrames: hist(X_d,freq=FALSE, breaks=10,col=&quot;light blue&quot;,xlab=&quot;Temperatures&quot;, ylab=&quot;Densitat&quot;,main=&quot;Histograma de temperatures de dones&quot;,ylim=c(0,max(density(X_d)$y))) lines(density(X_d),lty=2,lwd=2) curve(dnorm(x,mean(X_d),sd(X_d)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;), col=c(&quot;black&quot;,&quot;red&quot;),lty=c(2,1),cex=0.5) # hist(X_h,freq=FALSE, breaks=10,col=&quot;light blue&quot;,xlab=&quot;Temperatures&quot;, ylab=&quot;Densitat&quot;,main=&quot;Histograma de temperatures d&#39;homes&quot;,ylim=c(0,dnorm(mean(X_h),mean(X_h),sd(X_h)))) lines(density(X_h),lty=2,lwd=2) curve(dnorm(x,mean(X_h),sd(X_h)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;), col=c(&quot;black&quot;,&quot;red&quot;),lty=c(2,1),cex=0.5) i els normal-plot: qqPlot(X_d, distribution=&quot;norm&quot;, mean=mean(X_d), sd=sd(X_d), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, main=&quot;q-q-plot de la mostra de dones&quot;, pch=20, id=FALSE) qqPlot(X_h, distribution=&quot;norm&quot;, mean=mean(X_h), sd=sd(X_h), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, main=&quot;q-q-plot de la mostra d&#39;homes&quot;, pch=20, id=FALSE) Igual hagués estat millor emprar un test no paramètric, per més seguretat. En tot cas, més endavant (a l’Exemple 7.6) resoldrem si podem acceptar que aquestes mostres provenen de variables normals o no amb uns contrastos de normalitat. 6.2.3 Tests no paramètrics Quan alguna de les variables poblacionals involucrades en un test de dues variàncies no és normal, no es pot fer servir el test F. En aquest cas, us recomanam emprar el test de Fligner-Killeen, implementat en R en la funció fligner.test, que en la pràctica ha mostrat ser més exacte per a variables aleatòries no normals. Aquest test només serveix per a contrastos bilaterals, que en realitat són els més interessants, i està implementat en la funció fligner.test de R. S’aplica a una list formada per les dues mostres o a una fórmula que separi una variable numèrica en dos grups. Per exemple, per emprar-lo en el contrast bilateral de variàncies de l’exemple anterior, entraríem: fligner.test(list(X_h,X_d)) ## ## Fligner-Killeen test of homogeneity of variances ## ## data: list(X_h, X_d) ## Fligner-Killeen:med chi-squared = 1.7736, df = 1, p-value = 0.1829 Seguim acceptant que \\(X_h\\) i \\(X_d\\) tenen la mateixa variància. 6.3 Contrastos per a proporcions 6.3.1 Contrastos per a una proporció Suposem que la variable poblacional \\(X\\) és de Bernoulli, amb probabilitat d’èxit \\(p\\), i que volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:p=p_{0}\\\\ H_{1}:p\\neq p_{0}\\text{ o } p&gt;p_0 \\text{ o } p&lt;p_0 \\end{array} \\right. \\] Tenim dues opcions: Realitzar un test binomial exacte, que és el que explicàvem a la Secció 5.2 Realitzar un test aproximat basat en l’aproximació d’una distribució binomial per una normal, i que per tant només podem emprar si la mostra és gran Test binomial exacte Suposem que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) qualsevol i que hi obtenim \\(S_0\\) èxits, de manera que \\(\\widehat{p}_X=S_0/n\\). Si \\(p=p_{0}\\), el nombre d’èxits \\(S_n\\) en una mostra aleatòria simple de mida \\(n\\) segueix una distribució \\(B(n,p_0)\\). Ho podem emprar per calcular p-valors de la manera usual: Si \\(H_{1}:p&gt;p_{0}\\), el p-valor és \\(P(S_n\\geqslant S_0)\\) Si \\(H_{1}:p&lt;p_{0}\\), el p-valor és \\(P(S_n\\leqslant S_0)\\) Si \\(H_{1}:p\\neq p_{0}\\), el p-valor és la probabilitat que \\(S_n\\) estigui tan o més allunyat que \\(S_0\\) del nombre d’èxits que esperaríem si H0 fos vertadera, que és \\(p_0\\cdot n\\). Per tant, és \\[ \\text{p-valor}=P(|S_n-p_0\\cdot n|\\geqslant |S_0-p_0\\cdot n|) \\] Una distribució binomial \\(B(n,p_0)\\) només és simètrica quan \\(p_0= 0.5\\). Aquest test binomial exacte està implementat en R en la funció binom.test. La seva sintaxi és binom.test(x, n, p=..., alternative=..., conf.level=...) on x indica al nombre d’èxits a la mostra, n la mida de la mostra, p la probabilitat que es contrasta, i els altres dos paràmetres signifiquen el mateix que a les altres funcions explicades fins ara i els seus valors per defecte són els de sempre (\"two.sided\" i 0.95, respectivament). L’interval de confiança que dóna en els contrastos bilaterals és el de Clopper-Pearson. El p-valor s’obté amb el sufix $p.value i l’interval de confiança amb el sufix $conf.int. La funció binom.test calcula el p-valor del contrast bilateral no com l’hem definit nosaltres sinó com la probabilitat que \\(S_n\\) prengui un valor de probabilitat més petita o igual que la de \\(S_0\\): \\[ \\text{p-valor}=\\sum_{k\\ \\mathrm{tal\\ que}\\atop P(S_n=k)\\leqslant P(S_n=S_0)} P(S_n=k) \\] És una altra manera d’interpretar “la probabilitat que, si la hipòtesi nul·la és vertadera, obtinguem un valor tan o més extrem en el sentit de \\(H_1\\) que el nostre.” Gairebé sempre dóna el mateix que el nostre, però no sempre. Per exemple, preneu \\(n=50\\) i \\(p_0=0.8\\) i \\(S_0=36\\). Aleshores \\[ P(|S_n-p_0\\cdot n|\\geqslant |S_0-p_0\\cdot n|)=P(|S_n-40|\\geqslant 4)=P(S_n\\leq 36)+P(S_n\\geq 44) \\] Això val pbinom(36,50,0.8)+1-pbinom(43,50,0.8) ## [1] 0.2139847 que no és el p-valor que dóna binom.test: binom.test(36,50,0.8)$p.value ## [1] 0.1586137 D’altra banda, \\[ \\sum_{k\\ \\mathrm{tal\\ que}\\atop P(S_n=k)\\leqslant P(S_n=S_0)} P(S_n=k)= \\sum_{k\\ \\mathrm{tal\\ que}\\atop f_{S_{50}}(k))\\leqslant f_{S_{50}}(36)} P(S_{50}=k) \\] i això val probs=dbinom(0:50,50,0.8) # Vector de valors de la densitat de S_50 sum(probs[probs&lt;=dbinom(36,50,0.8)]) ## [1] 0.1586137 que sí que és el que donava binom.test. La moralitat d’aquesta història és que si us demanam que calculeu a mà el p-valor en un test binomial bilateral, no empreu binom.test, que igual no dóna el p-valor que donarem com a correcte. Exemple 6.13 Ens demanam si la proporció d’estudiants esquerrans a la UIB, és diferent de la de l’estat espanyol, que és del 10%. Prenem un mostra de 30 estudiants de la UIB més o menys a l’atzar i hi trobam 1 esquerrà. Entendrem que aquesta mostra és aleatòria simple. Variable aleatòria d’interès: \\(X\\): “Prenem un estudiant de la UIB i anotam si és esquerrà”, de probabilitat d’èxit \\(p\\) Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:p=0.1\\\\ H_{1}:p\\neq 0.1 \\end{array} \\right. \\] Emprarem el test binomial exacte Estadístic de contrast: Nombre d’èxits \\(S_{30}\\), que si H0 és vertadera, té distribució \\(B(30,0.1)\\) Valor de l’estadístic de contrast: 1 p-valor: Si la hipòtesi nul·la \\(p=0.1\\) fos vertadera, en una mostra aleatòria de 30 estudiants esperaríem 3 esquerrans, i n’hem trobat 1. Per tant el p-valor és la probabilitat que la diferència en valor absolut entre \\(S\\) i 3 sigui més gran o igual que 2, és a dir, que \\(S\\) sigui més petit o igual que 1 o més gran o igual que 5: \\[ \\begin{array}{l} P(|S-3|\\geqslant |S_0-3|)=P(|S-3|\\geqslant 2)\\\\ \\qquad = P(S\\leqslant 1)+P(S\\geqslant 5)\\\\ \\qquad =\\texttt{pbinom(1,30,0.1)+1-pbinom(4,30,0.1)}=0.3592 \\end{array} \\] Conclusió: No hem obtingut evidència estadísticament significativa que el percentatge d’esquerrans a la UIB sigui diferent del 10% (test binomial, p-valor 0.36). Hem dit que R calcula aquest p-valor com a \\[ \\text{p-valor}=\\sum_{P(S=k)\\leqslant P(S=S_0)} P(S=k) \\] En aquest cas dóna el mateix. Vegem-ho. Direm PB al vector que dóna els valors de la densitat de \\(S_{30}\\) sobre \\(k=0,\\ldots,30\\), que són tots els possibles valors de \\(k\\). Aleshores, els \\(k\\) tals que \\(P(S=k)\\leqslant P(S=S_0)\\) són els que satisfan PB&lt;=dbinom(1,30,0.1). Per tant, la suma de les seves probabilitats és: PB=dbinom(0:30,30,0.1) sum(PB[PB&lt;=dbinom(1,30,0.1)]) ## [1] 0.3591899 Amb R, entraríem: binom.test(1, 30, p=0.1, alternative=&quot;two.sided&quot;) ## ## Exact binomial test ## ## data: 1 and 30 ## number of successes = 1, number of trials = 30, p-value = 0.3592 ## alternative hypothesis: true probability of success is not equal to 0.1 ## 95 percent confidence interval: ## 0.0008435709 0.1721694556 ## sample estimates: ## probability of success ## 0.03333333 i a banda del p-valor obtenim l’IC 95% de Clopper-Pearson per a \\(p\\), mirau epitools::binom.exact(1,30) ## x n proportion lower upper conf.level ## 1 1 30 0.03333333 0.0008435709 0.1721695 0.95 Per tant podem refinar la nostra conclusió: Conclusió: No hem obtingut evidència estadísticament significativa que el percentatge d’esquerrans a la UIB sigui diferent del 10% (test binomial, p-valor 0.37, IC 95% de 0.1% a 17.2%). Test aproximat Suposem que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) gran, posem de 40 subjectes o més, i que hi obtenim una proporció mostral d’èxits \\(\\widehat{p}_X\\). En aquest cas, si \\(H_{0}:p=p_{0}\\) és vertadera, pel Teorema Central del Límit, la distribució de \\[ Z=\\frac{\\widehat{p}_X-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\] és aproximadament la d’una variable \\(N(0,1)\\). Ho podem emprar per calcular p-valors i intervals de confiança com en el test t. En particular, si \\(Z\\) pren el valor \\(z_0\\) sobre la nostra mostra, Quan \\(H_{1}:p&gt;p_{0}\\), el p-valor és \\(P(Z\\geqslant z_0)\\) Quan \\(H_{1}:p&lt;p_{0}\\), el p-valor és \\(P(Z\\leqslant z_0)\\) Quan \\(H_{1}:p\\neq p_{0}\\), el p-valor és \\(2P(Z\\geqslant |z_0|)\\) (recordau que \\(Z\\) és simètrica) Amb R, està implementat en la funció prop.test(x, n, p=...,alternative=..., conf.level=..., correct=...) on els paràmetres tenen el mateix significat que a binom.test excepte correct, que serveix per especificar si volem que s’apliqui una correcció de continuïtat com la que explicàvem a la Secció 2.5. En general, és recomanable emprar la correcció de continuïtat, però nosaltres no l’aplicarem en realitzar contrastos “a mà” per no complicar-los. El valor per defecte de correct és TRUE, i és el que us recomanan que empreu; el que hem explicat aquí correspon a correct=FALSE. L’interval de confiança que dóna aquesta funció en un contrast bilateral sense correcció de continuïtat és el de Wilson. Exemple 6.14 Continuant amb l’Exemple 6.13, ara hi emprarem el test aproximat, tot i que no és lo seu perquè la mostra no és prou gran. Estadístic de contrast: \\[ Z=\\frac{\\widehat{p}_X-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\] que, si H0 és vertadera, segueix una distribució (aproximadament) normal estándard. Valor sobre la nostra mostra: \\[ z_0=\\frac{\\frac{1}{30}-0.1}{\\sqrt{\\frac{0.1(1-0.1)}{30}}}=-1.217 \\] p-valor: \\(2P(Z\\geqslant |-1.217|)=\\texttt{2*(1-pnorm(1.217))}=0.224\\) Conclusió: Un altre cop, no obtenim evidència estadísticament significativa que el percentatge d’esquerrans a la UIB sigui diferent del 10% (prop-test, p-valor 0.22). Amb R, entraríem: prop.test(1, 30, p=0.1, alternative=&quot;two.sided&quot;) ## Warning in prop.test(1, 30, p = 0.1, alternative = &quot;two.sided&quot;): Chi-squared ## approximation may be incorrect ## ## 1-sample proportions test with continuity correction ## ## data: 1 out of 30, null probability 0.1 ## X-squared = 0.83333, df = 1, p-value = 0.3613 ## alternative hypothesis: true p is not equal to 0.1 ## 95 percent confidence interval: ## 0.001742467 0.190530216 ## sample estimates: ## p ## 0.03333333 No dóna el mateix p-valor que abans, perquè, com hem explicat, el nostre test correspon a correct=FALSE: prop.test(1, 30, p=0.1, alternative=&quot;two.sided&quot;, correct=FALSE) ## Warning in prop.test(1, 30, p = 0.1, alternative = &quot;two.sided&quot;, correct = ## FALSE): Chi-squared approximation may be incorrect ## ## 1-sample proportions test without continuity correction ## ## data: 1 out of 30, null probability 0.1 ## X-squared = 1.4815, df = 1, p-value = 0.2235 ## alternative hypothesis: true p is not equal to 0.1 ## 95 percent confidence interval: ## 0.00590859 0.16670391 ## sample estimates: ## p ## 0.03333333 Si llegiu amb cura la sortida del prop.test, veureu que no empra un estadístic de contrast que té una distribució normal, sinó un que té distribució \\(\\chi^2\\) amb 1 grau de llibertat: X-squared=..., df=1. El que passa és que R no empra l’estadístic \\(Z\\) que hem explicat, sinó el seu quadrat, \\(Z^2\\), que, si H0 és vertadera, té distribució \\(\\chi_1^2\\) perquè \\(Z\\) és normal estàndard. El missatge d’advertència que ens ha donat R en aquestes dues execucions de la funció prop.test ens diu que no se satisfan les condicions necessàries perquè el resultat d’aquest contrast sigui vàlid. Ja ho hem dit: 30 no és prou gran. De fet, R protesta si la mida de la mostra és inferior a 50, però amb 40 ja el podeu aplicar. Exemple 6.15 Quina és la potència del contrast realitzat a l’exemple anterior? Emprarem les funcions del paquet pwr per calcular-la; per a més informació sobre les funcions d’aquest paquet, consultau la secció corresponent del manual de R. Primer calculam la mida de l’efecte observat amb la funció ES.h aplicada a la proporció poblacional contrastada i a la proporció mostral: library(pwr) ES.h(0.1,0.03) ## [1] 0.2953351 I ara aplicam la funció pwr.p.test a la mida de l’efecte observat, h, la mida de la mostra, n, el nivell de significació, sig.level, i el tipus de contrast, alternative, i ens donarà la potència: pwr.p.test(h=0.3, n=30, sig.level=0.05, alternative=&quot;two.sided&quot;) ## ## proportion power calculation for binomial distribution (arcsine transformation) ## ## h = 0.3 ## n = 30 ## sig.level = 0.05 ## power = 0.3758563 ## alternative = two.sided Només un 37.6% de potència: en un estudi amb una mostra de mida 30, \\(\\alpha=0.05\\) i una mida de l’efecte com la que hem obtingut, només detectaríem que la hipòtesi alternativa és vertadera en 1 de cada 3 vegades que ho fos. Per tant, podria ser perfectament que la nostra acceptació de la hipòtesi nul·la hagi estat un fals negatiu. Què hagués passat si, en lloc d’1 esquerrà en una mostra de 30, haguéssim trobat 5 esquerrans en una mostra (aleatòria simple) de 150 estudiants, de manera que la proporció mostral fos la mateixa? prop.test(5, 150, p=0.1) ## ## 1-sample proportions test with continuity correction ## ## data: 5 out of 150, null probability 0.1 ## X-squared = 6.6852, df = 1, p-value = 0.009722 ## alternative hypothesis: true p is not equal to 0.1 ## 95 percent confidence interval: ## 0.01233588 0.08010876 ## sample estimates: ## p ## 0.03333333 Ara podríem rebutjar amb un nivell de significació del 5% que la proporció d’esquerrans a la UIB és del 10%. Quina ha estat la potència d’aquest test? pwr.p.test(h=0.3, n=150, sig.level=0.05, alternative=&quot;two.sided&quot;) ## ## proportion power calculation for binomial distribution (arcsine transformation) ## ## h = 0.3 ## n = 150 ## sig.level = 0.05 ## power = 0.9567605 ## alternative = two.sided Amb una mostra més gran, la potència és més gran, és més fàcil detectar que la hipòtesi alternativa sigui vertadera. Exemple 6.16 De quina mida hauríem d’haver pres la mostra per obtenir una potència del 90% amb \\(\\alpha=0.05\\) i esperant un efecte petit? Per determinar el valor d’un “efecte petit” entram cohen.ES(test=&quot;p&quot;,size=&quot;small&quot;) ## ## Conventional effect size from Cohen (1982) ## ## test = p ## size = small ## effect.size = 0.2 i ara, a l’argument pwr.p.test, en lloc d’entrar-hi la mida de la mostra n, hi entram la potència desitjada i ens donarà la mida necessària per assolir-la: pwr.p.test(h=0.2, power=0.9, sig.level=0.05, alternative=&quot;two.sided&quot;) ## ## proportion power calculation for binomial distribution (arcsine transformation) ## ## h = 0.2 ## n = 262.6855 ## sig.level = 0.05 ## power = 0.9 ## alternative = two.sided Ens caldria una mostra aleatòria simple de 263 estudiants. Com que en un contrast d’una proporció sempre hi podem emprar el test binomial exacte, no hi ha necessitat d’emprar-hi tests no paramètrics. 6.3.2 Contrastos per a 2 proporcions emprant mostres independents Siguin \\(X_1\\) i \\(X_2\\) dues variables aleatòries de Bernoulli de probabilitats poblacionals d’èxit \\(p_1\\) i \\(p_2\\), respectivament. Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2\\text{ o }p_1&gt; p_2\\text{ o }p_1&lt; p_2 \\end{array} \\right. \\] Suposem que, per realitzar aquest contrast, prenem una mostra aleatòria simple de cada variable, independents una de l’altra. Obtenim la taula de freqüències següent \\[ \\begin{array}{r|cc|c } &amp; X_1 &amp; X_2 &amp; \\textrm{Total} \\\\\\hline \\textrm{Èxits} &amp; n_{11} &amp; n_{12} &amp; E \\\\ \\textrm{Fracassos} &amp; n_{21} &amp; n_{22} &amp; F \\\\\\hline \\textrm{Total} &amp; n_{1} &amp; n_{2} \\end{array} \\] Aleshores tenim dues opcions: Realitzar un test \\(\\chi^2\\), que es basa en una aproximació a una normal i requereix algunes condicions sobre les dues mostres Realitzar un test de Fisher, que es pot emprar sempre però no dóna la informació exactament com la voldríem Test \\(\\chi^2\\) Suposem que les dues mostres són grans, per fixar idees \\(n_1,n_2\\geqslant 40\\), i que els nombres d’èxits i de fracassos a cada mostra no són molt petits, per fixar idees que tots dos són més grans o iguals que 5 a cada mostra. Siguin \\(\\widehat{p}_1\\) i \\(\\widehat{p}_2\\) les proporcions mostrals d’èxits a les mostres de \\(X_1\\) i \\(X_2\\), respectivament. En aquestes condicions, si la hipòtesi nul·la \\(H_0: p_1=p_2\\) és vertadera, l’estadístic de contrast \\[ Z=\\frac{\\widehat{p}_1 -\\widehat{p}_2}{ \\sqrt{\\frac{E}{n_1 +n_2}\\cdot \\Big(1-\\frac{E}{n_1 +n_2}\\Big)\\cdot \\Big(\\frac{1}{n_1}+\\frac{1}{n_2} \\Big)}} \\] (on \\(E=n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2\\) és el nombre total d’èxits a les dues mostres) té distribució aproximadament normal estàndard, la qual cosa es pot emprar com sempre per calcular p-valors i intervals de confiança. Aquest test està implementat en la funció de R prop.test(c(x1,x2), c(n1,n2), alternative=..., correct=..., conf.level=...,) on x1 i x2 són els nombres d’èxits a les dues mostres i n1, n2 les seves mides. Com al cas d’una proporció, la versió que hem explicat correspon a correct=FALSE, però és més recomanable emprar el valor per defecte de correct, que és TRUE i fa que s’hi apliqui una correcció de continuïtat. Aquest test s’anomena prop-test, o també test \\(\\chi^2\\) perquè és un cas particular d’un test \\(\\chi^2\\) que veurem al Tema 7. De fet, com en el cas d’una proporció, en la seva implementació en R no s’hi empra \\(Z\\) sinó \\(Z^2\\), que té distribució aproximadament \\(\\chi^2_1\\) si \\(p_1=p_2\\). Exemple 6.17 En un estudi es volgué saber si un determinat al·lel d’un gen és present o no amb la mateixa proporció entre els mallorquins i els menorquins. Es prengué una mostra d’ADN de 100 individus amb almenys tres generacions familiars a l’illa de Mallorca, i una altra de 50 individus amb almenys tres generacions familiars a l’illa de Menorca: les mostres es prengueren de manera independent. A la mostra mallorquina, 20 individus tengueren l’al·lel, i a la mostra menorquina, 12. La taula de freqüències és, doncs \\[ \\begin{array}{r|cc|c } &amp; \\textrm{Mallorca} &amp; \\textrm{Menorca} &amp; \\textrm{Total} \\\\\\hline \\textrm{Present} &amp; 20 &amp; 12 &amp; 32 \\\\ \\textrm{Absent} &amp; 80 &amp; 38 &amp; 118 \\\\\\hline \\textrm{Total} &amp; 100 &amp; 50 &amp; 150 \\end{array} \\] Aquesta mostra és estratificada. Us en recordau, de les mostres estratificades? Variables d’interès: \\(X_1\\): “Prenem un mallorquí amb 3 generacions familiars a l’illa i anotam si té aquest al·lel” \\(X_2\\): “Prenem un menorquí amb 3 generacions familiars a l’illa i anotam si té aquest al·lel” Totes dues són Bernoulli, amb proporcions poblacionals d’èxit \\(p_1\\) i \\(p_2\\), respectivament. Contrast: \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1\\neq p_2 \\end{array}\\right. \\] Estam en les condicions de poder emprar el test \\(\\chi^2\\), perquè les dues mostres i els seus nombres d’èxits (individus amb l’al·lel) i fracassos (individus sense l’al·lel) són prou grans. Estadístic de contrast: \\[ Z=\\frac{\\widehat{p}_1 -\\widehat{p}_2}{ \\sqrt{\\frac{E}{n_1+n_2}\\cdot \\Big(1-\\frac{E}{n_1 +n_2}\\Big)\\cdot\\Big(\\frac{1}{n_1}+\\frac{1}{n_2} \\Big)}} \\] que és aproximadament \\(N(0,1)\\) si H0 és vertadera. Valor de l’estadístic: Tenim que \\(\\widehat{p}_1=0.2\\), \\(\\widehat{p}_2=0.24\\), \\(n_1=100\\), \\(n_2=50\\), \\(E=32\\) i per tant \\[ z_0=\\frac{0.2 -0.24}{ \\sqrt{\\frac{32}{150}\\Big(1-\\frac{32}{150}\\Big)\\Big(\\frac{1}{100}+\\frac{1}{50} \\Big)}} =-0.5637 \\] p-valor: \\(2\\cdot P(Z\\geqslant |-0.5637|)=0.573\\) Conclusió: No hem trobat evidència estadísticament significativa que les proporcions de mallorquins i menorquins amb aquest al·lel siguin diferents (test \\(\\chi^2\\), p-valor 0.57). Amb R, entraríem prop.test(c(20,12), c(100,50), alternative=&quot;two.sided&quot;) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: c(20, 12) out of c(100, 50) ## X-squared = 0.12414, df = 1, p-value = 0.7246 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.1969858 0.1169858 ## sample estimates: ## prop 1 prop 2 ## 0.20 0.24 Bé, no exactament: com hem explicat, nosaltres hem fet la versió correct=FALSE. prop.test(c(20,12), c(100,50), alternative=&quot;two.sided&quot;, correct=FALSE) ## ## 2-sample test for equality of proportions without continuity ## correction ## ## data: c(20, 12) out of c(100, 50) ## X-squared = 0.3178, df = 1, p-value = 0.5729 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.1819858 0.1019858 ## sample estimates: ## prop 1 prop 2 ## 0.20 0.24 L’interval de confiança que dóna la funció prop.test en un contrast de dues proporcions és per a la diferència de les proporcions, \\(p_1-p_2\\). Test exacte de Fisher Si no se satisfan les condicions pel test \\(\\chi^2\\), sempre es pot aplicar el test exacte de Fisher, que es basa en la idea següent. Tenim la taula de freqüències \\[ \\begin{array}{r|cc|c } &amp; X_1 &amp; X_2 &amp; \\textrm{Total} \\\\\\hline \\textrm{Èxits} &amp; n_{11} &amp; n_{12} &amp; E \\\\ \\textrm{Fracassos} &amp; n_{21} &amp; n_{22} &amp; F \\\\\\hline \\textrm{Total} &amp; n_{1} &amp; n_{2} \\end{array} \\] Si \\(p_1=p_2\\), les dues variables \\(X_1\\) i \\(X_2\\) tenen la mateixa probabilitat d’èxit, i per tant les dues mostres podrien considerar-se com a dues mostres independents d’una mateixa variable \\(X\\). En aquest cas, podem considerar la unió de les dues mostres com una única mostra aleatòria d’aquesta variable \\(X\\). Llavors, la probabilitat d’obtenir \\(n_{11}\\) èxits dins la mostra de \\(X_1\\) és la de: Si en una bossa hi tenim \\(E\\) bolles “Èxit” i \\(F\\) bolles “Fracàs”, la probabilitat d’obtenir \\(n_{11}\\) bolles “Èxit” si en triam \\(n_{1}\\) de cop. Per tant, si \\(p_1=p_2\\), la variable \\(N_{11}\\) que dóna el valor de \\(n_{1,1}\\) (nombre d’èxits de \\(X_1\\) en una mostra amb els valors de \\(E,F,n_1\\) com la nostra) és hipergeomètrica \\(H(E,F,n_{1})\\). Podem emprar \\(N_{11}\\) com a estadístic de contrast i la distribució hipergeomètrica per calcular p-valors com en el test binomial. En particular, si \\(n_{1,1}\\) és el valor d’aquesta variable en la nostra mostra Si \\(H_1:p_1&gt;p_2\\), el p-valor és \\(P(N_{1,1}\\geqslant n_{1,1})\\), on, recordem, \\(N_{1,1}\\) és \\(H(E,F,n_{1})\\) Si \\(H_1:p_1&lt;p_2\\), el p-valor és \\(P(N_{1,1}\\leqslant n_{1,1})\\) Si \\(H_1:p_1=p_2\\), sigui \\(n_0\\) el valor esperat de la variable \\(N_{1,1}\\sim H(E,F,n_{1})\\), que és \\(n_1\\cdot E/(E+F)\\). Aleshores el p-valor és la probabilitat que la variable \\(N_{1,1}\\) prengui un valor tan o més diferent d’aquest \\(n_0\\) que \\(n_{1,1}\\): \\[ P(|N_{1,1}-n_0|\\geqslant |n_{1,1}-n_0|) \\] També es pot calcular com la probabilitat que \\(N_{1,1}\\) prengui un valor de probabilitat més petita o igual que la de \\(n_{1,1}\\): \\[ \\sum_{k\\ \\mathrm{tal\\ que}\\atop P(N_{1,1}=k)\\leqslant P(N_{1,1}=n_{1,1})} P(N_{1,1}=k) \\] Exemple 6.18 Per determinar si la Síndrome de Mort Sobtada del Nadó (SIDS) té component genètic, es consideren els casos de SIDS en parelles de bessons monozigòtics i dizigòtics. Diguem: \\(p_1\\): Proporció de parelles de bessons monozigòtics amb algun cas de SIDS on només un germà la sofrí \\(p_2\\): Proporció de parelles de bessons dizigòtics amb algun cas de SIDS on només un germà la sofrí Si la SIDS té component genètic, hauria de passar que \\(p_1&lt;p_2\\). En efecte, si aquesta síndrome té component genètic i en una parella de bessons un d’ells mor per SIDS, és més probable que l’altre bessó també la sofreixi si els bessons són monozigòtics que si són dizigòtics, ja que els genomes dels monozigòtics són pràcticament idèntics i els dels dizigòtics no. És a dir, és més probable que l’altre bessó també mori per SIDS si els bessons són monozigòtics que si són dizigòtics, o el que és el mateix, és MENYS probable que l’altre bessó NO mori per SIDS si els bessons són monozigòtics que si són dizigòtics. Per tant les variables d’interès són: \\(X_1\\): “Prenem una parella de bessons monozigòtics amb algun cas de SIDS, i anotam si només un germà la sofrí”, que és Bernoulli amb probabilitat d’èxit \\(p_1\\) \\(X_2\\): “Prenem una parella de bessons dizigòtics amb algun cas de SIDS, i anotam si només un germà la sofrí”, que és Bernoulli amb probabilitat d’èxit \\(p_2\\) i el contrast que volem realitzar és \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1&lt; p_2 \\end{array}\\right. \\] En un estudi s’obtingueren les dades següents: \\[ \\begin{array}{c} \\hphantom{Monozigotic} \\textbf{Tipus de bessons} \\\\ \\begin{array}{lr|cc|c} &amp; &amp; \\textrm{Monozigòtics} &amp; \\textrm{Dizigòtics} &amp; \\textrm{Total} \\\\ \\hline \\textbf{Casos} &amp; \\textrm{Un} &amp; 23 &amp; 35 &amp; 58\\\\ \\textbf{de SIDS} &amp; \\textrm{Dos} &amp; 1 &amp; 2 &amp; 3\\\\\\hline &amp; \\textrm{Total} &amp; 24 &amp; 37 &amp; \\end{array} \\end{array} \\] Emprarem el test de Fisher, ja que ni les mostres ni els nombres de “fracassos” no són prou grans per poder emprar el test \\(\\chi^2\\). p-valor: \\[ P(H(58,3,24)\\leqslant 23) =\\texttt{phyper(23,58,3,24)}=0.7841 \\] Conclusió: No hem obtingut evidència estadísticament significativa que la SIDS tengui un component genètic (test de Fisher, p-valor 0.78). Amb R el test de Fisher està implementat en la funció fisher.test(M,alternative=...,conf.level=...) on M és la matriu de freqüències de la mostra tal i com l’hem donada: fileres Èxits i Fracassos (en aquest ordre) i columnes \\(X_1\\) i \\(X_2\\). En el nostre exemple, entraríem M=matrix(c(23,35,1,2), nrow=2, byrow=TRUE) fisher.test(M,alternative=&quot;less&quot;) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: M ## p-value = 0.7841 ## alternative hypothesis: true odds ratio is less than 1 ## 95 percent confidence interval: ## 0.00000 39.73954 ## sample estimates: ## odds ratio ## 1.308589 Obtenim el mateix p-valor, i un interval de confiança del 95% que va de 0 a 39.7. Ja us podeu imaginar que aquest interval de confiança no pot ser per a \\(p_1-p_2\\). De fet, la funció fisher.test no compara \\(p_1\\) i \\(p_2\\), sinó les seves odds (oportunitats; en castellà, també momios) \\[ \\frac{p_1}{1-p_1}\\text{ i }\\frac{p_2}{1-p_2}. \\] L’interval de confiança que dóna és per al quocient d’aquestes odds: la seva odds ratio (OR, raó d’oportunitats; en castellà, també razón de momios). Figura 6.1: ‘Momios’ de moixets al British Museum (fotografia de M. Sánchez). Fem un incís sobre les odds. Les odds d’un esdeveniment \\(A\\) són \\[ \\text{Odds}(A)=\\frac{P(A)}{P(A^c)}=\\frac{P(A)}{1-P(A)} \\] i indiquen quantes vegades és més probable \\(A\\) que “no \\(A\\)”. Per exemple, que les odds de suspendre una assignatura siguin 2/3 significa que: \\(P(\\text{Suspendre})=\\frac{2}{3}P(\\text{Aprovar})\\). Per cada estudiant que aprova, hi ha 2/3 d’estudiant que suspenen. Per cada 3 estudiants que aproven, n’hi ha 2 que suspenen. De cada 5 estudiants, 3 aproven i 2 suspenen. 2 de cada 5 estudiants suspenen La probabilitat de suspendre és d’un 40%. Més exemples: Si \\(P(A)=0.3\\), \\(\\text{Odds}(A)=0.3/0.7=0.43\\) Si \\(P(A)=0\\), \\(\\text{Odds}(A)=0\\) Si \\(P(A)=0.5\\), \\(\\text{Odds}(A)=1\\) Si \\(P(A)=1\\), \\(\\text{Odds}(A)=\\infty\\) Fixau-vos que si coneixeu \\(\\text{Odds}(A)\\), podeu aïllar \\(P(A)\\). Per exemple si \\(\\text{Odds}(A)=0.6\\) \\[ \\begin{array}{l} 0.6=\\dfrac{P(A)}{1-P(A)}\\Rightarrow 0.6-0.6P(A)=P(A)\\\\ \\qquad \\Rightarrow 0.6=1.6P(A)\\Rightarrow P(A)=\\dfrac{0.6}{1.6}=0.375 \\end{array} \\] En general \\[ P(A)=\\dfrac{\\text{Odds}(A)}{1+\\text{Odds}(A)} \\] Observau que la funció \\[ y=\\frac{x}{1+x} \\] és creixent en \\(x\\): Figura 6.2: Gràfica de y=x/(1+x). Per tant \\[ \\text{Odds}(A)&gt;\\text{Odds}(B)\\Longleftrightarrow P(A)&gt;P(B) \\] És a dir, \\(A\\) és més probable que \\(B\\) si, i només si, les odds d’\\(A\\) són més grans que les de \\(B\\). I en particular, també, \\[ \\text{Odds}(A)=\\text{Odds}(B)\\Longleftrightarrow P(A)=P(B) \\] Així doncs, comparant les probabilitats o les odds de dos esdeveniments obteniu la mateixa informació sobre quin és més probable. La odds ratio de \\(A\\) i \\(B\\) és \\[ \\text{OR}(A,B)=\\frac{\\text{Odds}(A)}{\\text{Odds}(B)} \\] És a dir, \\(\\text{OR}(A,B)\\) ens diu quantes vegades són més grans (o més petites) les odds de \\(A\\) que les de \\(B\\). El seu valor és difícil d’interpretar en termes de probabilitats excepte pel que fa a la seva relació amb 1: \\(\\text{OR}(A,B)=1\\Longleftrightarrow \\text{Odds}(A)=\\text{Odds}(B) \\Longleftrightarrow P(A)=P(B)\\) \\(\\text{OR}(A,B)&gt;1\\Longleftrightarrow \\text{Odds}(A)&gt;\\text{Odds}(B) \\Longleftrightarrow P(A)&gt;P(B)\\) \\(\\text{OR}(A,B)&lt;1\\Longleftrightarrow \\text{Odds}(A)&lt;\\text{Odds}(B) \\Longleftrightarrow P(A)&lt;P(B)\\) Però imaginem que, per exemple, la odds ratio de \\(A\\) i \\(B\\) és \\[ \\text{OR}(A,B)=\\frac{\\text{Odds}(A)}{\\text{Odds}(B)}=1.5 \\] Aleshores \\(\\text{Odds}(A)=1.5\\cdot \\text{Odds}(B)\\): Com que en particular \\(\\text{Odds}(A)&gt; \\text{Odds}(B)\\), podem concloure que \\(P(A)&gt;P(B)\\) Però el fet que \\(\\text{Odds}(A)=1.5\\cdot \\text{Odds}(B)\\) no implica que \\(P(A)=1.5\\cdot P(B)\\). De fet, aquest valor de \\(OR(A,B)\\) no implica cap relació lineal entre \\(P(A)\\) i \\(P(B)\\), com comprovareu a l’exercici següent. Què valen les odds de treure 3 cares en 3 llançaments d’una moneda equilibrada? Si un esdeveniment passa 2 pics de cada 10 que pot passar, què valen les seves odds? Si les odds d’\\(A\\) són 1/2, què val \\(P(A)\\)? Si \\(\\text{OR}(A,B)=1.5\\) i \\(P(A)=1/2\\), què val \\(P(B)\\)? Sí \\(\\text{OR}(A,B)=1.5\\) i \\(P(A)=3/4\\), què val \\(P(B)\\)? El fet que l’odds ratio sigui mala d’interpretar és el motiu pel qual sempre que poguem evitarem el test exacte de Fisher. Hem dit que \\[ \\text{OR}(A,B)=1\\Longleftrightarrow \\text{Odds}(A)=\\text{Odds}(B) \\Longleftrightarrow P(A)=P(B) \\] Per tant, si l’interval de confiança per a la odds ratio que dóna la funció fisher.test conté l’1, no podem rebutjar que les dues proporcions poblacionals d’èxit siguin iguals. Exemple 6.19 Si realitzam el contrast de l’Exemple 6.17 amb el test \\(\\chi^2\\), obtenim prop.test(c(20,12),c(100,50),alternative=&quot;two.sided&quot;,correct=FALSE) ## ## 2-sample test for equality of proportions without continuity ## correction ## ## data: c(20, 12) out of c(100, 50) ## X-squared = 0.3178, df = 1, p-value = 0.5729 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.1819858 0.1019858 ## sample estimates: ## prop 1 prop 2 ## 0.20 0.24 El p-valor 0.5729 no ens permet rebutjar que les proporcions de mallorquins i menorquins amb l’al·lel objecte d’estudi siguin iguals L’IC 95% per a la diferència de proporcions va de -0.18 a 0.1: com que conté el 0, no podem rebutjar amb aquest nivell de confiança que aquestes proporcions siguin iguals La diferència de proporcions mostrals \\(p_1-p_2\\) ha estat \\(0.2-0.24=-0.04\\): la proporció de menorquins amb l’al·lel a la nostra mostra ha estat 4 punts percentuals més gran que la dels mallorquins Si ara l’efectuam amb el test de Fisher: M.A=matrix(c(20,12,80,38), nrow=2, byrow=TRUE) fisher.test(M.A,alternative=&quot;two.sided&quot;) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: M.A ## p-value = 0.673 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.3287521 1.9742955 ## sample estimates: ## odds ratio ## 0.7929466 El p-valor 0.673 no ens permet rebutjar que les odds de tenir aquest al·lel entre els mallorquins i els menorquins siguin iguals; com que igualtat d’odds és equivalent a igualtat de probabilitats, no podem rebutjar que els mallorquins i menorquins tenguin la mateixa probabilitat de tenir l’al·lel objecte d’estudi Vegem que coincideix amb el p-valor del contrast bilateral de Fisher que hem explicat. Recordem la taula de dades: \\[ \\begin{array}{r|cc|c } &amp; \\textrm{Mallorca} &amp; \\textrm{Menorca} &amp; \\textrm{Total} \\\\\\hline \\textrm{Present} &amp; 20 &amp; 12 &amp; 32 \\\\ \\textrm{Absent} &amp; 80 &amp; 38 &amp; 118 \\\\\\hline \\textrm{Total} &amp; 100 &amp; 50 &amp; 150 \\end{array} \\] Si la hipòtesi nul·la és vertadera, el nombre \\(N_{1,1}\\) de mallorquins amb l’al·lel en una mostra com la nostra té distribució hipergeomètrica \\(H(32,118,100)\\) i per tant valor esperat \\(100\\cdot 32/150=21.333\\). Com que a la nostra mostra \\(n_{1,1}=20\\), el p-valor és \\[ \\begin{array}{l} P(|N_{1,1}-21.333|\\geqslant |20-21.333|)=P(|N_{1,1}-21.333|\\geqslant 1.333)\\\\ \\qquad =P(N_{1,1}\\leqslant 20\\text{ o }N_{1,1}\\geqslant 22.666)\\\\ \\qquad= P(N_{1,1}\\leqslant 20\\text{ o }N_{1,1}\\geqslant 23)\\qquad \\text{(perquè $N_{1,1}\\in \\mathbb{N}$)}\\\\ \\qquad= P(N_{1,1}\\leqslant 20)+P(N_{1,1}\\geqslant 23)\\\\ \\qquad= \\texttt{phyper(20,32,118,100)+(1-phyper(22,32,118,100))}\\\\ \\qquad=0.673 \\end{array} \\] L’IC 95% per a la odds ratio (per al quocient de les odds) va de 0.33 a 1.97: com que conté l’1, no podem rebutjar amb aquest nivell de confiança que la odds ratio sigui 1. Per tant, no podem rebutjar que les odds siguin iguals, o el que és equivalent, que les proporcions de mallorquins i menorquins amb l’al·lel siguin iguals El quocient d’odds mostrals (la odds ratio mostral) ha estat 0.79: a la nostra mostra, les odds que un mallorquí tengués l’al·lel han estat 0.79 vegades (un 21% més petites que) les d’un menorquí; però això no ens dóna cap relació lineal entre les proporcions mostrals de mallorquins i menorquins amb l’al·lel. 6.3.3 Contrastos per a 2 proporcions emprant mostres aparellades Siguin una altra vegada \\(X_1\\) i \\(X_2\\) dues variables aleatòries de Bernoulli amb probabilitats poblacionals d’èxit \\(p_1\\) i \\(p_2\\), respectivament. Seguim volent realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2\\text{ o }p_1&gt; p_2\\text{ o }p_1&lt; p_2 \\end{array} \\right. \\] però ara mesuram \\(X_1\\) i \\(X_2\\) sobre els subjectes d’una mateixa mostra aleatòria simple de mida \\(n\\), o sobre els subjectes de dues mostres aleatòries simples aparellades de mida \\(n\\). Suposem que tenim els resultats en una taula \\[ \\begin{array}{c} \\hphantom{Variablesssss} \\text{Variable $X_2$}\\\\ \\begin{array}{r|cc} \\text{Variable $X_1$} &amp;\\text{Èxit} &amp; \\text{Fracàs} \\\\ \\hline \\text{Èxit} &amp; a &amp; b \\\\ \\text{Fracàs} &amp; c &amp; d\\\\ \\end{array} \\end{array} \\] on cada entrada representa el nombre de subjectes (o parelles) que satisfan les condicions de la filera i la columna. En aquest cas tenim dues opcions: Realitzar un test de McNemar, que només serveix per a contrastos bilaterals i a més requereix algunes condicions sobre les dues mostres Realitzar un test binomial, que es pot emprar sempre però no dóna la informació exactament com la voldríem Test de McNemar Quan el test és bilateral, si el nombre de casos discordants (\\(b+c\\) en la taula anterior) és prou gran (posem, més gran o igual que 25), es pot emprar el test de McNemar, que empra l’estadístic de contrast \\[ Z^2=\\frac{(b-c)^2}{b+c} \\] el qual, si se satisfan les condicions esmentades, segueix aproximadament una distribució \\(\\chi^2_1\\) si H0 és vertadera. En aquest test se rebutja la hipòtesi nul·la si \\(b\\) i \\(c\\) són prou diferents i per tant, malgrat ser un contrast bilateral, es pren com a p-valor \\(P(Z^2\\geqslant Z_0^2)\\), on \\(Z_0^2\\) és el valor de l’estadístic a la nostra mostra. Aquest test està implementat en R en la funció mcnemar.test, que s’aplica a la taula de freqüències absolutes de la mostra tal i com l’hem donada. Exemple 6.20 En un assaig clínic es volgué comparar l’efectivitat d’un fàrmac nou contra la migranya amb la d’un placebo. Es prengué una mostra de 500 persones afectades per migranya. A cada una, a l’atzar, se li administrà el fàrmac o el placebo. Se’ls demanà si havien notat alleujament del dolor. Al cap d’un temps, als mateixos individus se’ls subministrà l’altre tractament (fàrmac als que havien rebut placebo, placebo als que havien rebut fàrmac) i se’ls tornà a demanar si havien notat o no millora. Els resultats varen ser: \\[ \\begin{array}{c} \\hphantom{Variables} \\text{Placebo}\\\\ \\begin{array}{r|cc} \\text{Fàrmac} &amp;\\text{Sí} &amp; \\text{No} \\\\ \\hline \\text{Sí} &amp; 150 &amp; 41 \\\\ \\text{No} &amp; 19 &amp; 285\\\\ \\end{array} \\end{array} \\] on “Sí” indica que el malalt va dir que sí que havia notat alleujament del dolor. Variables d’interès: \\(X_1\\): “Prenem un malalt, li administram el fàrmac i anotam si diu que ha notat millora del dolor”. És Bernoulli amb proporció poblacional d’èxit \\(p_1\\) \\(X_2\\): “Prenem un malalt, li administram el placebo i anotam si diu que ha notat millora del dolor”. És Bernoulli amb proporció poblacional d’èxit \\(p_2\\) Contrast: Com que la mostra i el nombre de casos discordants són prou grans, podem emprar el test de McNemar, però aleshores el contrast ha de ser bilateral \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1\\neq p_2 \\end{array}\\right. \\] Estadístic de contrast: \\[ Z^2=\\frac{(b-c)^2}{b+c} \\] que segueix una distribució aproximadament \\(\\chi_1^2\\) si \\(p_1=p_2\\). Valor sobre la nostra mostra: \\(Z_0^2=(41-19)^2/(41+19)=8.067\\) p-valor: \\(P(Z^2\\geqslant 8.067)=\\texttt{1-pchisq(8.067,1)}=0.0045\\) Conclusió: Hem obtingut evidència estadísticament significativa que la taxa d’efectivitat del placebo i del fàrmac són diferents (test de McNemar, p-valor 0.0045). I arribats aquí, com que la taxa d’efectivitat del fàrmac ha estat superior a la del placebo (191/500 contra 169/500), faríem la trampa de concloure que la diferència entre aquestes taxes d’efectivitat és perquè el fàrmac es més efectiu. Amb R, entraríem Dades.M=matrix(c(150,41,19,285), nrow=2, byrow=TRUE) mcnemar.test(Dades.M) ## ## McNemar&#39;s Chi-squared test with continuity correction ## ## data: Dades.M ## McNemar&#39;s chi-squared = 7.35, df = 1, p-value = 0.006706 Ups! No ha donat el mateix estadístic ni el mateix p-valor. Això passa perquè R també aplica per defecte una correcció de continuïtat al test de McNemar. El que nosaltres hem explicat correspon a mcnemar.test(Dades.M,correct=FALSE) ## ## McNemar&#39;s Chi-squared test ## ## data: Dades.M ## McNemar&#39;s chi-squared = 8.0667, df = 1, p-value = 0.004509 Test binomial exacte Si no podeu emprar el test de McNemar, sempre podeu emprar el test binomial exacte següent. Considerau la taula de probabilitats poblacionals \\[ \\begin{array}{c} \\hphantom{Variablesssss} \\text{Variable $X_2$}\\\\ \\begin{array}{r|cc} \\text{Variable $X_1$} &amp;\\text{Èxit} &amp; \\text{Fracàs} \\\\ \\hline \\text{Èxit} &amp; p_{11} &amp; p_{10} \\\\ \\text{Fracàs} &amp; p_{01} &amp; p_{00} \\end{array} \\end{array} \\] Llavors \\[ p_1=p_{11}+p_{10},\\ p_2=p_{11}+p_{01} \\] i per tant \\[ \\begin{array}{l} \\displaystyle p_1=p_2\\Longleftrightarrow p_{10}=p_{01}\\Longleftrightarrow \\frac{p_{10}}{p_{10}+p_{01}}=0.5\\\\[1ex] \\displaystyle p_1\\neq p_2\\Longleftrightarrow p_{10}\\neq p_{01}\\Longleftrightarrow \\frac{p_{10}}{p_{10}+p_{01}}\\neq 0.5\\\\[1ex] \\displaystyle p_1&lt; p_2\\Longleftrightarrow p_{10}&lt; p_{01}\\Longleftrightarrow \\frac{p_{10}}{p_{10}+p_{01}}&lt;0.5\\\\[1ex] \\displaystyle p_1&gt; p_2\\Longleftrightarrow p_{10}&gt; p_{01}\\Longleftrightarrow \\frac{p_{10}}{p_{10}+p_{01}}&gt;0.5\\\\[1ex] \\end{array} \\] Això permet traduir un contrast sobre \\(p_1\\) i \\(p_2\\) en el mateix contrast sobre \\(p_{01}\\) i \\(p_{10}\\), i al final en un contrast sobre \\[ \\frac{p_{10}}{p_{10}+p_{01}}, \\] que és la proporció poblacional de parelles (Èxit,Fracàs) dins la població de casos discordants. Per exemple: \\[ \\begin{array}{rcl} \\left\\{\\begin{array}{l} H_0: p_1=p_2\\\\ H_1: p_1&lt; p_2 \\end{array}\\right. &amp; \\Longleftrightarrow &amp; \\left\\{\\begin{array}{l} H_0: p_{10}=p_{01}\\\\ H_1: p_{10}&lt;p_{01} \\end{array}\\right.\\\\[2ex] &amp; \\Longleftrightarrow &amp; \\left\\{\\begin{array}{l} H_0: \\dfrac{p_{10}}{p_{10}+p_{01}}=0.5\\\\ H_1: \\dfrac{p_{10}}{p_{10}+p_{01}}&lt;0.5 \\end{array}\\right. \\end{array} \\] Així doncs, el contrast \\[ \\left\\{\\begin{array}{l} H_0: p_1=p_2\\\\ H_1: p_1&lt; p_2\\text{ o }p_1&gt; p_2\\text{ o }p_1\\neq p_2 \\end{array}\\right. \\] es tradueix en el contrast \\[ \\left\\{\\begin{array}{l} H_0: \\dfrac{p_{10}}{p_{10}+p_{01}}=0.5\\\\[3ex] H_1: \\dfrac{p_{10}}{p_{10}+p_{01}}&lt;0.5\\text{ o }\\dfrac{p_{10}}{p_{10}+p_{01}}&gt;0.5\\text{ o }\\dfrac{p_{10}}{p_{10}+p_{01}}\\neq 0.5 \\end{array}\\right. \\] I aquest darrer contrast el podem efectuar amb un test binomial prenent: Com a mostra els casos discordants, de mida \\(b+c\\) Com a èxits els subjectes amb Èxit a \\(X_1\\) i Fracàs a \\(X_2\\): a la mostra n’hi ha \\(b\\) Exemple 6.21 Tornem a la situació de l’Exemple 6.20. Ara volem fer el contrast que realment ens interessa, que és si la taxa d’efectivitat del fàrmac és més gran que la del placebo: \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1&gt;p_2 \\end{array}\\right. \\] Dient \\(p=p_{10}/(p_{10}+p_{01})\\), el traduïm en \\[ \\left\\{\\begin{array}{l} H_0:p=0.5\\\\ H_1:p&gt; 0.5 \\end{array}\\right. \\] Les dades eren \\[ \\begin{array}{c} \\hphantom{Variables} \\text{Placebo}\\\\ \\begin{array}{r|cc} \\text{Fàrmac} &amp;\\text{Sí} &amp; \\text{No} \\\\ \\hline \\text{Sí} &amp; 150 &amp; 41 \\\\ \\text{No} &amp; 19 &amp; 285 \\end{array} \\end{array} \\] I per tant al contrast sobre \\(p\\) emprarem la mostra de 60 casos discordants on 41 són Èxits. Ho fen directament amb R: binom.test(41, 60, p=0.5, alternative=&quot;greater&quot;) ## ## Exact binomial test ## ## data: 41 and 60 ## number of successes = 41, number of trials = 60, p-value = 0.003109 ## alternative hypothesis: true probability of success is greater than 0.5 ## 95 percent confidence interval: ## 0.5708296 1.0000000 ## sample estimates: ## probability of success ## 0.6833333 Conclusió: Hem obtingut evidència estadísticament significativa que el fàrmac té una taxa d’efectivitat més gran que el placebo (test binomial, p-valor 0.003). El problema d’aquest test és que l’interval de confiança que dóna és per a \\(p_{10}/(p_{10}+p_{01})\\) i encara és més mal d’interpretar que el de l’odds ratio al test de Fisher. 6.4 Test de la lliçó 6 (1) En un contrast bilateral de dues mitjanes emprant dues mostres independents grans i utilitzant un test t (marca totes les afirmacions vertaderes): La hipòtesi nul·la és que les mitjanes mostrals són iguals. La hipòtesi nul·la és que les mitjanes mostrals no són significativament diferents. La hipòtesi nul·la és que les mitjanes poblacionals són iguals. La hipòtesi nul·la és que les mitjanes poblacionals són diferents. Les variàncies de les poblacions han de ser iguals. Les mides de les mostres han de ser iguals. Totes les altres respostes són incorrectes. (2) En analitzar els resultats d’un experiment on es comparaven dos tractaments, es va concloure que l’efectivitat dels dos tractaments estudiats és diferent, amb un p-valor de 0.034. Què significa aquest valor? Que hi ha un 3.4% de probabilitats que, si es repeteix l’estudi, no es trobin diferències significatives. Que hi ha un 3.4% de probabilitats que els tractaments estudiats tenguin la mateixa efectivitat. Que hi ha un 3.4% de diferència, o més, en l’efectivitat dels tractaments estudiats. Que hi ha hagut un 3.4% de diferència, o més, en l’efectivitat dels tractaments en les nostres mostres. Que hi ha un 3.4% de probabilitats que la diferència observada entre les efectivitats, o una encara més gran, s’hagi degut a l’atzar. (3) Sobre l’error de tipus I quan es contrasta la diferència de dues mitjanes (marca totes les respostes correctes): 1 menys la seva probabilitat és igual a la potència del contrast. 1 menys la seva probabilitat és igual al nivell de confiança del contrast. Porta a concloure que hi ha una diferència, quan en realitat no n’hi ha. Porta a concloure que no hi ha cap diferència, quan en realitat sí que n’hi ha. Significa que la hipòtesi alternativa és falsa. Totes les altres respostes són incorrectes. (4) En un experiment, a una sèrie de ratolins modificats genèticament se’ls tractà amb un compost per estudiar si, en un període de temps després d’administrar-lo, el nivell d’un cert metabòlit en sang havia disminuït. S’accepta que la distribució de la quantitat d’aquest metabòlit en sang és normal. Quina és la prova estadística més adient per realitzar el contrast? Test t per a mostres aparellades. Test t per a mostres independents. Test de Wilcoxon. Test de Mann-Whitney. Test exacte de Fisher. (5) La prova per comparar dues mitjanes emprant mostres aparellades basada en la t de Student (marcau les respostes correctes): Només es pot emprar sobre mostres grans. No es pot emprar si les variables poblacionals són normals i les mostres grans. També es pot emprar amb mostres independents. Només es pot emprar si les poblacions tenen distribucions normals. Depèn de si la variàncies de les dues mostres són iguals o diferents. Totes les altres respostes són incorrectes. (6) Quina o quines de les condicions següents són tals que elles totes soles ja permeten emprar un test t per comparar dues mitjanes? Si el nombre d’observacions és el mateix a les dues mostres. Si les observacions provenen de distribucions aproximadament normals. Si les desviacions estàndard són aproximadament les mateixes en les dues mostres. Si les mitjanes són aproximadament iguals en les dues mostres. Si almenys una de les dues mostres és molt gran. Totes les altres respostes són incorrectes. (7) En un experiment, una de les mesures que es va estudiar va ser un cert temps de reacció que és molt asimètric a la dreta. Per contrastar la diferència entre les mitjanes d’aquest temps de reacció sota dues condicions diferents amb dues mostres independents, els enfocaments possibles inclouen (marca totes les respostes correctes): Un test t si les dues mostres varen ser més grans que 100 cada una. Un test t si alguna de les dues mostres va ser més gran que 100. Com que es tracta d’un contrast de mitjanes amb mostres independents, podem emprar sempre un test t. Com que les mesures d’aquest temps de reacció segueixen una llei normal, podem emprar un test t encara que les mostres siguin petites. Un test no paramètric, essent conscients que en aquest cas compararem medianes i no mitjanes. La correlació entre els temps. Totes les altres respostes són incorrectes. (8) En un test t de comparació de mitjanes planejam emprar dues mostres independents. Entre les dues mostres, observarem 500 subjectes. El fet que les distribucions poblacionals es desviïn molt d’una normal pot afectar seriosament la validesa del contrast (marca totes les respostes correctes): Si les mides de les mostres no són iguals, però la diferència és inferior al 5%. Si una de les mostres és aproximadament 4 vegades més gran que l’altra. Si una de les mostres és aproximadament 25 vegades més gran que l’altra. Si les mides de les mostres són iguals, però les distribucions poblacionals són molt diferents. Si les variàncies són molt diferents. Totes les altres respostes són incorrectes. (9) Es pretén comparar l’eficàcia de dos mètodes d’encalentiment previs a un determinat exercici físic. Es va observar un 5% d’estrabades amb un mètode i un 3% amb l’altre, sent aquesta diferència estadísticament significativa (p-valor=0.045). Quina és la interpretació correcta d’aquest resultat? Si els dos mètodes tinguessin la mateixa freqüència d’estrabades, la probabilitat de trobar una diferència igual o major a l’observada és 0.045. La probabilitat que els dos mètodes tinguin la mateixa freqüència d’estrabades és de 0.045. Si els dos mètodes tinguessin la mateixa freqüència d’estrabades, la probabilitat d’observar un 5% o més d’estrabades en el que en va tenir una freqüència més gran és 0.045. Si els dos mètodes tinguessin diferents freqüències d’estrabades, la probabilitat de trobar una diferència igual o més petita que l’observada és 0.955. La probabilitat que els dos mètodes tinguin la mateixa freqüència d’estrabades és de 0.955. (10) En un estudi que compara l’eficàcia de dos fàrmacs mitjançant un test t no s’observa una diferència estadísticament significativa entre ells. Si en realitat aquests tractaments tinguessin eficàcies diferents, tots els factors següents podrien explicar per què s’ha obtingut un resultat fals negatiu, EXCEPTE un. Quin? Error de tipus I Error de tipus II Les variables no tenen distribució normal Les mostres no són suficientment grans No s’ha tingut en compte si les mostres són independents o aparellades (11) En un estudi es va prendre un grup de 100 plantes afectades d’una certa infestació. D’aquestes plantes, se’n triaren 50 a l’atzar i se les administrà un tractament. Al cap de 15 dies es compararen algunes dades fisiològiques dels dos grups de plantes (les tractades i les sense tractar). Un dels nivells que es van mesurar en aquest estudi té una distribució asimètrica. Per contrastar si la mitjana d’aquest nivell és més gran en les plantes tractades que en les plantes sense tractar, es va emprar un test t. Quina de les afirmacions següents és correcta en aquesta situació? Per emprar un test t, primer s’havia de contrastar la igualtat de variàncies: si les variàncies poblacionals són diferents, no es podia emprar un test t Per emprar un test t, primer s’havien de calcular les variàncies de les dues mostres: si aquestes variàncies són diferents, no es podia emprar un test t Emprar un test t va ser correcte, perquè les dues mostres són prou grans. Emprar un test t va ser correcte, perquè les variables poblacionals són normals. Emprar un test t va ser incorrecte, perquè les variables poblacionals no són normals. (12) En un estudi es va prendre un grup de 100 plantes afectades d’una certa infestació. Es mesurà la quantitat de nitrogen al terra al voltant de les seves arrels. A continuació, s’administrà a totes un tractament contra aquesta infestació, i al cap de 15 dies es tornà a mesurar la quantitat de nitrogen al terra al voltant de les seves arrels. Aquestes quantitats de nitrogen, tant abans com després, segueixen distribucions normals. Per contrastar si els continguts mitjans de nitrogens abans i després del tractament són iguals o diferents es va emprar un test t. Quina de les afirmacions següents és la correcta en aquesta situació? Com que les dues mostres són independents, el tipus concret de test t (l’estadístic concret i el seu nombre de graus de llibertat) que s’havia de fer servir depèn de si les mostres preses abans i després del tractament tenen la mateixa variància Com que les dues mostres són independents, el tipus concret de test t (l’estadístic concret i el seu nombre de graus de llibertat) que s’havia de fer servir depèn de si les quantitats de nitrogen al terra al voltant de les arrels abans i després del tractament tenen la mateixa variància Com que les dues mostres són independents, el tipus concret de test t (l’estadístic concret i el seu nombre de graus de llibertat) és únic, només depèn de la mida de les mostres. Com que les dues mostres són aparellades, el tipus concret de test t (l’estadístic concret i el seu nombre de graus de llibertat) que s’havia de fer servir depèn de si les mostres preses abans i després del tractament tenen la mateixa variància Com que les dues mostres són aparellades, el tipus concret de test t (l’estadístic concret i el seu nombre de graus de llibertat) que s’havia de fer servir depèn de si les quantitats de nitrogen al terra al voltant de les arrels abans i després del tractament tenen la mateixa variància Com que les dues mostres són aparellades, el tipus concret de test t (l’estadístic concret i el seu nombre de graus de llibertat) és únic, només depèn de la mida de les mostres. Com que el contrast és bilateral, el tipus concret de test t (l’estadístic concret i el seu nombre de graus de llibertat) és únic, només depèn de la mida de les mostres. (13) Hem efectuat un test t de dues mitjanes, amb hipòtesi alternativa \\(\\mu_1\\neq \\mu_2\\). És possible que hàgim obtingut un interval de confiança del contrast del 95% [2.1,3.2] i un p-valor 0.13? Sí No (14) Quina o quines de les afirmacions següents sobre el test F són correctes? Només serveix per a contrastos bilaterals de dues variàncies o dues desviacions típiques Només es pot emprar si les dues variables aleatòries són normals Només es pot emprar si les dues variables aleatòries són normals o si les dues mostres són grans Només es pot emprar si les dues variables aleatòries són normals i les dues mostres són de la mateixa mida Si se contrasten dues variàncies, l’estadístic de contrast és el quocient de variàncies mostrals, però si se contrasten dues desviacions típiques, l’estadístic de contrast és el quocient de les desviacions típiques mostrals S’empra en contrastos on la hipòtesi nul·la és que dues variàncies poblacionals, o dues desviacions típiques poblacionals, són iguals S’empra en contrastos on la hipòtesi nul·la és que dues variàncies mostrals, o dues desviacions típiques mostrals, són iguals (15) Vull comparar els nivells mitjans de LDL en pacients hipertensos i normotensos. Aquests nivells no segueixen una distribució normal. Per realitzar el contrast prenc una mostra de 40 individus normotensos i una altra de 20 individus hipertensos, a l’atzar i independents una de l’altra. Quina de les proves següents és la més adient per realitzar el contrast de les dues mitjanes? Un test t Un test de Wilcoxon Un test de Mann-Whitney Un test F Un test de Fligner (16) Vull comparar els nivells mitjans de LDL en pacients hipertensos i normotensos. Aquests nivells no segueixen una distribució normal. Per realitzar el contrast prenc una mostra de 20 individus hipertensos i una altra de 20 individus normotensos, a l’atzar però de manera que cada individu hipertens quedi aparellat amb un individu normotens per edat i sexe. Quina de les proves següents és la més adient per realitzar el contrast de les dues mitjanes? Un test t Un test de Wilcoxon Un test de Mann-Whitney Un test F Un test de Fligner (17) Quina o quines de les afirmacions següents sobre el test de Wilcoxon d’una mitjana o dues mitjanes són vertaderes? Tot i que el fem servir per contrastar el valor de mitjanes, en realitat compara medianes Només el podem fer servir si les variables involucrades no són normals i les mostres no són totes dues grans Per calcular els p-valors fem servir una distribució t de Student amb un nombre de graus de llibertat diferent del test t tradicional En un contrast de dues mitjanes, es pot fer servir amb mostres independents sempre que tenguin la mateixa mida Si les variables són normals, no es pot emprar Si les variables són normals, es pot emprar, però és millor emprar un test t (18) Suposem que hem realitzat un contrast \\(H_0: \\mu=\\mu_0\\) contra \\(H_1: \\mu\\neq \\mu_0\\) amb \\(\\alpha=0.05\\). amb un test t sobre una determinada mostra. Què li passaria a l’interval de confiança del contrast obtingut amb aquesta mateixa mostra si augmentàssim el nivell de significació a \\(\\alpha=0.1\\)? Seria més ample Seria més estret Seria exactament igual, perquè no hem canviat de mostra Pot passar qualsevol cosa (19) Hem efectuat un test t d’una mitjana, amb hipòtesi alternativa \\(\\mu\\neq 2\\). És possible que hàgim obtingut un IC 95% [0.5,1.8] i un p-valor 0.15? Sí No (20) Hem efectuat un test t d’una mitjana, amb hipòtesi alternativa \\(\\mu\\neq 2\\). És possible que hàgim obtingut un IC 95% [0.5,3.8] i un p-valor 0.15? Sí No (21) Hem efectuat un test t d’una mitjana, amb hipòtesi alternativa \\(\\mu&lt;2\\). És possible que hàgim obtingut un IC 95% [0.5,3.8] i un p-valor 0.15? Sí No (22) Per a què serveix un q-q-plot? Marca una sola resposta. Per estimar la q d’una mostra Per visualitzar si una mostra segueix una distribució donada Per visualitzar si els punts d’una mostra tendeixen a estar sobre una recta Per visualitzar si dues mostres són aparellades o independents (23) Quan podem emprar un test \\(\\chi^2\\) per contrastar una variància? Marca una sola resposta. Només si la variable poblacional és normal Només si la variància poblacional és normal o si la mostra és gran Només si la variància poblacional és normal i la mostra petita o si la mostra és gran Només si la variable poblacional és normal i coneixem la seva mitjana (23) Hem efectuat un test bilateral de Fisher de dues proporcions. És possible que hàgim obtingut un IC 95% [0.5,3.8] i un p-valor 0.15? Sí No (24) Hem efectuat un test bilateral de Fisher de dues proporcions. És possible que hàgim obtingut un IC 95% [1.5,3.8] i un p-valor 0.15? Sí No (25) Llegim en un article que les odds de sofrir la COVID-19 si se viu en una comunitat urbana dispersa són 0.8 vegades les odds de sofrir la COVID-19 si se viu en una ciutat. Què implica aquesta afirmació? Si vius en una comunitat urbana dispersa, tens un 20% manco de probabilitat de sofrir la COVID-19 que si vius en una ciutat Si vius en una comunitat urbana dispersa, tens un 20% més de probabilitat de sofrir la COVID-19 que si vius en una ciutat Si vius en una comunitat urbana dispersa, tens menys probabilitat de sofrir la COVID-19 que si vius en una ciutat, però no podem dir quanta menys Si vius en una comunitat urbana dispersa, tens més probabilitat de sofrir la COVID-19 que si vius en una ciutat, però no podem dir quanta més "],
["chap-bondat.html", "Tema 7 Contrastos de bondat d’ajust 7.1 Bondat d’ajust 7.2 Test \\(\\chi^2\\) de Pearson 7.3 Test de Kolmogorov-Smirnov 7.4 Test de Kolmogorov-Smirnov-Lilliefors 7.5 Test de la lliçó 7", " Tema 7 Contrastos de bondat d’ajust Els contrastos d’un paràmetre del tema anterior els empràvem bàsicament per cercar evidència que a un paràmetre poblacional (una mitjana, una proporció) “li passava qualque cosa”: Tenim evidència que la mitjana poblacional és diferent de 2? Tenim evidència que la proporció poblacional d’èxits és més gran que el 10%? Però també podem entendre que hi cercàvem si podem acceptar que el paràmetre poblacional de la variable que havia produït la mostra era igual a qualque cosa: Podem acceptar que la mitjana poblacional és igual a 2? Podem acceptar que la proporció poblacional d’èxits és del 10%? Als contrastos de bondat d’ajust anam una passa més enllà, i ens demanam si podem acceptar que la variable poblacional té una distribució concreta, o si per contra seria molt estrany que la nostra mostra hagués estat produïda per una variable amb aquella distribució. Per exemple: Llençam un dau en l’aire moltes vegades, apuntam els resultats, i ens demanam si podem acceptar que el dau està equilibrat (és a dir, que totes les cares tenen la mateixa probabilitat de sortir) o si per contra hi ha evidència que està trucat. Anotam els ingressos diaris per una determinada malaltia en un hospital i ens demanam si podem acceptar que segueixen una distribució de Poisson o si per contra hi ha evidència que no és el cas, la qual cosa seria senyal que hi ha un brot estrany de la malaltia. Volem emprar una mostra petita en un t-test. Podem acceptar que prové d’una distribució normal? De fet, ja hem estudiat un tipus de contrast de bondat d’ajust: els contrastos bilaterals d’una proporció, on ens demanàvem si podem acceptar que la mostra prové de tal variable Bernoulli o si per contra hi ha evidència que no. En els temes anteriors, les variables aleatòries eren sempre quantitatives: aplicacions que a cada subjecte d’una població li assignen una dada quantitativa, és a dir, un nombre real. En aquest tema i el següent relaxarem aquesta definició, i també considerarem variables aleatòries que assignen a cada subjecte d’una població una dada de qualsevol tipus: no necessàriament quantitativa, també podrà ser qualitativa o ordinal. En aquest context, parlarem de variables aleatòries qualitatives, ordinals o quantitatives, segons el tipus de dada que mesurin. 7.1 Bondat d’ajust Considerau l’exemple següent: Exemple 7.1 Les freqüències de les darreres xifres dels primers premis de la Grossa de la loteria de Nadal als 212 sortejos de la seva història (fins el de 2020, inclòs) han estat les següents: \\[ \\begin{array}{r|cccccccccc} \\hline \\text{xifra} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 \\\\ \\hline \\text{freqüència} &amp; 22 &amp; 8 &amp; 13 &amp; 21 &amp; 27 &amp; 31 &amp; 27 &amp; 23 &amp; 23 &amp; 17\\\\ \\hline \\end{array} \\] Hi ha evidència que no totes les xifres tenen la mateixa probabilitat de sortir com a darrera xifra de la Grossa? Aquesta és la típica pregunta d’un contrast de bondat d’ajust. En principi, estam disposats a acceptar que la nostra mostra prové d’una variable amb una certa distribució: Que totes les darreres xifres de la Grossa tenen la mateixa probabilitat d’aparèixer. Rebutjarem aquesta hipòtesi si seria molt estrany haver obtingut la nostra mostra en el cas que la variable seguís aquesta distribució: Si les darreres xifres tenguessin totes la mateixa probabilitat d’aparèixer, esperaríem una certa uniformitat en les seves freqüències a la nostra mostra. Si les freqüències reals se separen molt d’aquesta uniformitat, tendrem motius per dubtar que tots els dígits tenien la mateixa probabilitat d’aparèixer. Grossa=c(22,8,13,21,27,31,27,23,23,17) barplot(Grossa,col=&quot;light blue&quot;,names=0:9, main=&quot;Darreres xifres de la Grossa de Nadal&quot;) Més en general, un contrast de bondat d’ajust té la forma següent: \\[ \\left\\{ \\begin{array}{l} H_0: \\text{la mostra prové de la distribució esperada}\\\\ H_1: \\text{la mostra NO prové de la distribució esperada} \\end{array} \\right. \\] I, com sempre, Si obtenim evidència que ens permeti rebutjar la hipòtesi nul·la, conclourem que la mostra no prové de la distribució esperada Si no obtenim evidència que ens permeti rebutjar la hipòtesi nul·la, donarem per bo que la mostra prové de la distribució esperada Els tests de bondat d’ajust es basen bàsicament en: Comparar les freqüències observades amb les freqüències esperades si la distribució fos la que contrastam Determinar si les freqüències observades són prou diferents de les esperades com per fer inversemblant la hipòtesi nul·la Per exemple, continuant amb el nostre exemple de la Grossa, si totes les darreres xifres tinguessin la mateixa probabilitat d’aparèixer, la seva probabilitat seria 1/10, i per tant el nombre esperat d’aparicions de cadascuna d’elles seria 212/10=21.2. barplot(Grossa, col=&quot;light blue&quot;, names=0:9, main=&quot;Darreres xifres de la Grossa de Nadal&quot;) abline(h=21.2, col=&quot;red&quot;, lwd=2, lty=&quot;dashed&quot;) Les desviacions observades respecte d’aquest valor esperat, representat per la línia vermella al gràfic anterior, són prou grans com per fer-nos dubtar que les darreres xifres de les Grosses de Nadal tenguin totes la mateixa probabilitat d’aparèixer? O, pel contrari, entren dins el que és raonable esperar per mor de l’atzar? 7.2 Test \\(\\chi^2\\) de Pearson 7.2.1 El test bàsic El test més popular per a variables aleatòries qualitatives, ordinals i quantitatives discretes (o contínues agrupades) és el test \\(\\chi^2\\) de Pearson. Suposem que tenim una mostra aleatòria simple de mida \\(n\\) de la variable poblacional \\(X\\). Agrupam tots els resultats possibles en \\(k\\geqslant 2\\) classes, \\(C_1,\\ldots,C_k\\) (poden ser tots els resultats individuals possibles, si només n’hi ha un conjunt finit). Així, al nostre exemple de les terminacions de la loteria, hi emprarem 10 classes, definides pels 10 valors possibles de la darrera xifra: \\(C_1=\\{0\\}\\), \\(C_2=\\{1\\}\\),…, \\(C_{10}=\\{9\\}\\). Volem contrastar si les observacions segueixen una distribució totalment coneguda, per a la qual poguem calcular la probabilitat que una observació caigui dins cada una de les classes. El contrast és, recordem, \\[ \\left\\{\\begin{array}{l} H_{0}: \\text{La v.a. poblacional té aquesta distribució }\\\\ H_{1}: \\text{La v.a. poblacional no té aquesta distribució} \\end{array} \\right. \\] Per a cada classe \\(C_i\\), diguem \\(obs_i\\): la freqüència absoluta observada d’aquesta classe. Per exemple, en el nostre exemple de la loteria, \\(obs_1\\) és el nombre de vegades que la Grossa ha acabat en 0: 21; \\(obs_2\\) és el nombre de vegades que la Grossa ha acabat en 1: 8; etc. \\(p_i\\): la probabilitat teòrica que una observació pertanyi a aquesta classe si \\(H_0\\) és vertadera. En el nostre exemple de la loteria, totes les probabilitats \\(p_i\\) valen el mateix, 1/10. \\(esp_i\\): la freqüència absoluta esperada d’aquesta classe si \\(H_0\\) és vertadera: \\(esp_i=p_i\\cdot n\\). En el nostre exemple de la loteria, totes aquestes freqüències esperades \\(esp_i\\) valen el mateix, 212/10=21.2. Rebutjarem \\(H_0\\) si les \\(obs_i\\) són prou diferents de les \\(esp_i\\). Per mesurar-ho, empram el teorema següent: Teorema 7.1 Suposem que la distribució contrastada està completament determinada i que se satisfan les condicions següents: La mida \\(n\\) de la mostra és gran (ho fixarem en \\(n\\geqslant 30\\)) Les classes cobreixen tots els resultats possibles: \\(\\sum\\limits_{i=1}^kesp_i= n\\) Totes les classes tenen prou probabilitat teòrica com per tenir-les en compte (nosaltres emprarem la Regla de Cochran: totes les \\(esp_i\\geqslant 5\\)) Aleshores, si \\(H_0\\) és vertadera, l’estadístic de contrast \\[ \\chi^2=\\sum_{i=1}^k \\frac{(obs_{i}-esp_{i})^2}{esp_{i}} \\] té (aproximadament) una distribució \\(\\chi_{k-1}^2\\). Si la distribució contrastada no estava completament determinada i se n’han estimat \\(m\\) paràmetres a partir de la mostra, s’ha de prendre com a distribució de l’estadístic de contrast una \\(\\chi_{k-1-m}^2\\). Fixau-vos que l’estadístic de contrast \\(\\chi^2\\) s’obté de la manera següent: Per cada classe \\(C_i\\): Se resta \\(obs_{i}-esp_{i}\\) S’eleva el resultat al quadrat: \\((obs_{i}-esp_{i})^2\\) Es divideix el resultat per \\(esp_i\\): \\((obs_{i}-esp_{i})^2/esp_{i}\\) Se sumen aquests valors per a totes les classes \\(C_i\\). Aleshores, el contrast se fa de la manera següent: Se calcula el valor que pren l’estadístic de contrast sobre la nostra mostra, diguem-li \\(\\chi_0^2\\) El p-valor del contrast és \\(P(\\chi^2\\geqslant \\chi_0^2)\\), calculada tenint en compte que \\(\\chi^2\\) té distribució \\(\\chi^2\\) amb nombre de graus de llibertat: Si no s’ha hagut d’estimar cap paràmetre de la distribució amb la mostra, el nombre de classes menys 1: \\(\\chi^2_{k-1}\\) Si s’ha estimat qualque paràmetre de la distribució amb la mostra, el nombre de classes menys 1 i menys el nombre de paràmetres estimats: \\(\\chi^2_{k-1-m}\\) amb \\(m\\) el nombre de paràmetres estimats Com més gran sigui el nombre de classes emprades, més potència té el contrast, per tant procurau emprar-ne el màxim nombre possible tot respectant la regla de Cochran. Exemple 7.2 Tornem a l’Exemple 7.1. Recordem que la nostra mostra era \\[ \\begin{array}{r|cccccccccc} \\hline \\text{xifra} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 \\\\ \\hline \\text{freqüència} &amp; 22 &amp; 8 &amp; 13 &amp; 21 &amp; 27 &amp; 31 &amp; 27 &amp; 23 &amp; 23 &amp; 17\\\\ \\hline \\end{array} \\] Com que totes les freqüències esperades valen 21.2, el valor de l’estadístic de contrast sobre aquesta mostra és \\[ \\begin{array}{rl} \\chi_0^2&amp; \\displaystyle=\\frac{(22-21.2)^2}{21.2}+\\frac{(8-21.2)^2}{21.2}+\\cdots\\\\[2ex] &amp; \\qquad\\quad\\displaystyle +\\frac{(23-21.2)^2}{21.2} +\\frac{(17-21.2)^2}{21.2}=20.264 \\end{array} \\] Calculat amb R: X2=sum((Grossa-21.2)^2/21.2) X2 ## [1] 20.26415 En resum, per resoldre la qüestió plantejada en l’Exemple 7.1 procedim de la manera següent: Variable aleatòria d’interès, \\(X\\): Faig un sorteig de la Grossa de Nadal i anot la darrera xifra del nombre guanyador. Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}: \\text{$X$ és uniforme}\\\\ H_{1}: \\text{$X$ no és uniforme} \\end{array} \\right. \\] (Recordau que una variable aleatòria discreta és uniforme quan tots els elements del seu domini tenen la mateixa probabilitat.) Estadístic de contrast: \\[ \\chi^2=\\sum_{i=1}^k \\frac{(obs_{i}-esp_{i})^2}{esp_{i}} \\] Estam en les condicions del Teorema 7.1: \\(n=212\\), gran Les classes, que corresponen als dígits 0,…,9, cobreixen tots els resultats possibles; \\(k=10\\) Cada \\(esp_i=21.2\\geqslant 5\\) Per tant, com que no estimam cap paràmetre de la distribució, aquest estadístic de contrast segueix una llei \\(\\chi^2_9\\). Valor de l’estadístic de contrast: Ja l’hem calculat, 20.264. p-valor: \\(P(\\chi_9^2\\geqslant 20.264)=\\texttt{1-pchisq(20.264,9)}= 0.0164\\) Conclusió: Hem obtingut evidència estadísticament significativa que les darreres xifres de la Grossa no apareixen de manera equiprobable (test \\(\\chi^2\\) de Pearson, p-valor 0.0164). Exemple 7.3 Anem a confirmar amb una simulació aquest p-valor. El que farem serà el següent: Repetirem 10000 vegades, amb un replicate, el procés de generar a l’atzar i de manera equiprobable 212 dígits, calcular la taula de freqüències de cada una d’aquestes mostres i calcular l’estadístic de contrast \\(\\chi^2\\) sobre cada una d’aquestes taules. Finalment, calcularem la fracció de vegades que \\(\\chi^2\\) ha valgut més que a la nostra mostra. set.seed(42) X2sim=replicate(10000,sum((table(sample(0:9,212,rep=TRUE))-21.2)^2/21.2)) length(which(X2sim&gt;=X2))/10000 ## [1] 0.0145 Només un 1.45% de les 10000 simulacions han donat un valor de \\(\\chi^2\\) més gran o igual que el de la mostra de Grosses de Nadal. Per tant, el valor de la \\(\\chi^2\\) de la mostra de Grosses de Nadal és anormalment gran si les darreres xifres tenen totes la mateixa probabilitat d’aparèixer. Naturalment, anormal no vol dir impossible. Sense anar més enfora, algunes de les mostres de la nostra simulació han donat un valor més gran, i alguna fins i tot ha arribat a: max(X2sim) ## [1] 34.98113 Però tenim evidència estadística per dubtar que les darreres xifres de la Grossa surtin equiprobablement. Naturalment, podria ser un error de tipus I. La nota següent us pot ser útil si qualque dia heu de decidir a ull si el valor de l’estadístic d’un test \\(\\chi^2\\) és molt gran. Recordau que la distribució d’una \\(\\chi^2_n\\) és la de la suma de \\(n\\) normals estàndard al quadrat independents, i que l’interval de referència d’una normal estàndard és \\([-1.69,1.69]\\). Això implica que en un 95% de les ocasions una normal estàndard val entre -1.69 i 1.69, i per tant el seu quadrat és més petit que \\(1.69^2=2.856\\leqslant 3\\). Ara fixau-vos que si sumam \\(n\\) numeros més petits que 3, la suma dóna més petita que \\(3n\\). Per tant, si una variable \\(\\chi_n^2\\) pren un valor més gran que \\(3n\\), algun dels quadrats de normal estàndard que hi sumam ha de donar més gran que 3. Això implica que la probabilitat que una \\(\\chi_n^2\\) doni un valor més gran que \\(3n\\) ha de ser molt petita, com podeu observar a la Figura 7.1. Figura 7.1: Algunes probabilitats per a una distribució khi quadrat La funció per realitzar un test \\(\\chi^2\\) amb R és chisq.test(obs, p=...) on obs és el vector de les freqüències observades de les classes, \\((obs_i)_i\\) i p s’ha d’igualar al vector de les probabilitats teòriques de les classes, \\((p_i)_i\\). Si no s’especifica aquest paràmetre p, R entén que totes les probabilitats són iguals. La suma de les probabilitats entrades a p ha de ser igual a 1. Recordau que les classes han de cobrir tots els casos possibles. Al nostre exemple de la Grossa de Nadal, entraríem simplement chisq.test(Grossa) ## ## Chi-squared test for given probabilities ## ## data: Grossa ## X-squared = 20.264, df = 9, p-value = 0.01635 Obtenim el valor de \\(\\chi^2\\), X-squared, els graus de llibertat, df, i el p-valor, p-value. Exemple 7.4 Un tècnic de medi ambient vol estudiar l’augment de temperatura de l’aigua a dos quilòmetres dels abocaments d’aigua autoritzats d’una planta industrial. El responsable de l’empresa afirma que aquests augments de temperatura segueixen una llei normal amb \\(\\mu=3.5\\) dècimes de grau C i \\(\\sigma=0.7\\) dècimes de grau C. El tècnic ho posa en dubte. Per decidir-ho, pren una mostra aleatòria d’observacions de l’augment de les temperatures (en dècimes de grau). Les dades són les de la taula següent, ja agrupades en classes: \\[ \\begin{array}{c|c} \\text{Rang d&#39;augments} &amp; \\text{Freqüències}\\\\ \\hline 1.45\\text{ a }1.95 &amp; 2 \\\\ 1.95\\text{ a }2.45 &amp; 1 \\\\ 2.45\\text{ a }2.95 &amp; 4 \\\\ 2.95\\text{ a }3.45 &amp; 15 \\\\ 3.45\\text{ a }3.95 &amp; 10 \\\\ 3.95\\text{ a }4.45 &amp; 5 \\\\ 4.45\\text{ a }4.95 &amp; 3 \\\\ \\hline \\text{Total} &amp; 40\\\\ \\end{array} \\] Hi ha evidència que la sospita del tècnic sigui vertadera, amb un nivell de significació del 5%? Variable aleatòria d’interès, \\(X\\): Prenc un lloc a 2 km dels abocaments d’aigua autoritzats d’una planta industrial i hi mesur l’augment de temperatura (en dècimes de grau). Contrast: \\[ \\left\\{ \\begin{array}{l} H_{0}:\\text{$X$ és $N(3.5,0.7)$}\\\\ H_{1}: \\text{$X$ no és $N(3.5,0.7)$} \\end{array} \\right. \\] Estadístic de contrast: Volem emprar el test \\(\\chi^2\\), així que l’estadístic de contrast serà \\[ \\chi^2=\\sum_{i=1}^k \\frac{(obs_{i}-esp_{i})^2}{esp_{i}} \\] Cal comprovar que se satisfan les condicions del Teorema 7.1. La mida de la mostra és \\(n=40\\), suficient. Les classes, cobreixen tots els resultats possibles? No, perquè els possible valors d’una variable normal són tots els nombres reals, i les nostres classes només cobreixen l’interval [1.45,4.95]. El que farem serà afegir les cues a les dues classes dels extrems, i considerar les classes \\[ \\begin{array}{l|c} \\text{Rang d&#39;augments} &amp; \\text{Freqüències}\\\\ \\hline \\text{menys de 1.95} &amp; 2 \\\\ 1.95 \\text{ a } 2.45 &amp; 1 \\\\ 2.45\\text{ a }2.95 &amp; 4 \\\\ 2.95\\text{ a }3.45 &amp; 15 \\\\ 3.45\\text{ a }3.95 &amp; 10 \\\\ 3.95\\text{ a }4.45 &amp; 5 \\\\ \\text{més de 4.45} &amp; 3 \\\\ \\hline \\text{Total} &amp; 40\\\\ \\end{array} \\] Ara ja cobreixen tots els resultats possibles. Totes les freqüències esperades són com a mínim 5? Doncs no ho sabem, les haurem de calcular. Recordem que són les freqüències esperades de cada classe suposant que la variable poblacional és \\(N(3.5,0.7)\\), i s’obtenen multiplicant la probabilitat de cada interval (amb aquesta distribució) per la mida de la mostra, 40. La probabilitat de la 1a classe és \\[ p_1 =P(X\\leqslant 1.95)=\\texttt{pnorm(1.95,3.5,0.7)}=0.0134 \\] i la seva freqüència esperada és \\[ esp_1=p_1\\cdot n= 0.0134\\cdot 40=0.536 \\] La probabilitat de la 2a classe és \\[ \\begin{array}{rl} p_2 &amp; =P(1.95\\leqslant X\\leqslant 2.45)\\\\ &amp; =\\texttt{pnorm(2.45,3.5,0.7)-pnorm(1.95,3.5,0.7)}=0.0534 \\end{array} \\] i per tant la seva freqüència esperada és \\[ esp_2=p_2\\cdot n= 0.0534\\cdot 40= 2.136 \\] Calcularem amb R totes les freqüències esperades d’aquesta manera i d’un sol cop: freq.obs=c(2,1,4,15,10,5,3) n=sum(freq.obs) lims=c(-Inf,1.95,2.45,2.95,3.45,3.95,4.45,Inf) lim.esq=lims[-length(lims)] #Els límits inferiors de les classes lim.dret=lims[-1] #Els límits superiors de les classes mu=3.5 sigma=0.7 prob.esp=pnorm(lim.dret,mu,sigma)-pnorm(lim.esq,mu,sigma) freq.esp=n*prob.esp round(freq.esp,3) ## [1] 0.536 2.136 5.968 10.220 10.733 6.912 3.495 Per tant, tenim la taula \\[ \\begin{array}{r|c|c} \\text{Rang de temperatures} &amp; obs_i &amp; esp_i\\\\ \\hline \\text{menys de 1.95} &amp; 2 &amp; 0.536 \\\\ 1.95\\text{ a }2.45 &amp; 1 &amp; 2.136 \\\\ 2.45\\text{ a }2.95 &amp; 4 &amp; 5.968 \\\\ 2.95\\text{ a }3.45 &amp; 15 &amp; 10.220 \\\\ 3.45\\text{ a }3.95 &amp; 10 &amp; 10.733 \\\\ 3.95\\text{ a }4.45 &amp; 5 &amp; 6.912 \\\\ \\text{més de 4.45} &amp; 3 &amp; 3.495 \\end{array} \\] Tenim freqüències esperades per davall de 5, per tant no podem aplicar el test \\(\\chi^2\\) tal qual. El que farem serà agrupar classes contigües a fi d’obtenir freqüències esperades més grans o iguals que 5 amb el màxim de classes. En concret, haurem d’agrupar per un costat les tres primeres classes, i per un altre costat les dues darreres classes \\[ \\begin{array}{r|c|c} \\text{Rang de temperatures} &amp; obs_i &amp; esp_i\\\\\\hline \\text{menys de 2.95} &amp; 7 &amp; 8.64\\\\ 2.95\\text{ a }3.45 &amp; 15 &amp; 10.22 \\\\ 3.45\\text{ a }3.95 &amp; 10 &amp; 10.733 \\\\ \\text{més de 3.95} &amp; 8&amp; 10.407 \\end{array} \\] Ara ja podem aplicar el text \\(\\chi^2\\) amb aquestes \\(k=4\\) classes. Com que no hem estimat cap paràmetre, prendrem com a distribució de l’estadístic de contrast una \\(\\chi^2_3\\). Valor de l’estadístic de contrast: \\[ \\begin{array}{rl} \\chi_0^2 &amp;\\displaystyle=\\frac{(7-8.64)^2}{8.64}+\\frac{(15-10.22)^2}{10.22}\\\\ &amp;\\displaystyle\\qquad\\quad +\\frac{(10-10.733)^2}{10.733}+\\frac{(8-10.407)^2}{10.407}=3.154 \\end{array} \\] p-valor: \\[ P(\\chi_{3}^2\\geqslant 3.154)=\\texttt{1-pchisq(3.154,3)}=0.37 \\] Conclusió: Podem acceptar que els augments de temperatures observats segueixen una llei normal \\(N(3.5,0.7)\\) (test \\(\\chi^2\\) de Pearson, p-valor=0.37). Amb R, si aplicam directament la funció chisq-test als vectors de freqüències i probabilitats de les classes originals (bé, de les esteses per cobrir tot \\(\\mathbb{R}\\)) R ens avisa que el resultat no és de fiar: chisq.test(freq.obs,p=prob.esp) ## Warning in chisq.test(freq.obs, p = prob.esp): Chi-squared approximation may be ## incorrect ## ## Chi-squared test for given probabilities ## ## data: freq.obs ## X-squared = 8.1337, df = 6, p-value = 0.2285 Haurem d’agrupar primer a mà les classes, abans d’aplicar chisq.test: freq.obs.agrup=c(sum(freq.obs[1:3]), freq.obs[4:5], sum(freq.obs[6:7])) prob.esp.agrup=c(sum(prob.esp[1:3]), prob.esp[4:5], sum(prob.esp[6:7])) chisq.test(freq.obs.agrup, p=prob.esp.agrup) ## ## Chi-squared test for given probabilities ## ## data: freq.obs.agrup ## X-squared = 3.1531, df = 3, p-value = 0.3686 7.2.2 Mètode de Montecarlo Quan volem realitzar un test \\(\\chi^2\\) i no es compleixen les condicions perquè el p-valor tengui sentit, es pot emprar el mètode de Montecarlo (o basat en simulacions) per estimar el p-valor: Es genera un conjunt molt gran de mostres aleatòries amb la distribució esperada i de la mateixa mida que la nostra mostra Es calcula l’estadístic de contrast \\(\\chi^2\\) sobre cada mostra S’estima el p-valor mitjançant la fracció de mostres que han donat un \\(\\chi^2\\) més gran que el de la nostra mostra Recordau que ja hem emprat aquest mètode a l’Exemple 7.3 per “comprovar” el p-valor obtingut a l’Exemple 7.2 amb el test \\(\\chi^2\\) “exacte”. Però no cal complicar-se tant la vida per realitzar-lo. La funció chisq.test també permet usar el mètode de Montecarlo, entrant-hi el paràmetre simulate.p.value=TRUE i, si es vol, igualant el paràmetre B al nombre de simulacions desitjat (per defecte, en farà 2000). Naturalment, com que es basa en una simulació aleatòria, pot ser que en cada execució doni un p-valor diferent. Per exemple, podíem emprar el mètode de Montecarlo per realitzar el contrast de l’Exemple 7.4 amb les classes originals esteses, sense agrupar-les. set.seed(42) chisq.test(freq.obs, p=prob.esp, simulate.p.value=TRUE, B=5000) ## ## Chi-squared test for given probabilities with simulated p-value (based ## on 5000 replicates) ## ## data: freq.obs ## X-squared = 8.1337, df = NA, p-value = 0.2206 Conclusió: Podem acceptar que els augments de temperatures observats segueixen una llei normal \\(N(3.5,0.7)\\) (test \\(\\chi^2\\) de Montecarlo, p-valor=0.22). Arribam, doncs, a la mateixa conclusió que amb el test \\(\\chi^2\\) aplicat a les dades agrupades. 7.2.3 Test \\(\\chi^2\\) amb paràmetres poblacionals desconeguts De vegades ens interessarà contrastar si les observacions segueixen algun tipus determinat de distribució (Poisson, normal…) amb algun paràmetre indeterminat. En aquest cas, primer estimam els paràmetres desconeguts a partir de les observacions i a continuació contrastam l’ajustament de la mostra a la distribució amb aquests paràmetres. El test és exactament el mateix que el de les seccions anteriors, excepte que ara cal restar al nombre \\(k-1\\) de graus de llibertat de la \\(\\chi^2\\) el nombre \\(m\\) de paràmetres que hem estimat. L’estimació dels paràmetres s’ha de realitzar amb els estimadors màxim versemblants, que són els que maximitzen la probabilitat de la nostra mostra. D’aquesta manera, si amb els paràmetres que fan màxima la probabilitat de la nostra mostra, aquesta encara ens surt molt rara, més evidència tenim que el tipus de distribució no és el correcte. Exemple 7.5 Volem determinar si el nombre de vegades que apareix la seqüència GATACA en una cadena d’ADN humà de longitud 1000 segueix una llei de Poisson. Per fer-ho, prenem 576 mostres de cadenes d’ADN humà de longitud 1000 i hi comptam els nombres de GATACA. Els resultats són els de la taula següent: \\[ \\begin{array}{r|rrrrrr} \\hline \\text{nombre $x_i$ de vegades} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\\\[-1ex] \\text{que hi apareix GATACA} &amp; &amp; &amp; &amp; &amp; &amp; \\\\ \\hline \\text{freqüència $obs_{i}$} &amp; 229 &amp; 211 &amp; 93 &amp; 35 &amp; 7 &amp; 1 \\\\ \\hline \\end{array} \\] Variable aleatòria d’interès, \\(X\\): Prenc una cadena d’ADN humà de 1000 bases i hi compt el nombre de seqüències GATACA. Contrast: \\[ \\left\\{ \\begin{array}{ll} H_0: \\text{$X$ és de Poisson}\\\\ H_1: \\text{$X$ no és de Poisson} \\end{array} \\right. \\] Per poder calcular les probabilitats de les classes, necessitam estimar el paràmetre \\(\\lambda\\) de la variable de Poisson. El seu estimador màxim versemblant és la mitjana mostral: \\[ \\lambda =\\dfrac{229 + 211 + 93 + 35 +7 + 1 }{576}=\\dfrac{576}{576}=1 \\] Aquesta no és la mitjana de la mostra! Ara sí: \\[ \\begin{array}{rl} \\lambda &amp; =\\dfrac{229\\cdot 0+ 211\\cdot 1+ 93\\cdot 2+ 35\\cdot 3+7\\cdot 4+ 1\\cdot 5}{576}\\\\ &amp; =\\dfrac{535}{576}=0.929 \\end{array} \\] Estadístic de contrast: Volem emprar el test \\(\\chi^2\\), així que l’estadístic de contrast serà \\[ \\chi^2=\\sum_{i=1}^k \\frac{(obs_{i}-esp_{i})^2}{esp_{i}} \\] Cal comprovar que se satisfan les condicions del Teorema 7.1. La mida de la mostra és \\(n=576\\), ben gran. Per veure si les freqüències esperades són totes més grans o iguals que 5, les hem de calcular. Recordem que, si \\(X\\) és una variable aleatòria de Poisson \\(Po(\\lambda)\\), \\[ P(X=k)=e^{-\\lambda}\\cdot \\frac{\\lambda^k}{k!}=\\texttt{dpois(k,lambda)} \\] Les probabilitats \\(p_i\\) d’obtenir \\(i=0,1,2,3,4,5\\) són round(dpois(0:5,0.929),3) ## [1] 0.395 0.367 0.170 0.053 0.012 0.002 i les freqüències esperades \\(esp_i=p_i\\cdot n\\) d’aquests valors són round(dpois(0:5,0.929)*576,2) ## [1] 227.49 211.34 98.17 30.40 7.06 1.31 Obtenim la taula \\[ \\begin{array}{l|rrrrrr} \\hline x_i &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\\\ \\hline obs_{i} &amp; 229 &amp; 211 &amp; 93 &amp; 35 &amp; 7 &amp; 1 \\\\ \\hline p_i &amp;0.395 &amp; 0.367 &amp;0.170 &amp; 0.053 &amp; 0.012 &amp; 0.002 \\\\ \\hline esp_i &amp; 227.49 &amp; 211.34 &amp; 98.17 &amp; 30.40 &amp; 7.06 &amp; 1.31\\\\ \\hline \\end{array} \\] Aquestes classes estan malament! Recordau que les classes han de cobrir tots els resultats possibles! Els resultats possibles d’una variable Poisson són tots els nombres naturals. Per cobrir tots els resultats possibles, cal canviar el 5 per “5 o més” i recalcular la probabilitat i la freqüència esperada d’aquesta classe: la seva probabilitat és \\(P(X\\geqslant 5)=1-P(X\\leqslant 4)\\) round(1-ppois(4,0.929),3) ## [1] 0.003 i la seva freqüència esperada és round((1-ppois(4,0.929))*576,2) ## [1] 1.55 Obtenim la taula \\[ \\begin{array}{l|rrrrrr} \\hline x_i &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; \\geqslant 5 \\\\ \\hline obs_{i}&amp; 229 &amp; 211 &amp; 93 &amp; 35 &amp; 7 &amp; 1 \\\\ \\hline p_i &amp;0.395 &amp; 0.367 &amp;0.170 &amp; 0.053 &amp; 0.012 &amp; 0.003 \\\\ \\hline esp_i &amp; 227.49 &amp; 211.34 &amp; 98.17 &amp; 30.40 &amp; 7.06 &amp; 1.55\\\\ \\hline \\end{array} \\] Perquè totes les classes tenguin freqüència esperada més gran o igual que 5, agruparem les dues darreres classes \\[ \\begin{array}{l|rrrrr} \\hline x_i &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; \\geqslant 4 \\\\ \\hline obs_{i}&amp; 229 &amp; 211 &amp; 93 &amp; 35 &amp; 8 \\\\ \\hline p_i &amp;0.395 &amp; 0.367 &amp;0.170 &amp; 0.053 &amp; 0.015 \\\\ \\hline esp_i &amp; 227.49 &amp; 211.34 &amp; 98.17 &amp; 30.40 &amp; 8.61\\\\ \\hline \\end{array} \\] Ara totes les freqüències esperades són prou grans i les classes cobreixen tots els valors possibles de la variable. L’estadístic de contrast té distribució \\(\\chi_{k-1}^2\\) amb \\(k=5\\), per tant \\(\\chi_{4}^2\\). Com que hem estimat la \\(\\lambda\\), hem de considerar l’estadístic de contrast amb distribució \\(\\chi_{k-1-m}^2\\) amb \\(k\\) el nombre de classes i \\(m\\) el nombre de paràmetres estimats, en aquest cas 1. Perdó. L’estadístic de contrast té distribució \\(\\chi_{3}^2\\). Podem continuar. Valor de l’estadístic de contrast: obs.gataca=c(229,211,93,35,8) n=sum(obs.gataca) probs.gataca=c(dpois(0:3,0.929),1-ppois(3,0.929)) esp.gataca=probs.gataca*n X02=sum((obs.gataca-esp.gataca)^2/esp.gataca) round(X02,2) ## [1] 1.02 p-valor: \\(P(\\chi_3^2\\geqslant 1.02)=\\texttt{1-pchisq(1.02,3)}=0.796\\) Conclusió: Podem acceptar que les observacions trobades segueixen una llei de Poisson (test \\(\\chi^2\\) de Pearson, p-valor 0.796). Amb R simplement ens estalviam el càlcul explícit de \\(\\chi_0^2\\) i del p-valor, perquè tota la saragata de calcular freqüències esperades i agrupar a fi que se satisfaci la llei de Cochran no ens la podem estalviar. chisq.test(obs.gataca,p=probs.gataca) ## ## Chi-squared test for given probabilities ## ## data: obs.gataca ## X-squared = 1.0215, df = 4, p-value = 0.9065 Conclusió: No podem rebutjar que les observacions trobades segueixin una llei de Poisson (test \\(\\chi^2\\) de Pearson, p-valor 0.9065????). No havíem quedat que el nombre de graus de llibertat era 3? R n’ha emprat 4, df=4, perquè no sap que hem estimat un paràmetre R ha calculat el p-valor prenent \\(\\chi_4^2\\), nosaltres l’hem de calcular amb \\(\\chi_3^2\\): 1-pchisq(1.0215,3) ## [1] 0.7960498 Ara ja tenim el mateix p-valor que abans. 7.3 Test de Kolmogorov-Smirnov El test de Kolgomorov-Smirnov (test K-S, per abreviar) és el test més popular per contrastar si una mostra segueix o no una distribució contínua completament determinada, sense restriccions sobre la mida de la mostra. Es pot emprar amb tota distribució contínua sempre que estigui completament especificada. Per a distribucions concretes, mides de mostres dins marges concrets o quan hem d’estimar els paràmetres, existeixen mètodes específics millors que el K-S, però no els veurem aquí. Estan a la lliçó corresponent de R. Tot seguit explicam com funciona aquest test. Partim d’una mostra \\(x_1,x_2,\\ldots,x_n\\) amb tots els valors diferents i volem contrastar si ha estat produïda per una variable \\(X\\) contínua amb funció de distribució \\(F_X\\). Per exemple, suposem que volem contrastar si podem acceptar que els valors del vector següent provenen d’una distribució normal \\(N(3,1.5)\\). valors=c(5.84,4.57,1.34,3.58,1.54,2.25) Sigui \\(X\\) la variable aleatòria que ha produït aquest conjunt de números. Aleshores, el contrast és \\[ \\left\\{ \\begin{array}{l} H_0: \\text{$X$ és $N(3,1.5)$}\\\\ H_0: \\text{$X$ no és $N(3,1.5)$} \\end{array} \\right. \\] Ordenam la mostra: \\(x_{(1)}&lt; x_{(2)}&lt;\\cdots&lt; x_{(n)}\\). valors=sort(valors) valors ## [1] 1.34 1.54 2.25 3.58 4.57 5.84 Consideram la funció de distribució mostral \\(F_{n}\\) d’aquesta mostra: la funció de distribució d’una variable \\(n\\) amb domini tot \\(\\mathbb{R}\\) per a la qual cada \\(x_{(i)}\\) tingués probabilitat \\(1/n\\) i la resta de reals tingués probabilitat 0: \\[ F_n(x)=\\left\\{\\begin{array}{ll} 0 &amp;\\text{ si } x&lt; x_{(1)} \\\\ \\dfrac{k}{n}&amp;\\text{ si } x_{(k)}\\leqslant x &lt; x_{(k+1)}\\\\ 1 &amp; \\text{ si } x_{(n)} \\leqslant x \\end{array} \\right. \\] A la nostra mostra ja ordenada, seria \\[ F_6(x)=\\left\\{\\begin{array}{ll} 0 &amp;\\text{ si } x&lt; 1.34 \\\\ 1/6 &amp;\\text{ si } 1.34\\leqslant x &lt;1.54\\\\ 2/6 &amp;\\text{ si } 1.54\\leqslant x &lt;2.25\\\\ 3/6 &amp;\\text{ si } 2.25\\leqslant x &lt;3.58\\\\ 4/6 &amp;\\text{ si } 3.58\\leqslant x &lt;4.57\\\\ 5/6 &amp;\\text{ si } 4.57\\leqslant x &lt;5.84\\\\ 1 &amp;\\text{ si } 5.84\\leqslant x \\end{array} \\right. \\] El gràfic d’aquesta distribució és el següent: plot(c(1,valors,7), c(0,(0:5)/5,1), type=&quot;s&quot;, lwd=1.5, xlab=&quot;&quot;, ylab=&quot;&quot;) Comparam la funció \\(F_n(x)\\) amb la funció de distribució \\(F_X(x)\\) que tendria la variable aleatòria \\(X\\) si satisfés la hipòtesi nul·la. Si són molt diferents, rebutjarem que la variable \\(X\\) que ha produït la mostra tengui funció de distribució \\(F_X\\). plot(c(1,valors,6),c(0,(0:5)/5,1),type=&quot;s&quot;, xlab=&quot;&quot;,ylab=&quot;&quot;,lwd=1.5) curve(pnorm(x,3,1.5),col=&quot;red&quot;,lwd=1.5,add=TRUE) legend(&quot;topleft&quot;,col=c(&quot;black&quot;,&quot;red&quot;),lty=c(1,1), legend=c(expression(F[6]),&quot;N(3,1.5)&quot;),cex=0.7) Per comparar \\(F_n(x)\\) amb \\(F_X(x)\\), calcularem \\[ \\max\\{|F_n(x)-F_X(x)|\\mid x\\in \\mathbb{R}\\} \\] Com que \\(F_X\\) és creixent, aquest màxim s’assoleix a qualque escaló. Per tant, per calcular aquest màxim primer calculam, per a cada \\(x_{(i)}\\), la seva discrepància: la distància entre \\(F_X(x_{(i)})\\) i els extrems de l’escaló corresponent, \\[ D_n(x_{(i)})=\\max\\Big\\{\\Big| F_X(x_{(i)})-\\frac{i-1}{n}\\Big|, \\Big|F_{X}(x_{(i)})-\\frac{i}{n}\\Big|\\Big\\} \\] i prenem la discrepància màxima, és a dir, el màxim d’aquestes discrepàncies: \\[ D_n=\\max\\big\\{D_n(x_{(i)})\\mid i=1,\\ldots, n\\big\\} \\] Al nostre exemple, els valors \\(F_X(x_{(i)})\\) són: round(pnorm(valors,3,1.5),3) ## [1] 0.134 0.165 0.309 0.650 0.852 0.971 i per tant les discrepàncies són \\[ \\begin{array}{rl} D_6(x_{(1)}) &amp; =\\max\\{| F_X(1.34)-0|, |F_X(1.34)-1/6|\\}\\\\ &amp; =\\max\\{|0.134-0|, |0.134-1/6|\\}\\\\ &amp; =\\max\\{ 0.134, 0.033\\}=0.134\\\\[2ex] D_6(x_{(2)}) &amp; =\\max\\{| F_X(1.54)-1/6|, |F_X(1.54)-2/6|\\}\\\\ &amp; =\\max\\{| 0.165-1/6|, |0.165-2/6|\\}\\\\ &amp; =\\max\\{ 0.002, 0.168\\}=0.168\\\\[2ex] D_6(x_{(3)}) &amp; =\\max\\{| F_X(2.25)-2/6|, |F_X(2.25)-3/6|\\}\\\\ &amp; =\\max\\{|0.309-2/6|, |0.309-3/6|\\}\\\\ &amp; =\\max\\{ 0.024, 0.191\\}=0.191\\\\[2ex] D_6(x_{(4)}) &amp; =\\max\\{| F_X(3.58)-3/6|, |F_X(3.58)-4/6|\\}\\\\ &amp; =\\max\\{| 0.65-3/6|, |0.65-4/6|\\}\\\\ &amp; =\\max\\{ 0.15, 0.017\\}=0.15\\\\[2ex] D_6(x_{(5)}) &amp; =\\max\\{| F_X(4.57)-4/6|, |F_X(4.57)-5/6|\\}\\\\ &amp; =\\max\\{|0.852-4/6|, |0.852-5/6|\\}\\\\ &amp; =\\max\\{ 0.185, 0.019\\}=0.185\\\\[2ex] D_6(x_{(6)}) &amp; =\\max\\{| F_X(5.84)-5/6|, |F_X(5.84)-6/6|\\}\\\\ &amp; =\\max\\{| 0.971-5/6|, |0.971-1|\\}\\\\ &amp; =\\max\\{ 0.138, 0.029\\}=0.138 \\end{array} \\] i la discrepància màxima és \\[ D_6=\\max\\{0.134,0.168,0.191,0.15,0.185,0.138\\}=0.191 \\] Aquesta discrepància màxima segueix una distribució coneguda (que no depèn de la \\(X\\) mentre sigui contínua) que permet calcular el p-valor com la probabilitat que \\(D_n\\) prengui un valor més gran o igual que l’obtingut sobre la nostra mostra. Al nostre exemple, seria \\(P(D_6\\geqslant 0.191)\\). La corresponent funció de distribució acumulada és donada per la funció pkolm del paquet kolmim. Per tant, el p-valor és library(kolmim) round(1-pkolm(0.191,6),3) ## [1] 0.951 Conclusió: Podem acceptar que la mostra prové d’una variable aleatòria normal amb \\(\\mu=3\\) i \\(\\sigma=1.5\\) (test de Kolmogorov-Smirnov, p-valor 0.95) Per realitzar un test K-S amb R, disposam de la instrucció ks.test(x,&quot;pdistribució&quot;,paràmetres) on x és el vector que conté la mostra, la pdistribució és la funció de distribució que contrastam, i els paràmetres són els de la distribució tal i com els entraríem a la funció pdistribució. Al nostre exemple, simplement entraríem valors=c(5.84,4.57,1.34,3.58,1.54,2.25) ks.test(valors,&quot;pnorm&quot;,3,1.5) ## ## One-sample Kolmogorov-Smirnov test ## ## data: valors ## D = 0.19146, p-value = 0.95 ## alternative hypothesis: two-sided Dóna el valor de l’estadístic (la D) i el p-valor 7.4 Test de Kolmogorov-Smirnov-Lilliefors Quan es vol emprar el test K-S per contrastar si una mostra prové de qualque distribució normal, i no d’una concreta, l’opció més popular és: Estimar els paràmetres de la normal a partir de la mostra Calcular l’estadístic del test K-S amb aquests paràmetres Emprar la distribució del test K-S-Lilliefors per calcular el p-valor Amb R, aquest test està implementat en la funció lillie.test del paquet nortest. Per exemple, si ens haguéssim demanat d’entrada si la nostra mostra prové de qualque variable normal, haguéssim entrat library(nortest) lillie.test(valors) ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: valors ## D = 0.19912, p-value = 0.6425 L’estadístic de contrast no val el mateix que abans, perquè ara la variable normal que contrasta té paràmetres \\(\\mu=\\texttt{mean(valors)}=3.187\\) i \\(\\sigma=\\texttt{sd(valors)}=1.795\\). Exemple 7.6 Podem acceptar que les variables \\(X_d\\) i \\(X_h\\) de l’Exemple 6.4 són normals? Apliquem el test K-S-Lilliefors a les dues mostres: lillie.test(X_d) ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: X_d ## D = 0.08289, p-value = 0.04842 lillie.test(X_h) ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: X_h ## D = 0.055977, p-value = 0.5128 Podem acceptar que les temperatures dels homes tenen distribució normal, però essent rigorosos, amb nivell de significació 0.05 no podem acceptar que \\(X_d\\) sigui normal. 7.5 Test de la lliçó 7 (1) Quina o quines de les afirmacions següents són vertaderes sobre un test \\(\\chi^2\\) de bondat d’ajust? Si la mostra és de mida com a mínim 30, segur que podem aplicar-lo Si la mida de la mostra és menor que 30, no podem aplicar-lo Si la mostra és de mida com a mínim 30, i empram 4 classes, segur que podem aplicar-lo Si alguna freqüència observada és més petita que 5, no podem aplicar-lo Si alguna freqüència esperada és més petita que 5, no podem aplicar-lo Cap de les altres afirmacions és vertadera (2) Quina o quines de les afirmacions següents són vertaderes sobre un test \\(\\chi^2\\) de bondat d’ajust? Si totes les freqüències observades són més grans o iguals que 5, segur que podem aplicar-lo Si totes les freqüències esperades són més grans o iguals que 5, segur que podem aplicar-lo Si totes les freqüències observades són més grans o iguals que 5, i empram 10 classes, segur que podem aplicar-lo Si totes les freqüències esperades són més grans o iguals que 5, i empram 10 classes, segur que podem aplicar-lo Cap de les altres afirmacions és vertadera (3) En un contrast de bondat d’ajust, volem contrastar a partir d’una sèrie de llançaments d’un dau si aquest dau està equilibrat o trucat. Quina de les afirmacions següents és correcta? La hipòtesi nul·la és que el dau està equilibrat La hipòtesi nul·la és que el dau podria estar equilibrat La hipòtesi nul·la és que el dau podria estar trucat La hipòtesi nul·la és que el dau està trucat Cap de les altres respostes és correcta (4) En un contrast de bondat d’ajust on volem emprar un test \\(\\chi^2\\) per contrastar a partir d’una sèrie de llançaments d’un dau de 10 cares si aquest dau està equilibrat o trucat, quina o quines de les afirmacions següents són correctes? Si a la nostra mostra no hi obtenim cap 4, no cal considerar aquest valor a l’hora de fer el test \\(\\chi^2\\) Si a la nostra mostra no hi obtenim cap 4, no podem aplicar un test \\(\\chi^2\\) Si la nostra mostra és de 40 llançaments segur que podem aplicar un test \\(\\chi^2\\) Si la nostra mostra és de 40 llançaments segur que no podem aplicar un test \\(\\chi^2\\) Si la nostra mostra és de 40 llançaments, pot ser que poguem aplicar un test \\(\\chi^2\\) i pot ser que no el poguem aplicar Si la nostra mostra és de 50 llançaments segur que no podem aplicar un test \\(\\chi^2\\) Si la nostra mostra és de 50 llançaments, pot ser que poguem aplicar un test \\(\\chi^2\\) i pot ser que no el poguem aplicar Si la nostra mostra és de 50 llançaments, segur que podem aplicar un test \\(\\chi^2\\) Cap de les altres afirmacions és correcta (5) Tenim una variable aleatòria \\(X\\) que pot prendre els valors 1, 2, 3 o 4. En prenem una mostra, i a partir d’aquesta mostra volem contrastar si la densitat d’aquesta variable és \\(P(X=1)=P(X=2)=0.2\\), \\(P(X=3)=P(X=4)=0.3\\). Quina o quines de les afirmacions següents són correctes? La hipòtesi nul·la és que X pren els valors 1,2,3,4 de manera equiprobable La hipòtesi nul·la és que X pren els valors 1,2,3,4 amb probabilitats \\(P(X=1)=P(X=2)=0.2\\), \\(P(X=3)=P(X=4)=0.3\\) La hipòtesi alternativa és que X pren els valors 1,2,3,4 amb probabilitats \\(P(X=1)=P(X=2)=0.2\\), \\(P(X=3)=P(X=4)=0.3\\) La hipòtesi alternativa és que X pren els valors 1,2,3,4 de manera equiprobable La hipòtesi alternativa és que X no pren els valors 1,2,3,4 de manera equiprobable Cap de les altres respostes és correcta (6) Volem contrastar si una mostra de 35 valors s’ajusta a una certa distribució usant un test \\(\\chi^2\\). Quina de les afirmacions següents és vertadera? Pot ser que puguem emprar 5 classes, però segur que no en podrem emprar 6 Pot ser que puguem emprar 6 classes, però segur que no en podrem emprar 7 Pot ser que puguem emprar 7 classes, però segur que no en podrem emprar 8 Pot ser que puguem emprar 8 classes, però segur que no en podrem emprar 9 Pot ser que puguem emprar 9 classes, però segur que no en podrem emprar 10 Cap de les altres afirmacions és vertadera (7) Volem contrastar si una mostra de nombres de malalts prové d’una variable aleatòria amb alguna distribució de Poisson usant un test \\(\\chi^2\\). Quina o quines de les afirmacions següents són correctes? Podem prendre com a classes tots els valors possibles de la variable Si la mostra és de 30 o més individus, segur que podem fer servir el test \\(\\chi^2\\), independentment de les classes que prenguem Si la freqüència esperada de cada classe que prenguem és com a mínim 5, segur que podem fer servir el test \\(\\chi^2\\) Si la mostra és de 30 o més individus i empram classes que tenguin freqüències observades com a mínim 5, segur que podem fer servir el test \\(\\chi^2\\) Alguna classe haurà de contenir un nombre infinit de valors possibles No fa falta estimar la lambda per emprar un test \\(\\chi^2\\) Totes les altres afirmacions són falses (8) Volem contrastar si una mostra de nombres de malalts prové d’una variable aleatòria amb alguna distribució de Poisson usant un test \\(\\chi^2\\). Quina o quines de les afirmacions següents són correctes? El nombre de graus de llibertat de la distribució de l’estadístic que hauríem d’emprar per calcular el p-valor és el nombre de classes menys 1 El nombre de graus de llibertat de la distribució de l’estadístic que hauríem d’emprar per calcular el p-valor és el nombre de classes menys 2 El nombre de graus de llibertat de la distribució de l’estadístic que hauríem d’emprar per calcular el p-valor és el nombre de classes menys 3 Totes les altres afirmacions són falses (9) En un contrast de bondat d’ajust per decidir si una mostra s’ajusta a una variable normal o no, obtenim un p-valor més gran que el nivell de significació. Quina o quines de les afirmacions següents són correctes? Concloem que la variable no segueix una distribució normal Acceptam que la variable segueix una distribució normal. Hem obtingut evidència estadísticament significativa que la variable és normal. No hem obtingut evidència estadísticament significativa que la variable sigui normal. No hem obtingut evidència estadísticament significativa que la variable no sigui normal. Podria tractar-se d’un error de tipus I Podria tractar-se d’un error de tipus II Totes les altres afirmacions són falses. (10) En un test \\(\\chi^2\\) on contrastau si la mostra s’ajusta a alguna variable normal hi emprau 10 classes. Quants graus de llibertat tendrà l’estadístic de contrast que heu d’emprar per calcular el p-valor? 12 11 10 9 8 7 6 (11) Va, vegem si llegiu els apunts. Si \\(X\\) és variable\\(\\chi_n^2\\), quin dels valors següents és el més petit d’aquesta llista que us diem en una nota que la probabilitat que \\(X\\) sigui més gran que ell és molt petita? \\(n\\) \\(2n\\) \\(3n\\) \\(4n\\) \\(5n\\) 42 (12) Podem emprar un test de Kolgomorov-Smirnov per contrastar a partir d’una mostra si una variable poblacional és de Poisson? Sí No "],
["contrastos-dindependència-i-homogeneïtat.html", "Tema 8 Contrastos d’independència i homogeneïtat 8.1 Test \\(\\chi^2\\) d’independència 8.2 Test \\(\\chi^2\\) d’homogeneïtat 8.3 Test \\(\\chi^2\\) de tendència (Opcional) 8.4 Test de la lliçó 8", " Tema 8 Contrastos d’independència i homogeneïtat En els contrastos d’independència de dues variables \\(X\\) i \\(Y\\), la hipòtesi nul·la és no hi ha cap relació entre \\(X\\) i \\(Y\\), és a dir, que són independents. Quan traduïm la independència de dues variables en termes de “la probabilitat de la intersecció és el producte de probabilitats”, resulta que un contrast d’independència és un tipus concret de contrast de bondat d’ajust. En els contrastos d’homogeneïtat de dues variables \\(X\\) i \\(Y\\), la hipòtesi nul·la és la distribució de \\(Y\\) condicionada a cada un dels valors que pot prendre \\(X\\) és sempre la mateixa, que és una altra manera de dir que \\(X\\) i \\(Y\\) són independents. Per tant, els contrastos d’homogeneïtat són formalment contrastos d’independència, però difereixen en la forma com s’hi recull la mostra: En un contrast d’independència, la mostra és transversal: es pren una mostra de la població on estan definides \\(X\\) i \\(Y\\) i es mesuren les dues variables sobre els individus de la mostra. En un contrast d’homogeneïtat, la mostra és estratificada: es classifiquen els individus de la població segons el seu valor de \\(X\\), es pren una mostra independent de cada una d’aquestes classes definides pels valors de \\(X\\), amb totes aquestes mostres de mides fixades d’antuvi, i es mesura \\(Y\\) sobre tots aquests individus. 8.1 Test \\(\\chi^2\\) d’independència Suposem que tenim dues variables aleatòries \\(X\\) i \\(Y\\) que només poden prendre valors \\(X_{1},\\ldots,X_{s}\\) i \\(Y_{1},\\ldots,Y_{t}\\), respectivament. Les considerarem qualitatives i direm a aquests \\(X_i\\) i \\(Y_j\\) els seus nivells, però poden ser ordinals o quantitatives discretes. L’important és que només poden prendre un conjunt finit de valors cadascuna. Volem contrastar si \\(X\\) i \\(Y\\) són independents, és a dir \\[ \\begin{array}{l} \\hspace{-2ex}P(X=X_i\\mid Y=Y_j)=P(X=X_i\\mid Y=Y_{j&#39;})=P(X=X_i)\\text{ per a tots $i,j,j&#39;$}\\\\ \\hspace{-2ex}P(Y=Y_j\\mid X=X_i)=P(Y=Y_j\\mid X=X_{i&#39;})=P(Y=Y_j)\\text{ per a tots $i,i&#39;,j$} \\end{array} \\] o equivalentment \\[ P(X=X_i,Y=Y_j)=P(X=X_i)\\cdot P(Y=Y_j)\\text{ per a tots $i,j$} \\] El contrast serà \\[ \\left\\{\\begin{array}{l} H_0: \\mbox{$X$ i $Y$ són independents}\\\\ H_1: \\mbox{$X$ i $Y$ no són independents} \\end{array} \\right. \\] Sovint en lloc de dir que “\\(X\\) i \\(Y\\) no són independents” o “\\(X\\) i \\(Y\\) són dependents”, es diu que “hi ha associació entre \\(X\\) i \\(Y\\)”. Recordau que, en general, la hipòtesi nul·la representa, en el context del contrast, que “no passa res”. En els contrastos d’independència això correspon a “no hi ha cap relació entre \\(X\\) i \\(Y\\)”, és a dir, que són independents. Fixem-nos ara que la caracterització de la independència com a \\[ P(X=X_i,Y=Y_j)=P(X=X_i)\\cdot P(Y=Y_j)\\text{ per a tots $i,j$} \\] ens permet entendre el contrast d’independència com un contrast de bondat d’ajust, amb hipòtesi nul·la \\[ H_0: P(X=X_i,Y=Y_j)=P(X=X_i)\\cdot P(Y=Y_j)\\text{ per a tots $i,j$} \\] i hipòtesi alternativa \\[ H_1: P(X=X_i,Y=Y_j)\\neq P(X=X_i)\\cdot P(Y=Y_j)\\text{ per a alguns $i,j$} \\] De la mateixa manera que el contrari d’aprovar totes les assignatures no és suspendre totes les assignatures, sinó suspendre’n almenys una, el contrari de per a tots els valors de \\(i\\) i \\(j\\), \\(P(X=X_i,Y=Y_j)=P(X=X_i)\\cdot P(Y=Y_j)\\) no és per a tots els valors de \\(i\\) i \\(j\\), \\(P(X=X_i,Y=Y_j)\\neq P(X=X_i)\\cdot P(Y=Y_j)\\) sinó per almenys un \\(i\\) i un \\(j\\), \\(P(X=X_i,Y=Y_j)\\neq P(X=X_i)\\cdot P(Y=Y_j)\\) Hi farem servir un test \\(\\chi^2\\). El contrast d’igualtat de dues proporcions és un cas particular de contrast d’independència: que l’esdeveniment “Èxit” sigui independent de la variable. Exemple 8.1 En un estudi es volgué determinar si hi ha associació entre l’hàbit de fumar i patir tos nocturna entre els nins. S’entrevistà una mostra de 2847 nins i nines de 12 anys i es recollí informació sobre el seu estatus de fumador i si patien de tos nocturna o no. S’obtingueren els resultats següents: \\[ \\begin{array}{l} \\hphantom{No fumador ocasional un }\\text{Fumador}\\\\ \\begin{array}{l|ccc|c} &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} &amp; \\text{Total} \\\\\\hline \\text{Tos} &amp; 266 &amp; 395 &amp; 80 &amp; 741\\\\ \\text{No tos}&amp; 1037 &amp; 977 &amp; 92 &amp; 2106\\\\\\hline \\text{Total} &amp;1303 &amp; 1372 &amp; 172 &amp; 2847 \\end{array} \\end{array} \\] En aquesta situació: Variables aleatòries d’interès: \\(X\\): “Prenem un nin i anotam si té tos nocturna o no” \\(Y\\): “Prenem un nin i anotam el seu estatus de fumador” Contrast: \\[ \\left\\{\\begin{array}{l} H_0: \\mbox{$X$ i $Y$ són independents}\\\\ H_1: \\mbox{Hi ha associació entre $X$ i $Y$} \\end{array} \\right. \\] Anem a traduir ara un contrast d’independència com l’anterior en un contrast d’igualtat de distribucions de probabilitat. Diguem \\[ \\begin{array}{c} p_{ij}=P(X=X_i, Y=Y_j)\\\\ p_i=P(X=X_i)\\quad q_{j}=P(Y=Y_j) \\end{array} \\] El test d’independència equival a contrastar \\[ \\left\\{ \\begin{array}{ll} H_0: p_{ij}=p_i \\cdot q_j \\text{ per a tots } 1\\leqslant i \\leqslant s,\\ 1\\leqslant j\\leqslant t \\\\ H_1: \\mbox{No totes aquestes igualtats són vertaderes} \\end{array} \\right. \\] El decidirem amb un test \\(\\chi^2\\). Els passos concrets seran els següents: Mesuram les variables aleatòries sobre una mostra aleatòria simple de \\(n\\) subjectes, i obtenim una taula de contingència de freqüències absolutes com la següent (on cada \\(n_{i,j}\\) indica el nombre de subjectes amb \\(X=X_i\\) i \\(Y=Y_j\\); \\(n_{i\\bullet}\\) indica el nombre de subjectes amb \\(X=X_i\\), és a dir, el nombre total de subjectes de la filera \\(i\\); i \\(n_{\\bullet j}\\) indica el nombre de subjectes amb \\(Y=Y_j\\), és a dir, el nombre total de subjectes de la columna \\(j\\)): \\[ \\begin{array}{c|cccccc|c} X\\backslash Y &amp; Y_1 &amp; Y_2 &amp; \\ldots &amp; Y_j &amp; \\ldots &amp; Y_t &amp; \\text{Total} \\\\ \\hline X_1 &amp; n_{11} &amp; n_{12} &amp; \\ldots &amp; n_{1j} &amp; \\ldots &amp; n_{1t} &amp; n_{1 \\bullet} \\\\ X_2 &amp; n_{21} &amp; n_{22} &amp; \\ldots &amp; n_{2j} &amp; \\ldots &amp; n_{2t} &amp; n_{2 \\bullet} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ X_i &amp; n_{i1} &amp; n_{i2} &amp; \\ldots &amp; n_{ij} &amp; \\ldots &amp; n_{it} &amp; n_{i \\bullet} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ X_s &amp; n_{s1} &amp; n_{s2} &amp; \\ldots &amp; n_{sj} &amp; \\ldots &amp; n_{st} &amp; n_{s \\bullet} \\\\ \\hline \\text{Total} &amp; n_{\\bullet 1} &amp; n_{\\bullet 2} &amp; \\ldots &amp; n_{\\bullet j} &amp; \\ldots &amp; n_{\\bullet t} &amp; n \\end{array} \\] Estimam cada \\(p_i\\) amb \\({n_{i\\bullet}}/{n}\\) i cada \\(q_j\\) amb \\({n_{\\bullet j}}/{n}\\) Si les variables aleatòries fossin independents, les probabilitats teòriques serien \\[ p_{ij}=\\frac{n_{i\\bullet}}{n}\\cdot \\frac{n_{\\bullet j}}{n} \\] i per tant la freqüència esperada de cada parell \\((X_i,Y_j)\\) si les variables aleatòries són independents és \\[ esp_{ij}=p_{ij}\\cdot n=\\dfrac{n_{i\\bullet}}{n}\\cdot \\dfrac{n_{\\bullet j}}{n}\\cdot n=\\dfrac{n_{i\\bullet}\\cdot n_{\\bullet j}}{n} \\] L’estadístic del test \\(\\chi^2\\) és doncs \\[ \\chi^2=\\sum\\limits_{i=1}^s\\sum\\limits_{j=1}^t \\frac{ ( n_{ij}- esp_{ij})^2 } {esp_{ij}} \\] Arribats en aquest punt, el Teorema 7.1 ens diu que: Teorema 8.1 Suposem que \\(n\\) és gran (diguem \\(n\\geqslant 30\\)) i que se satisfà la Regla de Cochran: per a cada \\(i,j\\), \\[ esp_{ij}=\\frac{n_{i\\bullet}\\cdot n_{\\bullet j}}{n}\\geqslant 5 \\] Aleshores, si les variables \\(X\\) i \\(Y\\) són independents, l’estadístic \\[ \\chi^2=\\sum\\limits_{i=1}^s\\sum\\limits_{j=1}^t \\frac{ ( n_{ij}- esp_{ij})^2 } {esp_{ij}} \\] segueix (aproximadament) una llei \\(\\chi^2\\) amb \\((s-1) \\cdot (t -1)\\) graus de llibertat. D’on surt aquest nombre de graus de llibertat? Vegem, hem estimat les \\(p_i\\) i les \\(q_j\\), i per tant hem estimat \\(s+t-2\\) paràmetres (fixau-vos que en realitat només hem estimat \\(p_1,\\ldots,p_{s-1}\\) i \\(q_1,\\ldots,q_{t-1}\\), ja que \\(p_s\\) i \\(q_t\\) queden fixats per la regla “suma de probabilitats igual a 1”). Per tant el nombre de graus de llibertat és el nombre de classes, \\(st\\) (una per cada combinació \\((X_i,Y_j)\\) d’un possible valor de \\(X\\) i un possible valor de \\(Y\\)) menys 1 i menys el nombre de paràmetres estimats: \\[ \\mbox{graus de llibertat}=st-1-(s+t-2)=(s-1)(t-1) \\] Fixau-vos que el Teorema 8.1 és un cas particular del Teorema 7.1, i per tant les hipòtesis per poder emprar el test \\(\\chi^2\\) en aquest context són les mateixes que en el cas general: mostra de mida com a mínim 30 i totes les freqüències esperades més grans o iguals que 5. Si \\(\\chi_0^2\\) és el valor que pren l’estadístic de contrast a la nostra mostra, el p-valor del contrast és \\[ \\text{p-valor}=P(\\chi_{(s-1) \\cdot (t -1)}^2\\geqslant \\chi_0^2) \\] Exemple 8.2 Continuem amb l’Exemple 8.1. Ja teníem les variables i el contrast. Les freqüències observades són \\[ \\begin{array}{l} \\hphantom{No fumador ocasional un }\\text{Fumador}\\\\ \\begin{array}{l|ccc|c} &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} &amp; \\text{Total} \\\\\\hline \\text{Tos} &amp; 266 &amp; 395 &amp; 80 &amp; 741\\\\ \\text{No tos}&amp; 1037 &amp; 977 &amp; 92 &amp; 2106\\\\\\hline \\text{Total} &amp;1303 &amp; 1372 &amp; 172 &amp; 2847 \\end{array} \\end{array} \\] La mida de la mostra és gran. Calculem les freqüències esperades, per veure si són totes més grans o iguals que 5. \\[ \\begin{array}{l|ccc} &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} \\\\\\hline \\text{Tos} &amp; 741\\cdot 1303/2847 &amp; 741\\cdot 1372/2847 &amp; 741\\cdot 172/2847 \\\\ \\text{No tos}&amp; 2106\\cdot 1303/2847 &amp; 2106\\cdot 1372/2847 &amp; 2106\\cdot 172/2847 \\end{array} \\] Operant: \\[ \\begin{array}{l|ccc} &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} \\\\\\hline \\text{Tos} &amp; 339.14 &amp; 357.1 &amp; 44.77 \\\\ \\text{No tos}&amp; 963.86 &amp; 1014.9 &amp; 127.23 \\end{array} \\] Són totes prou grans. Per tant l’estadístic de contrast \\[ \\chi^2=\\sum_{i=1}^s\\sum_{j=1}^t \\frac{(n_{ij}-esp_{ij})^2}{esp_{ij}} \\] (on \\(s=2\\) i \\(t=3\\)) seguirà una distribució \\(\\chi^2_{(s-1)(t-1)}=\\chi^2_2\\). Valor de l’estadístic de contrast: \\[ \\chi_0^2=\\frac{(266-339.14)^2}{339.14}+\\frac{(395-357.1)^2}{357.1}+\\cdots=64.25 \\] Calculem-lo amb R: Entram la taula: Taula=matrix(c(266,395,80,1037,977,92),nrow=2,byrow=TRUE) Taula ## [,1] [,2] [,3] ## [1,] 266 395 80 ## [2,] 1037 977 92 n=sum(Taula) n ## [1] 2847 Les \\(n_{i\\bullet}\\) són les sumes de les fileres: n.i.bolla=rowSums(Taula) n.i.bolla ## [1] 741 2106 Les \\(n_{\\bullet j}\\) són les sumes de les columnes: n.bolla.j=colSums(Taula) n.bolla.j ## [1] 1303 1372 172 La matriu de les \\((n_{i\\bullet}n_{\\bullet j}/n)_{i,j}\\) s’obté fent el producte matricial \\[ \\begin{array}{l} \\displaystyle \\frac{1}{n}\\left(\\begin{array}{c} n_{1\\bullet}\\\\ n_{2\\bullet}\\\\ \\vdots\\\\ n_{s\\bullet} \\end{array}\\right)\\cdot \\big(n_{\\bullet 1},n_{\\bullet 2},\\ldots,n_{\\bullet t}\\big)\\\\ \\qquad \\displaystyle = \\left( \\begin{array}{cccc} \\frac{n_{1\\bullet}n_{\\bullet 1}}{n} &amp; \\frac{n_{1\\bullet}n_{\\bullet 2}}{n} &amp; \\ldots &amp; \\frac{n_{1\\bullet}n_{\\bullet t}}{n}\\\\ \\frac{n_{2\\bullet}n_{\\bullet 1}}{n} &amp; \\frac{n_{2\\bullet}n_{\\bullet 2}}{n} &amp; \\ldots &amp; \\frac{n_{2\\bullet}n_{\\bullet t}}{n}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{n_{s\\bullet}n_{\\bullet 1}}{n} &amp; \\frac{n_{s\\bullet}n_{\\bullet 2}}{n} &amp; \\ldots &amp; \\frac{n_{s\\bullet}n_{\\bullet t}}{n} \\end{array} \\right) \\end{array} \\] Freqs.Esp=(1/n)*n.i.bolla%*%t(n.bolla.j) Freqs.Esp ## [,1] [,2] [,3] ## [1,] 339.137 357.0959 44.76712 ## [2,] 963.863 1014.9041 127.23288 L’estadístic de contrast: X2=sum((Taula-Freqs.Esp)^2/Freqs.Esp) X2 ## [1] 64.24672 p-valor: \\(P(\\chi^2_2\\geqslant 64.25)=\\texttt{1-pchisq(64.25,2)}=1.1\\cdot 10^{-14}\\) Conclusió: Hem trobat evidència estadísticament significativa que hi ha associació entre l’estatus de fumador d’un nin i que pateixi tos nocturna (test \\(\\chi^2\\), p-valor 10-14). Podem efectuar un test \\(\\chi^2\\) d’independència aplicant la funció chisq.test a la taula de freqüències absolutes: chisq.test(Taula) ## ## Pearson&#39;s Chi-squared test ## ## data: Taula ## X-squared = 64.247, df = 2, p-value = 1.119e-14 Exemple 8.3 Volem contrastar si hi ha associació entre el grau de compliment del calendari de vacunacions (CCV) dels fills i el nivell sociocultural dels pares. La taula següent mostra la classificació d’una mostra de 444 nins i nines segons el seu CCV i el nivell sociocultural dels pares: \\[ \\begin{array}{l} \\hphantom{Compli CCV BaixBB}\\text{Nivell sociocultural}\\\\ \\begin{array}{r|ccc|l} \\text{Compliment CCV} &amp;\\text{Baix}&amp; \\text{Mitjà} &amp;\\text{Alt} &amp;\\text{Total}\\\\ \\hline \\text{Baix} &amp;38 &amp;76 &amp;79 &amp; 193\\\\ \\text{Mitjà-baix}&amp; 2&amp; 41&amp; 92 &amp; 135\\\\ \\text{Mitjà-alt}&amp; 2&amp; 21&amp; 50 &amp; 73\\\\ \\text{Alt}&amp; 0 &amp;12&amp; 31 &amp; 43\\\\ \\hline \\text{Total} &amp; 42 &amp; 150 &amp; 252 &amp; 444 \\end{array} \\end{array} \\] Variable aleatòries d’interès: \\(X\\): “Prenem un nin i anotam el seu grau de compliment del CCV” \\(Y\\): “Prenem un nin i anotam el nivell sociocultural dels pares” Contrast: \\[ \\left\\{\\begin{array}{l} H_0: \\mbox{$X$ i $Y$ són independents}\\\\ H_1: \\mbox{Hi ha associació entre $X$ i $Y$} \\end{array} \\right. \\] Fem un test \\(\\chi^2\\) amb R: TaulaCCV=matrix(c(38,76,79,2,41,92,2,21,50,0,12,31), nrow=4, byrow=TRUE) chisq.test(TaulaCCV) ## Warning in chisq.test(TaulaCCV): Chi-squared approximation may be incorrect ## ## Pearson&#39;s Chi-squared test ## ## data: TaulaCCV ## X-squared = 56.378, df = 6, p-value = 2.441e-10 R ens avisa que no es compleixen les condicions per usar el test \\(\\chi^2\\); segurament hi ha freqüències esperades petites. Vegem-ho, i aprofitarem per comprovar-ho amb R: Les \\(n_{i\\bullet}\\) són les sumes de les fileres: Freq.CCV=rowSums(TaulaCCV) Freq.CCV ## [1] 193 135 73 43 Les \\(n_{\\bullet j}\\) són les sumes de les columnes: Freq.NSC=colSums(TaulaCCV) Freq.NSC ## [1] 42 150 252 La matriu de les \\(n_{i\\bullet}n_{\\bullet j}/n\\): Freqs.Esp=(1/sum(TaulaCCV))*Freq.CCV%*%t(Freq.NSC) Freqs.Esp ## [,1] [,2] [,3] ## [1,] 18.256757 65.20270 109.54054 ## [2,] 12.770270 45.60811 76.62162 ## [3,] 6.905405 24.66216 41.43243 ## [4,] 4.067568 14.52703 24.40541 Efectivament, l’entrada (4,1) és menor que 5. Farem servir el mètode de Montecarlo: set.seed(42) chisq.test(TaulaCCV,simulate.p.value=TRUE,B=5000) ## ## Pearson&#39;s Chi-squared test with simulated p-value (based on 5000 ## replicates) ## ## data: TaulaCCV ## X-squared = 56.378, df = NA, p-value = 2e-04 Conclusió: Hem trobat evidència estadísticament significativa que hi ha associació entre el grau de compliment del calendari de vacunacions d’un nin i el nivell sociocultural dels seus pares (test \\(\\chi^2\\) de Montecarlo, p-valor 0.0002). 8.2 Test \\(\\chi^2\\) d’homogeneïtat En un contrast d’homogeneïtat de proporcions, tenim una variable aleatòria \\(X\\) que pot prendre els valors \\(X_1,\\ldots,X_k\\) i una variable aleatòria de Bernoulli \\(Y\\) que pot prendre els valors “Èxit” i “Fracàs”. Per a cada \\(i=1,\\ldots,k\\), diguem \\(p_i=P(Y=\\text{Èxit}|X=X_i)\\). És a dir, \\(p_i\\) és la probabilitat que \\(Y\\) doni Èxit sobre un individu per al qual \\(X\\) val \\(X_i\\). Volem contrastar si aquestes probabilitats \\(p_1,\\ldots,p_k\\) són totes iguals o no. El contrast és, doncs, \\[ \\left\\{ \\begin{array}{ll} H_0: \\text{ $p_1=\\cdots=p_k$}\\\\ H_1: \\text{ No totes les $p_i$ són iguals} \\end{array} \\right. \\] Per efectuar el contrast, per a cada \\(i=1,\\ldots,k\\) prenem una mostra aleatòria simple d’individus per als quals \\(X\\) val \\(X_i\\), independents cada una de les altres. Com que dir que \\[ P(Y=\\text{Èxit}|X=X_1)=\\cdots=P(Y=\\text{Èxit}|X=X_k) \\] és exactament el mateix que dir que \\(X\\) i \\(Y\\) són independents, el contrast d’homogeneïtat que hem plantejat és equivalent a \\[ \\left\\{ \\begin{array}{ll} H_0: \\text{ $X$ i $Y$ són independents}\\\\ H_1: \\text{ $X$ i $Y$ no són independents} \\end{array} \\right. \\] Però el disseny de l’experiment és diferent: En un contrast d’independència prenem una mostra transversal de la població, sense controlar el nombre de subjectes que hi surten de cada nivell \\(X_i\\). En un contrast d’homogeneïtat prenem una mostra estratificada, és a dir, una mostra independent de cada nivell \\(X_i\\) de \\(X\\), triant a priori el nombre de subjectes de cada un d’aquests nivells; per exemple, imposant que totes aquestes mostres tenguin la mateixa mida, o que la mida de cada mostra sigui proporcional al nombre d’individus de la població sobre els que \\(X\\) val \\(X_i\\). Exemple 8.4 Volem comparar 3 tractaments per baixar el nivell de colesterol, A, B i C, per veure si tenen taxes d’èxit diferents. En una primera aproximació, entendrem com a “Èxit” que el nivell de colesterol baixi dels 240 mg/dl a les 5 setmanes de tractament. En un assaig clínic, assignam cada tractament a 100 pacients amb colesterol alt escollits de manera independent uns dels altres, i anotam si el tractament ha tengut èxit. Els resultats són \\[ \\begin{array}{l} \\hphantom{FracasAAa}\\text{Tractament}\\\\ \\begin{array}{l|ccc|c} &amp; A &amp; B &amp; C &amp; \\text{Total} \\\\\\hline \\text{Èxit} &amp; 43 &amp; 61 &amp; 53 &amp; 157\\\\ \\text{Fracàs} &amp; 57 &amp; 39 &amp; 47 &amp; 143\\\\\\hline \\text{Total} &amp; 100 &amp; 100 &amp; 100 &amp; 300 \\end{array} \\end{array} \\] Volem contrastar si la probabilitat d’èxit de cada tractament és la mateixa o no. Fixem-nos que és un contrast d’homogeneïtat, perquè hem pres una mostra de mida prefixada de cada tractament. Seria un contrast d’independència si haguéssim pres 300 malalts d’hipercolesterolèmia que estiguessin prenent algun d’aquests tractaments i haguéssim anotat de cada un quin tractament pren i si ha tengut èxit. Amb una mostra transversal obtinguda d’aquesta darrera manera, hi havia el risc que algun tractament fos seguit per molt pocs, o fins i tot cap, malalt. Variables aleatòries: En realitat, aquí tendríem dues interpretacions correctes. Per una banda, la usual, en termes de dues variables mesurades sobre els mateixos individus: \\(X\\): “Prenem un pacient i anotam quin tractament segueix” \\(Y\\): “Prenem un pacient i anotam si al cap de 5 setmanes el seu nivell de colesterol està per davall dels 240 mg/dl” Però d’altra banda, tal i com hem pres la mostra, seria perfectament vàlid entendre que les variables aleatòries en joc són: \\(Y_A\\): “Prenem un pacient tractat amb A i anotam si al cap de 5 setmanes el seu nivell de colesterol està per davall dels 240 mg/dl” \\(Y_B\\): “Prenem un pacient tractat amb B i anotam si al cap de 5 setmanes el seu nivell de colesterol està per davall dels 240 mg/dl” \\(Y_C\\): “Prenem un pacient tractat amb C i anotam si al cap de 5 setmanes el seu nivell de colesterol està per davall dels 240 mg/dl” En aquest cas, les variables estan definides sobre poblacions diferents. Dos comentaris: Als contrastos d’independència com el de l’Exemple 8.1, la segona interpretació és incorrecta, ja que allà sí que preníem una mostra transversal de nins i sobre cada un d’ells miràvem dues coses. En canvi, aquí podem entendre que prenem malalts de tres poblacions diferents i mesuram sobre ells una cosa, la qual cosa defineix tres variables diferents. Si volguéssim comparar taxes d’èxit de coses diferents sobre poblacions diferents per mitjà d’un contrast d’homogeneïtat, la interpretació en termes de dues variables \\(X,Y\\) mesurades sobre una mateixa població quedaria una mica artificial. Imaginau per exemple que us deman que contrasteu si són iguals o diferents les proporcions de Estudiants de Matemàtiques I que enguany aprovaren l’assignatura Malalts d’hipercolesterolèmia sobre els quals el tractament A és efectiu Nins fumadors ocasionals amb tos nocturna A veure com vos ho faríeu per plantejar-ho en termes de dues variables, una \\(X\\) que digui què miram i una \\(Y\\) que doni “Èxit” o “Fracàs”, i que no us quedàs un nyap de redacció. Contrast: Si diem \\(p_A\\), \\(p_B\\) i \\(p_C\\) a les probabilitats que un pacient tractat amb A, B o C, respectivament, davalli dels 240 mg/dl de colesterol al cap de 5 setmanes de tractament, \\[ \\left\\{\\begin{array}{l} H_0: p_A=p_B=p_C\\\\ H_1: \\mbox{No és veritat que $p_A=p_B=p_C$} \\end{array}\\right. \\] Emprarem un test \\(\\chi^2\\): TaulaC=matrix(c(43,61,53,57,39,47), nrow=2 ,byrow=TRUE) TaulaC ## [,1] [,2] [,3] ## [1,] 43 61 53 ## [2,] 57 39 47 chisq.test(TaulaC) ## ## Pearson&#39;s Chi-squared test ## ## data: TaulaC ## X-squared = 6.5209, df = 2, p-value = 0.03837 Conclusió: Hem trobat evidència significativa que els tres tractaments no tenen la mateixa taxa d’èxit (test \\(\\chi^2\\) d’homogeneïtat, p-valor 0.04). Ara seria necessari efectuar 3 contrastos de parelles de proporcions per trobar quines parelles de tractaments tenen taxes d’èxit diferents. Us ho deixam com a exercici. De la mateixa manera que les dues variables involucrades en un contrast d’independència podien tenir més de dos nivells, podem efectuar contrastos d’homogeneïtat en situacions més generals que la comparació de proporcions. Suposem doncs que tenim una variable aleatòria qualitativa \\(X\\) de nivells \\(X_1,\\ldots,X_k\\), i una variable aleatòria qualitativa \\(Y\\) de nivells \\(Y_1,\\ldots,Y_l\\), i volem contrastar si la probabilitat que \\(Y\\) prengui els seus diferents valors sobre un individu depèn o no del valor de \\(X\\) sobre aquest individu. És a dir, volem contrastar si \\(P(Y=Y_h|X=X_i)=P(Y=Y_h|X=X_j)\\) per a tots \\(i,j,h\\). Exemple 8.5 Tornem a la situació de l’Exemple 8.4. Volem comparar 3 tractaments, A, B i C, per baixar el nivell de colesterol, per veure si tenen taxes d’èxit diferents. Però ara, en lloc de considerar l’èxit com una variable binària (baixes dels 240 mg/dl o no) distingirem si al cap de 5 setmanes de tractament s’ha baixat dels 200 mg/dl (el nivell desitjable de colesterol), s’ha assolit un nivell entre 200 i 240 mg/dl (el nivell límit), o si no s’ha baixat de 240 (nivell alt). Les dades de l’estudi esmentat a l’Exemple 8.4 amb aquesta nova classificació dels resultats són: \\[ \\begin{array}{l} \\hphantom{200-240AAaa}\\text{Tractament}\\\\ \\begin{array}{r|ccc|c} \\text{Nivell} &amp; A &amp; B &amp; C &amp; \\text{Total} \\\\\\hline \\text{Desitjable} &amp; 12 &amp; 21 &amp; 13 &amp; 46\\\\ \\text{Límit} &amp; 31 &amp; 40 &amp; 40 &amp; 111\\\\ \\text{Alt} &amp; 57 &amp; 39 &amp; 47 &amp; 143 \\\\\\hline \\text{Total} &amp; 100 &amp; 100 &amp; 100 &amp; 300\\\\\\hline \\end{array} \\end{array} \\] Variables aleatòries: Com abans, tenim dues interpretacions correctes: \\(X\\): “Prenem un pacient i anotam quin tractament segueix” \\(Y\\): “Prenem un pacient i anotam al cap de 5 setmanes en quina classe està el seu nivell de colesterol” o \\(Y_A\\): “Prenem un pacient tractat amb A i anotam al cap de 5 setmanes en quina classe està el seu nivell de colesterol” \\(Y_B\\): “Prenem un pacient tractat amb B i anotam al cap de 5 setmanes en quina classe està el seu nivell de colesterol” \\(Y_C\\): “Prenem un pacient tractat amb C i anotam al cap de 5 setmanes en quina classe està el seu nivell de colesterol” : \\[ \\left\\{\\begin{array}{l} H_0: P(Y=L|X=T)=P(Y=L|X=T&#39;)\\\\ \\hphantom{H_0: }\\quad\\text{ per a cada nivell $L$ de colesterol}\\\\ \\hphantom{H_0: }\\quad \\text{ i cada parell de tractaments $T,T&#39;$}\\\\ H_1: \\mbox{Almenys una d&#39;aquestes igualtats és falsa} \\end{array}\\right. \\] És un test d’homogeneïtat, farem servir un test \\(\\chi^2\\): TaulaC2=matrix(c(12,21,13,31,40,40,57,39,47), nrow=3, byrow=TRUE) TaulaC2 ## [,1] [,2] [,3] ## [1,] 12 21 13 ## [2,] 31 40 40 ## [3,] 57 39 47 chisq.test(TaulaC2) ## ## Pearson&#39;s Chi-squared test ## ## data: TaulaC2 ## X-squared = 8.046, df = 4, p-value = 0.08991 Conclusió: No hem trobat evidència estadísticament significativa que sigui fals que A, B i C tenen el mateix efecte quan distingim tres classes de nivell de colesterol (test \\(\\chi^2\\) d’homogeneïtat, p-valor 0.09). La conclusió concreta ja dependria de si prenguéssim nivell de significació 0.05 o 0.1. 8.3 Test \\(\\chi^2\\) de tendència (Opcional) Un contrast de tendència és una generalització del contrast d’homogeneïtat de proporcions. En el contrast de tendència, tenim una variable aleatòria ordinal \\(X\\) de nivells ordenats \\(X_1&lt;\\cdots&lt; X_k\\), i una variable aleatòria Bernoulli \\(Y\\) de nivells “Èxit” i “Fracàs”. Diguem \\(p_i=P(Y=\\text{Èxit}|X=X_i)\\), per a tot \\(i\\). El contrast que volem realitzar és \\[ \\left\\{ \\begin{array}{ll} H_0: \\text{ $p_1=\\cdots=p_k$}\\\\ H_1: \\text{ $p_1\\leqslant\\cdots \\leqslant p_k$ i almenys una }\\\\ \\hphantom{H_1: } \\text{ d&#39;aquestes desigualtats és estricta} \\end{array} \\right. \\] S’efectua amb un test \\(\\chi^2\\) de Cochran-Armitage, una variant del test \\(\\chi^2\\) explicat a les seccions anteriors. Per utilitzar-lo, basta que la mostra total sigui gran (\\(\\geqslant 30\\)), no cal la condició de Cochran. (Si teniu curiositat sobre com es fa, podeu consultar la seva entrada de la Wikipedia) Amb R s’efectua amb la funció prop.trend.test, aplicada al vector de freqüències d’èxits i el vector de freqüències de cada nivell de \\(X\\). Exemple 8.6 Continuem amb l’Exemple 8.1. Recordem que hi volíem determinar si hi ha associació entre l’hàbit de fumar i patir tos nocturna entre els nins. Les dades recollides varen ser: \\[ \\begin{array}{l} \\hphantom{No fumador ocasional un }\\text{Fumador}\\\\ \\begin{array}{l|ccc|c} &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} &amp; \\text{Total} \\\\\\hline \\text{Tos} &amp; 266 &amp; 395 &amp; 80 &amp; 741\\\\ \\text{No tos}&amp; 1037 &amp; 977 &amp; 92 &amp; 2106\\\\\\hline \\text{Total} &amp;1303 &amp; 1372 &amp; 172 &amp; 2847\\\\ \\end{array} \\end{array} \\] Com que l’estatus de fumador és una variable ordinal i, naturalment, creiem que quant més se fuma, més probabilitat hi ha de patir de tos nocturna, ens pot interessar contrastar si la probabilitat de tos nocturna creix amb la freqüència de fumar. Variables d’interès: \\(X\\): “Prenem un nin i anotam el seu estatus de fumador”; la considerarem una variable ordinal amb nivells “No fumador” &lt; “Ocasional” &lt; “Regular” \\(Y\\): “Prenem un nin i anotam si té tos nocturna o no” Contrast: Si diem \\(p_N\\), \\(p_O\\) i \\(p_R\\) a la probabilitat que tengui tos nocturna un nin no fumador, un nin fumador ocasional i un nin fumador regular, respectivament, \\[ \\left\\{ \\begin{array}{ll} H_0: \\text{ $p_N=p_O=p_R$}\\\\ H_1: \\text{ $p_N\\leqslant p_O \\leqslant p_R$ i $p_N&lt;p_R$} \\end{array} \\right. \\] Fixau-vos que, a la hipòtesi alternativa, dir “\\(p_N\\leqslant p_O \\leqslant p_R\\) i almenys una d’aquestes desigualtats és estricta” és equivalent a dir “\\(p_N\\leqslant p_O \\leqslant p_R\\) i \\(p_N&lt;p_R\\)” només que aquesta darrera reformulació és més curta. Emprarem un test \\(\\chi^2\\) de tendència: Tos=c(266,395,80) Fum=c(1303,1372,172) prop.trend.test(Tos,Fum) ## ## Chi-squared Test for Trend in Proportions ## ## data: Tos out of Fum , ## using scores: 1 2 3 ## X-squared = 59.47, df = 1, p-value = 1.242e-14 Conclusió: Hem trobat evidència estadísticament significativa que la probabilitat de patir tos nocturna creix amb la freqüència de fumar (test \\(\\chi^2\\) de Cochran-Armitage, p-valor 10-14) 8.4 Test de la lliçó 8 (1) En un contrast d’independència, quina és la hipòtesi alternativa? Que les dues variables són independents Que hi ha associació entre les dues variables Que les dues variables tenen distribucions diferents Que les dues variables podrien ser dependents Que les dues variables depenen d’una tercera (2) Perquè el test khi quadrat per contrastar la independència de dues variables sigui vàlid, és necessari que (marcau totes les continuacions correctes): Totes les freqüències esperades siguin més grans o iguals que 5 Totes les freqüències observades siguin més grans o iguals que 5 Les dues variables siguin independents La mida total de la mostra sigui com a mínim 30 La mida total de la mostra sigui com a mínim 100. Les dues variables siguin normals o les dues mostres siguin de mida \\(\\geqslant 40\\). Totes les altres respostes són incorrectes (3) Si fem un test khi quadrat per contrastar la independència d’una variable amb 5 possibles valors i una variable amb 3 possibles valors, a partir de la taula de contingència \\(3\\times 5\\), quants graus de llibertat tendrà l’estadístic de contrast que hi hem d’emprar? 15 14 13 12 Cap dels nombres anteriors (4) Quina o quines de les afirmacions següents sobre un test khi quadrat d’independència són vertaderes? S’hi comparen les freqüències observades dels valors de cada variable amb les seves freqüències esperades si les variables fossin independents S’hi comparen les freqüències observades de cada parella de valors de les variables, un de cada variable, amb les seves freqüències esperades si les variables fossin independents S’hi comparen les freqüències observades dels valors de cada variable amb les seves freqüències esperades si les variables fossin dependents S’hi comparen les freqüències observades de cada parella de valors, un de cada variable, de cada variable amb les seves freqüències esperades si les variables fossin dependents És un cas particular de test khi quadrat de bondat d’ajust És un cas particular de test khi quadrat de comparació de dues proporcions (5) Volem contrastar la independència de dues variables de Bernoulli a partir de la taula següent: \\[ \\begin{array}{l} \\hphantom{\\textbf{Variable 2}}\\qquad \\textbf{Variable 1}\\\\ \\begin{array}{l|cc|c} \\textbf{Variable 2} &amp; \\text{Èxit} &amp; \\text{Fracàs} &amp; \\text{Total}\\\\\\hline \\text{Èxit} &amp; 100 &amp; 300 &amp; 400\\\\ \\text{Fracàs} &amp; 400 &amp; 4200 &amp; 4600\\\\ \\hline \\text{Total} &amp; 500 &amp; 4500 &amp; 5000 \\end{array} \\end{array} \\] Quina de les afirmacions següents és correcta? Si les dues variables fossin independents, esperaríem que les quatre entrades de la taula central fossin iguals Si hi hagués associació entre les dues variables, esperaríem que les quatre entrades de la taula central fossin iguals Si les dues variables fossin independents, esperaríem que no hi hagués casos discordants Si hi hagués associació entre les dues variables, esperaríem que no hi hagués casos discordants Si les dues variables fossin independents, esperaríem que l’entrada corresponent a (Èxit,Èxit) fos 40 Si hi hagués associació entre les dues variables, esperaríem que l’entrada corresponent a (Èxit,Èxits) fos 40 Totes les altres respostes són incorrectes (6) A partir de la taula de la pregunta anterior (marcau totes les continuacions correctes) Que existeixi o no associació entre la variable 1 i la variable 2 es pot contrastar amb un test khi quadrat Que existeixi o no associació entre la variable 1 i la variable 2 es pot contrastar amb un test de McNemar Que existeixi o no associació entre la variable 1 i la variable 2 es pot contrastar amb un test de Fisher Que la probabilitat d’èxit de les dues variables sigui la mateixa o no es pot contrastar amb un test khi quadrat Que la probabilitat d’èxit de les dues variables sigui la mateixa o no es pot contrastar amb un test de McNemar Que la probabilitat d’èxit de les dues variables sigui la mateixa o no es pot contrastar amb un test de Fisher Totes les altres continuacions són incorrectes (7) Quina de les afirmacions següents és vertadera? La diferència entre un contrast d’independència i un d’homogeneïtat està en la hipòtesi nul.la: que les variables siguin independents al contrast d’independència i que siguin homogènies al contrast d’homogeneïtat La diferència entre un contrast d’independència i un d’homogeneïtat està en la hipòtesi alternativa: que hi hagi associació entre les variables al contrast d’independència i que hi hagi heterogeneïtat entre les variables al contrast d’homogeneïtat La diferència entre un contrast d’independència i un d’homogeneïtat està en com prenem les mostres: transversal al contrast d’independència i estratificada al contrast d’homogeneïtat La diferència entre un contrast d’independència i un d’homogeneïtat està en com prenem les mostres: transversal al contrast d’homogeneïtat i estratificada al contrast d’independència La diferència entre un contrast d’independència i un d’homogeneïtat està en el nombre de graus de llibertat de l’estadístic: si les variables tenen \\(s\\) nivells i \\(t\\) nivells, respectivament, al d’independència hi empram \\((s-1)(t-1)\\) graus de llibertat i al d’homogeneïtat n’hi empram \\(st-1\\) Cap de les altres respostes és correcta (8) Per contrastar si el percentatge de sanitaris infectats amb COVID-19 és el mateix a les diferents illes balears, prenem una mostra formada per 100 sanitaris de Mallorca, 50 sanitaris de Menorca i 50 sanitaris de les Pitiüses, i els fem un test d’anticossos per veure si han estat infectats o no. Marcau l’afirmació correcta: Aquest contrast és d’independència, perquè la mostra és transversal Aquest contrast no és d’homogeneïtat, perquè les mostres de les tres illes no tenen la mateixa mida Aquest contrast no és d’homogeneïtat, perquè les mostres de les tres illes no s’adapten a les proporcions que representen les diferents illes en el total de les Balears Aquest contrast no és d’independència, perquè les mostres de les tres illes no tenen la mateixa mida Aquest contrast és d’homogeneïtat perquè hem pres una mostra específica de cada illa Aquest contrast és d’homogeneïtat perquè la mostra és transversal Aquest contrast no és ni d’independència ni homogeneïtat Cap de les altres respostes és correcta (9) Per contrastar si el percentatge de sanitaris infectats amb COVID-19 és el mateix a les diferents illes balears, prenem una mostra formada per 50 sanitaris de Mallorca, 50 sanitaris de Menorca i 50 sanitaris de les Pitiüses, i els fem un test d’anticossos per veure si han estat infectats o no. Marcau l’afirmació correcta: Aquest contrast és d’independència, perquè la mostra és transversal Aquest contrast és d’independència, perquè les mostres de les tres illes tenen la mateixa mida Aquest contrast no és d’homogeneïtat, perquè les mostres de les tres illes no s’adapten a les proporcions que representen les diferents illes en el total de les Balears Aquest contrast és d’homogeneïtat perquè hem pres una mostra específica de cada illa Aquest contrast és d’homogeneïtat perquè la mostra és transversal Aquest contrast és d’homogeneïtat, perquè les mostres de les tres illes tenen la mateixa mida Aquest contrast no és ni d’independència ni homogeneïtat Cap de les altres respostes és correcta (10) Per contrastar si el percentatge de sanitaris infectats amb COVID-19 és el mateix a les diferents illes balears, prenem una mostra formada per 150 sanitaris extreta del llistat de tots el personal sanitari dels hospitals de les Balears, a continuació miram a quina illa treballen i els fem un test d’anticossos per veure si han estat infectats o no. Per casualitat, ens hi surten 50 de Mallorca, 50 de Menorca i 50 d’Eivissa/Formentera. Marcau l’afirmació correcta: Aquest contrast és d’independència, perquè la mostra és transversal Aquest contrast és d’independència, perquè les mostres de les tres illes tenen la mateixa mida Aquest contrast no és d’homogeneïtat, perquè les mostres de les tres illes no s’adapten a les proporcions que representen les diferents illes en el total de les Balears Aquest contrast és d’homogeneïtat perquè la mostra és transversal Aquest contrast és d’homogeneïtat, perquè les mostres de les tres illes tenen la mateixa mida Aquest contrast no és ni d’independència ni homogeneïtat Cap de les altres respostes és correcta "],
["chap-ED.html", "Tema 9 Introducció a l’estadística multidimensional 9.1 Poblacions: vectors aleatoris 9.2 Estadística descriptiva: Mostres 9.3 Test de la lliçó 9", " Tema 9 Introducció a l’estadística multidimensional En general, les dades que es recullen en experiments són multidimensionals: mesuram diverses variables aleatòries sobre una mateixa mostra d’individus i organitzam aquesta informació en taules de dades on les fileres representen els individus observats i cada columna correspon a una variable diferent. És a dir, el que fem és avaluar un vector de variables aleatòries (en direm un vector aleatori) sobre els individus d’una població. En aquesta lliçó introduïm alguns conceptes nous sobre vectors de variables aleatòries i taules multidimensionals de dades quantitatives. 9.1 Poblacions: vectors aleatoris Un vector aleatori de dimensió \\(p\\) és un vector format per \\(p\\) variables aleatòries \\[ \\underline{X}=(X_1,X_2,\\ldots,X_p). \\] Una realització de \\(\\underline{X}\\) és un vector \\((x_1,\\ldots,x_p)\\) format pels valors de \\(X_1,\\ldots,X_p\\) sobre un individu. Una mostra de \\(\\underline{X}\\) és un conjunt de realitzacions. Usualment, organitzam una mostra de \\(\\underline{X}\\) per mitjà d’una taula de dades amb les columnes definides per les variables \\(X_1,\\ldots,X_p\\) i on cada filera és una realització d’aquestes variables, és a dir, un vector format pels valors de \\(X_1,\\ldots,X_p\\) sobre un individu de la mostra. Exemple 9.1 Si diem \\(\\textit{BMI}\\) a la variable aleatòria que dóna l’Índex de Massa Corporal (BMI) d’una persona, \\(C\\) a la variable aleatòria que dóna el nivell de colesterol en mg/dl d’una persona i \\(E\\) a la variable aleatòria que dóna l’edat d’una persona en anys, llavors \\[ \\underline{X}=(\\textit{BMI},C,E) \\] és un vector aleatori de dimensió 3. Cada cop que prenem una persona i n’anotam el BMI, el nivell de colesterol i l’edat i organitzam aquestes mesures en aquest ordre en un vector, obtenim una realització d’aquest vector aleatori \\(\\underline{X}\\). Llavors,una mostra de \\(\\underline{X}\\) serà un conjunt de vectors amb el BMI, el nivell de colesterol i l’edat d’un grup de persones de la població. Per exemple BMI C E 18.3 170 49 24.4 202 39 24.6 215 50 24.4 218 44 22.2 210 40 19.5 210 36 Siguin \\(\\underline{X}=(X_1,X_2,\\ldots,X_p)\\) un vector aleatori i \\(\\mu_i\\) i \\(\\sigma_i\\) la mitjana i la desviació típica, respectivament, de cada \\(X_i\\). El valor esperat, o vector de mitjanes, de \\(\\underline{X}\\) és el vector format pels valors esperats, o mitjanes, de les seves components: \\[ E(\\underline{X})=(\\mu_1,\\ldots,\\mu_p). \\] Per abreviar, de vegades indicarem aquest vector simplement amb \\(\\boldsymbol\\mu\\). El vector de variàncies de \\(\\underline{X}\\) és el vector format per les variàncies de les seves components: \\[ \\sigma^2(\\underline{X})=(\\sigma_1^2,\\ldots,\\sigma_p^2). \\] El vector de desviacions típiques de \\(\\underline{X}\\) és el vector format per les desviacions típiques de les seves components: \\[ \\sigma(\\underline{X})=(\\sigma_1,\\ldots,\\sigma_p). \\] 9.1.1 Covariància La covariància de dues variables \\(X\\) i \\(Y\\) és una mesura del seu comportament conjunt. Formalment, donades dues variables aleatòries \\(X,Y\\) de mitjanes \\(\\mu_X\\) i \\(\\mu_Y\\), respectivament, la seva covariància és \\[ \\sigma_{X,Y}=E((X-\\mu_X)\\cdot ( Y-\\mu_Y)). \\] És fàcil comprovar que \\[ \\sigma_{X,Y}=E(X\\cdot Y) -\\mu_X\\cdot \\mu_Y. \\] En efecte, \\[ \\begin{array}{rl} \\sigma_{X,Y} &amp; =E((X-\\mu_X) ( Y-\\mu_Y))= E(XY-\\mu_XY-\\mu_YX+\\mu_X\\mu_Y)\\\\ &amp; =E(XY)-\\mu_XE(Y)-\\mu_YE(X)+\\mu_X\\mu_Y\\\\ &amp;= E(XY)-\\mu_X\\mu_Y-\\mu_Y\\mu_X+\\mu_X\\mu_Y =E(XY)-\\mu_X\\mu_Y \\end{array} \\] La covariància de \\(X\\) i \\(Y\\) pot prendre qualsevol valor real (no com la variància, que sempre és positiva), i mesura el grau de variació conjunta de les variables en el sentit següent: \\(\\sigma_{X,Y}&gt;0\\) significa que Quan \\(X\\) és més gran en un individu 1 que en un individu 2, \\(Y\\) tendeix a també ser més gran en l’individu 1 que en l’individu 2 Quan \\(X\\) és més petit en un individu 1 que en un individu 2, \\(Y\\) tendeix a també ser més petit en l’individu 1 que en l’individu 2 \\(\\sigma_{X,Y}&lt;0\\) significa que Quan \\(X\\) és més gran en un individu 1 que en un individu 2, \\(Y\\) tendeix a ser més petit en l’individu 1 que en l’individu 2 Quan \\(X\\) és més petit en un individu 1 que en un individu 2, \\(Y\\) tendeix a ser més gran en l’individu 1 que en l’individu 2 \\(\\sigma_{X,Y}=0\\) significa que no hi ha cap tendència en aquest sentit El signe de la covariància reflecteix la “tendència del creixement conjunt” de les variables: Covariància positiva: Si \\(X\\) creix, \\(Y\\) tendeix a créixer, i si \\(X\\) decreix, \\(Y\\) tendeix a decréixer Covariància negativa: Si \\(X\\) creix, \\(Y\\) tendeix a decréixer, i si \\(X\\) decreix, \\(Y\\) tendeix a créixer Si \\(X\\) i \\(Y\\) són variables independents, la seva covariància es 0, perquè en aquest cas \\(E(X\\cdot Y) =\\mu_X\\mu_Y\\) i per tant \\[ \\sigma_{X,Y}=E(X\\cdot Y) -\\mu_X\\cdot \\mu_Y=\\mu_X\\cdot \\mu_Y-\\mu_X\\cdot \\mu_Y=0. \\] Ups, aquesta és nova! Per què, si \\(X\\) i \\(Y\\) són independents, \\(E(X\\cdot Y) =\\mu_X\\mu_Y\\)? Us ho demostrarem en el cas discret; l’argument en el cas continu és el mateix canviant sumatoris per integrals. \\[ \\begin{array}{rl} E(X\\cdot Y)\\!\\!\\! &amp;\\displaystyle =\\sum_{x\\in D_X,y\\in D_Y} xyP(X=x,Y=y)\\\\ &amp;\\displaystyle =\\sum_{x\\in D_X,y\\in D_Y} xyP(X=x)P(Y=y)\\\\ &amp;\\text{(per la independència de $X$ i $Y$)}\\\\ &amp;\\displaystyle =\\Big(\\sum_{x\\in D_X}xP(X=x)\\Big)\\Big(\\sum_{y\\in D_Y} yP(Y=y)\\Big)=E(X)E(Y) \\end{array} \\] És important remarcar que la igualtat \\(E(X\\cdot Y) =\\mu_X\\mu_Y\\) és equivalent a la igualtat \\(\\sigma(X+Y)^2 =\\sigma(X)^2+\\sigma(Y)^2\\) que dèiem al Tema 2 que satisfan les variables independents. En efecte \\[ \\begin{array}{l} \\sigma(X+Y)^2 -(\\sigma(X)^2+\\sigma(Y)^2)\\\\ \\quad = E((X+Y)^2)-E(X+Y)^2-(E(X^2)-E(X)^2+E(Y^2)-E(Y)^2)\\\\ \\quad = E(X^2+2XY+Y^2)-(E(X)+E(Y))^2\\\\ \\qquad\\qquad -E(X^2)+E(X)^2-E(Y^2)+E(Y)^2\\\\ \\quad = E(X^2)+2E(XY)+E(Y^2)-E(X)^2-2E(X)E(Y)-E(Y)^2\\\\ \\qquad\\qquad -E(X^2)+E(X)^2-E(Y^2)+E(Y)^2\\\\ \\quad = 2E(XY)-2E(X)E(Y)=2(E(XY)-\\mu_X\\mu_Y) \\end{array} \\] i per tant \\[ \\sigma(X+Y)^2 -(\\sigma(X)^2+\\sigma(Y)^2)=0 \\Longleftrightarrow E(XY)-\\mu_X\\mu_Y=0 \\] Si \\(X\\) i \\(Y\\) són variables independents, la seva covariància es 0, però la implicació a l’inrevés és falsa: Dues variables aleatòries poden tenir covariància 0 i no ser independents. Vegem un exemple d’aquest darrer fet: Exemple 9.2 Suposem que tenim un dau tetraèdric no trucat amb les cares marcades amb els valors -2, -1, 1 i 2. Siguin \\(X\\) la variable aleatòria que consisteix a llançar el dau i anotar el resultat, i \\(Y\\) la variable aleatòria que consisteix a llançar el dau i anotar el quadrat del resultat obtingut. Com que les quatre cares del dau són equiprobables, \\[ \\begin{array}{l} \\displaystyle P(X=-2)=P(X=-1)=P(X=1)=P(X=2)=\\frac{1}{4}\\\\ \\displaystyle P(Y=1)=P(Y=4)=\\frac{1}{2} \\end{array} \\] Com que \\(Y\\) és funció de \\(X\\), ja que \\(Y=X^2\\), \\(X\\) i \\(Y\\) no poden ser mai independents. Vegem que, en efecte, no ho són. Observau que els únics possibles valors per al vector \\((X,Y)\\) en una tirada del dau són (-2,4), (-1,1), (1,1) i (2,4), cadascun amb probabilitat 1/4. Llavors, per exemple, la probabilitat d’obtenir en una tirada \\(X=-1\\) i \\(Y=4\\) és 0, perquè és impossible, mentre que \\[ P(X=-1)\\cdot P(Y=4)=\\frac{1}{4}\\cdot\\frac{1}{2}=\\frac{1}{8}\\neq 0. \\] Vegem ara que la covariància de \\(X\\) i \\(Y\\) es 0. Per calcular-la, primer necessitam calcular els valors esperats de les variables: \\[ \\begin{array}{l} \\displaystyle \\mu_X=(-2)\\cdot \\frac{1}{4}+(-1)\\cdot \\frac{1}{4}+1\\cdot \\frac{1}{4}+2\\cdot \\frac{1}{4}=0\\\\ \\displaystyle \\mu_Y=1\\cdot \\frac{1}{2}+4\\cdot \\frac{1}{2}=2.5 \\end{array} \\] Per tant \\[ \\begin{array}{l} \\sigma_{X,Y}=E\\big(X\\cdot Y\\big)-\\mu_X\\cdot \\mu_Y=E\\big(X\\cdot Y\\big)-0\\cdot 2.5=E\\big(X\\cdot Y\\big)\\\\ \\qquad =P\\big(X=-2,Y=4\\big)\\cdot (-2\\cdot 4)+P\\big(X=-1,Y=1\\big)\\cdot (-1\\cdot 1)\\\\ \\qquad\\qquad\\qquad +P\\big(X=1,Y=1\\big)\\cdot (1\\cdot 1)+P\\big(X=2,Y=4\\big)\\cdot (2\\cdot 4)\\\\ \\qquad =\\displaystyle \\frac{1}{4}\\cdot (-8)+\\frac{1}{4}\\cdot (-1)+\\frac{1}{4}\\cdot 1+\\frac{1}{4}\\cdot 8=0. \\end{array} \\] Així doncs, \\(X\\) i \\(Y\\) són variables dependents, però la seva covariància és 0. Dues propietats importants més de la covariància: La covariància és simètrica: \\[ \\begin{array}{rl} \\sigma_{X,Y}\\!\\!\\! &amp; =E((X-\\mu_X)\\cdot ( Y-\\mu_Y))\\\\ &amp; =E(( Y-\\mu_Y)\\cdot (X-\\mu_X))=\\sigma_{Y,X} \\end{array} \\] La covariància d’una variable aleatòria amb ella mateixa és la seva variància: \\[ \\sigma_{X,X}=E((X-\\mu_X)^2)=\\sigma^2(X) \\] La matriu de covariàncies d’un vector aleatori \\(\\underline{X}=(X_1,\\ldots,X_p)\\) és la matriu formada per les covariàncies dels parells de variables que la formen: \\[ \\sigma_{\\underline{X},\\underline{X}}=\\begin{pmatrix} \\sigma_{X_1,X_1} &amp; \\sigma_{X_1,X_2} &amp; \\ldots &amp; \\sigma_{X_1,X_p}\\\\ \\sigma_{X_2,X_1} &amp; \\sigma_{X_2,X_2} &amp; \\ldots &amp; \\sigma_{X_2,X_p}\\\\ \\vdots &amp; \\vdots &amp;\\ddots &amp; \\vdots\\\\ \\sigma_{X_p,X_1} &amp; \\sigma_{X_p,X_2} &amp; \\ldots &amp; \\sigma_{X_p,X_p}\\\\ \\end{pmatrix} \\] Aquesta matriu és simètrica i les entrades de la diagonal són les variàncies de les variables del vector, perquè \\(\\sigma_{X_i,X_i}=\\sigma^2_{X_i}\\). 9.1.2 Correlació Com hem dit, el signe de la covariància té una interpretació senzilla, ja que reflecteix la tendència del creixement conjunt de les variables. Emperò, la seva magnitud no té una interpretació senzilla. Com a alternativa, es pot mesurar la tendència que hi hagi una relació lineal entre dues variables aleatòries contínues emprant l’anomenat coeficient de correlació lineal de Pearson (o, per abreviar, la correlació), que ve a ser una versió normalitzada de la covariància. En concret, la correlació de les variables \\(X\\) i \\(Y\\) es defineix com el quocient de la seva covariància pel producte de les seves desviacions típiques: \\[ \\rho_{X,Y}=\\frac{\\sigma_{X,Y}}{\\sigma_{X} \\sigma_{Y}} \\] La correlació té les propietats importants següents: No té unitats (perquè les unitats de \\(\\sigma_X\\) són les de \\(X\\), les unitats de \\(\\sigma_Y\\) són les de \\(Y\\), i les unitats de \\(\\sigma_{X,Y}\\) són les de \\(X\\) per les de \\(Y\\)) Pren valors entre -1 i 1: \\(-1\\leqslant \\rho_{X,Y}\\leqslant 1\\) És simètrica, \\(\\rho_{X,Y}= \\rho_{Y,X}\\) La correlació d’una variable amb ella mateixa és 1: \\(\\rho_{X,X}=1\\) \\(\\rho_{X,Y}=\\pm 1\\) si, i només si, les variables \\(X,Y\\) tenen una relació lineal perfecta. És a dir, \\(\\rho_{X,Y}=\\pm 1\\) si, i només si, existeixen \\(a,b\\in \\mathbb{R}\\) tals que \\(Y=a X+b\\). La pendent \\(a\\) d’aquesta recta té el mateix signe que \\(\\rho_{X,Y}\\). Com més s’acosta \\(|\\rho_{X,Y}|\\) a 1, més s’acosta \\(Y\\) a ser funció lineal de \\(X\\). Si \\(\\rho_{X,Y}&gt;0\\), la funció és creixent Si \\(\\rho_{X,Y}&lt;0\\), la funció és decreixent Si \\(\\rho_{X,Y}=0\\), diem que les variables \\(X\\) i \\(Y\\) són incorrelades. Notem que la correlació és 0 si, i només si, la covariància és 0. Per tant, si \\(X\\) i \\(Y\\) són independents, també són incorrelades. El recíproc en general és fals, com mostra l’Exemple 9.2. La matriu de correlacions d’un vector aleatori \\(\\underline{X}=(X_1,\\ldots,X_p)\\) és la matriu formada per les correlacions de parells de les seves variables: \\[ \\rho(\\underline{X}) =\\begin{pmatrix} 1 &amp; \\rho_{X_1,X_2} &amp; \\ldots &amp; \\rho_{X_1,X_p}\\\\ \\rho_{X_2,X_1} &amp; 1 &amp; \\ldots &amp; \\rho_{X_2,X_p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\rho_{X_p,X_1} &amp; \\rho_{X_p,X_2} &amp; \\ldots &amp; 1\\\\ \\end{pmatrix}. \\] Aquesta matriu és simètrica per la simetria de la correlació. La correlació de Pearson de dues variables contínues mesura la tendència de les variables a variar conjuntament de manera lineal. En particular, per exemple, si \\(\\rho_{X,Y}&gt;0\\), \\(Y\\) tendeix a créixer quan \\(X\\) creix. Però això no significa que un augment del valor de \\(X\\) causi que el valor de \\(Y\\) tendeixi a augmentar: Correlació no implica causalitat! La tendencia al creixement simultani de \\(X\\) i \\(Y\\) es pot deure a una tercera variable que les faci créixer totes dues, o pot ser purament espúria. Figura 9.1: Correlació no implica causalitat (https://xkcd.com/552/ (CC-BY-NC 2.5)) O millor: Figura 9.2: Correlació no implica causalitat, segons Dilbert Si entrau a la pàgina web Spurious Correlations podreu explorar un munt de correlacions espúries molt grans. La nostra preferida és una correlació de 0.947 entre la variable \\(X\\) “Prenc un any i anot el consum per capita de formatge als EEUU” i \\(Y\\) “Prenc un any i anot el nombre de morts per estrangulament accidental amb els llençols del llit als EEUU”. Hi ha un exemple de correlació negativa que és important tenir present per no deixar-se enganar. Teorema 9.1 Si \\(X_1\\), \\(X_2\\) són dues còpies independents d’una mateixa variable aleatòria \\(X\\), \\[ \\rho_{X_1,X_2-X_1}=-\\frac{1}{\\sqrt{2}}\\approx -0.71 \\] Això ens diu que, sigui quina sigui la variable \\(X\\), si la mesuram en dos moments independents o sobre dos individus triats de manera independent, la diferència entre els dos valors té una tendència destacada a decréixer linealment en el primer valor. Per exemple: Feu un test i traieu una nota molt baixa (\\(X_1\\)). L’endemà feu un altre test similar (\\(X_2\\)) sense haver estudiat més. El més probable és que, per pur atzar, tengueu una nota més alta (que \\(X_2-X_1\\) sigui gran, per tant positiu). Feu un test i traieu una nota molt alta (\\(X_1\\)). L’endemà feu un altre test (\\(X_2\\)) sense haver estudiat més. El més probable és que, per pur atzar, tengueu una nota més baixa (que \\(X_2-X_1\\) sigui petit, per tant negatiu). Per si qualcú necessita una demostració del teorema anterior, recordem que \\[ \\rho_{X_1,X_2-X_1}=\\dfrac{\\sigma_{X_1,X_2-X_1}}{\\sigma_{X_1}\\sigma_{X_2-X_1}} \\] Ara \\[ \\begin{array}{l} \\sigma_{X_2-X_1}=\\sqrt{\\sigma^2_{X_2-X_1}}\\\\[2ex] \\quad =\\sqrt{\\sigma^2_{X_1}+\\sigma^2_{X_2}}\\ \\text{(perquè són independents)}\\\\[2ex] \\quad =\\sqrt{\\sigma^2_{X}+\\sigma^2_{X}}\\ \\text{(perquè $X_1,X_2$ són còpies de $X$)}\\\\[2ex] \\quad =\\sqrt{2\\sigma^2_{X}}=\\sigma_{X}\\sqrt{2} \\end{array} \\] I \\[ \\begin{array}{l} \\sigma_{X_1,X_2-X_1}=E(X_1(X_2-X_1))-E(X_1)E(X_2-X_1)\\\\[1ex] \\quad =E(X_1X_2-X_1^2)-E(X_1)(E(X_2-E(X_1))\\\\[1ex] \\quad =E(X_1X_2)-E(X_1^2)-E(X_1)E(X_2)+E(X_1)E(X_1)\\\\[1ex] \\quad =E(X_1)E(X_2)-E(X_1^2)-E(X_1)E(X_2)+E(X_1)E(X_1)\\\\[1ex] \\quad \\text{(perquè $X_1,X_2$ són independents)}\\\\[1ex] \\quad =-E(X_1^2)+E(X_1)E(X_1)=-\\sigma^2_{X_1}=-\\sigma^2_{X} \\end{array} \\] Combinant-ho: \\[ \\rho_{X_1,X_2-X_1}=\\dfrac{\\sigma_{X_1,X_2-X_1}}{\\sigma_{X_1}\\sigma_{X_2-X_1}}=\\dfrac{-\\sigma^2_{X}}{\\sigma_{X}\\cdot \\sigma_{X}\\sqrt{2}} =-\\frac{1}{\\sqrt{2}} \\] Exemple 9.3 Com a exemple, generarem una mostra \\(X\\) de 101 “notes” aleatòries entre 0 i 100 amb distribució binomial \\(B(100,0.5)\\). Prendrem com a \\(X_1\\) el vector de les primeres 100 notes, \\[ X_1=(x_1,x_2,\\ldots,x_{100}) \\] i com a \\(X_2-X_1\\) el vector de les diferències de cada nota \\(x_i\\), \\(i\\geqslant 2\\), amb l’anterior: \\[ X_2-X_1=(x_2-x_1,x_3-x_2,\\ldots,x_{101}-x_{100}). \\] Calcularem la correlació entre \\(X_1\\) i \\(X_2-X_1\\), i ho il·lustrarem amb un gràfic. X=rbinom(101,100,0.5) X1=X[-101] X2.menys.X1=diff(X) plot(X1,X2.menys.X1,pch=20,xlab=expression(X[1]),ylab=expression(X[2]-X[1])) cor(X1,X2.menys.X1) ## [1] -0.7068097 La correlació predita pel teorema anterior és -1/sqrt(2) ## [1] -0.7071068 9.2 Estadística descriptiva: Mostres 9.2.1 Covariàncies Siguin \\(x=(x_1,\\ldots,x_n)\\) i \\(y=(y_1,\\ldots,y_n)\\) dos vectors obtinguts mesurant dues variables aleatòries quantitatives \\(X\\) i \\(Y\\) sobre una mateixa mostra ordenada d’individus de mida \\(n\\) d’una població. Siguin \\(\\overline{X}\\) i \\(\\overline{Y}\\) les seves mitjanes mostrals. Aleshores la seva covariància mostral és \\[ \\widetilde{S}_{X,Y} =\\frac{1}{n-1} \\sum_{i =1}^n\\big((x_{i}-\\overline{{X}})(y_i-\\overline{Y})\\big) \\] i la seva covariància (a seques) és \\[ {S}_{X,Y} =\\frac{1}{n} \\sum_{i =1}^n\\big((x_{i}-\\overline{{X}})(y_i-\\overline{Y})\\big)=\\frac{n-1}{n}\\widetilde{S}_{X,Y}. \\] És a dir, com sempre, la diferència entre la versió “mostral” i la versió “a seques” rau en el denominador, \\(n-1\\) i \\(n\\) respectivament. La covariància de dos vectors només té sentit quan aquests vectors representen els valors de dues variables quantitatives sobre els mateixos individus, o sobre dues mostres aparellades, i en el mateix ordre. En particular, els dos vectors han de tenir la mateixa longitud. Com en el cas poblacional, la covariància entre dos vectors mesura la tendència que tenen les seves dades a variar conjuntament: Quan \\(\\widetilde{S}_{X,Y}&gt;0\\), si \\(x_i&gt;x_j\\), \\(y_i\\) tendeix a ser més gran que \\(y_j\\) Quan \\(\\widetilde{S}_{X,Y}&gt;0\\), si \\(x_i&gt;x_j\\), \\(y_i\\) tendeix a ser més petit que \\(y_j\\) Quan \\(\\widetilde{S}=0\\), no hi ha cap tendència en aquest sentit És fàcil comprovar que: Les dues covariàncies són simètriques \\[ \\widetilde{S}_{X,Y}=\\widetilde{S}_{Y,X},\\ {S}_{X,Y}={S}_{Y,X} \\] La variància d’un vector és la seva covariància amb ell mateix \\[ \\widetilde{S}_{X,X}=\\widetilde{S}^2_{X},\\ {S}_{X,X}={S}^2_{X}. \\] Exemple 9.4 Hem mesurat l’índex de massa corporal, BMI, i el nivell de colesterol en 5 individus sans. Guardam els resultats en un dataframe i en calculam les mitjanes: BMI= c(18.3,24.4,24.6,24.4,22.2,19.5) Chol=c(170,202,215,218,210,210) DF=data.frame(BMI,Chol) mean(BMI) ## [1] 22.23333 mean(Chol) ## [1] 204.1667 Aleshores la covariància mostral d’aquests dos vectors és \\[ \\begin{array}{l} \\dfrac{1}{5}\\Big((18.3-22.23)(170-204.17)+(24.4-22.23)(202-204.17)\\\\ \\qquad +(24.6-22.23)(215-204.17)+(24.4-22.23)(218-204.17)\\\\ \\qquad +(22.2-22.23)(210-204.17)+(19.5-22.23)(210-204.17)\\Big)=33.8333 \\end{array} \\] i la seva covariància a seques és \\[ \\begin{array}{l} \\dfrac{1}{6}\\Big((18.3-22.23)(170-204.17)+(24.4-22.23)(202-204.17)\\\\ \\qquad +(24.6-22.23)(215-204.17) +(24.4-22.23)(218-204.17)\\\\ \\qquad +(22.2-22.23)(210-204.17)+(19.5-22.23)(210-204.17)\\Big)=28.1944 \\end{array} \\] La covariància mostral de dos vectors numèrics de la mateixa longitud \\(n\\) es calcula amb R amb la funció cov. cov(BMI,Chol) ## [1] 33.83333 Per obtenir la seva covariància a seques, cal multiplicar el resultat de cov per \\((n-1)/n\\). n=length(BMI) cov(BMI,Chol)*(n-1)/n ## [1] 28.19444 Considerem una taula de dades quantitatives de la forma \\[ \\begin{array}{cccc} X_1 &amp; X_2 &amp; \\ldots &amp; X_p\\\\ \\hline x_{1 1} &amp; x_{1 2} &amp;\\ldots &amp; x_{1 p}\\\\ x_{2 1} &amp; x_{2 2} &amp;\\ldots &amp; x_{2 p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ x_{n 1} &amp; x_{n 2} &amp;\\ldots &amp; x_{n p} \\end{array} \\] on cada columna representa els valors d’una certa variable \\(X_i\\) i cada filera un individu d’una mostra de la població, de manera que l’entrada \\(x_{ij}\\) d’aquesta taula és el valor de \\(X_j\\) sobre l’individu \\(i\\)-èssim de la mostra. La matriu de covariàncies mostrals d’aquesta taula és la matriu \\[ \\widetilde{{S}}= \\begin{pmatrix} \\widetilde{S}^2_{X_1} &amp; \\widetilde{S}_{X_1,X_2} &amp; \\ldots &amp; \\widetilde{S}_{X_1,X_p}\\\\ \\widetilde{S}_{X_2,X_1} &amp; \\widetilde{S}^2_{X_2} &amp; \\ldots &amp; \\widetilde{S}_{X_2,X_p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\widetilde{S}_{X_p,X_1} &amp; \\widetilde{S}_{X_p,X_2} &amp; \\ldots &amp; \\widetilde{S}^2_{X_p} \\end{pmatrix} \\] i la matriu de covariàncies (a seques) es defineix de manera similar, però amb les covariàncies a seques: \\[ {S}= \\begin{pmatrix} S^2_{X_1} &amp; S_{X_1,X_2} &amp; \\ldots &amp; S_{X_1,X_p}\\\\ S_{X_2,X_1} &amp; S^2_{X_2} &amp; \\ldots &amp; S_{X_2,X_p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ S_{X_p,X_1} &amp; S_{X_p,X_2} &amp; \\ldots &amp; S^2_{X_p} \\end{pmatrix} \\] Totes dues són simètriques. La matriu de covariàncies mostrals es calcula amb la funció cov aplicada a la matriu o el data frame de variables numèriques que emmagatzema la taula de dades. Per calcular la matriu de covariàncies a seques, es multiplica el resultat de cov per \\((n-1)/n\\), on \\(n\\) és el nombre de fileres de la taula. Exemple 9.5 Afegirem a les dades de l’Exemple 9.4 una tercera variable amb les edats dels 6 individus. DF$Edats=c(49,39,50,44,40,36) DF ## BMI Chol Edats ## 1 18.3 170 49 ## 2 24.4 202 39 ## 3 24.6 215 50 ## 4 24.4 218 44 ## 5 22.2 210 40 ## 6 19.5 210 36 La matriu de covariàncies mostrals d’aquesta taula és cov(DF) ## BMI Chol Edats ## BMI 7.586667 33.83333 1.14 ## Chol 33.833333 309.76667 -33.00 ## Edats 1.140000 -33.00000 32.00 Podreu observar que és simètrica, que l’entrada (2,1) coincideix amb la covariància de BMI i Chol que hem calculat abans, i que a la diagonal hi obtenim les variàncies mostrals de les variables de la taula: apply(DF,MARGIN=2,FUN=var) ## BMI Chol Edats ## 7.586667 309.766667 32.000000 9.2.2 Correlació de Pearson Siguin \\(x=(x_1,\\ldots,x_n)\\) i \\(y=(y_1,\\ldots,y_n)\\) dos vectors obtinguts mesurant dues variables aleatòries contínues \\(X\\) i \\(Y\\) sobre una mateixa mostra d’individus de mida \\(n\\) d’una població. La correlació de Pearson de \\(x\\) i \\(y\\) és la seva covariància mostral dividida pel producte de les seves desviacions típiques mostrals: \\[ R_{X,Y}=\\frac{\\widetilde{S}_{X,Y}}{\\widetilde{S}_X\\cdot \\widetilde{S}_Y}. \\] La correlació de Pearson de \\(x\\) i \\(y\\) també és igual a la seva covariància a seques dividida pel producte de les seves desviacions típiques a seques, perquè els canvis de denominador se cancel·len: \\[ R_{X,Y}=\\frac{\\widetilde{S}_{X,Y}}{\\widetilde{S}_X\\cdot \\widetilde{S}_Y}= \\frac{\\frac{n}{n-1}\\cdot {S}_{X,Y}}{\\sqrt{\\frac{n}{n-1}}\\cdot {S}_X \\cdot\\sqrt{\\frac{n}{n-1}}\\cdot{S}_Y}= \\frac{S_{X,Y}}{S_X \\cdot S_Y}=R_{X,Y}. \\] Exemple 9.6 Tornem a la situació de l’Exemple 9.4. La covariància mostral i les desviacions típiques mostrals dels vectors BMI i Chol són cov(BMI,Chol) ## [1] 33.83333 sd(BMI) ## [1] 2.75439 sd(Chol) ## [1] 17.60019 i per tant la seva correlació de Pearson és \\[ R_{BMI,Chol}=\\frac{33.833}{2.754\\cdot 17.6}= 0.698 \\] Algunes propietats importants de la correlació de Pearson: La correlació de Pearson és simètrica: \\(R_{X,Y}=R_{Y,X}\\) La correlació de Pearson pren valors només entre -1 i 1: \\(-1\\leqslant R_{X,Y}\\leqslant 1\\) La correlació de Pearson d’un vector amb ell mateix és 1: \\(R_{X,X}=1\\) \\(R_{X,Y}\\) té el mateix signe que \\(S_{X,Y}\\) \\(R_{X,Y}=\\pm 1\\) si, i només si, existeixen \\(a, b\\in \\mathbb{R}\\) tals que \\(y=ax+b\\), és a dir, tals que \\(y_i=ax_i+b\\) per a cada \\(i=1,\\ldots,n\\). La pendent \\(a\\) d’aquesta relació lineal té el mateix signe que \\(R_{X,Y}\\). El coeficient de determinació \\(R^2\\) de la regressió lineal per mínims quadrats de \\(y\\) respecte de \\(x\\) és igual al quadrat de la seva correlació de Pearson: \\[ R^2=R_{X,Y}^2 \\] Per tant, com més s’acosta la correlació de Pearson de \\(x\\) i \\(y\\) a 1 o a -1, més s’acosten els punts \\((x_i,y_i)\\) a estar sobre una recta. El signe de \\(R_{X,Y}\\) indica si aquesta recta és creixent (\\(R_{X,Y}&gt;0\\)) o decreixent (\\(R_{X,Y}&lt;0\\)). Amb R, la correlació de Pearson de dos vectors es pot calcular amb la funció cor. Per exemple, la correlació del Pearson dels vectors BMI i Chol s’obté amb cor(BMI,Chol) ## [1] 0.6979141 Vegem que el seu quadrat és igual al \\(R^2\\) de la regressió lineal de Chol en funció de BMI: cor(BMI,Chol)^2 ## [1] 0.487084 summary(lm(Chol~BMI))$r.squared ## [1] 0.487084 Per fer-nos una idea de què representa aquest valor de la correlació, vegem el gràfic dels punts (BMI,Chol) amb la seva recta de regressió lineal: plot(BMI,Chol,pch=20) abline(lm(Chol~BMI),col=&quot;red&quot;,lwd=1.5) Hi podem observar com Chol tendeix a créixer quan BMI creix, però els punts (BMI,Chol) no tendeixen a estar sobre una recta. És convenient acompanyar un càlcul de correlació o covariància de dos vectors \\(x,y\\) amb un gràfic dels punts \\((x_i,y_i)\\), perquè conjunts molt diferents de punts poden donar lloc a la mateixa correlació. Un exemple clàssic d’aquest fet són els quatre conjunts de dades \\((x_{1,i},y_{1,i})_{i=1,\\ldots,11}\\), \\((x_{2,i},y_{2,i})_{i=1,\\ldots,11}\\), \\((x_{3,i},y_{3,i})_{i=1,\\ldots,11}\\), \\((x_{4,i},y_{4,i})_{i=1,\\ldots,11}\\) que formen el dataframe anscombe de R: str(anscombe) ## &#39;data.frame&#39;:\t11 obs. of 8 variables: ## $ x1: num 10 8 13 9 11 14 6 4 12 7 ... ## $ x2: num 10 8 13 9 11 14 6 4 12 7 ... ## $ x3: num 10 8 13 9 11 14 6 4 12 7 ... ## $ x4: num 8 8 8 8 8 8 8 19 8 8 ... ## $ y1: num 8.04 6.95 7.58 8.81 8.33 ... ## $ y2: num 9.14 8.14 8.74 8.77 9.26 8.1 6.13 3.1 9.13 7.26 ... ## $ y3: num 7.46 6.77 12.74 7.11 7.81 ... ## $ y4: num 6.58 5.76 7.71 8.84 8.47 7.04 5.25 12.5 5.56 7.91 ... Les correlacions dels quatre parells de vectors són molt semblants: cor(anscombe$x1,anscombe$y1) ## [1] 0.8164205 cor(anscombe$x2,anscombe$y2) ## [1] 0.8162365 cor(anscombe$x3,anscombe$y3) ## [1] 0.8162867 cor(anscombe$x4,anscombe$y4) ## [1] 0.8165214 Però si els dibuixam veureu que els quatre conjunts de punts són molt diferents: par(mfrow=c(2,2)) plot(anscombe$x1,anscombe$y1,pch=20,main=&quot;Conjunt de dades 1&quot;,cex=1.25) abline(lm(y1~x1,data=anscombe),col=&quot;red&quot;,lwd=1.5) plot(anscombe$x2,anscombe$y2,pch=20,main=&quot;Conjunt de dades 2&quot;,cex=1.25) abline(lm(y2~x2,data=anscombe),col=&quot;red&quot;,lwd=1.5) plot(anscombe$x3,anscombe$y3,pch=20,main=&quot;Conjunt de dades 3&quot;,cex=1.25) abline(lm(y3~x3,data=anscombe),col=&quot;red&quot;,lwd=1.5) plot(anscombe$x4,anscombe$y4,pch=20,main=&quot;Conjunt de dades 4&quot;,cex=1.25) abline(lm(y4~x4,data=anscombe),col=&quot;red&quot;,lwd=1.5) par(mfrow=c(1,1)) Exemples més espectaculars es poden obtenir amb les funcions del paquet datasaurus, que permeten crear conjunts de punts de “formes” diferents i mateixos estadístics, i en particular la mateixa correlació. Emprant aquest paquet, hem creat dos parells de vectors de dades dino i star, que hem recollit a la taula de dades https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/Datasaurus.txt. Aquesta taula de dades té tres variables: una variable dataset que indica el conjunt de dades, i les variables x i y que donen les coordenades dels punts que formen cada conjunt de dades. Comprovarem que els dos parells de vectors de dades el mateix coeficient de correlació (almenys fins a la setena xifra decimal) i els dibuixarem. datasaure=read.table(&quot;https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/Datasaurus.txt&quot;,header=TRUE,sep=&quot;\\t&quot;) str(datasaure) ## &#39;data.frame&#39;:\t284 obs. of 3 variables: ## $ dataset: chr &quot;dino&quot; &quot;dino&quot; &quot;dino&quot; &quot;dino&quot; ... ## $ x : num 55.4 51.5 46.2 42.8 40.8 ... ## $ y : num 97.2 96 94.5 91.4 88.3 ... dino=datasaure[datasaure$dataset==&quot;dino&quot;,2:3] star=datasaure[datasaure$dataset==&quot;star&quot;,2:3] cor(dino$x,dino$y) ## [1] -0.0629611 cor(star$x,star$y) ## [1] -0.0629611 par(mfrow=c(1,2)) plot(dino,pch=20,cex=1.25) plot(star,pch=20,cex=1.25) par(mfrow=c(1,1)) Suposem ara que tenim una taula de dades numèriques de la forma \\[ \\begin{array}{cccc} X_1 &amp; X_2 &amp; \\ldots &amp; X_p\\\\ \\hline x_{1 1} &amp; x_{1 2} &amp;\\ldots &amp; x_{1 p}\\\\ x_{2 1} &amp; x_{2 2} &amp;\\ldots &amp; x_{2 p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ x_{n 1} &amp; x_{n 2} &amp;\\ldots &amp; x_{n p} \\end{array} \\] on cada columna representa els valors d’una certa variable \\(X_i\\) i cada filera un individu d’una mostra de la població, de manera que l’entrada \\(x_{ij}\\) d’aquesta taula és el valor de \\(X_j\\) sobre l’individu \\(i\\)-èssim de la mostra. La seva matriu de correlacions de Pearson és la matriu simètrica \\[ \\begin{pmatrix} 1 &amp; R_{X_1,X_2} &amp; \\ldots &amp; R_{X_1,X_p}\\\\ R_{X_2,X_1} &amp; 1 &amp; \\ldots &amp; R_{X_2,X_p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ R_{X_p,X_1} &amp; R_{X_p,X_2} &amp; \\ldots &amp; 1 \\end{pmatrix} \\] Aquesta matriu de correlacions es calcula amb la funció cor aplicada a la matriu o el data frame de variables numèriques que emmagatzema la taula de dades. Per exemple, la matriu de correlacions de Pearson de la taula de dades DF de l’Exemple 9.5 és cor(DF) ## BMI Chol Edats ## BMI 1.00000000 0.6979141 0.07316517 ## Chol 0.69791406 1.0000000 -0.33145274 ## Edats 0.07316517 -0.3314527 1.00000000 9.2.3 Estimació Les covariàncies de dos vectors obtinguts mesurant dues variables \\(X,Y\\) sobre una mostra aleatòria simple de subjectes d’una població estimen la covariància poblacional de les variables \\(X,Y\\) que han produït els vectors: La covariància mostral \\(\\widetilde{S}_{X,Y}\\) sempre és un estimador no esbiaixat de la covariància poblacional \\(\\sigma_{X,Y}\\) La covariància \\({S}_{X,Y}=\\frac{n-1}{n}\\widetilde{S}_{X,Y}\\) és un estimador esbiaixat de la covariància poblacional \\(\\sigma_{X,Y}\\), amb biaix que tendeix a 0, i és més eficient que \\(\\widetilde{S}_{X,Y}\\) La covariància \\(S_{X,Y}\\) és l’estimador màxim versemblant de \\(\\sigma_{X,Y}\\) quan la distribució conjunta de les variables \\(X,Y\\) és el que s’anomena normal bivariant. La correlació de Pearson de dos vectors obtinguts mesurant dues variables contínues \\(X,Y\\) sobre una mostra aleatòria simple de subjectes d’una població estima la correlació poblacional de les variables \\(X,Y\\). En concret: \\(R_{X,Y}\\) és un estimador màxim versemblant de \\(\\rho_{X,Y}\\) quan la distribució conjunta de \\(X,Y\\) és normal bivariant. N’és un estimador esbiaixat, però el seu biaix tendeix a 0. 9.2.4 Correlació de Spearman La correlació de Pearson mesura específicament la tendència de dues variables contínues a dependre linealment l’una de l’altra. Si no esperam que aquesta dependència lineal existeixi, o si les nostres variables són discretes o simplement ordinals, emprar la correlació de Pearson per a analitzar la relació entre dues variables no és el més adequat. Entre les propostes alternatives, la més popular és la correlació de Spearman. Intuïtivament, la correlació de Spearman mesura la tendència que si \\(x_i&gt;x_j\\), passi que \\(y_i&gt;y_j\\). El seu valor és 1 si, per a tots \\(i,j\\), \\[ x_i&gt;x_j\\Longleftrightarrow y_i&gt;y_j \\] i el seu valor és -1 si, per a tots \\(i,j\\), \\[ x_i&gt;x_j\\Longleftrightarrow y_i&lt;y_j \\] Com més s’acosta la correlació de Spearman a valer 1 (o -1), per a més parelles d’índexs \\((i,j)\\) tals que \\(x_i&gt;x_j\\) es té que \\(y_i&gt;y_j\\) (\\(y_i&lt;y_j\\), si s’acosta a -1). Formalment, la correlació de Spearman de dos vectors \\(x\\) i \\(y\\) se defineix com la correlació de Pearson dels vectors de rangs de \\(x\\) i \\(y\\). El vector de rangs d’un vector \\(x\\) s’obté substituint cada valor de \\(x\\) per la seva posició en el vector ordenat de menor a major, i en cas d’empats assignant a grups de valors empatats la mitjana de les posicions que ocuparien (aquests rangs ja han sortit, al test de Wilcoxon i al test de bondat d’ajust de Kolmogorov-Smirnov). Per exemple, el vector de rangs de \\[ x=(4,5,1,5,1,3,4,4) \\] és \\[ (5,7.5,1.5,7.5,1.5,3,5,5) \\] Com hem calculat aquest vector? Primer assignam a cada valor del vector la seva posició si estiguessin ordenats de menor a major, i en cas d’empat per ara els ordenarem d’esquerra a dreta: \\[ \\begin{array}{r|cccccccc} x &amp; 4&amp; 5 &amp; 1 &amp; 5 &amp; 1 &amp; 3 &amp; 4 &amp; 4\\\\ \\hline \\text{Posició} &amp; 4 &amp; 7 &amp; 1 &amp; 8 &amp; 2 &amp; 3 &amp; 5 &amp; 6\\\\ \\end{array} \\] Ara, per assignar els rangs finals: El rang dels dos elements 1 de \\(x\\) és la mitjana de les posicions 1, 2 del vector ordenat: 1.5. Com que només hi ha un 3 a \\(x\\), el seu rang és la seva posició en el vector ordenat: 3. El rang dels tres elements 4 és la mitjana de les posicions 4, 5 i 6 del vector ordenat: 5. Finalment, el rang dels dos elements 5 és la mitjana de les posicions 7, 8 del vector ordenat: 7.5. \\[ \\begin{array}{r|cccccccc} x &amp; 4&amp; 5 &amp; 1 &amp; 5 &amp; 1 &amp; 3 &amp; 4 &amp; 4\\\\ \\hline \\text{Posició} &amp; 4 &amp; 7 &amp; 1 &amp; 8 &amp; 2 &amp; 3 &amp; 5 &amp; 6\\\\ \\hline \\text{Rang} &amp; 5 &amp; 7.5 &amp; 1.5 &amp; 7.5 &amp; 1.5 &amp; 3 &amp; 5 &amp; 5 \\end{array} \\] Per cert, amb R el vector de rangs es calcula amb la funció rank: rank(c(4,5,1,5,1,3,4,4)) ## [1] 5.0 7.5 1.5 7.5 1.5 3.0 5.0 5.0 Amb R, la correlació de Spearman es calcula directament amb la funció cor entrant-li el paràmetre method=\"spearman\". (El valor per defecte del paràmetre method és \"pearson\" i per això no l’indicam quan calculam la correlació de Pearson.) Exemple 9.7 Considerem els vectors BMI i Chol de l’Exemple 9.4. El primer que farem serà calcular els seus vectors de rangs: \\[ \\begin{array}{|c|c||c|c|} \\hline BMI &amp; \\text{Rangs} &amp; Chol&amp; \\text{Rangs} \\\\\\hline\\hline 18.3&amp; 1 &amp; 170&amp; 1 \\\\ 24.4&amp;4.5 &amp; 202 &amp; 2\\\\ 24.6&amp;6 &amp; 215&amp; 5 \\\\ 24.4&amp;4.5 &amp; 218&amp; 6\\\\ 22.2&amp;3 &amp; 210&amp; 3.5\\\\ 19.5&amp;2 &amp; 210&amp; 3.5\\\\\\hline \\end{array} \\] Per tant, la correlació de Spearman de \\[ \\mathit{BMI}=(18.3, 24.4, 24.6, 24.4, 22.2, 19.5)\\mbox{ i }\\mathit{Chol}=(170, 202, 215, 218, 210, 210) \\] és la correlació de Pearson de \\[ (1, 4.5, 6, 4.5, 3, 2)\\mbox{ i }(1, 2, 5, 6, 3.5, 3.5) \\] Comprovem-ho: cor(BMI,Chol,method=&quot;spearman&quot;) ## [1] 0.6470588 cor(c(1,4.5,6,4.5,3,2),c(1,2,5,6,3.5,3.5)) ## [1] 0.6470588 9.2.5 Contrastos de correlació En un contrast de correlació de dues variables poblacionals contínues \\(X\\) i \\(Y\\), la hipòtesi nul·la és que no hi ha correlació entre les dues variables, la qual cosa s’entén que tradueix que no hi ha cap relació entre elles. \\[ \\left\\{ \\begin{array}{ll} H_0: &amp; \\rho_{XY}=0\\\\ H_1: &amp; \\rho_{XY}&gt; 0\\text{ o }\\rho_{XY}&lt; 0\\text{ o }\\rho_{XY}\\neq 0 \\end{array}\\right. \\] Si en un contrast de correlació rebutjam la hipòtesi nul·la, en particular concloem que les variables \\(X\\) i \\(Y\\) són dependents (perquè si fossin independents, la seva correlació seria 0). No explicarem com es fa a mà aquest contrast ni quines hipòtesis han de satisfer les variables poblacionals per que el resultat sigui fiable. Si estau interessats en el detall, podeu consultar la corresponent entrada de la Wikipedia. Simplement heu de saber que s’efectua amb la funció cor.test. La seva sintaxi és similar a la de les altres funcions que efectuen contrastos. Exemple 9.8 Volem contrastar si hi ha correlació positiva entre el BMI i el nivell de colesterol d’un adult sa, amb un nivell de significació del 5%. Variables poblacionals d’interès: \\(\\mathit{BMI}\\): “Prenem un adult sa i anotam el seu BMI” \\(\\mathit{Chol}\\): “Prenem un adult sa i anotam el nivell de colesterol en mg/dl” Contrast: \\[ \\left\\{ \\begin{array}{ll} H_0: &amp; \\rho_{\\textit{BMI,Chol}}=0\\\\ H_1: &amp; \\rho_{\\textit{BMI,Chol}}&gt;0 \\end{array}\\right. \\] Emprarem les mostres BMI i Chol de l’Exemple9.4. cor.test(BMI,Chol,alternative=&quot;greater&quot;) ## ## Pearson&#39;s product-moment correlation ## ## data: BMI and Chol ## t = 1.949, df = 4, p-value = 0.06155 ## alternative hypothesis: true correlation is greater than 0 ## 95 percent confidence interval: ## -0.08621998 1.00000000 ## sample estimates: ## cor ## 0.6979141 Conclusió: No hem obtingut evidència estadísticament significativa que el BMI i el nivell de colesterol d’un adult sa tenguin correlació positiva (test de correlació, p-valor 0.06, IC 95% per a \\(\\rho\\) de -0.086 a 1). La conclusió és que no hem obtingut evidència que el BMI i el nivell de colesterol tenguin correlació positiva a la població dels adults sans. No a la nostra mostra, que sí que ha donat correlació positiva. Recordau que els contrastos sempre refereixen a la població. 9.3 Test de la lliçó 9 (1) La covariància de dues variables aleatòries (marcau totes les continuacions correctes) És sempre més gran o igual que 0 Mesura la tendència general de les dues variables a créixer (o decréixer) conjuntament Mesura la tendència de les dues variables a créixer (o decréixer) conjuntament segons una funció lineal Si val 0, les dues variables són independents És el quocient de les variàncies de les dues variables aleatòries Si les dues variables són independents, val 0 Totes les altres respostes són incorrectes (2) La correlació de Pearson de dues variables aleatòries (marcau totes les continuacions correctes) Mesura la tendència general de les dues variables a créixer (o decréixer) conjuntament Mesura la tendència de les dues variables a créixer (o decréixer) conjuntament segons una funció lineal És l’arrel quadrada de la covariància Si val 0, les dues variables són independents Si les dues variables són independents, val 0 Totes les altres respostes són incorrectes (3) Quins valors pot prendre el coeficient de correlació de Pearson de dues variables quantitatives? Qualsevol valor real Qualsevol valor real més gran o igual que 0 Qualsevol valor real més gran o igual que 0, i també \\(\\infty\\) Qualsevol valor real entre -1 i 1 Qualsevol valor real entre 0 i 1 Els valors 0, -1 i 1 Totes les altres respostes són falses (4) Quina, o quines, de les mesures següents serveix per quantificar la dispersió d’una variable aleatòria? La covariància amb una variable constant El p-valor d’un test khi quadrat La variància mostral La mitjana La desviació típica La variància La correlació de Pearson amb una variable constant (5) Una covariància -0.7 entre dues variables \\(X\\) i \\(Y\\) indica (marcau una sola resposta): Que un augment de \\(X\\) sol anar associat a un augment de \\(Y\\) Que un augment de \\(X\\) sol causar un augment de \\(Y\\) Que un augment de \\(X\\) sol anar associat a una disminució de \\(Y\\) Que un augment de \\(X\\) sol causar una disminució de \\(Y\\) Que les variables \\(X\\) i \\(Y\\) són independents (6) La covariància mostral de dos vectors (marcau totes les continuacions correctes): Només està definida per a vectors de la mateixa longitud Pot prendre qualsevol valor real Només pot prendre valors entre -1 i 1 És la correlació de Pearson dividida pel producte de les desviacions típiques mostrals dels vectors Si els vectors són \\((x_1,\\ldots ,x_n)\\) i \\((y_1,\\ldots ,y_n)\\), mesura la tendència dels punts \\((x_i,y_i)\\) a estar sobre una recta S’obté multiplicant per \\(n-1\\) i dividint per \\(n\\) la covariància “a seques” dels vectors Estima la covariància de les variables aleatòries que han produït els vectors Totes les altres respostes són incorrectes (7) La correlació de Pearson de dos vectors (marcau totes les continuacions correctes): Només està definida per a vectors de la mateixa longitud Pot prendre qualsevol valor real Només pot prendre valors entre -1 i 1 És la covariància mostral dividida pel producte de les desviacions típiques dels vectors Si els vectors són \\((x_1,\\ldots ,x_n)\\) i \\((y_1,\\ldots ,y_n)\\), mesura la tendència dels punts \\((x_i,y_i)\\) a estar sobre una recta S’obté multiplicant per \\(n\\) i dividint per \\(n-1\\) la correlació mostral de Pearson dels vectors Estima la correlació de les variables aleatòries que han produït els vectors Totes les altres respostes són incorrectes (8) Quines de les matrius següents són matrius de correlacions de Pearson d’alguna parella de vectors? \\[ \\begin{array}{ccccc} \\left(\\begin{array}{ccc} 1 &amp; 1\\cr 1 &amp; 1 \\end{array}\\right) &amp; \\left(\\begin{array}{ccc} 1 &amp; 1.2 \\cr 1.2 &amp; 1 \\end{array}\\right) &amp; \\left(\\begin{array}{ccc} 1 &amp; 0.8\\cr -0.8 &amp; 1 \\end{array}\\right) &amp; \\left(\\begin{array}{ccc} 0.6 &amp; 0.8\\cr 0.8 &amp; 0.6 \\end{array}\\right) &amp; \\left(\\begin{array}{ccc} 1 &amp; 0\\cr 0 &amp; 1 \\end{array}\\right)\\\\ \\text{(a)} &amp; \\text{(b)} &amp; \\text{(c)} &amp; \\text{(d)} &amp; \\text{(e)} \\end{array} \\] Marcau totes les respostes correctes: La (a) La (b) La (c) La (d) La (e) Cap (9) La correlació de Pearson de dos vectors (marcau totes les continuacions correctes, haureu de pensar un poc): No varia si sumam a un dels vectors una constant No varia si multiplicam un dels vectors per una constant \\(&gt;0\\) No varia si multiplicam un dels vectors per una constant diferent de 0 No varia si multiplicam els dos vectors per la mateixa constant diferent de 0 Totes les altres respostes són incorrectes (10) Un contrast de correlació de Pearson (marcau totes les continuacions correctes): Té sempre com a hipòtesi nul·la que les dues variables tenen correlació de Pearson 0 Té sempre com a hipòtesi nul·la que les dues variables tenen correlació de Pearson positiva Té sempre com a hipòtesi alternativa que els dos vectors tenen correlació de Pearson 0 Té sempre com a hipòtesi alternativa que els dos vectors tenen correlació de Pearson positiva També es pot usar per comparar amb 0 la covariància poblacional Totes les altres respostes són incorrectes (11) Volem contrastar si el nivell mitjà de colesterol en sang (mesurat en mg/dl) és igual, o no, en els pacients que presenten accidents cardiovasculars que en els pacients que no en presenten a partir de dues mostres independents de 100 individus cadascuna. Quina prova estadística és la més apropiada? Marcau una sola resposta. Un contrast de correlació de Spearman Un test t Un test khi quadrat Un contrast de correlació de Pearson Un test exacte de Fisher (12) En un contrast de correlació entre xifres de colesterol lligat a lipoproteïnes de baixa densitat i la reducció del diàmetre de les artèries coronàries s’ha observat una \\(R\\) de 0.14, amb un p-valor menor de 0.01. Quina és la interpretació més correcta? Existeix una correlació forta entre els dos vectors, però no és estadísticament significativa Existeix una correlació feble positiva entre els dos vectors, però és estadísticament significativa Existeix una correlació forta entre els dos vectors i és estadísticament significativa L’augment de les xifres de colesterol lligat a proteïnes de baixa densitat provoca l’augment del diàmetre de les artèries coronàries L’augment del diàmetre de les artèries coronàries causa l’augment de les xifres de colesterol lligat a proteïnes de baixa densitat (13) En els 10 naixements que van tenir lloc en un hospital en un dia determinat, es va anotar el pes del nadó (\\(X\\)) i l’edat de la mare (\\(Y\\)). Curiosament, tots els nadons van pesar el mateix: 2.6 kg. Quina va ser la covariància entre els pesos i les edats? 1 0 -1 2.6 0.26 És impossible saber-ho sense conèixer les edats de les mares Figura 9.3: Gràfics de dispersió de les preguntes (14) a (18) (14) Dels gràfics de dispersió de la figura, quin correspon a \\(R=-0.5\\)? El (a) El (b) El (c) El (d) El (e) (15) Dels gràfics de dispersió de la figura, quin correspon a \\(R=-0.1\\)? El (a) El (b) El (c) El (d) El (e) (16) Dels gràfics de dispersió de la figura, quin correspon a \\(R=0.1\\)? El (a) El (b) El (c) El (d) El (e) (17) Dels gràfics de dispersió de la figura, quin correspon a \\(R=0.5\\)? El (a) El (b) El (c) El (d) El (e) (18) Dels gràfics de dispersió de la figura, quin correspon a \\(R=0.9\\)? El (a) El (b) El (c) El (d) El (e) (19) Quin és el rang dels valors 2 al vector \\((-1, -1, 1, -2, -1, 1, 3, 1, 1, 2, 1, 2, 1, 3)\\)? 4 11 11.5 12 11 i 12 Cap dels anteriors "],
["chap-ANOVA.html", "Tema 10 ANOVA 10.1 Nocions bàsiques 10.2 ANOVA d’1 via 10.3 ANOVA de blocs 10.4 ANOVA de 2 vies 10.5 Test de la lliçó 10", " Tema 10 ANOVA L’objectiu d’aquest tema és generalitzar el contrast bilateral de dues mitjanes emprant un test t a més de dues mitjanes, de tal manera que amb un sol test poguem decidir si hi ha evidència que alguna parella d’aquestes mitjanes siguin diferents o si pel contrari podem acceptar que totes les mitjanes són iguals. 10.1 Nocions bàsiques Comencem considerant un problema concret. Exemple 10.1 Es realitzà un estudi per investigar l’efecte del CO2 sobre la taxa de creixement de Pseudomonas fragi, un corruptor d’aliments. Per contrastar si el seu creixement es veu afectat per la quantitat de CO2 en l’aire, s’administrà CO2 a 5 pressions atmosfèriques diferents a 10 cultius diferents per cada nivell de pressió de CO2 i s’anotà el percentatge d’increment de la massa cel·lular de cada cultiu al cap d’una hora. Les dades obtingudes varen ser: \\[ \\begin{array}{c} \\text{Pressió de CO${}_2$ (en atmosferes)}\\\\ \\begin{array}{rrrrr} 0.0 &amp; 0.08 &amp; 0.29 &amp; 0.50 &amp; 0.86 \\\\\\hline 62.6 &amp; 50.9 &amp; 45.5 &amp; 29.5 &amp; 24.9 \\\\ 59.6 &amp; 44.3 &amp; 41.1 &amp; 22.8 &amp; 17.2 \\\\ 64.5 &amp; 47.5 &amp; 29.8 &amp; 19.2 &amp; 7.8 \\\\ 59.3 &amp; 49.5 &amp; 38.3 &amp; 20.6 &amp; 10.5 \\\\ 58.6 &amp; 48.5 &amp; 40.2 &amp; 29.2 &amp; 17.8 \\\\ 64.6 &amp; 50.4 &amp; 38.5 &amp; 24.1 &amp; 22.1 \\\\ 50.9 &amp; 35.2 &amp; 30.2 &amp; 22.6 &amp; 22.6 \\\\ 56.2 &amp; 49.9 &amp; 27.0 &amp; 32.7 &amp; 16.8 \\\\ 52.3 &amp; 42.6 &amp; 40.0 &amp; 24.4 &amp; 15.9 \\\\ 62.8 &amp; 41.6 &amp; 33.9 &amp; 29.6 &amp; 8.8 \\end{array} \\end{array} \\] El contrast que es volia realitzar era: \\(H_0\\): El percentatge mitjà d’increment del volum cel·lular d’un cultiu de P. fragi al cap d’una hora és el mateix per a totes les pressions de CO2 considerades. \\(H_1\\): El percentatge mitjà d’increment del volum cel·lular d’un cultiu de P. fragi al cap d’una hora depèn de la pressió de CO2. que en el nostre experiment traduïm en: \\(H_1\\): No és veritat que el percentatge mitjà d’increment del volum cel·lular d’un cultiu de P. fragi al cap d’una hora sigui el mateix per a totes les pressions de CO2 considerades. És a dir: \\(H_1\\): Hi ha almenys dues d’aquestes pressions de CO2 sota les quals els percentatges mitjans d’increment del volum cel·lular d’un cultiu de P. fragi al cap d’una hora són diferents. Recordau que el contrari de “totes les mitjanes són iguals” és hi ha almenys dues mitjanes que són diferents. Aquest experiment és un cas particular del problema següent: Tenim \\(k&gt;2\\) poblacions. Volem decidir si la mitjana d’una certa variable aleatòria és la mateixa a totes aquestes poblacions, o no. Usualment, aquestes \\(k\\) poblacions seran subpoblacions d’una única població, definides pels nivells d’un o diversos factors. Per exemple, a l’estudi del creixement del P. fragi, les poblacions que consideram estan totes formades per cultius d’aquest bacteri, i es diferencien en la pressió de CO2. En el context d’aquest tipus d’estudis, a aquests nivells els anomenam tractaments. És a dir, tornant a l’exemple anterior, els nivells de pressió de CO2 serien els tractaments que analitzam en aquest estudi. Per simplificar el llenguatge, sovint cometrem l’abús d’identificar una subpoblació d’aquestes amb el nivell, o tractament, que la defineix. D’aquesta manera, parlarem per exemple de la mitjana poblacional del tractament “0.29 atmosferes” per referir-nos a la mitjana de la població definida pel tractament “0.29 atmosferes”, és a dir, al percentatge mitjà d’increment del volum cel·lular en una hora d’un cultiu de P. fragi a 0.29 atmosferes de pressió de CO2. I parlarem de la mitjana mostral del tractament “0.29 atmosferes” per referir-nos a la mitjana de la nostra mostra de la població definida pel tractament “0.29 atmosferes”, és a dir, a la mitjana mostral dels percentatges d’increment del volum cel·lular dels cultius de P. fragi a 0.29 atmosferes obtinguts en aquest experiment. Si diem \\(\\mu_1,\\ldots,\\mu_k\\) a les mitjanes d’aquesta variable en aquestes \\(k\\) poblacions, la pregunta que ens plantejam correspon al contrast: \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_1 =\\mu_2 =\\cdots =\\mu_k \\\\ H_1 : \\text{Hi ha }i,j\\text{ tals que } \\mu_i \\neq\\mu_j \\end{array} \\right. \\] Aleshores, prendrem una mostra aleatòria de cada població (una mostra estratificada de la població total, recordau?), i a partir d’aquestes mostres decidirem aquest contrast. Exemple 10.2 Continuem amb el nostre Exemple 10.1. Per a cada \\(\\ell=0,0.08,0.29,0.50,0.86\\), consideram la variable aleatòria \\(X_\\ell\\): “Prenc un cultiu de P. fragi a \\(\\ell\\) atmosferes de CO2 i mesur el percentatge de creixement del seu volum cel·lular en una hora”. Volem realitzar el contrast \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_0=\\mu_{0.08}=\\mu_{0.29}=\\mu_{0.50}=\\mu_{0.86} \\\\ H_1 : \\text{No totes aquestes mitjanes són iguals} \\end{array} \\right. \\] En temes anteriors, per comparar les mitjanes d’una variable sobre dues poblacions, calculàvem les mitjanes de dues mostres i les comparàvem. Per comparar les mitjanes de \\(k\\geqslant 3\\) poblacions, podríem fer-ho per parelles, però hauríem de fer \\(\\binom{k}{2}\\) contrastos i això augmenta la probabilitat d’error. A més, les hem de comparar totes amb totes, perquè podria passar que no poguéssim rebutjar que \\(\\mu_1= \\mu_2\\) ni que \\(\\mu_2= \\mu_3\\) però en canvi sí que poguéssim rebutjar que \\(\\mu_1= \\mu_3\\). El que volem és un test que ens digui en un sol pas si totes les mitjanes són iguals o no; si concloem que no, després ja cercarem quines mitjanes són diferents si volem saber-ho. La tècnica més usual per efectuar aquest tipus de contrast és l’Anàlisi de la Variància o ANOVA (de l’anglès ANalysis Of VAriance; en llibres en castellà o català de vegades hi trobareu el terme ANDEVA, d’ANàlisi DE la VAriància, però no el farem servir, perquè trobam que sona més a marca de producte d’higiene íntima femenina que a tècnica estadística seriosa). L’ANOVA és tot un món, i té moltes variants segons el disseny de l’experiment que ha produït les dades: Segons quants factors emprem per separar la població en subpoblacions Segons com triem els nivells dels factors Segons com prenguem les mostres En aquest curs veurem els tres dissenys més bàsics: L’ANOVA d’1 via, que generalitza el test t de dues mitjanes a partir de dues mostres independents a \\(k\\) mitjanes de poblacions definides pels nivells d’un únic factor, a partir de \\(k\\) mostres independents. L’ANOVA de blocs, que generalitza el test t de dues mitjanes a partir de dues mostres aparellades a \\(k\\) mitjanes de poblacions definides pels nivells d’un únic factor, a partir de \\(k\\) mostres aparellades. L’ANOVA de 2 vies, que generalitza el test t de dues mitjanes a partir de dues mostres independents a més de dues mitjanes de poblacions definides per les combinacions de nivells de dos factors, a partir de mostres independents. Recordau que en català “Anàlisi” és femení, mentre que en castellà “Análisis” és masculí. Per tant en català diem “una ANOVA” i en castellà “un ANOVA”. ANO…VA? Que no volíem comparar mitjanes? Idò com és que analitzam variàncies? L’estratègia per comparar les mitjanes de 3 o més poblacions serà fixar-nos en tres fonts de variabilitat, o dispersió, de les dades: La variabilitat total de les dades La variabilitat dins cada mostra La variabilitat de les mitjanes mostrals La idea és que si les mitjanes mostrals tenen molta variabilitat, ho prendrem com a senyal que les mitjanes poblacionals no poden ser totes iguals. Com ho mesurarem? Amb definicions adients de les “variabilitats”, resultarà que La variabilitat total de les dades és igual a la suma de la variabilitat de les mitjanes mostrals més la suma de les variabilitats dins les mostres. Aleshores, la idea bàsica anterior es tradueix en: Si la variabilitat total de les dades és molt més gran que la suma de les variabilitats dins les mostres, hi haurà una gran variabilitat de les mitjanes mostrals, i ho prendrem com a senyal que les mitjanes poblacionals no són iguals. Per exemple, si teniu molta variabilitat global i molt poca dins cada tractament serà evidència que les mitjanes poblacionals no són iguals. Si en canvi teniu molta variabilitat global però també molta dins cada tractament no obtendrem evidència per rebutjar que les mitjanes poblacionals siguin totes tres iguals. La pregunta és ara com quantificam aquestes variabilitats i com definim què significa “molt més gran”. Es tractarà de trobar un estadístic de contrast del qual en coneguem la distribució mostral si la hipòtesi nul·la és vertadera i que esperem que prengui un valor petit si la hipòtesi nul·la és vertadera. 10.2 ANOVA d’1 via 10.2.1 Contrast bàsic La situació és la següent. Tenim una variable aleatòria \\(X\\) i un (únic) factor amb \\(k\\geqslant 3\\) nivells (o tractaments). Aquests nivells classifiquen la població en \\(k\\) subpoblacions. Diguem \\(\\mu_i\\) a la mitjana de \\(X\\) en els individus del nivell \\(i\\)-èsim. Volem comparar aquestes mitjanes \\(\\mu_1\\),…,\\(\\mu_k\\) i més en concret decidir si són totes iguals o no. En un experiment de disseny d’ANOVA d’1 via (en anglès, 1 way; el motiu d’aquest nom és que empram una única “manera” de classificar la població, en anglès one way que també es tradueix per “una via”, i així ha quedat el nom en les nostres llengües): S’empra un factor amb \\(k&gt;2\\) nivells per classificar una població en subpoblacions. Es pren una m.a.s. de cada subpoblació, de manera independent les unes de les altres, i es mesura la variable d’interès \\(X\\) sobre tots els subjectes de les mostres. Per exemple, l’experiment del nostre Exemple 10.1 té disseny d’ANOVA d’1 via: La variable \\(X\\) assigna a cada cultiu de P. fragi el seu percentatge d’increment cel·lular en una hora. El factor emprat per classificar la població és la pressió de CO2: es consideren 5 nivells diferents, sota els quals es realitzen els cultius. Cada \\(X_\\ell\\) de l’Exemple 10.2 és la restricció de \\(X\\) a la subpoblació definida pel nivell \\(\\ell\\): els cultius realitzats a \\(\\ell\\) atmosferes de CO2. S’hi ha pres una m.a.s. per a cada nivell de pressió \\(\\ell\\), i de manera independent les unes de les altres. Ja que hi som, anam a organitzar les dades d’aquest experiment de manera adient. Les emmagatzemarem en un dataframe que anomenarem CO2 amb dues variables: Inc: Percentatge d’increment de la massa cel·lular (al cap d’una hora); una variable numèrica Pre: Nivell de pressió, com a factor De cara a fer-ho amb R, és important que tengueu present que la variable que defineix les subpoblacions, en aquest cas la que dóna el nivell de pressió de CO2, ha de ser un factor o, almenys, una vector de paraules. No pot ser un vector numéric. Les dades eren: \\[ \\begin{array}{c} \\text{Pressió de CO${}_2$ (en atmosferes)}\\\\ \\begin{array}{rrrrr} 0.0 &amp; 0.08 &amp; 0.29 &amp; 0.50 &amp; 0.86 \\\\\\hline 62.6 &amp; 50.9 &amp; 45.5 &amp; 29.5 &amp; 24.9 \\\\ 59.6 &amp; 44.3 &amp; 41.1 &amp; 22.8 &amp; 17.2 \\\\ 64.5 &amp; 47.5 &amp; 29.8 &amp; 19.2 &amp; 7.8 \\\\ 59.3 &amp; 49.5 &amp; 38.3 &amp; 20.6 &amp; 10.5 \\\\ 58.6 &amp; 48.5 &amp; 40.2 &amp; 29.2 &amp; 17.8 \\\\ 64.6 &amp; 50.4 &amp; 38.5 &amp; 24.1 &amp; 22.1 \\\\ 50.9 &amp; 35.2 &amp; 30.2 &amp; 22.6 &amp; 22.6 \\\\ 56.2 &amp; 49.9 &amp; 27.0 &amp; 32.7 &amp; 16.8 \\\\ 52.3 &amp; 42.6 &amp; 40.0 &amp; 24.4 &amp; 15.9 \\\\ 62.8 &amp; 41.6 &amp; 33.9 &amp; 29.6 &amp; 8.8 \\end{array} \\end{array} \\] Entrarem els increments per fileres (és com és més fàcil copiar-los i aferrar-los), per tant el factor Pre ha d’estar format per 10 còpies consecutives del vector (0.0,0.08,0.29,0.50,0.86). Inc=c(62.6,50.9,45.5,29.5,24.9,59.6,44.3,41.1,22.8,17.2,64.5, 47.5,29.8,19.2,7.8,59.3,49.5,38.3,20.6,10.5,58.6,48.5, 40.2,29.2,17.8,64.6,50.4,38.5,24.1,22.1,50.9,35.2,30.2, 22.6,22.6,56.2,49.9,27.0,32.7,16.8,52.3,42.6,40.0,24.4, 15.9,62.8,41.6,33.9,29.6,8.8) Pre=as.factor(rep(c(&quot;0.0&quot;,&quot;0.08&quot;,&quot;0.29&quot;,&quot;0.50&quot;,&quot;0.86&quot;), times=10)) CO2=data.frame(Inc,Pre) str(CO2) ## &#39;data.frame&#39;:\t50 obs. of 2 variables: ## $ Inc: num 62.6 50.9 45.5 29.5 24.9 59.6 44.3 41.1 22.8 17.2 ... ## $ Pre: Factor w/ 5 levels &quot;0.0&quot;,&quot;0.08&quot;,&quot;0.29&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... head(CO2,7) ## Inc Pre ## 1 62.6 0.0 ## 2 50.9 0.08 ## 3 45.5 0.29 ## 4 29.5 0.50 ## 5 24.9 0.86 ## 6 59.6 0.0 ## 7 44.3 0.08 Veiem que hem definit del dataframe com toca. Donem ara una ullada a les dades. Primer un diagrama de punts de cada nivell de CO2 (amb només 10 valors per nivell, és més adient dibuixar-los tots que resumir-los en diagrames de caixes): stripchart(Inc~Pre,data=CO2,xlab=&quot;Pressions&quot;,ylab=&quot;Increment&quot;,method=&quot;stack&quot;, vertical=TRUE,pch=20,cex=0.75) I ara un que mostri la variabilitat de les dades i les mitjanes com els del final de la secció anterior. Aquest gràfic normalment no el dibuixarem, simplement és per comparar-lo amb aquells gràfics. De totes formes, donam el codi per si qualque dia voleu produir un gràfic d’aquest estil. # Els paràmetres generals plot(1:50,c(CO2$Inc[CO2$Pre==&quot;0.0&quot;],CO2$Inc[CO2$Pre==&quot;0.08&quot;],CO2$Inc[CO2$Pre==&quot;0.29&quot;],CO2$Inc[CO2$Pre==&quot;0.50&quot;],CO2$Inc[CO2$Pre==&quot;0.86&quot;]),type=&quot;n&quot;,xlab=&quot;Número del cultiu&quot;,ylab=&quot;Increment&quot;) # Els punts points(1:10,CO2$Inc[CO2$Pre==&quot;0.0&quot;],pch=16,col=&quot;red&quot;) points(11:20,CO2$Inc[CO2$Pre==&quot;0.08&quot;],pch=15,col=&quot;blue&quot;) points(21:30,CO2$Inc[CO2$Pre==&quot;0.29&quot;],pch=17,col=&quot;green&quot;) points(31:40,CO2$Inc[CO2$Pre==&quot;0.50&quot;],pch=19,col=&quot;brown2&quot;) points(41:50,CO2$Inc[CO2$Pre==&quot;0.86&quot;],pch=18,col=&quot;brown&quot;) # La mitjana mostral global lines(c(0,50),c(mean(CO2$Inc),mean(CO2$Inc)),lwd=2) text(5,34,&quot;Mitjana global&quot;,cex=0.75) # Les mitjanes mostrals de les mostres lines(c(0,10),c(mean(CO2$Inc[CO2$Pre==&quot;0.0&quot;]),mean(CO2$Inc[CO2$Pre==&quot;0.0&quot;])),lwd=2,col=&quot;red&quot;) lines(c(10,20),c(mean(CO2$Inc[CO2$Pre==&quot;0.08&quot;]),mean(CO2$Inc[CO2$Pre==&quot;0.08&quot;])),lwd=2,col=&quot;blue&quot;) lines(c(20,30),c(mean(CO2$Inc[CO2$Pre==&quot;0.29&quot;]),mean(CO2$Inc[CO2$Pre==&quot;0.29&quot;])),lwd=2,col=&quot;green&quot;) lines(c(30,40),c(mean(CO2$Inc[CO2$Pre==&quot;0.50&quot;]),mean(CO2$Inc[CO2$Pre==&quot;0.50&quot;])),lwd=2,col=&quot;brown2&quot;) lines(c(40,50),c(mean(CO2$Inc[CO2$Pre==&quot;0.86&quot;]),mean(CO2$Inc[CO2$Pre==&quot;0.86&quot;])),lwd=2,col=&quot;brown&quot;) text(20,mean(CO2$Inc[CO2$Pre==&quot;0.0&quot;]),&quot;Mitjana del nivell 0.0&quot;,col=&quot;red&quot;,cex=0.75) text(30,mean(CO2$Inc[CO2$Pre==&quot;0.08&quot;]),&quot;Mitjana del nivell 0.083&quot;,col=&quot;blue&quot;,cex=0.75) text(40,mean(CO2$Inc[CO2$Pre==&quot;0.29&quot;]+2),&quot;Mitjana del nivell 0.29&quot;,col=&quot;green&quot;,cex=0.75) text(20,mean(CO2$Inc[CO2$Pre==&quot;0.50&quot;]),&quot;Mitjana del nivell 0.50&quot;,col=&quot;brown2&quot;,cex=0.75) text(30,mean(CO2$Inc[CO2$Pre==&quot;0.86&quot;]),&quot;Mitjana del nivell 0.86&quot;,col=&quot;brown&quot;,cex=0.75) Veiem que hi ha una gran dispersió dins la mostra completa, no massa dispersió dins cada mostra per nivell, i les mitjanes mostrals per nivells són bastant diferents. Naturalment, fins que no fem una anàlisi estadística no sabrem si aquestes variabilitats i diferències són estadísticament significatives o no. En un experiment amb disseny d’ANOVA d’1 via, disposarem les dades en una taula com la de l’Exemple anterior, amb les columnes representant els tractaments: \\[ \\begin{array}{c} \\text{Tractaments}\\\\ \\begin{array}{cccc} 1 &amp; 2 &amp;\\ldots &amp; k \\\\\\hline X_{11} &amp; X_{21} &amp; \\cdots &amp; X_{k1} \\\\ X_{12} &amp; X_{22} &amp; \\cdots &amp; X_{k2} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; X_{kn_k} \\\\ X_{1n_1} &amp; \\vdots &amp; \\vdots &amp; \\\\ &amp; X_{2n_2} &amp; &amp; \\\\\\hline \\end{array} \\end{array} \\] on Cada \\(n_i\\) és la mida de la mostra del tractament \\(i\\); com hem intentat representar a la taula, aquestes \\(n_i\\) no tenen perquè ser totes iguals (però és convenient que ho siguin, perquè la potència d’un contrast ANOVA depèn del mínim d’aquestes \\(n_i\\)). \\(X_{ij}\\) és el valor de la variable sota estudi al subjecte \\(j\\) del tractament \\(i\\). \\(N=n_1+\\cdots+n_k\\) és la mida total de la mostra. ALERTA! Aquestes notacions no són les usuals a les matrius o a les taules de dades. Aquí, a \\(X_{ij}\\), \\(i\\) hi indica la columna i \\(j\\) la filera. Observau també que a la taula de dades anterior no és veritat que cada filera representi un individu: en realitat cada columna pot tenir una alçada diferent. En aquesta taula cada \\(X_{ij}\\) representa un individu diferent. Perquè es pugui realitzar un contrast ANOVA d’1 via, s’han de satisfer les condicions següents: Les \\(k\\) mostres han de ser m.a.s. independents extretes de \\(k\\) poblacions específiques, amb mitjanes \\(\\mu_1,\\ldots,\\mu_k\\) \\(N\\geqslant k+1\\) (alguna mostra ha de tenir més d’un subjecte) Cadascuna de les \\(k\\) poblacions ha de seguir una llei normal Homogeneïtat de les variàncies, o homocedasticitat: Totes aquestes poblacions han de tenir la mateixa variància, que indicarem amb \\(\\sigma^2\\) No basten mostres grans. Aquí no hi juga cap paper el Teorema Central del Límit. Però, per sort, les conclusions d’una ANOVA són bastant robustes encara que falli la condició de normalitat de les subpoblacions. En canvi són molt sensibles a l’heterocedasticitat (el contrari d’homocedasticitat; “hetero” indica el contrari de “homo”). Donades diverses variables, hi tenim homocedasticitat quan totes tenen la mateixa variància, i heterocedasticitat quan no totes tenen la mateixa variància. Fixau-vos que ens referim a les variàncies de les poblacions, no de les mostres. Per exemple, les tres mostres del gràfic de l’esquerra següent provenen de variables normals amb la mateixa variància, representades al gràfic de la dreta: hi ha homocedasticitat: En canvi, dues de les mostres del gràfic següent provenen de variables normals amb la mateixa variància, mentre que la tercera prové d’una normal amb una variància molt més gran: hi ha heterocedasticitat: L’homocedasticitat no és que les mostres dels tractaments tenguin la mateixa variància, sinó que els tractaments tenguin la mateixa variància poblacional. Diguem \\(\\mu\\) a la mitjana poblacional de la població global (sense tenir en compte la classificació donada pels tractaments). Recordau que la hipòtesi nul·la del contrast que volem realitzar és \\[ H_0: \\mu_1=\\cdots=\\mu_k \\] Si és vertadera, aleshores en realitat passarà que \\[ \\mu_1=\\cdots=\\mu_k=\\mu \\] perquè si totes les subpoblacions tenen la mateixa mitjana, aquesta mitjana comuna serà la mitjana de tota la població. En aquest tema és el primer cop que tenim ocasió de parlar de models estadístics. Informalment, un model no és res més que una descripció matemàtica del comportament d’una o vàries variables aleatòries sobre una població. Aquests models inclouen assumpcions sobre la població que poden ser veritat o no, i que si no ho són aleshores les conclusions de l’anàlisi estadística que fem basant-nos en aquest model no tendran cap sentit. En concret, l’ANOVA d’1 via es basa en el model següent: per a cada \\(i=1,\\ldots,k\\), \\[ X_i=\\mu+(\\mu_i-\\mu)+(X_i-\\mu_i) \\] on: \\(X_i\\) representa el valor de la variable \\(X\\) sobre un individu del nivell \\(i\\)-èsim. \\(\\mu_i-\\mu\\) representa la desviació de la mitjana de \\(X\\) en el nivell \\(i\\)-èsim respecte de la mitjana global \\(\\mu\\); en direm l’efecte del tractament \\(i\\)-èsim i representa la contribució al valor de \\(X\\) sobre un individu del nivell \\(i\\)-èsim del fet de pertànyer a aquest nivell. \\(X_i-\\mu_i\\), la desviació de la variable \\(X\\) sobre un individu del nivell \\(i\\)-èsim respecte de la mitjana d’aquest nivell, \\(\\mu_i\\), representa el component aleatori en una medició concreta de \\(X\\) sobre un individu del nivell \\(i\\)-èsim, és a dir, “la part de la diferència entre \\(X_{i}\\) i \\(\\mu\\) que no explica el tractament”; en diem l’error aleatori, o el residu. Fixau-vos que, formalment, la fórmula que descriu aquest model és sempre vertadera: podeu simplificar les \\(\\mu_i\\) i les \\(\\mu\\) de la dreta. Però el que diu aquest model és que el valor de \\(X\\) sobre un individu és la suma de tres components: La mitjana global L’efecte del tractament L’error aleatori i en particular que res més no influeix en el valor de \\(X\\) sobre un individu. Per tant, si això no és cert, és a dir, si aquest valor pot dependre d’altres efectes que no tinguem en compte, el model no és vàlid, i les conclusions de l’ANOVA tampoc. Passem ara a la mostra amb què volem realitzar el contrast. Siguin: \\(\\overline{X}_{i}\\): La mitjana mostral de la mostra del tractament \\(i\\)-èsim: \\[ \\overline{X}_{i} = \\frac{\\sum_{j=1}^{n_i} X_{ij}}{n_i} \\] Estima la mitjana \\(\\mu_i\\) de la subpoblació definida pel tractament \\(i\\)-èsim. \\(\\overline{X}\\): La mitjana mostral de tota la mostra: \\[ \\overline{X}=\\frac{\\sum_{i=1}^k \\sum_{j=1}^{n_i} X_{ij}}{N} \\] Estima la mitjana \\(\\mu\\) de la població global. Es té la identitat següent: Teorema 10.1 (Identitat de les sumes de quadrats) \\[ SS_{Total}=SS_{Tr}+SS_E \\] on \\(SS_{Total}=\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^{n_i} (X_{ij}-\\overline{X})^2\\); és la Suma Total de Quadrats. \\(SS_{Tr}=\\displaystyle\\sum_{i=1}^k n_i(\\overline{X}_{i}-\\overline{X})^2\\); és la Suma de Quadrats dels Tractaments. \\(SS_E=\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^{n_i} (X_{ij}-\\overline{X}_{i})^2\\); és la Suma de Quadrats dels Residus o dels Errors. Fixau-vos que \\(SS_{Total}\\) representa la variabilitat total de les dades: de fet, és el numerador de la variància de la mostra total. \\(SS_{Tr}\\) representa la variabilitat de les mitjanes mostrals: és el numerador de la variància d’un vector format per \\(n_1\\) còpies de \\(\\overline{X}_1\\), \\(n_2\\) còpies de \\(\\overline{X}_2\\), … i \\(n_k\\) còpies de \\(\\overline{X}_k\\). \\(SS_E\\) representa la suma de les variabilitats de les dades de la mostra de cada tractament: és la suma dels numeradors de les variàncies de les \\(k\\) mostres dels diferents tractaments. \\(SS_{Total}=SS_{Tr}+SS_E\\) diu que la variabilitat total de la mostra descompon en la suma de la variabilitat de les mitjanes i la suma de les variabilitats de les mostres de cada tractament. Amb la terminologia introduïda quan explicàvem el model de l’ANOVA d’1 via, cada \\(X_{ij}-\\overline{X}_i\\) estima el residu, o error, sobre l’individu \\(j\\)-èsim del nivell \\(i\\)-èsim \\(X_{ij}-\\mu_i\\). Per això a \\(\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^{n_i} (X_{ij}-\\overline{X}_{i})^2\\) li diem la Suma de Quadrats dels Residus o dels Errors. Exemple 10.3 Tornem al nostre Exemple 10.1. Tenim les dades guardades en el dataframe CO2 str(CO2) ## &#39;data.frame&#39;:\t50 obs. of 2 variables: ## $ Inc: num 62.6 50.9 45.5 29.5 24.9 59.6 44.3 41.1 22.8 17.2 ... ## $ Pre: Factor w/ 5 levels &quot;0.0&quot;,&quot;0.08&quot;,&quot;0.29&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... Aleshores: Les mitjanes mostrals dels tractaments, \\(\\overline{X}_{i}\\), es calculen amb mitjanes.tracts=aggregate(Inc~Pre,data=CO2,mean) mitjanes.tracts ## Pre Inc ## 1 0.0 59.14 ## 2 0.08 46.04 ## 3 0.29 36.45 ## 4 0.50 25.47 ## 5 0.86 16.44 La mitjana mostral global, \\(\\overline{X}\\), és: mitjana.total=mean(CO2$Inc) mitjana.total ## [1] 36.708 La \\(SS_{Total}=\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^{n_i} (X_{ij}-\\overline{X})^2\\) és SSTotal=sum((CO2$Inc-mitjana.total)^2) SSTotal ## [1] 12522.36 Per calcular \\[ SS_{Tr}=\\displaystyle\\sum_{i=1}^k n_i(\\overline{X}_{i}-\\overline{X})^2 \\] hem d’observar que les mitjanes \\(\\overline{X}_{i}\\) formen la variable Inc del dataframe mitjanes.tracts mitjanes.tracts$Inc ## [1] 59.14 46.04 36.45 25.47 16.44 i els \\(n_i\\) són les freqüències absolutes de cada nivell dins la variable CO2$Pre table(CO2$Pre) ## ## 0.0 0.08 0.29 0.50 0.86 ## 10 10 10 10 10 Per tant la fórmula que defineix \\(SS_{Tr}\\) se tradueix en SSTr=sum(table(CO2$Pre)*(mitjanes.tracts$Inc-mitjana.total)^2) SSTr ## [1] 11274.32 Per calcular \\[ SS_E=\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^{n_i} (X_{ij}-\\overline{X}_{i})^2 \\] podem fixar-nos que, tal i com hem construït el dataframe CO2, les entrades de CO2$Inc que difereixen en un múltiple de 5 són del mateix tractament; per exemple, les entrades que corresponen a pressió 0 són la 1a, la 6a, la 11a etc.; les entrades que corresponen a pressió 0.83 són la 2a, la 7a, la 12a etc.; i així successivament. Per tant, si fem CO2$Inc-mitjanes.tracts$Inc, com que la longitud de CO2$Inc és 10 vegades la de mitjanes.tracts$Inc, el que estarem dient és que a CO2$Inc se li resti un vector format per 10 còpies consecutives de mitjanes.tracts$Inc, i d’aquesta manera justament a cada entrada de CO2$Inc se li restarà l’entrada de mitjanes.tracts$Inc que conté la mitjana del seu tractament. Per tant, \\(SS_E\\) es pot calcular amb SSE=sum((CO2$Inc-mitjanes.tracts$Inc)^2) SSE ## [1] 1248.038 Si no estau còmodes amb això de restar vectors de longituds una un múltiple de l’altra, el que heu de fer és restar a CO2$Inc un vector format per 10 còpies consecutives de mitjanes.tracts$Inc: SSEalt=sum((CO2$Inc-rep(mitjanes.tracts$Inc,times=10))^2) SSEalt ## [1] 1248.038 Comprovem la identitat de les sumes de quadrats: SSTotal ## [1] 12522.36 SSTr+SSE ## [1] 12522.36 La idea del contrast ANOVA és que Rebutjam la hipòtesi nul·la si \\(SS_{Tr}\\) és molt gran. Per la identitat de les sumes de quadrats \\(SS_{Total}=SS_{Tr}+SS_E\\), això ho podem traduir en Rebutjam la hipòtesi nul·la si \\(SS_{Total}\\) és molt més gran que \\(SS_E\\). I això en realitat ho traduïm en Rebutjam la hipòtesi nul·la si \\(SS_{Tr}\\) és molt més gran que \\(SS_E\\). Per mesurar-ho emprarem els estadístics següents: Quadrat mitjà dels tractaments: \\[ MS_{Tr}=\\frac{SS_{Tr}}{k-1} \\] Quadrat mitjà residual: \\[ MS_E=\\frac{SS_E}{N-k} \\] Aquests estadístics són variables aleatòries, i sota les condicions necessàries per poder fer una ANOVA (mostres aleatòries simples independents, variable poblacional normal per a cada tractament i totes amb la mateixa variància, que indicarem amb \\(\\sigma^2\\)), satisfan que: \\(E(MS_{Tr})=\\displaystyle\\sigma^2 + \\sum_{i=1}^k \\frac{n_i (\\mu_i-\\mu)^2}{k-1}\\) \\(E(MS_E)=\\sigma^2\\) En particular, \\(MS_E\\) és un estimador no esbiaixat de la variància poblacional comuna de tots els tractaments, \\(\\sigma^2\\). Ara, si \\(H_0:\\mu_1=\\cdots=\\mu_k (=\\mu)\\) és certa, \\[ \\sum_{i=1}^k \\frac{n_i (\\mu_i -\\mu)^2}{k-1}=0, \\] i si \\(H_0\\) no és certa, aquesta quantitat és \\(&gt;0\\). Per tant Si \\(H_0\\) és certa, \\(E(MS_E)=E(MS_{Tr})\\) i per tant hauríem d’esperar que aquests dos estadístics prenguessin valors propers, és a dir, hauríem d’esperar que \\[ \\frac{MS_{Tr}}{MS_E}\\approx 1 \\] Si \\(H_0\\) és falsa, \\(E(MS_E)&lt;E(MS_{Tr})\\) i hauríem d’esperar que \\(MS_{Tr}\\) donàs valors més grans que \\(MS_E\\), és a dir, hauríem d’esperar que \\[ \\frac{MS_{Tr}}{MS_E}&gt; 1 \\] Aleshores, prenem com a estadístic de contrast el quocient \\[ F=\\frac{MS_{Tr}}{MS_E} \\] el qual satisfà la propietat següent. Teorema 10.2 Sota les condicions necessàries per poder realitzar una ANOVA i si \\(H_0:\\mu_1=\\cdots=\\mu_k\\) és certa, La variable F té distribució F de Fisher amb \\(k-1\\) i \\(N-k\\) graus de llibertat, \\(F_{k-1,N-k}\\). El seu valor és proper a 1. Per tant, en una ANOVA rebutjarem la hipòtesi nul·la si el valor \\(F_0\\) de F obtingut sobre la nostra mostra és molt gran. Això ho traduirem en que rebutjarem la hipòtesi nul·la si la probabilitat que F sigui més gran que \\(F_0\\) és petita, i aquesta probabilitat serà el p-valor del contrast. Si \\(k=2\\), aquesta F és igual al quadrat de l’estadístic del test t de 2 mostres independents i variàncies iguals. Per tant, efectuar una ANOVA d’1 via amb només 2 tractaments és equivalent a efectuar un test t amb mostres independents i mateixa variància poblacional. Per si qualcú necessita una dosi d’àlgebra, recordau que el quadrat de l’estadístic del test t de 2 mostres independents i variàncies iguals és \\[ T^2=\\frac{(\\overline{X}_1-\\overline{X}_2)^2}{(\\frac{1}{n_1}+\\frac{1}{n_2})\\cdot \\frac{(n_1-1)\\widetilde{S}_{X_1}^2+(n_2-1)\\widetilde{S}_{X_2}^2}{n_1+n_2-2}} \\] i que el nostre F és \\(MS_{Tr}/MS_E\\). Ara, en el cas \\(k=2\\), \\[ MS_E=\\frac{\\sum_{j=1}^{n_1}(X_{1j}-\\overline{X}_1)^2+\\sum_{j=1}^{n_2}(X_{2j}-\\overline{X}_2)}{N-2}= \\frac{(n_1-1)\\widetilde{S}_{X_1}+(n_2-1)\\widetilde{S}_{X_2}}{n_1+n_2-2} \\] que surt tal qual al denominador de \\(T^2\\). Per tant ens queda veure que \\(MS_{Tr}\\) és igual a \\[ \\frac{(\\overline{X}_1-\\overline{X}_2)^2}{\\frac{1}{n_1}+\\frac{1}{n_2}} \\] Per simplificar, diguem \\(S_1=n_1\\overline{X}_1=\\sum_{j=1}^{n_1} X_{1j}\\), \\(S_2=n_2\\overline{X}_2=\\sum_{j=1}^{n_2} X_{2j}\\) i \\[ S=(n_1+n_2)\\overline{X}=\\sum_{i=1}^2\\sum_{j=1}^{n_i} X_{ij}=S_1+S_2=n_1\\overline{X}_1+n_2\\overline{X}_2. \\] Doncs va, desenvolupem \\(MS_{Tr}\\) en aquest cas \\(k=2\\): \\[ \\begin{array}{rl} MS_{Tr} &amp; \\displaystyle = \\frac{n_1(\\overline{X}_1-\\overline{X})^2+n_2(\\overline{X}_2-\\overline{X})^2}{1}\\\\ &amp; \\displaystyle = n_1\\overline{X}_1^2-2n_1\\overline{X}_1\\overline{X}+n_1\\overline{X}^2+ n_2\\overline{X}_2^2-2n_2\\overline{X}_2\\overline{X}+n_2\\overline{X}^2\\\\ &amp; \\displaystyle = S_1\\overline{X}_1+S_2\\overline{X}_2-2S_1\\overline{X}-2S_2\\overline{X}+(n_1+n_2)\\overline{X}^2\\\\ &amp; \\displaystyle =S_1\\overline{X}_1+S_2\\overline{X}_2-2(S_1+S_2)\\overline{X}+(S_1+S_2)\\overline{X}\\\\ &amp; \\displaystyle =S_1\\overline{X}_1+S_2\\overline{X}_2-(S_1+S_2)\\overline{X}\\\\ &amp; \\displaystyle = S_1\\overline{X}_1+S_2\\overline{X}_2 -\\frac{(S_1+S_2)(n_1\\overline{X}_1+n_2\\overline{X}_2)}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{(n_1+n_2)S_1\\overline{X}_1+(n_1+n_2)S_2\\overline{X}_2-n_1S_1\\overline{X}_1-n_1S_2\\overline{X}_1-n_2S_1\\overline{X}_2-n_2S_2\\overline{X}_2}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{n_2S_1\\overline{X}_1+n_1S_2\\overline{X}_2-n_1S_2\\overline{X}_1-n_2S_1\\overline{X}_2}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{n_2n_1\\overline{X}_1^2+n_1n_2\\overline{X}_2^2-n_1n_2\\overline{X}_2\\overline{X}_1-n_2n_1\\overline{X}_1\\overline{X}_2}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{n_1n_2(\\overline{X}_1^2+\\overline{X}_2^2-2\\overline{X}_1\\overline{X}_2)}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{n_1n_2(\\overline{X}_1-\\overline{X}_2^2}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{(\\overline{X}_1-\\overline{X}_2)^2}{\\frac{n_1+n_2}{n_1n_2}}\\\\ &amp; \\displaystyle =\\frac{(\\overline{X}_1-\\overline{X}_2)^2}{\\frac{1}{n_1}+\\frac{1}{n_2}} \\end{array} \\] En resum, per realitzar una ANOVA d’1 via a partir d’una mostra: Calculam les sumes de quadrats \\[ SS_{Tr},\\ SS_E \\] Calculam els quadrats mitjans \\[ MS_{Tr}=\\frac{SS_{Tr}}{k-1},\\ MS_E=\\frac{SS_E}{N-k} \\] Calculam el valor de l’estadístic de contrast \\[ F_0=\\frac{MS_{Tr}}{MS_E} \\] Calculam el p-valor \\[ P(F_{k-1,N-k}\\geqslant F_0) \\] Si el p-valor és més petit que el nivell de significació \\(\\alpha\\), rebutjam \\(H_0\\) i concloem que no totes les mitjanes són iguals. En cas contrari, acceptam que totes les mitjanes són iguals. Exemple 10.4 Continuem amb el nostre Exemple 10.1. Ja sabem que \\(N=50\\), \\(k=5\\), \\(SS_{Total}=12522.36\\), \\(SS_{Tr}=11274.32\\) i \\(SS_E=1248.038\\). Els quadrats mitjans són: N=50 k=5 MSTr=SSTr/(k-1) MSTr ## [1] 2818.58 MSE=SSE/(N-k) MSE ## [1] 27.73418 L’estadístic de contrast val: F0=MSTr/MSE F0 ## [1] 101.6284 El p-valor \\(P(F_{k-1,N-k}\\geqslant F_0)\\) val 1-pf(F0,k-1,N-k) ## [1] 0 Conclusió: Hem trobat evidència estadística que el nivell de pressió de CO2 influeix en el creixement mitjà del microorganisme Pseudomonas fragi (ANOVA, p-valor 0). Per ara només concloem que no totes les mitjanes (dels percentatges d’increment de volum cel·lular) són iguals: no concloem que totes aquestes mitjanes siguin diferents. No és el mateix! Un contrast ANOVA d’1 via se sol resumir en la taula ANOVA següent: \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; k-1 &amp; SS_{Tr}&amp; MS_{Tr} &amp; F &amp; \\text{p-valor} \\\\ \\text{Residus} &amp; N-k &amp; SS_E &amp; MS_E &amp; \\\\\\hline \\end{array} \\] Així, la taula de l’ANOVA de l’Exemple 10.1 és \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; 4 &amp; 11274.32&amp; 2818.58 &amp; 101.63 &amp; 0 \\\\ \\text{Residus} &amp; 45 &amp; 1248.04 &amp; 27.73 &amp; \\\\\\hline \\end{array} \\] En aquesta taula, a banda de l’estadístic de contrast i el p-valor, ens pot interessar el valor del \\(MS_E\\), que estima la variància comuna de tots els tractaments. En el nostre exemple, (si se satisfan les condicions per poder efectuar una ANOVA d’1 via) estimam que les variables que ens donen els percentatges d’increment en 1 hora de les poblacions de P. fragi sota les diferents pressions de CO2 considerades tenen totes variància (poblacional) 27.73. Vegem un altre exemple. Exemple 10.5 Disposam de quatre tractaments genètics diferents, numerats de l’1 al 4, per corregir un cert gen defectuós responsable d’una malaltia. Els investigadors volen saber si els quatre tractaments tenen una eficàcia similar o no. Per contrastar-ho, en un assaig clínic es varen prendre 20 pacients amb aquesta malaltia, els repartiren aleatòriament en 4 grups de 5 malalts cadascun, i assignaren de forma aleatòria un dels quatre tractaments a cada grup. Després d’aplicar el tractament, es va mesurar a cada pacient l’expressió del gen defectuós sota estudi. Les dades obtingudes varen ser \\[ \\begin{array}{c} \\text{Tractament}\\\\ \\begin{array}{llll} 1 &amp; 2 &amp; 3 &amp; 4 \\\\ \\hline 96 &amp; 93 &amp; 70 &amp; 78 \\\\ 99 &amp; 90 &amp; 90 &amp; 87 \\\\ 100 &amp; 75 &amp; 84 &amp; 57 \\\\ 104 &amp; 80 &amp; 76 &amp; 66 \\\\ 84 &amp; 90 &amp; 78 &amp; 76 \\end{array} \\end{array} \\] Aquest experiment té disseny d’ANOVA d’1 via: La variable \\(X\\) és “Prenc un individu amb aquest gen defectuós i mesur l’expressió del gen” (aquí es quantificà per mitjà de la quantitat de mRNA en una mostra biològica mesurada amb un Northern blot, no entrarem en més detall). El factor emprat per classificar les expressions té com a nivells els 4 tractaments objecte d’estudi. S’hi ha pres una m.a.s. per a cada tractament, i de manera independent les unes de les altres. Efectuau a mà l’ANOVA d’1 via d’aquestes dades. Els resultats parcials us haurien de donar: \\(N=20\\), \\(k=4\\), Les mitjanes: \\(\\overline{X}_{1}=96.6\\), \\(\\overline{X}_{2}=85.6\\), \\(\\overline{X}_{3}=79.6\\), \\(\\overline{X}_{4}=72.8\\), \\(\\overline{X}=83.65\\) Les sumes de quadrats: \\(SS_{Total}=2766.55\\), \\(SS_{Tr}=1528.15\\), \\(SS_E=1238.4\\) Els quadrats mitjans: \\(MS_{Tr}=509.4\\), \\(MS_{E}=77.4\\) L’estadístic de contrast, \\(F_0=6.6\\) El p-valor: \\(P(F_{3,16}&gt;6.6)=\\texttt{1-pf(6.6,3,16)}=0.004\\) La taula de l’ANOVA \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; 3&amp; 1528.15 &amp; 509.4 &amp; 6.6 &amp; 0.004 \\\\ \\text{Residus} &amp; 16 &amp; 1238.4 &amp; 77.4 &amp; \\\\\\hline \\end{array} \\] Conclusió: Hem trobat evidència estadística que les quatre teràpies no tenen totes la mateixa eficàcia mitjana (ANOVA, p-valor 0.004). 10.2.2 Amb R Per realitzar una ANOVA, s’aplica la funció summary(aov( )) a la fórmula que separa les dades numèriques segons els nivells del factor (ha de ser un factor o, a partir de la versió 4.0 de R, un vector de paraules). Si la fórmula només especifica els noms de les variables, s’hi ha d’indicar el nom del dataframe amb el paràmetre data. Per exemple, l’ANOVA de l’Exemple 10.1 s’obté amb summary(aov(CO2$Inc~CO2$Pre)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## CO2$Pre 4 11274 2818.6 101.6 &lt;2e-16 *** ## Residuals 45 1248 27.7 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 o, equivalentment, amb summary(aov(Inc~Pre,data=CO2)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Pre 4 11274 2818.6 101.6 &lt;2e-16 *** ## Residuals 45 1248 27.7 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 D’aquesta manera obtenim la taula de l’ANOVA que hem explicat fa una estona. La primera filera, Pre, correspon als tractaments, que són els nivells del factor Pre de CO2. El valor de Pr(&gt; F) és el p-valor del contrast. Exemple 10.6 Per realitzar l’ANOVA de l’Exemple 10.5, primer hem d’entrar les dades en un dataframe. Un altre cop, entrarem les dades per fileres i per tant els indicadors dels tractaments s’han d’entrar com el vector (1,2,3,4) repetit 5 vegades. Expr=c(96,93,70,78,99,90,90,87,100,75,84,57,104,80,76,66,84,90,78,76) Tract=rep(1:4,5) EG=data.frame(Expr,Tract) str(EG) ## &#39;data.frame&#39;:\t20 obs. of 2 variables: ## $ Expr : num 96 93 70 78 99 90 90 87 100 75 ... ## $ Tract: int 1 2 3 4 1 2 3 4 1 2 ... summary(aov(Expr~Tract,data=EG)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Tract 1 1498 1497.7 21.25 0.000218 *** ## Residuals 18 1269 70.5 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 No ha donat el mateix p-valor que quan l’hem fet a mà! No hem entrat els tractaments com un factor. Fixau-vos que el nombre de graus de llibertat a la filera dels tractaments en aquesta taula és 1 i no 3, que és el que tocaria. Va, tornem a començar i ara fem-ho bé: Expr=c(96,93,70,78,99,90,90,87,100,75,84,57,104,80,76,66,84,90,78,76) Tract=as.factor(rep(1:4,5)) EG=data.frame(Expr,Tract) str(EG) ## &#39;data.frame&#39;:\t20 obs. of 2 variables: ## $ Expr : num 96 93 70 78 99 90 90 87 100 75 ... ## $ Tract: Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 1 2 3 4 1 2 3 4 1 2 ... head(EG) ## Expr Tract ## 1 96 1 ## 2 93 2 ## 3 70 3 ## 4 78 4 ## 5 99 1 ## 6 90 2 summary(aov(Expr~Tract,data=EG)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Tract 3 1528 509.4 6.581 0.00417 ** ## Residuals 16 1238 77.4 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Ara sí que hem obtingut el mateix. 10.2.3 Comparacions posteriors per parelles Si hem rebutjat la hipòtesi nul·la \\(H_0:\\mu_1=\\cdots =\\mu_k\\), podem demanar-nos quins són els tractaments que donen mitjanes diferents. Això es pot fer de diverses maneres, aquí veurem la més “òbvia”: comparar totes les parelles de mitjanes per mitjà de tests t. És a dir, per a cada parell de tractaments, realitzar el contrast \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_i=\\mu_j \\\\ H_1 : \\mu_i\\neq\\mu_j \\end{array} \\right. \\] L’estadístic que fem servir en cada un d’aquests contrastos és ara \\[ T=\\frac{\\overline{X}_{i} - \\overline{X}_{j}}{\\sqrt{{MS_E}\\cdot (\\frac{1}{n_i} +\\frac{1}{n_j})}} \\] que, si la hipòtesi nul·la d’aquest contrast és vertadera, segueix una distribució \\(t\\) de Student amb \\(N-k\\) graus de llibertat, \\(t_{N-k}\\). Tots aquests contrastos per parelles serien tests t amb mostres independents i la mateixa variància. Per ventura alguns recordeu que la fórmula que us hem explicat al tema de Contrastos paramètrics per a aquests tests no és aquesta, sinó \\[ T=\\frac{\\overline{X}_i-\\overline{X}_j}{\\sqrt{ \\frac{(n_i-1)\\widetilde{S}_i^2+(n_j-1)\\widetilde{S}_j^2}{n_i+n_j-2}\\cdot \\Big(\\frac{1}{n_i}+\\frac{1}{n_j}\\Big)}} \\] que, si \\(\\mu_i=\\mu_j\\) és vertadera, té distribució \\(t_{n_i+n_j-2}\\). En aquesta fórmula, el factor \\[ \\frac{(n_i-1)\\widetilde{S}_i^2+(n_j-1)\\widetilde{S}_j^2}{n_i+n_j-2} \\] dins l’arrel quadrada del denominador estima la variància comuna de \\(X_i\\) i \\(X_j\\). Però en una ANOVA tenim més dades (les mostres de tots els tractaments, no només d’una parella) i les podem emprar totes per estimar la variància comuna de tots els tractaments. Com ja hem dit quan parlàvem de la distribució dels Quadrats Mitjans, aquesta estimació és \\(MS_E\\), que és el que apareix ara dins l’arrel quadrada del denominador. I com que hem emprat totes les dades que tenim per estimar aquesta variància, i no només les de dues mostres, també canvia el nombre de graus de llibertat. El p-valor de cada contrast serà \\(2P(t_{N-k}\\geqslant |t_{i,j}|)\\), on \\(t_{i,j}\\) és el valor que hi pren aquest estadístic \\(T\\). Ara bé, observau que d’aquesta manera realitzam \\(\\binom{k}{2}\\) contrastos. Com més contrastos fem, més probabilitat tenim d’equivocar-nos. Si es realitzen \\(c\\) contrastos amb nivell de significació \\(\\alpha\\), la probabilitat d’Error de Tipus I a qualcun és més gran que \\(\\alpha\\): de fet, és \\(1-(1-\\alpha)^c\\). Per exemple, a l’Exemple 10.1, si realitzam els \\(c=\\binom{5}{2}=10\\) contrastos (totes les pressions contra totes les pressions) amb nivell de significació \\(\\alpha =0.05\\), la probabilitat de cometre almenys un Error de Tipus I a qualcun (si totes les mitjanes fossin iguals en la realitat) és \\(1-(1-0.05)^{10} \\approx 0.4\\). Per tant, haurem de reduir el nivell de significació de cada contrast perquè la probabilitat global de cometre qualque Error de Tipus I sigui \\(\\alpha\\). O, equivalentment, augmentar (se’n diu ajustar) el p-valor de cada contrast abans de comparar-lo amb l’\\(\\alpha\\) global fixat. Tot seguit explicam dos mètodes d’ajust de p-valors. 10.2.3.1 Mètode de Bonferroni El mètode d’ajust de p-valors més popular és el de Bonferroni. Emprant que \\(1-(1-x)^c \\leqslant c\\cdot x\\), si volem efectuar \\(c\\) contrastos amb nivell de significació (global) \\(\\alpha\\), realitzam cada contrast amb nivell de significació \\(\\alpha/c\\) i així el nivell de significació global segur que serà menor o igual que \\(c\\cdot \\alpha/c=\\alpha\\). O, equivalentment multiplicam el p-valor de cada contrast per \\(c\\) abans de comparar-lo amb el nivell de significació \\(\\alpha\\). Les dues accions són equivalents, perquè \\[ p&lt;\\alpha/c \\Longleftrightarrow c\\cdot p&lt;\\alpha \\] Bé, gairebé equivalents. Si quan multiplicau un dels p-valors per \\(c\\) us dóna un valor més gran que 1, heu de donar com a p-valor ajustat 1. Pensau que, ajustats o no, els p-valors representen probabilitats, i per tant és incorrecte donar-ne de més grans que 1. Exemple 10.7 A l’Exemple 10.1, si realitzam els 10 contrastos per parelles, per obtenir un nivell de significació global \\(\\alpha =0.05\\) amb el mètode de Bonferroni, Hem de efectuar cada contrast amb nivell de significació 0.05/10=0.005 o equivalentment Hem de multiplicar cada p-valor per 10 i comparar-los amb 0.05. A l’Exemple 2, si realitzam els 6 contrastos de totes les parelles possibles, per obtenir un nivell de significació global \\(\\alpha =0.05\\), Hem de efectuar cada contrast amb nivell de significació 0.05/6=0.0083 o equivalentment Hem de multiplicar cada p-valor per 6. Amb R, per calcular tots els p-valors de cop (sense ajustar) podem emprar la funció pairwise.t.test(variable numèrica, factor, p.adjust.method=&quot;none&quot;) El resultat d’un pairwise.t.test dóna el triangle inferior de la matriu dels p-valors: l’entrada \\((i,j)\\) correspon al contrast de mitjanes del nivell \\(i\\)-èsim i el nivell \\(j\\)-èsim. Per calcular tots els p-valors ajustats amb qualque mètode, s’ha d’especificar al paràmetre p.adjust.method. Per exemple, per ajustar-los amb el mètode de Bonferroni, s’hauria d’entrar p.adjust.method=\"bonferroni\" (fixau-vos que bonferroni hi va entre cometes i començant amb minúscula). Exemple 10.8 Tornem a l’Exemple 10.5. Per obtenir tots els p-valors sense ajustar, els quals després nosaltres haurem de comparar amb \\(\\alpha/6\\), executam pairwise.t.test(EG$Expr,EG$Tract, p.adjust.method=&quot;none&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: EG$Expr and EG$Tract ## ## 1 2 3 ## 2 0.06554 - - ## 3 0.00756 0.29688 - ## 4 0.00058 0.03522 0.23937 ## ## P value adjustment method: none La primera entrada d’aquest resultat, 0.06554, és el p-valor sense ajustar del contrast de \\(\\mu_2\\) contra \\(\\mu_1\\); el 0.00756 és el p-valor sense ajustar del contrast de \\(\\mu_3\\) contra \\(\\mu_1\\); etc. Per obtenir tots els p-valors ajustats segons Bonferroni, que després nosaltres haurem de comparar amb \\(\\alpha\\), entram pairwise.t.test(EG$Expr,EG$Tract,p.adjust.method=&quot;bonferroni&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: EG$Expr and EG$Tract ## ## 1 2 3 ## 2 0.3933 - - ## 3 0.0453 1.0000 - ## 4 0.0035 0.2113 1.0000 ## ## P value adjustment method: bonferroni Podeu comprovar que els p-valors d’aquest segon resultat són els del primer resultat multiplicats per 6 (llevat d’arrodoniments i dels 1 que poden representar resultats més grans que 1). Suposem que fixam el nivell de significació global usual \\(\\alpha=0.05\\). En la primera execució de pairwise.t.test, els únics p-valors per davall de \\(0.05/6=0.0083\\) han estat els dels parells (1,3) i (1,4). En la segona, els únics p-valors per davall de 0.05 han estat també els dels parells (1,3) i (1,4). Casualitat? És clar que no! Les conclusions havien de coincidir, perquè les dues tècniques són equivalents. Conclusió: Hem trobat evidència estadística que la teràpia 1 té una eficàcia mitjana diferent de la de les teràpies 3 i 4 (ANOVA d’1 via, test posterior de Bonferroni, p-valors 0.0453 i 0.0035, respectivament), i no n’hem trobat de cap altra diferència. 10.2.3.2 Mètode de Holm Un altre mètode popular d’ajust de p-valors, més potent que el de Bonferroni, i que de fet és el mètode que empra R per defecte és el mètode de Holm, que funciona bàsicament de la forma següent: Siguin \\(C_{1},\\ldots ,C_{c}\\) els contrastos per parelles que es volen realitzar i \\(p_{1},\\ldots ,p_{c}\\) els p-valors corresponents. Ordenam aquests p-valors en ordre creixent \\(p_{(1)}&lt; \\cdots&lt; p_{(c)}\\) i re-enumeram consistentment els contrastos \\(C_{(1)},\\ldots, C_{(c)}\\). Per a cada \\(j=1,\\ldots,c\\), calculam el p-valor ajustat \\(\\widetilde{p}_{(j)}=(c+1-j)\\cdot p_{(j)}\\). Aleshores rebutjam la hipòtesi nul·la als contrastos \\(C_{(j)}\\) on \\(\\widetilde{p}_{(j)}&lt;\\alpha\\). Exemple 10.9 Anem a fer a mà l’ajust dels p-valors segons Holm a l’Exemple 10.5. La taula amb els p-valors dels contrastos és: \\[ \\begin{array}{c|c} \\text{Contrast} &amp; \\text{p-valor} \\\\ \\hline \\text{1-2} &amp; 0.06554\\\\ \\text{1-3} &amp; 0.00756\\\\ \\text{1-4} &amp; 0.00058\\\\ \\text{2-3} &amp;0.29688\\\\ \\text{2-4} &amp; 0.03522\\\\ \\text{3-4} &amp; 0.23937 \\end{array} \\] Ordenam en ordre creixent del p-valor: \\[ \\begin{array}{c|c} \\text{Contrast} &amp; \\text{p-valor} \\\\ \\hline \\text{1-4} &amp; 0.00058\\\\ \\text{2-3} &amp; 0.00756\\\\ \\text{2-4} &amp; 0.03522\\\\ \\text{1-2} &amp; 0.06554\\\\ \\text{3-4} &amp; 0.23937\\\\ \\text{2-3} &amp;0.29688\\\\ \\end{array} \\] Ajustam, multiplicant, per a cada \\(j\\), el \\(j\\)-èsim p-valor (en ordre decreixent) per \\(6+1-j\\): \\[ \\begin{array}{c|cc} \\text{Contrast} &amp; \\text{p-valor} &amp; \\text{p-valor ajustat}\\\\ \\hline \\text{1-4} &amp; 0.00058 &amp; 6\\times 0.00058 = 0.00348\\\\ \\text{1-3} &amp; 0.00756 &amp; 5\\times 0.00756 = 0.03780\\\\ \\text{2-4} &amp; 0.03522 &amp; 4\\times 0.03522 = 0.14088\\\\ \\text{1-2} &amp; 0.06554 &amp; 3\\times 0.06554 = 0.19662\\\\ \\text{3-4} &amp; 0.23937 &amp; 2\\times 0.23937 = 0.47874\\\\ \\text{2-3} &amp; 0.29688 &amp; 1\\times 0.29688 = 0.29688\\\\ \\end{array} \\] Comparam els p-valors ajustats amb \\(\\alpha\\). En aquest cas, amb \\(\\alpha=0.05\\) arribam a la mateixa conclusió que amb el mètode de Bonferroni: concloem que \\(\\mu_1\\neq \\mu_4\\) i \\(\\mu_1\\neq \\mu_3\\) i que no podem rebutjar que les altres parelles de mitjanes siguin iguals. Amb R, s’ha d’especificar a la funció pairwise.t.test el paràmetre p.adjust.method=\"holm\", o no especificar aquest paràmetre perquè “holm” és el valor per defecte de p.adjust.method. pairwise.t.test(EG$Expr,EG$Tract,p.adjust.method=&quot;holm&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: EG$Expr and EG$Tract ## ## 1 2 3 ## 2 0.1966 - - ## 3 0.0378 0.4787 - ## 4 0.0035 0.1409 0.4787 ## ## P value adjustment method: holm Exemple 10.10 Els tests posteriors per parelles de l’Exemple 10.1 amb el mètode de Bonferroni i de Holm són: pairwise.t.test(CO2$Inc,CO2$Pre,p.adjust.method=&quot;bonferroni&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: CO2$Inc and CO2$Pre ## ## 0.0 0.08 0.29 0.50 ## 0.08 1.4e-05 - - - ## 0.29 1.6e-11 0.00186 - - ## 0.50 &lt; 2e-16 3.0e-10 0.00028 - ## 0.86 &lt; 2e-16 2.5e-15 6.6e-10 0.00389 ## ## P value adjustment method: bonferroni pairwise.t.test(CO2$Inc,CO2$Pre,p.adjust.method=&quot;holm&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: CO2$Inc and CO2$Pre ## ## 0.0 0.08 0.29 0.50 ## 0.08 5.6e-06 - - - ## 0.29 1.2e-11 0.00037 - - ## 0.50 &lt; 2e-16 1.8e-10 8.4e-05 - ## 0.86 &lt; 2e-16 2.0e-15 3.3e-10 0.00039 ## ## P value adjustment method: holm Conclusió: Hem trobat evidència estadística que cada una de les diferents pressions de CO2 considerades dona lloc a un increment mitjà diferent del volum cel·lular de P. fragi al cap d’una hora (ANOVA d’1 via, test posterior de Holm, p-valors ajustats &lt; 0.0004). Ara sí que hem trobat evidència que totes les mitjanes són diferents. Amb l’ANOVA, només podíem concloure que algunes mitjanes són diferents, però no quines. 10.2.4 Comprovació de les condicions Recordau que perquè la conclusió d’una ANOVA d’1 via tengui sentit: Les mostres de cada tractament han de ser aleatòries simples i independents i almenys una ha de tenir més d’un element. La població definida per cada tractament ha de ser normal. Totes aquestes poblacions han de tenir la mateixa variància (homocedasticitat). El punt (1) és responsabilitat de l’investigador, però (2) i (3) s’han de contrastar. Si fallen, sobretot si falla (3), no es pot usar una ANOVA: convé emprar un test no paramètric. La normalitat de les mostres s’ha de contrastar amb algun test de normalitat. Per exemple, emprarem el test de Shapiro-Wilks per contrastar la normalitat dels nostre exemple de creixement del volum cel·lular de P. fragi: shapiro.test(CO2$Inc[CO2$Pre==&quot;0.0&quot;])$p.value ## [1] 0.320568 shapiro.test(CO2$Inc[CO2$Pre==&quot;0.08&quot;])$p.value ## [1] 0.1023687 shapiro.test(CO2$Inc[CO2$Pre==&quot;0.29&quot;])$p.value ## [1] 0.5197501 shapiro.test(CO2$Inc[CO2$Pre==&quot;0.50&quot;])$p.value ## [1] 0.465208 shapiro.test(CO2$Inc[CO2$Pre==&quot;0.86&quot;])$p.value ## [1] 0.4840276 Podem acceptar que totes les mostres provenen de variables normals. Naturalment, el més pràctic és fer tots aquests tests de cop, emprant la funció aggregate. En el bloc de codi següent, definim una funció Test.SW que calcula el p-valor del test de Shapiro-Wilks i l’aplicam a la variable CO2$Inc separada segons el factor CO2$Pre. Test.SW=function(x){shapiro.test(x)$p.value} p.vals.CO2=aggregate(Inc~Pre, data=CO2, FUN=Test.SW) p.vals.CO2 ## Pre Inc ## 1 0.0 0.3205680 ## 2 0.08 0.1023687 ## 3 0.29 0.5197501 ## 4 0.50 0.4652080 ## 5 0.86 0.4840276 El resultat és un data frame, la variable Inc del qual conté els p-valors. Pel que fa l’exemple de l’expressió de gens, p.vals.EG=aggregate(Expr~Tract, data=EG, FUN=Test.SW) p.vals.EG ## Tract Expr ## 1 1 0.3062060 ## 2 2 0.2722278 ## 3 3 0.9611411 ## 4 4 0.9065984 També podem acceptar que totes les mostres provenen de variables normals. Si efectuam \\(k\\) contrastos de normalitat amb nivell de significació \\(\\alpha\\), tenim una probabilitat de cometre algun error de tipus I de \\(1-(1-\\alpha)^k\\). Per tant, com als contrastos posteriors per parelles, convé ajustar els p-valors a fi que el nivell de significació global sigui \\(\\alpha\\). En els nostres dos exemples això no afecta les conclusions, perquè els p-valors han estat grans i en ajustar-los encara creixeran. Però si us cal comprovar-ho, podeu fer servir la funció p.adjust(p-valors, method=...) especificant a method el mètode d’ajust amb la mateixa sintaxi que a pairwise.t.test (per defecte, serà el de Holm). Per exemple, per ajustar els p-valors de l’exemple del CO2 pel mètode de Bonferroni, i afegir el resultat al data frame amb els p-valors, faríem p.vals.CO2$p.vals.ajustats=p.adjust(p.vals.CO2$Inc,method=&quot;bonferroni&quot;) p.vals.CO2 ## Pre Inc p.vals.ajustats ## 1 0.0 0.3205680 1.0000000 ## 2 0.08 0.1023687 0.5118436 ## 3 0.29 0.5197501 1.0000000 ## 4 0.50 0.4652080 1.0000000 ## 5 0.86 0.4840276 1.0000000 Pel que fa a contrastar l’homocedasticitat, els dos tests més populars són: Si acceptam que les mostres provenen de distribucions normals, el test de Bartlett, implementat en R en la funció bartlett.test. Si no acceptam que les mostres provenen de distribucions normals, el test de Fligner-Killeen, implementat en R en la funció fligner.test. En tots dos casos, la funció s’aplica a una fórmula, exactament igual que aov. Per exemple, per contrastar l’homocedasticitat dels increments de volum cel·lular sota diferents pressions de CO2 de l’Exemple 10.1 amb un test de Bartlett, entraríem: bartlett.test(CO2$Inc~CO2$Pre) ## ## Bartlett test of homogeneity of variances ## ## data: CO2$Inc by CO2$Pre ## Bartlett&#39;s K-squared = 1.0701, df = 4, p-value = 0.899 Podem acceptar que les variàncies de les subpoblacions definides pels percentatges d’increment del volum cel·lular sota les diferents pressions de CO2 considerades són totes iguals. Ja que hi som, comprovem l’homocedasticitat de l’Exemple 10.5, ara amb el test de Fligner-Killeen i emprant l’altra sintaxi possible perquè la vegeu: fligner.test(Expr~Tract, data=EG) ## ## Fligner-Killeen test of homogeneity of variances ## ## data: Expr by Tract ## Fligner-Killeen:med chi-squared = 0.89109, df = 3, p-value = 0.8276 Acceptaríem (si el test de Fligner fos l’adient) que se satisfà l’homocedasticitat. 10.2.5 Test no paramètric Si en un experiment de disseny d’ANOVA d’1 via no podem emprar una ANOVA perquè no se satisfaci la normalitat de les poblacions o, sobretot, l’homocedasticitat, cal emprar un test no paramètric. El més popular es el test de Kruskal-Wallis, que generalitza el test de Mann-Whitney a més de 2 poblacions igual que l’ANOVA d’1 via generalitza el test t amb mostres independents. Es fa amb la funció kruskal.test. Per exemple, per aplicar-lo a les dades de l’Exemple 10.1: kruskal.test(CO2$Inc~CO2$Pre) ## ## Kruskal-Wallis rank sum test ## ## data: CO2$Inc by CO2$Pre ## Kruskal-Wallis chi-squared = 44.716, df = 4, p-value = 4.555e-09 Seguim concloent que no totes les mitjanes (en realitat, les medianes) són iguals. Si el test de Kruskal-Wallis permet rebutjar la igualtat de mitjanes, i voleu determinar quines parelles són diferents, disposau de la funció pairwise.wilcox.test que efectua contrastos per parelles de Mann-Whitney (amb el paràmetre paired=FALSE). Té la mateixa sintaxi que pairwise.t.test i com en aquella funció, el mètode d’ajust dels p-valors s’hi entra amb el paràmetre p.adjust.method. El mètode per defecte emprat per aquesta funció també és el mètode de Holm. Per exemple, per realitzar tots els contrastos de Mann-Whitney en l’exemple del CO2 emprant el mètode d’ajust de Bonferroni, entram: pairwise.wilcox.test(CO2$Inc, CO2$Pre, paired=FALSE, p.adjust.method=&quot;bonferroni&quot;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: CO2$Inc and CO2$Pre ## ## 0.0 0.08 0.29 0.50 ## 0.08 0.00211 - - - ## 0.29 0.00011 0.01050 - - ## 0.50 0.00011 0.00011 0.00325 - ## 0.86 0.00011 0.00011 0.00011 0.03186 ## ## P value adjustment method: bonferroni Tornam a concloure que els percentatges mitjans poblacionals d’increment són tots diferents. 10.3 ANOVA de blocs De la mateixa manera que l’ANOVA d’1 via generalitza a més de dues mitjanes el contrast d’igualtat de dues mitjanes emprant mostres independents, l’ANOVA de blocs generalitza a més de dues mitjanes el contrast d’igualtat de dues mitjanes emprant mostres aparellades. 10.3.1 Contrast bàsic Comencem amb un exemple Exemple 10.11 Volem determinar si l’energia que es requereix per dur a terme tres activitats físiques (córrer, caminar i muntar amb bicicleta) és la mateixa o no. Quantificam aquesta energia amb el nombre de Kcal consumides per Km recorregut. Les diferències metabòliques entre els individus poden afectar l’energia requerida per dur a terme una determinada activitat. Si triam tres grups d’individus i a cada grup li fem fer una de les tres activitats físiques, aquestes diferències metabòliques entre els individus triats podrien afectar els resultats i amagar l’efecte real. Per aquest motiu, ens decidim per un disseny experimental en paral·lel. Seleccionam alguns individus i fem que cadascun corri, camini i recorri amb bicicleta una distància fixada i mesuram per a cada individu en tres moments diferents i cada activitat el consum de Kca/Km. A més, seleccionam l’ordre de les activitats de cada individu a l’atzar. Si a tots els individus els féssim fer les tres activitats en el mateix ordre, podria ser que qualque factor extern que no controlàssim influís en el resultat. Per exemple, si tots caminen al mateix temps, després corren al mateix temps i després pedalen al mateix temps, i hi ha grans diferències de temperatura ambient entre els tres moments, això podria influir en el resultat final. Si, en canvi, aleatoritzam l’ordre de les activitats, en principi podem esperar que aquestes diferències es compensin. Aquests són els resultats obtinguts per a 8 individus: \\[ \\begin{array}{c} \\hphantom{Individu}\\text{Activitat}\\\\ \\begin{array}{c|ccc} \\text{Individu} &amp;\\text{1 (corrent)} &amp;\\text{2 (caminant)}&amp;\\text{3 (pedalant)}\\\\ \\hline 1&amp;1.4&amp;1.1&amp;0.7\\\\ 2&amp;1.5&amp;1.2&amp;0.8\\\\ 3&amp;1.8&amp;1.3&amp;0.7\\\\ 4&amp;1.7&amp;1.3&amp;0.8\\\\ 5&amp;1.6&amp;0.7&amp;0.1\\\\ 6&amp;1.5&amp;1.2&amp;0.7\\\\ 7&amp;1.7&amp;1.1&amp;0.4\\\\ 8&amp;2.0&amp;1.3&amp;0.6\\\\ \\end{array} \\end{array} \\] En aquest estudi, fixau-vos que empram els nivells d’un factor (tipus de desplaçament) per classificar la població (els consums energètics) en tres subpoblacions, però ara les mostres que hem pres no són independents sinó aparellades: hem mesurat els consums energètics dels tres esports sobre els mateixos individus. Per tant no podem realitzar una ANOVA d’1 via per analitzar els resultats. L’ANOVA de blocs (complets aleatoris, però ometrem aquests adjectius perquè és l’únic que veurem) generalitza el contrast de 2 mitjanes amb mostres aparellades a \\(k\\) mitjanes amb mostres aparellades. La situació general és la següent. Tenim una variable aleatòria \\(X\\) i un factor de \\(k\\) nivells, o tractaments, que classifica la població en \\(k\\) subpoblacions (les quals, recordau, identificam amb els tractaments). Diguem \\(\\mu_i\\) a la mitjana de \\(X\\) en els individus del nivell \\(i\\)-èsim. Volem decidir si aquestes mitjanes \\(\\mu_1\\),…,\\(\\mu_k\\) són totes iguals o no. És a dir, el contrast és \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{1} =\\mu_{2} =\\cdots =\\mu_{k} \\\\ H_1 : \\text{Hi ha } i,j \\text{ tals que } \\mu_{i} \\not=\\mu_{j} \\end{array} \\right. \\] En un experiment de disseny d’ANOVA de blocs: Escollim una mostra aleatòria de \\(b\\) blocs: conjunts de \\(k\\) subjectes aparellats (per exemple, escollim \\(b\\) subjectes i entenem cada bloc com a format per \\(k\\) còpies del mateix subjecte), on \\(k\\) és el nombre de tractaments. Dins cada bloc, assignam aleatòriament a cada subjecte un tractament, de manera que cada tractament s’empri exactament un cop dins cada bloc. Així, el disseny de l’Exemple 10.11 és d’una ANOVA de blocs: La variable aleatòria d’interès és l’energia consumida (en Kcal) per una persona en recórrer 1 km. Els tractaments són els tres tipus de desplaçament. Prenem 8 persones de manera raonablement aleatòria i interpretam cada una com un bloc. Assignam a cada persona el tres tractaments en un ordre escollit a l’atzar per a cada una d’elles. La filosofia del contrast serà similar a la de l’ANOVA d’1 via, comparant variabilitats: si la variabilitat de les mitjanes de les mostres és molt més gran que la variabilitat dels “errors”, rebutjarem la igualtat de totes les mitjanes poblacionals. En una ANOVA de blocs, les dades se solen representar en forma d’una taula com la següent \\[ \\begin{array}{c} \\hphantom{Bloc}\\text{Tractament}\\\\ \\begin{array}{ccccc} \\text{Bloc} &amp;\\text{Tract. 1} &amp;\\text{Tract. 2}&amp;\\ldots &amp; \\text{Tract. $k$}\\\\ \\hline 1 &amp; X_{11} &amp; X_{21} &amp; \\ldots &amp; X_{k1} \\\\ 2 &amp; X_{12} &amp; X_{22} &amp; \\ldots &amp; X_{k2} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ b &amp; X_{1b} &amp; X_{2b} &amp; \\ldots &amp; X_{kb} \\\\ \\hline \\end{array} \\end{array} \\] on cada \\(X_{ij}\\) és el valor del tractament \\(i\\)-èsim en l’individu corresponent del bloc \\(j\\)-èsim. Com en les taules emprades en l’ANOVA d’1 via, observau que no és la notació usual de les taules de dades, sinó la transposada: a \\(X_{{i}{j}}\\), \\(i\\) hi indica la columna, el tractament, i \\(j\\) hi indica la filera, és a dir, el bloc. D’aquesta manera, cada filera \\((X_{1j},\\ldots,X_{kj})\\) representa un bloc. Exemple 10.12 Tornant al nostre Exemple 10.11 inicial, els blocs són els 8 individus (\\(b=8\\)) i els tractaments, les diferents activitats (\\(k=3\\)). Si \\(\\mu_{1}\\) representa el nombre mitjà de Kcal que es consumeixen corrent 1 km \\(\\mu_{2}\\) representa el nombre mitjà de Kcal que es consumeixen caminant 1 km \\(\\mu_{3}\\) representa el nombre mitjà de Kcal que es consumeixen pedalant 1 km el contrast que volem realitzar és \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{1} = \\mu_{2} = \\mu_{3} \\\\ H_1 : \\mu_{1} \\neq \\mu_{2}\\text{ o } \\mu_{1} \\neq \\mu_{3}\\text{ o } \\mu_{2} \\neq \\mu_{3} \\end{array} \\right. \\] Perquè les conclusions d’una ANOVA de blocs tenguin sentit cal que: Les \\(k\\cdot b\\) observacions constitueixin mostres aleatòries, cadascuna de mida 1, de les \\(k\\cdot b\\) poblacions definides per les parelles (tractament,bloc) Aquestes \\(k\\cdot b\\) poblacions siguin totes normals, cada una amb mitjana \\(\\mu_{ij}\\), on \\(i\\) indica el tractament i \\(j\\) indica el bloc, i totes amb la mateixa variància \\(\\sigma^2\\) No hi hagi interacció entre els blocs i els tractaments. Això significa que l’efecte dels blocs i els tractaments és additiu: la diferència entre les mitjanes poblacionals de cada parella concreta de tractaments és la mateixa a cada bloc \\[ \\mu_{i_1j_1}-\\mu_{i_2j_1}=\\mu_{i_1j_2}-\\mu_{i_2j_2} \\] Per exemple, que no hi hagi interacció entre els blocs i els tractaments a l’Exemple 10.11 significa que: La diferència entre el consum energètic mitjà en córrer 1 km i en caminar 1 km és la mateixa a cada individu de la mostra La diferència entre el consum energètic mitjà en córrer 1 km i en pedalar 1 km és la mateixa a cada individu de la mostra La diferència entre el consum energètic mitjà en caminar 1 km i en pedalar 1 km és la mateixa a cada individu de la mostra En canvi, hi hauria interacció si, per exemple, la diferència entre el consum energètic mitjà en córrer i en caminar depengués de l’individu: si en uns la diferència fos més gran que en d’altres. Observau que \\(\\mu_{i_1j_1}-\\mu_{i_2j_1}=\\mu_{i_1j_2}-\\mu_{i_2j_2}\\) és equivalent a \\(\\mu_{i_1j_1}-\\mu_{i_1j_2}=\\mu_{i_2j_1}-\\mu_{i_2j_2}\\). Per tant, la interacció també es pot descriure intercanviant els blocs i els tractaments. En el nostre exemple, no hi hauria interacció si, per a cada parella d’individus de la mostra, fossin iguals: la diferència entre els seus consums energètics mitjans en córrer 1 km, la diferència entre els seus consums energètics mitjans en caminar 1 km, la diferència entre els seus consums energètics mitjans en pedalar 1 km. Amb un sol valor per cada parell (tractament,bloc), cap d’aquestes condicions necessàries per poder realitzar una ANOVA de blocs no es pot contrastar i per tant l’experimentador ha de decidir si se satisfan o no segons la seva experiència. Què significa això de la interacció entre dues variables? Imaginau que podem administrar dos analgèsics, A i B, a dones i homes, i mesuram el temps que triguen en fer efecte. Diguem \\(\\mu_{AD}\\): temps mitjà que triga en fer efecte l’analgèsic A sobre les dones \\(\\mu_{BD}\\): temps mitjà que triga en fer efecte l’analgèsic B sobre les dones \\(\\mu_{AH}\\): temps mitjà que triga en fer efecte l’analgèsic A sobre els homes \\(\\mu_{BH}\\): temps mitjà que triga en fer efecte l’analgèsic B sobre els homes Aleshores: No hi ha interacció entre els analgèsics i el sexe si la diferència en el temps mitjà en fer efecte A i B és la mateixa en les dones que en els homes: \\[ \\mu_{AD}-\\mu_{BD}= \\mu_{AH}-\\mu_{BH} \\] En canvi, sí que hi ha interacció entre els analgèsics i el sexe quan aquestes dues diferències són diferents, la qual cosa significaria que la diferència d’efectivitat entre els dos analgèsics no és la mateixa en els homes que en les dones: \\[ \\mu_{AD}-\\mu_{BD}\\neq \\mu_{AH}-\\mu_{BH} \\] Fixau-vos que l’existència d’interacció no és equivalent al fet que un analgèsic sigui més efectiu en un sexe que en l’altre, per exemple més en les dones que en els homes: si l’altre analgèsic també és més efectiu en les dones que en els homes, pot ser que la diferència entre les mitjanes se mantengui i no hi hagi interacció. Recordarem algunes notacions, i n’introduïm algunes altres. Pel que fa a la població: Direm \\(\\mu_i\\) a la mitjana de la variable d’interès sobre la població definida pel tractament \\(i\\)-èsim. Direm \\(\\mu\\) a la mitjana de la variable d’interès sobre el total de la població, sense distingir tractaments. Direm \\(\\mu_{\\bullet j}\\) a la mitjana de la variable d’interès sobre el bloc \\(j\\)-èsim. L’ANOVA de blocs se basa en el model següent: per a tots \\(i=1,\\ldots,k\\) i \\(j=1,\\ldots,b\\) \\[ X_{ij}=\\mu+ (\\mu_{i}-\\mu) +(\\mu_{\\bullet j}-\\mu) + E_{ij} \\] on: \\(X_{ij}\\) indica el valor de la variable \\(X\\) per al tractament \\(i\\)-èsim en el bloc \\(j\\)-èsim. \\(\\mu_i-\\mu\\) representa la desviació de la mitjana de \\(X\\) en el nivell \\(i\\)-èsim respecte de la mitjana global \\(\\mu\\) (l’efecte del tractament \\(i\\)-èsim). \\(\\mu_{\\bullet j}-\\mu\\) representa la desviació de la mitjana de \\(X\\) en el bloc \\(j\\)-èsim respecte de la mitjana global \\(\\mu\\) (l’efecte del bloc \\(j\\)-èsim). \\(E_{ij}\\) representa la part de la diferència entre \\(X_{ij}\\) i \\(\\mu\\) que no expliquen ni el tractament ni el bloc; en diem l’error aleatori, o el residu. Aquest model diu bàsicament que el valor de \\(X\\) sobre un individu és la suma de quatre components: La mitjana global \\(\\mu\\) de \\(X\\) sobre tota la població L’efecte del tractament L’efecte del bloc L’error aleatori i per tant hi pressuposam que res més no influeix en el valor de \\(X\\), i en particular que l’efecte del bloc i el del tractament se sumen, sense que hi hagi interacció entre ells. Si això no és cert, és a dir, si aquest valor pot dependre d’altres efectes que no tinguem en compte o si hi ha interacció entre els blocs i els tractaments, el model no és vàlid, i les conclusions de l’ANOVA tampoc. Pel que fa a la nostra mostra: \\(\\overline{X}_{i}\\) és la mitjana mostral de la mostra del tractament \\(i\\)-èsim \\[ \\overline{X}_{i}=\\dfrac{\\sum_{j=1}^b X_{ij}}{b} \\] Estima la mitjana poblacional del tractament \\(i\\)-èsim, \\(\\mu_i\\). \\(\\overline{X}_{\\bullet j}\\) és la mitjana mostral de les mesures preses sobre el bloc \\(j\\)-èsim \\[ \\overline{X}_{\\bullet j}=\\dfrac{\\sum_{i=1}^k X_{ij}}{k} \\] Estima la mitjana poblacional del bloc \\(j\\)-èsim, \\(\\mu_{\\bullet j}\\). \\(\\overline{X}\\) és la mitjana mostral de tota la mostra \\[ \\overline{X}=\\dfrac{\\sum_{i=1}^k\\sum_{j=1}^b X_{ij}}{k\\cdot b} \\] Estima la mitjana poblacional global, \\(\\mu\\). Exemple 10.13 Tornem a l’Exemple 10.11. Recordem que les dades eren \\[ \\begin{array}{c} \\hphantom{Individu}\\text{Tractament}\\\\ \\begin{array}{c|ccc} \\text{Individu} &amp;\\text{1 (corrent)} &amp;\\text{2 (caminant)}&amp;\\text{3 (pedalant)}\\\\ \\hline 1&amp;1.4&amp;1.1&amp;0.7\\\\ 2&amp;1.5&amp;1.2&amp;0.8\\\\ 3&amp;1.8&amp;1.3&amp;0.7\\\\ 4&amp;1.7&amp;1.3&amp;0.8\\\\ 5&amp;1.6&amp;0.7&amp;0.1\\\\ 6&amp;1.5&amp;1.2&amp;0.7\\\\ 7&amp;1.7&amp;1.1&amp;0.4\\\\ 8&amp;2.0&amp;1.3&amp;0.6\\\\ \\end{array} \\end{array} \\] Per tant les mitjanes serien, amb aquestes notacions \\[ \\begin{array}{c} \\text{Tractament}\\\\ \\begin{array}{c|ccc|c} \\text{Individu} &amp;\\text{1 (corrent)} &amp;\\text{2 (caminant)}&amp;\\text{3 (pedalant)} &amp; \\text{Mitjanes}\\\\ \\hline 1&amp;1.4&amp;1.1&amp;0.7 &amp; \\overline{X}_{\\bullet1}\\\\ 2&amp;1.5&amp;1.2&amp;0.8 &amp; \\overline{X}_{\\bullet2}\\\\ 3&amp;1.8&amp;1.3&amp;0.7 &amp; \\overline{X}_{\\bullet3}\\\\ 4&amp;1.7&amp;1.3&amp;0.8 &amp; \\overline{X}_{\\bullet4}\\\\ 5&amp;1.6&amp;0.7&amp;0.1 &amp; \\overline{X}_{\\bullet5}\\\\ 6&amp;1.5&amp;1.2&amp;0.7 &amp; \\overline{X}_{\\bullet6}\\\\ 7&amp;1.7&amp;1.1&amp;0.4 &amp; \\overline{X}_{\\bullet7}\\\\ 8&amp;2.0&amp;1.3&amp;0.6 &amp; \\overline{X}_{\\bullet8}\\\\ \\hline \\text{Mitjanes} &amp; \\overline{X}_{1} &amp; \\overline{X}_{2} &amp; \\overline{X}_{3} &amp; \\overline{X} \\end{array} \\end{array} \\] Anem a calcular-les. Emmagatzemarem les dades en un dataframe Dades de tres variables: kilocal: les Kcal/Km consumides blocs: l’individu tracts: l’activitat Per poder després fer l’ANOVA amb R, aquests dos darrers han de ser factors. Com que entrarem les dades de la taula per fileres: El factor blocs ha de tenir la forma (1,1,1,2,2,2,3,3,3,…). El factor tracts ha d’estar format per 8 còpies del vector (1,2,3), on 1 representa córrer, 2, caminar i 3, pedalar. kilocal=c(1.4,1.1,0.7,1.5,1.2,0.8,1.8,1.3,0.7,1.7,1.3,0.8, 1.6,0.7,0.1,1.5,1.2,0.7,1.7,1.1,0.4,2.0,1.3,0.6) blocs=as.factor(rep(1:8,each=3)) blocs ## [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6 7 7 7 8 8 8 ## Levels: 1 2 3 4 5 6 7 8 tracts=as.factor(rep(1:3,times=8)) tracts ## [1] 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 ## Levels: 1 2 3 Dades=data.frame(kilocal,tracts,blocs) str(Dades) ## &#39;data.frame&#39;:\t24 obs. of 3 variables: ## $ kilocal: num 1.4 1.1 0.7 1.5 1.2 0.8 1.8 1.3 0.7 1.7 ... ## $ tracts : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 2 3 1 2 3 1 2 3 1 ... ## $ blocs : Factor w/ 8 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 1 1 2 2 2 3 3 3 4 ... head(Dades) ## kilocal tracts blocs ## 1 1.4 1 1 ## 2 1.1 2 1 ## 3 0.7 3 1 ## 4 1.5 1 2 ## 5 1.2 2 2 ## 6 0.8 3 2 Calculem les mitjanes mostrals dels tractaments, \\(\\overline{X}_i\\): mitjanes.tracts=aggregate(kilocal~tracts,data=Dades,mean) mitjanes.tracts ## tracts kilocal ## 1 1 1.65 ## 2 2 1.15 ## 3 3 0.60 Calculem les mitjanes mostrals dels blocs, \\(\\overline{X}_{\\bullet j}\\): mitjanes.blocs=aggregate(kilocal~blocs,data=Dades,mean) mitjanes.blocs ## blocs kilocal ## 1 1 1.066667 ## 2 2 1.166667 ## 3 3 1.266667 ## 4 4 1.266667 ## 5 5 0.800000 ## 6 6 1.133333 ## 7 7 1.066667 ## 8 8 1.300000 Calculem la mitjana mostral global \\(\\overline{X}\\): mitjana.total=mean(Dades$kilocal) mitjana.total ## [1] 1.133333 A l’ANOVA de blocs s’hi té la identitat següent: Teorema 10.3 (Identitat de les sumes de quadrats) \\[ SS_{Total}=SS_{Tr}+SS_{Blocs}+SS_E \\] on \\(SS_{Total}=\\displaystyle\\sum\\limits_{i=1}^k\\sum\\limits_{j=1}^b (X_{ij}- \\overline{X})^2\\); és la Suma Total de Quadrats. \\(SS_{Tr}=\\displaystyle b\\sum\\limits_{i=1}^k (\\overline{X}_{i}-\\overline{X})^2\\); és la Suma de Quadrats dels Tractaments. \\(SS_{Blocs}=\\displaystyle k\\sum\\limits_{j=1}^b (\\overline{X}_{\\bullet j}-\\overline{X})^2\\); és la Suma de Quadrats dels Blocs. \\(SS_E=\\displaystyle\\sum\\limits_{i=1}^k\\sum\\limits_{j=1}^b (X_{ij} - \\overline{X}_{i}- \\overline{X}_{\\bullet j}+\\overline{X})^2\\); és la Suma de Quadrats dels Residus o dels Errors. En aquesta identitat \\(SS_{Total}\\) representa la variabilitat total de les dades: és el numerador de la variància de la mostra total. \\(SS_{Tr}\\) representa la variabilitat de les mitjanes dels tractaments: és igual al numerador de la variància d’una mostra formada per \\(b\\) còpies de cada una de les mitjanes mostrals dels tractaments, \\(\\overline{X}_1,\\overline{X}_2,\\ldots,\\overline{X}_k\\). \\(SS_{Tr}\\) representa la variabilitat de les mitjanes dels blocs: és igual al numerador de la variància d’una mostra formada per \\(k\\) còpies de cada una de les mitjanes mostrals dels blocs, \\(\\overline{X}_{\\bullet 1},\\overline{X}_{\\bullet 2},\\ldots,\\overline{X}_{\\bullet b}\\). \\(SS_E\\) representa la “resta de la variabilitat”. Si se satisfà el model de l’ANOVA de blocs \\[ X_{ij}=\\mu+ (\\mu_{i}-\\mu) +(\\mu_{\\bullet j}-\\mu) + E_{ij} \\] aleshores \\[ E_{ij}=X_{ij}-\\mu_{i}-\\mu_{\\bullet j}+\\mu \\] Veiem així que \\(SS_E\\) és la suma dels quadrats de les estimacions d’aquests errors aleatoris per als individus de la nostra mostra. Per tant \\[ SS_{Total}=SS_{Tr}+SS_{Blocs}+SS_E \\] bàsicament diu que en una ANOVA de blocs la variabilitat total descompon en la suma de la variabilitat de les mitjanes dels tractaments més la variabilitat de les mitjanes dels blocs més la variabilitat “residual”. Exemple 10.14 Tornem a l’Exemple 10.11. Recordem les dades que ja tenim: str(Dades) ## &#39;data.frame&#39;:\t24 obs. of 3 variables: ## $ kilocal: num 1.4 1.1 0.7 1.5 1.2 0.8 1.8 1.3 0.7 1.7 ... ## $ tracts : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 2 3 1 2 3 1 2 3 1 ... ## $ blocs : Factor w/ 8 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 1 1 2 2 2 3 3 3 4 ... k=3 #Nombre de tractaments b=8 #Nombre de blocs mitjanes.tracts #Mitjanes de tractaments ## tracts kilocal ## 1 1 1.65 ## 2 2 1.15 ## 3 3 0.60 mitjanes.blocs #Mitjanes de blocs ## blocs kilocal ## 1 1 1.066667 ## 2 2 1.166667 ## 3 3 1.266667 ## 4 4 1.266667 ## 5 5 0.800000 ## 6 6 1.133333 ## 7 7 1.066667 ## 8 8 1.300000 mitjana.total # Mitjana global ## [1] 1.133333 Calculem la suma total de quadrats \\[ SS_{Total}=\\sum\\limits_{i=1}^k\\sum\\limits_{j=1}^b (X_{ij}- \\overline{X})^2 \\] SS.Tot=sum((kilocal-mitjana.total)^2) SS.Tot ## [1] 5.353333 Calculem la suma de quadrats dels tractaments \\[ SS_{Tr}=b\\sum\\limits_{i=1}^k (\\overline{X}_{i}-\\overline{X})^2 \\] Recordau que el vector \\((\\overline{X}_{1},\\overline{X}_{2},\\overline{X}_{3})\\) és la variable kilocal de mitjanes.tracts. SS.Tr=b*sum((mitjanes.tracts$kilocal-mitjana.total)^2) SS.Tr ## [1] 4.413333 Calculem la suma de quadrats dels blocs \\[ SS_{Blocs}=k\\sum\\limits_{j=1}^b (\\overline{X}_{\\bullet j}-\\overline{X})^2 \\] Recordau que el vector \\((\\overline{X}_{\\bullet 1},\\ldots,\\overline{X}_{\\bullet b})\\) és la variable kilocal de mitjanes.blocs. SS.Bl=k*sum((mitjanes.blocs$kilocal-mitjana.total)^2) SS.Bl ## [1] 0.5533333 Calculem la suma de quadrats dels residus \\[ SS_E=\\sum\\limits_{i=1}^k\\sum\\limits_{j=1}^b (X_{ij} - \\overline{X}_{i}- \\overline{X}_{\\bullet j}+\\overline{X})^2 \\] Per calcular aquesta suma, procedirem com al càlcul de la \\(SS_E\\) de l’ANOVA d’1 via, tenint en compte que Les entrades de Dades$kilocal que difereixen en un múltiple de 3 són del mateix tractament: per exemple, la 1a, la 4a, la 7a etc. corresponen al tractament 1 (córrer). Si a Dades$kilocal li restam el vector de les mitjanes del tractaments, mitjanes.tracts$kilocal, en realitat estam dient a R que li resti 8 còpies consecutives d’aquest vector, i per tant a cada entrada de Dades$kilocal li restam la mitjana del seu tractament. Cada grup de 3 entrades consecutives de Dades$kilocal corresponen a un bloc: les tres primeres al bloc 1, les tres següents al bloc 2 etc. Per tant, per restar a cada entrada de Dades$kilocal la mitjana del bloc corresponent, li hem de restar rep(mitjanes.blocs$kilocal,each=3). SSE=sum((Dades$kilocal-mitjanes.tracts$kilocal -rep(mitjanes.blocs$kilocal,each=3)+mitjana.total)^2) SSE ## [1] 0.3866667 Comprovem la identitat de les sumes de quadrats: SS.Tot ## [1] 5.353333 SS.Tr+SS.Bl+SSE ## [1] 5.353333 A partir d’aquí, tot funciona com a l’ANOVA d’1 via. Al contrast \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{1}=\\cdots =\\mu_{k} \\\\ H_1 : \\text{Hi ha } i,j=1,\\ldots ,k \\text{ tals que } \\mu_{i}\\neq \\mu_{j} \\end{array} \\right. \\] rebutjarem la hipòtesi nul·la si \\(SS_{Tr}\\) és prou més gran que \\(SS_{E}\\). Per mesurar-ho, emprarem els estadístics següents: Quadrat mitjà dels tractaments: \\[ MS_{Tr}=\\dfrac{SS_{Tr}}{k-1} \\] Quadrat mitjà dels errors: \\[ MS_E = \\dfrac{SS_E}{(b-1) (k-1)} \\] Fixau-vos que el denominador és diferent que al \\(MS_E\\) de l’ANOVA d’1 via. A més, R calcula el Quadrat mitjà dels blocs, que nosaltres no farem servir però que definim perquè sapigueu què és: \\[ MS_{Blocs}=\\dfrac{SS_{Blocs}}{b-1} \\] Si se satisfan les condicions necessàries que hem esmentat perquè l’ANOVA es pugui realitzar, es té que \\[ \\begin{array}{l} E(MS_{Tr})=\\sigma^2 + \\dfrac{b}{k-1}\\sum\\limits_{i=1}^k (\\mu_{i}-\\mu)^2 \\\\ E(MS_E)=\\sigma^2 \\end{array} \\] on \\(\\sigma^2\\) indica la variància comuna de totes les poblacions definides per les parelles (tractament,bloc). Per tant, \\(MS_E\\) torna a ser un estimador no esbiaixat d’aquesta \\(\\sigma^2\\). Aleshores, com a l’ANOVA d’1 via, si \\(H_0:\\mu_{1}=\\cdots =\\mu_{k}(=\\mu)\\) és certa, \\[ \\sum\\limits_{i=1}^k (\\mu_{i}-\\mu)^2 = 0, \\] i per tant \\(E(MS_{Tr})=E(MS_E)\\), mentre que si \\(H_0\\) no és certa \\[ \\sum\\limits_{i=1}^k (\\mu_{i}-\\mu)^2 &gt; 0 \\] cas en el qual \\(E(MS_{Tr})&gt;E(MS_E)\\). Aleshores prendrem com a estadístic de contrast el quocient \\[ F=\\frac{MS_{Tr}}{MS_E} \\] Si \\(H_0\\) és certa: La seva distribució és F de Fisher amb \\(k-1\\) i \\((k-1)(b-1)\\) graus de llibertat, \\(F_{k-1,(k-1)(b-1)}\\). En general, els graus de llibertat de l’estadístic F d’una ANOVA, sigui del tipus que sigui, són els denominadors emprats en les definicions dels quadrats mitjans del numerador i el denominador. El seu valor és proper a 1. I per tant rebutjarem la hipòtesi nul·la si el valor \\(F_0\\) de F sobre la nostra mostra és prou més gran que 1, la qual cosa decidirem comparant el p-valor \\(P(F_{k-1,(k-1)(b-1)}\\geqslant F_0)\\) amb el nivell de significació \\(\\alpha\\). En resum, per realitzar una ANOVA de blocs a partir d’una mostra: Calculam \\(SS_{Tr},SS_E\\) Calculam \\(MS_{Tr},MS_E\\) Calculam el valor \\(F_0\\) de l’estadístic de contrast \\[ F=\\frac{MS_{Tr}}{MS_E} \\] Calculam el p-valor \\[ P(F_{k-1,(k-1)(b-1)}\\geqslant F_0) \\] Si aquest p-valor és més petit que el nivell de significació \\(\\alpha\\), rebutjam \\(H_0\\) i concloem que no totes les mitjanes són iguals. En cas contrari, acceptam que totes les mitjanes són iguals. Totes aquestes dades se solen recollir en la taula ANOVA següent: \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; k-1 &amp; SS_{Tr}&amp; MS_{Tr} &amp; F &amp; \\text{p-valor} \\\\ \\text{Blocs} &amp; b-1 &amp; SS_{Blocs} &amp; MS_{Blocs} &amp; \\\\ \\text{Residus} &amp; (k-1)(b-1) &amp; SS_E &amp; MS_E &amp; \\\\\\hline \\end{array} \\] Exemple 10.15 Tornem al nostre Exemple 10.11. Ja hem calculat: \\[ \\begin{array}{cccccc} k &amp; b &amp; SS_{Total} &amp; SS_{Tr} &amp; SS_{Blocs} &amp; SS_E\\\\ \\hline 3 &amp; 8 &amp; 5.3533 &amp; 4.4133 &amp; 0.5533 &amp; 0.3867 \\end{array} \\] Aleshores: \\(MS_{Tr}=\\dfrac{SS_{Tr}}{k-1}=2.2066\\) \\(MS_{Blocs}=\\dfrac{SS_{Blocs}}{b-1}=0.079\\) \\(MS_E = \\dfrac{SS_E}{(b-1) (k-1)}=0.0276\\) \\(F=\\dfrac{MS_{Tr}}{MS_E}=79.949\\) p-valor: \\(P(F_{2,14}\\geqslant 79.949)=2\\cdot 10^{-8}\\) Conclusió: Hem obtingut evidència estadística que no és cert que les tres activitats tenguin el mateix consum energètic mitjà per km (ANOVA de blocs, p-valor 2·10-8) La taula ANOVA d’aquest exemple és \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; 2 &amp; 4.4133&amp;2.2067&amp;79.949 &amp; 2\\cdot 10^{-8} \\\\ \\text{Blocs} &amp; 7 &amp; 0.5533&amp;0.079&amp; &amp; \\\\ \\text{Residus} &amp; 14 &amp; 0.3867&amp;0.0276&amp; &amp; \\\\\\hline \\end{array} \\] 10.3.2 Amb R L’ANOVA de blocs s’efectua amb R aplicant summary(aov( )) a la fórmula que separa la variable numèrica per la suma dels factors que representen els tractaments i els blocs. Així, l’ANOVA de blocs de l’Exemple 10.11 es fa amb summary(aov(Dades$kilocal~Dades$tracts+Dades$blocs)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dades$tracts 2 4.413 2.2067 79.897 2.2e-08 *** ## Dades$blocs 7 0.553 0.0790 2.862 0.0446 * ## Residuals 14 0.387 0.0276 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 o, equivalentment, amb summary(aov(kilocal~tracts+blocs, data=Dades)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## tracts 2 4.413 2.2067 79.897 2.2e-08 *** ## blocs 7 0.553 0.0790 2.862 0.0446 * ## Residuals 14 0.387 0.0276 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Obtenim la taula d’abans (llevat d’una petita diferència en la F deguda a que als càlculs a mà hem arrodonit pel camí) amb dues entrades més: l’estadístic de contrast i el p-valor de la filera blocs, que corresponen al contrast sobre hi ha diferència o no entre les mitjanes dels blocs (en aquest exemple, els consums mitjans energètics per km dels individus de la mostra en desplaçar-se de qualsevol de les tres maneres). 10.3.3 Comparacions posteriors per parelles Com en el cas d’1 via, si rebutjam la hipòtesi nul·la, podem demanar-nos quins són els tractaments que tenen mitjanes diferents. Ho podem respondre fent un test t per a cada parella de tractaments emprant mostres aparellades i ajustant el p-valor (per Bonferroni, Holm…). No donarem els detalls de les fórmules, simplement heu de saber que amb R es fa com a l’ANOVA d’1 via: amb la funció pairwise.t.test, però ara indicant-hi que paired=TRUE. Exemple 10.16 A l’experiment de l’Exemple 10.11 hem arribat a la conclusió que no totes les mitjanes són iguals. Emprem un contrast posterior per parelles amb l’ajust de Bonferroni per esbrinar quines són diferents. pairwise.t.test(Dades$kilocal, Dades$tracts, paired=TRUE, p.adjust.method=&quot;bonferroni&quot;) ## ## Pairwise comparisons using paired t tests ## ## data: Dades$kilocal and Dades$tracts ## ## 1 2 ## 2 0.00108 - ## 3 0.00011 1.1e-05 ## ## P value adjustment method: bonferroni Conclusió: Hem obtingut evidència estadística que les tres activitats tenen consum energètic mitjà per km diferent (ANOVA de blocs, test posterior de Bonferroni, p-valors ajustats inferiors a 0.0011) 10.3.4 Contrast no paramètric Si en un experiment amb disseny d’ANOVA de blocs no podem aplicar l’ANOVA perquè sospitem que no se satisfan les condicions necessàries, cal emprar un test no paramètric. El més popular és el test de Friedman, que generalitza el test de Wilcoxon a més de 2 mostres aparellades. En R està implementat en la funció friedman.test que s’aplica a la mateixa fórmula que summary(aov( )) excepte que cal substituir-hi la suma “+” per una barra vertical “|”. Per exemple: friedman.test(kilocal~tracts|blocs,data=Dades) ## ## Friedman rank sum test ## ## data: kilocal and tracts and blocs ## Friedman chi-squared = 16, df = 2, p-value = 0.0003355 La conclusió és la mateixa que abans: No tots els consums energètics mitjans són iguals (test de Friedman, p-valor 0.0003). Si ara volem realitzar els tests posteriors per parelles, el més adient és emprar en tots ells el test de Wilcoxon, amb la funció pairwise.wilcox.test que ja empràvem a l’ANOVA d’1 via, però ara amb paired=TRUE: pairwise.wilcox.test(Dades$kilocal, Dades$tracts, paired =TRUE) ## ## Pairwise comparisons using Wilcoxon signed rank test with continuity correction ## ## data: Dades$kilocal and Dades$tracts ## ## 1 2 ## 2 0.042 - ## 3 0.042 0.042 ## ## P value adjustment method: holm Obtenim evidència estadística que les tres activitats tenen consums energètics mitjans diferents (test de Friedman, test posterior per parelles de Wilcoxon amb ajust de Holm, p-valors ajustats 0.042). 10.4 ANOVA de 2 vies Amb l’ANOVA d’1 via comparàvem les mitjanes de més de 2 subpoblacions definides pels nivells d’un únic factor. Ara ens interessa el cas quan aquestes subpoblacions estan definides combinant els nivells de més d’un factor. Es diu en aquest cas que el disseny de l’experiment és d’ANOVA factorial. Nosaltres aquí explicarem només el cas més senzill, quan s’empren només 2 factors (2 vies). A més, per simplificar, només considerarem el cas que totes les mostres de cada combinació de nivells d’un factor i de l’altre tenen la mateixa mida. Per tant, en un experiment amb disseny d’ANOVA de 2 vies: Tenim una variable aleatòria \\(X\\). Classificam la població segons les combinacions dels nivells de dos factors. Prenem una m.a.s. de cada combinació de nivells, independents i totes de la mateixa mida, i hi mesuram la variable \\(X\\). 10.4.1 Contrast bàsic Comencem amb un exemple. Exemple 10.17 S’havien observat diferències estacionals en el desenvolupament de les gònades d’una espècie de peixos que viuen als llacs africans, i es volia saber si això era conseqüència de la diferència entre estacions en hores de llum o en temperatura. Per decidir-ho, en un experiment s’intentà determinar l’efecte de la llum i la temperatura sobre l’índex gonadosomàtic o GSI (una mesura de creixement de l’ovari) d’aquesta espècie de peixos. S’hi van utilitzar dos fotoperíodes (l’estival, 14 hores de llum i 10 hores de foscor; i l’hivernal, 9 hores de llum i 15 hores de foscor) i dues temperatures (l’estival, 27o C, i l’hivernal, 16o C). En concret, com diem, es volia determinar si el GSI mitjà depèn del fotoperíode, o de la temperatura, o de la combinació dels dos tractaments, i si a més hi ha interacció entre ells, en el sentit que en alguna combinació de nivells dels dos tractaments els dos efectes no s’acumulin, sinó que l’efecte final sigui més gran, o més petit, que la suma dels dos efectes per separat. L’experiment es va realitzar sobre 20 femelles recent nascudes. Es van dividir aleatòriament en 4 subgrups de 5 exemplars cadascun. Cada grup va rebre una combinació diferent de llum i temperatura. Als 3 mesos es mesuraren els seus GSI. Els resultats obtinguts varen ser: \\[ \\begin{array}{c} \\hphantom{(temperatura)}\\text{Factor A}\\\\ \\hphantom{(temperatura)}\\text{(hores de llum)}\\\\ \\begin{array}{c|cc} \\text{Factor B} &amp; \\text{9 hores}&amp; \\text{14 hores}\\\\ \\text{(temperatura)}&amp; &amp;\\\\\\hline 16^\\circ &amp;1.30&amp;1.01\\\\ &amp;2.88&amp;1.52\\\\ &amp;2.42&amp;1.02\\\\ &amp;2.66&amp;1.32\\\\ &amp;2.94&amp;1.63\\\\\\hline 27^\\circ &amp;0.90&amp;0.83\\\\ &amp;1.06&amp;0.67\\\\ &amp;0.98&amp;0.57\\\\ &amp;1.29&amp;0.47\\\\ &amp;1.12&amp;0.66\\\\ \\end{array} \\end{array} \\] El disseny experimental d’aquest estudi és d’ANOVA de 2 vies: La variable aleatòria d’interès \\(X\\) és el GSI d’un peix (femella) de 3 mesos. Classificam la població (els peixos) segons les combinacions dels nivells de dos factors (A: el foto-període; B: la temperatura). Prenem una m.a.s. de cada combinació de nivells, independents i totes de la mateixa mida, i mesuram el GSI dels individus seleccionats. La situació general en una ANOVA de 2 vies serà la següent: Tenim en compte dos factors, A i B. El factor A té \\(a\\) nivells (o tractaments, recordau) i el factor B, \\(b\\) nivells. En el nostre exemple, \\(a=b=2\\). Fem \\(n\\) observacions de cada combinació de tractaments, un de cada factor. El nombre total d’observacions serà per tant \\(N=n\\cdot a\\cdot b\\). En el nostre exemple, \\(n=5\\) i \\(N=20\\). Indicarem amb \\(X_{ijk}\\), \\(i=1,\\ldots,a\\), \\(j=1,\\ldots,b\\), \\(k=1,\\ldots,n\\), el valor de la variable \\(X\\) en el \\(k\\)-èsim subjecte de la mostra corresponent al nivell \\(i\\)-èsim del factor A i el nivell \\(j\\)-èsim del factor B. Donarem les dades en una taula d’aquest estil: \\[ \\begin{array}{c} \\hphantom{Factor B}\\text{Factor A}\\\\ \\begin{array}{c|cccc} \\text{Factor B} &amp; 1&amp; 2 &amp; \\ldots &amp; a\\\\ \\hline 1&amp;X_{111}&amp;X_{211}&amp;\\cdots&amp;X_{a11}\\\\ &amp;X_{112}&amp;X_{212}&amp;\\cdots&amp;X_{a12}\\\\ &amp;\\cdots&amp;\\cdots&amp;\\cdots&amp;\\cdots\\\\ &amp;X_{11n}&amp;X_{21n}&amp;\\cdots&amp;X_{a1n}\\\\\\hline 2&amp;X_{121}&amp;X_{221}&amp;\\cdots&amp;X_{a21}\\\\ &amp;X_{122}&amp;X_{222}&amp;\\cdots&amp;X_{a22}\\\\ &amp;\\cdots&amp;\\cdots&amp;\\cdots&amp;\\cdots\\\\ &amp;X_{12n}&amp;X_{22n}&amp;\\cdots&amp;X_{a2n}\\\\\\hline \\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\ \\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\\\hline b&amp;X_{1b1}&amp;X_{2b1}&amp;\\cdots&amp;X_{ab1}\\\\ &amp;X_{1b2}&amp;X_{2b2}&amp;\\cdots&amp;X_{ab2}\\\\ &amp;\\cdots&amp;\\cdots&amp;\\cdots&amp;\\cdots\\\\ &amp;X_{1bn}&amp;X_{2bn}&amp;\\cdots&amp;X_{abn}\\\\\\hline \\end{array} \\end{array} \\] Perquè tengui sentit realitzar una ANOVA de 2 vies sobre aquestes dades, s’han de satisfer les condicions següents: Les observacions per a cada combinació de nivells constitueixen mostres aleatòries simples independents, totes de la mateixa mida \\(n\\geqslant 2\\). Cadascuna de les \\(a\\cdot b\\) subpoblacions definides per les combinacions de tractaments, un de cada factor, és normal. Homocedasticitat: Totes aquestes subpoblacions tenen la mateixa variància, que indicarem amb \\(\\sigma^2\\). Els paràmetres que intervindran en el contrast són: \\(\\mu\\): la mitjana poblacional global. \\(\\mu_{i\\bullet}\\): la mitjana poblacional del nivell \\(i\\)-èsim del factor A. \\(\\mu_{\\bullet j}\\): mitjana poblacional del nivell \\(j\\)-èsim del factor B. \\(\\mu_{ij}\\): mitjana poblacional de la combinació \\((i,j)\\) de nivells d’A i B. L’ANOVA de 2 vies se basa en el model següent: per a tots \\(i=1,\\ldots,a\\) i \\(j=1,\\ldots,b\\) \\[ X_{ij}=\\mu+ \\alpha_i +\\beta_j + (\\alpha\\beta)_{ij}+E_{ij} \\] on: \\(X_{ij}\\) indica el valor de la variable \\(X\\) sobre un individu que pertany al nivell \\(i\\)-èsim del factor A i al nivell \\(j\\)-èsim del factor B. \\(\\alpha_i=\\mu_{i\\bullet}-\\mu\\) representa la desviació de la mitjana de \\(X\\) en el nivell \\(i\\)-èsim del factor A respecte de la mitjana global \\(\\mu\\) (l’efecte del tractament \\(i\\)-èsim del factor A). \\(\\beta_j=\\mu_{\\bullet j}-\\mu\\) representa la desviació de la mitjana de \\(X\\) en el nivell \\(j\\)-èsim del factor B respecte de la mitjana global \\(\\mu\\) (l’efecte del tractament \\(j\\)-èsim del factor B). \\((\\alpha\\beta)_{ij}=\\mu_{ij}-\\mu_{i\\bullet}-\\mu_{\\bullet j}+\\mu\\) representa l’efecte de la interacció entre el nivell \\(i\\)-èsim del factor \\(A\\) i el nivell \\(j\\)-èsim del factor \\(B\\); si no hi hagués interacció, tendríem que \\[ \\mu_{ij}-\\mu=(\\mu_{i\\bullet}-\\mu)+(\\mu_{\\bullet j}-\\mu) \\] (l’efecte dels dos tractaments se sumaria; la demostració la donam en un bloc de corbes perilloses més a baix) i aquesta contribució de la interacció seria 0. \\(E_{ij}=X_{ij}-\\mu_{ij}\\) representa la part de la diferència entre \\(X_{ij}\\) i \\(\\mu\\) que no expliquen ni el tractament ni el bloc ni la interacció; en diem l’error aleatori, o el residu. Aquest model diu bàsicament que el valor de \\(X\\) sobre un individu és la suma de cinc components: La mitjana global \\(\\mu\\) de \\(X\\) sobre tota la població L’efecte del tractament A L’efecte del tractament B L’efecte de la interacció L’error aleatori Passem ara a la mostra amb què volem realitzar el contrast. Siguin: \\(\\overline{X}_{ij}=\\dfrac{\\sum_{k=1}^n X_{ijk}}{n}\\): la mitjana mostral de la combinació \\((i,j)\\) de nivells d’A i B; estima \\(\\mu_{ij}\\). \\(\\overline{X}_{i\\bullet}=\\dfrac{\\sum_{j=1}^b\\sum_{k=1}^n X_{ijk}}{bn}\\): la mitjana mostral del nivell \\(i\\)-èsim del factor A; estima \\(\\mu_{i\\bullet}\\). \\(\\overline{X}_{\\bullet j}=\\dfrac{\\sum_{i=1}^a\\sum_{k=1}^n X_{ijk}}{an}\\): la mitjana mostral del nivell \\(j\\)-èsim del factor B estima \\(\\mu_{\\bullet j}\\). \\(\\overline{X}=\\dfrac{\\sum_{i=1}^{a}\\sum_{j=1}^b\\sum_{k=1}^n X_{ijk}}{a b n}\\): la mitjana mostral de tota la mostra; estima \\(\\mu\\). Exemple 10.18 Les mitjanes de la taula de l’Exemple 10.17 correspondrien a \\[ \\begin{array}{c} \\text{Factor A}\\\\ \\begin{array}{c|cc|cc|c} \\text{Factor B}&amp;\\text{9 hores} &amp; &amp;\\text{14 hores} &amp; &amp; \\\\ \\hline 16^\\circ &amp;1.30&amp; &amp; 1.01&amp; &amp;\\\\ &amp;2.88&amp; &amp; 1.52&amp; &amp;\\\\ &amp;2.42&amp; \\!\\!\\!\\!\\!\\!\\overline{X}_{11} &amp; 1.02&amp;\\!\\!\\!\\!\\!\\!\\! \\overline{X}_{21} &amp;\\overline{X}_{\\bullet1}\\\\ &amp;2.66&amp; &amp; 1.32&amp; &amp;\\\\ &amp;2.94&amp; &amp; 1.63&amp; &amp;\\\\\\hline 27^\\circ &amp;0.90&amp; &amp; 0.83&amp; &amp;\\\\ &amp;1.06&amp; &amp; 0.67&amp; &amp;\\\\ &amp;0.98&amp;\\!\\!\\!\\!\\!\\! \\overline{X}_{12} &amp; 0.57&amp;\\!\\!\\!\\!\\!\\!\\! \\overline{X}_{22} &amp;\\overline{X}_{\\bullet2}\\\\ &amp;1.29&amp; &amp; 0.47&amp; &amp;\\\\ &amp;1.12&amp; &amp; 0.66&amp; &amp;\\\\\\hline &amp; \\overline{X}_{1\\bullet} &amp; &amp; \\overline{X}_{2\\bullet} &amp; &amp; \\end{array} \\end{array} \\] Anem a calcular-les. Organitzarem les dades en un dataframe peixos amb 3 variables: GSI, quantitativa, contendrà el GSI de cada peix llum, un factor que contendrà el valor del nivell del factor A (foto-període) per a cada peix temp, un factor que contendrà el valor del nivell del factor B (temperatura) per a cada peix Com a totes les ANOVA, els factors que s’empren per classificar la població convé que siguin això, factors (o, almenys, vectors de paraules, no vectors numèrics), al dataframe si volem després emprar la funció aov per fer l’ANOVA. Entrarem les dades de la taula per fileres. Per tant el factor llum ha d’estar format per 10 còpies consecutives del vector (9,14) i el factor temp ha d’estar format per 10 còpies de “16” seguides de 10 còpies de “27”. GSI= c(1.30,1.01,2.88,1.52,2.42,1.02,2.66,1.32,2.94,1.63,0.90, 0.83,1.06,0.67,0.98,0.57,1.29,0.47,1.12,0.66) llum=as.factor(rep(c(9,14),10)) llum ## [1] 9 14 9 14 9 14 9 14 9 14 9 14 9 14 9 14 9 14 9 14 ## Levels: 9 14 temp=as.factor(rep(c(16,27),each=10)) temp ## [1] 16 16 16 16 16 16 16 16 16 16 27 27 27 27 27 27 27 27 27 27 ## Levels: 16 27 peixos=data.frame(GSI,llum,temp) str(peixos) ## &#39;data.frame&#39;:\t20 obs. of 3 variables: ## $ GSI : num 1.3 1.01 2.88 1.52 2.42 1.02 2.66 1.32 2.94 1.63 ... ## $ llum: Factor w/ 2 levels &quot;9&quot;,&quot;14&quot;: 1 2 1 2 1 2 1 2 1 2 ... ## $ temp: Factor w/ 2 levels &quot;16&quot;,&quot;27&quot;: 1 1 1 1 1 1 1 1 1 1 ... head(peixos) ## GSI llum temp ## 1 1.30 9 16 ## 2 1.01 14 16 ## 3 2.88 9 16 ## 4 1.52 14 16 ## 5 2.42 9 16 ## 6 1.02 14 16 Calculem les mitjanes: Les \\(\\overline{X}_{ij}\\): Xb.i.j.bolleta=aggregate(GSI~llum+temp, data=peixos,mean) Xb.i.j.bolleta ## llum temp GSI ## 1 9 16 2.44 ## 2 14 16 1.30 ## 3 9 27 1.07 ## 4 14 27 0.64 Hem obtingut aquesta taula: \\[ \\begin{array}{c|cc} \\overline{X}_{ij} &amp; 9 &amp; 14\\\\ \\hline 16 &amp; 2.44 &amp; 1.30\\\\ 27 &amp; 1.07 &amp; 0.64 \\end{array} \\] Les \\(\\overline{X}_{i\\bullet}\\): Xb.A=aggregate(GSI~llum,data=peixos,mean) Xb.A ## llum GSI ## 1 9 1.755 ## 2 14 0.970 Les \\(\\overline{X}_{\\bullet j}\\): Xb.B=aggregate(GSI~temp,data=peixos,mean) Xb.B ## temp GSI ## 1 16 1.870 ## 2 27 0.855 La \\(\\overline{X}\\): mean(peixos$GSI) ## [1] 1.3625 Hem obtingut la taula següent: \\[ \\begin{array}{cc|cc|c} \\overline{X}_{1\\bullet} &amp; \\overline{X}_{2\\bullet} &amp; \\overline{X}_{\\bullet 1} &amp; \\overline{X}_{\\bullet 2} &amp; \\overline{X} \\\\ \\hline 1.755 &amp; 0.970 &amp; 1.870 &amp; 0.855 &amp; 1.3625 \\end{array} \\] En l’ANOVA de 2 vies hi tenim les identitats següents: Teorema 10.4 (Identitat de les sumes de quadrats) \\[ \\begin{array}{l} SS_{Total} = SS_{Tr}+SS_E\\\\[1ex] SS_{Tr} = SS_A+SS_B+SS_{AB} \\end{array} \\] on \\(SS_{Total}=\\displaystyle\\sum\\limits_{i=1}^a\\sum\\limits_{j=1}^b\\sum\\limits_{k=1}^n (X_{ijk}-\\overline{X})^2\\); és la Suma Total de Quadrats. \\(SS_{Tr}=\\displaystyle n\\sum\\limits_{i=1}^a\\sum\\limits_{j=1}^b (\\overline{X}_{ij}-\\overline{X})^2\\); és la Suma de Quadrats dels Tractaments. \\(SS_{A}=\\displaystyle b n\\sum\\limits_{i=1}^a (\\overline{X}_{i\\bullet}-\\overline{X})^2\\); és la Suma de Quadrats del Factor A. \\(SS_{B}=\\displaystyle a n\\sum\\limits_{i=1}^b (\\overline{X}_{\\bullet j}-\\overline{X})^2\\); és la Suma de Quadrats del Factor B. \\({SS_{AB}}=n \\sum\\limits_{i=1}^a\\sum\\limits_{j=1}^b (\\overline{X}_{ij}-\\overline{X}_{i\\bullet}-\\overline{X}_{\\bullet j}+\\overline{X})^2\\); és la Suma de Quadrats de la Interacció. \\(SS_E=\\displaystyle\\sum\\limits_{i=1}^a\\sum\\limits_{j=1}^b\\sum\\limits_{k=1}^n (X_{ijk}-\\overline{X}_{ij})^2\\); és la Suma de Quadrats dels Residus o dels Errors. Com als ANOVA anteriors, aquestes sumes de quadrats representen les diferents fonts de variabilitat de les dades: \\(SS_{Total}\\) representa la variabilitat total de les dades. \\(SS_{Tr}\\) representa la variabilitat de les mitjanes de les combinacions de nivells. \\(SS_{A}\\) representa la variabilitat de les mitjanes dels nivells del factor A. \\(SS_{B}\\) representa la variabilitat de les mitjanes dels nivells del factor B. \\(SS_E\\) representa la suma de les variabilitats dins cada combinació de nivells. \\(SS_{AB}\\) representa la variabilitat deguda a la interacció. Recordau que, si no hi hagués interacció, per a cada parella de nivells \\(j,j&#39;\\) de B, les diferències \\[ \\mu_{ij}-\\mu_{ij&#39;} \\] serien totes la mateixa, independentment del nivell \\(i\\) de \\(A\\). Diguem a aquesta diferència \\(\\delta_{jj&#39;}\\). Si ara calculam la mitjana per a tots els nivells \\(j&#39;\\) de B tenim \\[ \\mu_{ij}-\\mu_{i\\bullet}=\\mu_{ij}-\\frac{1}{b}\\sum_{j&#39;=1}^b \\mu_{ij&#39;}= \\frac{1}{b} \\sum_{j&#39;=1}^b(\\mu_{ij}-\\mu_{ij&#39;})= \\frac{1}{b}\\sum_{j&#39;=1}^b \\delta_{jj&#39;} \\] Aquest valor no depèn del nivell \\(i\\). Per tant, si ara calculam la mitjana per a tots els nivells \\(i\\) d’A \\[ \\mu_{\\bullet j}-\\mu=\\frac{1}{a}\\sum_{i=1}^a(\\mu_{ij}-\\mu_{i\\bullet})=\\frac{1}{b}\\sum_{j&#39;=1}^b \\delta_{jj&#39;} \\] En resum, si no hi hagués interacció entre els dos factors, tendríem que \\[ \\begin{array}{l} \\mu_{ij}-\\mu_{i\\bullet}-\\mu_{\\bullet j}+\\mu=(\\mu_{ij}-\\mu_{i\\bullet})-(\\mu_{\\bullet j}-\\mu)\\\\ \\qquad\\displaystyle =\\frac{1}{b}\\sum_{j&#39;=1}^b \\delta_{jj&#39;}-\\frac{1}{b}\\sum_{j&#39;=1}^b \\delta_{jj&#39;}=0 \\end{array} \\] i per tant, sobre la nostra mostra, esperaríem que \\[ \\overline{X}_{ij}-\\overline{X}_{i\\bullet}-\\overline{X}_{\\bullet j}+\\overline{X}=0 \\] Aleshores, \\(SS_{AB}\\) és la suma dels quadrats de les divergències, per a cada parell \\((i,j)\\), d’aquests valors a la nostra mostra respecte del que esperaríem si no hi hagués interacció. A més, de \\(\\mu_{ij}-\\mu_{i\\bullet}-\\mu_{\\bullet j}+\\mu=0\\) deduïm que \\[ \\mu_{ij}-\\mu=\\mu_{i\\bullet}+\\mu_{\\bullet j}-2\\mu=(\\mu_{i\\bullet}-\\mu)+(\\mu_{\\bullet j}-\\mu) \\] com afirmàvem en parlar del model de l’ANOVA de 2 vies. Observau que de \\[ \\begin{array}{l} SS_{Total} = SS_{Tr}+SS_E\\\\[1ex] SS_{Tr} = SS_A+SS_B+SS_{AB} \\end{array} \\] se’n dedueix que \\[ SS_{Total} = SS_A+SS_B+SS_{AB}+SS_E \\] La variabilitat total descompon en la suma de la variabilitat de les mitjanes del factor A més la variabilitat de les mitjanes del factor B més la variabilitat deguda a la interacció i més, finalment, la variabilitat “residual”. Exemple 10.19 Comprovem aquestes identitats amb les dades de l’Exemple 10.17. Procurau entendre com calculam les sumes de quadrats; hem donat els raonaments detallats als altres dos tipus d’ANOVA, aquí ja no els donarem. n=5 a=2 b=2 X.barra=mean(peixos$GSI) La \\(SS_{Total}\\): SS.Tot=sum((peixos$GSI-X.barra)^2) SS.Tot ## [1] 11.13377 La \\(SS_{A}\\): SS.A=b*n*sum((Xb.A$GSI-X.barra)^2) SS.A ## [1] 3.081125 La \\(SS_{B}\\): SS.B=a*n*sum((Xb.B$GSI-X.barra)^2) SS.B ## [1] 5.151125 La \\(SS_{AB}\\): SS.AB=n*sum((Xb.i.j.bolleta$GSI-Xb.A$GSI-rep(Xb.B$GSI,each=a)+X.barra)^2) SS.AB ## [1] 0.630125 La \\(SS_{Tr}\\): SS.Tr=n*sum((Xb.i.j.bolleta$GSI-X.barra)^2) SS.Tr ## [1] 8.862375 La \\(SS_{E}\\): SS.E=sum((peixos$GSI-c(rep(Xb.i.j.bolleta[1:2,3],n),rep(Xb.i.j.bolleta[3:4,3],n)))^2) SS.E ## [1] 2.2714 Comprovem les igualtats de sumes de quadrats SS.Tr ## [1] 8.862375 SS.A+SS.B+SS.AB ## [1] 8.862375 SS.Tot ## [1] 11.13377 SS.Tr+SS.E ## [1] 11.13377 Com a les altres ANOVA, compararem la variabilitat de les mitjanes amb la variabilitat dels errors. Per això, emprarem els quadrats mitjans següents: Quadrat mitjà del factor A: \\[ MS_A =\\dfrac{SS_A}{a-1} \\] Quadrat mitjà del factor B: \\[ MS_B =\\dfrac{SS_B}{b-1} \\] Quadrat mitjà de la interacció: \\[ MS_{AB}=\\dfrac{SS_{AB}}{(a-1)(b-1)} \\] Quadrat mitjà dels tractaments: \\[ MS_{Tr}=\\dfrac{SS_{Tr}}{ab-1} \\] Quadrat mitjà dels errors: \\[ MS_E=\\dfrac{SS_E}{ab (n-1)} \\] Fixau-vos que els denominadors són diferents dels dels quadrats mitjans homònims en les altres ANOVA. Exemple 10.20 Al nostre Exemple 10.17, hem obtingut les sumes de quadrats següents: \\[ \\begin{array}{cccccc} SS_{Total} &amp; SS_A &amp; SS_B &amp; SS_{AB} &amp;SS_{Tr} &amp; SS_E\\\\ \\hline 11.1338 &amp; 3.0811 &amp; 5.1511 &amp; 0.6301 &amp; 8.8624 &amp; 2.2714 \\end{array} \\] En aquest exemple, \\(n=5\\) i \\(a=b=2\\). Per tant \\[ \\begin{array}{ccccc} MS_A &amp; MS_B &amp; MS_{AB} &amp; MS_{Tr} &amp; MS_E\\\\ \\hline 3.0811 &amp; 5.1511 &amp; 0.6301 &amp; 2.9541 &amp; 0.142 \\end{array} \\] En una ANOVA de 2 vies, ens poden interessar els quatre contrastos següents: Contrast de mitjanes del factor A: Contrastam si hi ha diferències entre les mitjanes dels tractaments del factor A: \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{1\\bullet}=\\mu_{2\\bullet}=\\cdots =\\mu_{a\\bullet} \\\\ H_1 : \\text{Hi ha } i,i&#39;\\text{ tals que } \\mu_{i\\bullet} \\not = \\mu_{i&#39;\\bullet} \\end{array} \\right. \\] L’estadístic de contrast és \\[ F_A=\\frac{MS_A}{MS_E}, \\] el qual, si \\(H_0\\) és certa, té distribució F de Fisher amb \\(a-1\\) i \\(ab(n-1)\\) graus de llibertat i valor proper a 1. Contrast de mitjanes del factor B: Contrastam si hi ha diferències entre les mitjanes dels tractaments del factor B: \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{\\bullet 1}=\\mu_{\\bullet 2}=\\cdots =\\mu_{ \\bullet b} \\\\ H_1 : \\text{Hi ha } j,j&#39;\\text{ tals que } \\mu_{\\bullet j} \\not = \\mu_{\\bullet j&#39;} \\end{array} \\right. \\] L’estadístic de contrast és \\[ F_B=\\frac{MS_B}{MS_E}, \\] el qual, si \\(H_0\\) és certa, té distribució F de Fisher amb \\(b-1\\) i \\(ab(n-1)\\) graus de llibertat i valor proper a 1. Contrast dels tractaments: Contrastam si hi ha diferències entre les mitjanes de les parelles (nivell de A, nivell de B): \\[ \\left\\{ \\begin{array}{l} H_0 : \\text{Per a tots }i,j,i&#39;,j&#39;,\\ \\mu_{ij}=\\mu_{i&#39;j&#39;} \\\\ H_1 : \\text{Hi ha } i,j,i&#39;,j&#39;\\text{ tals que } \\mu_{ij}\\neq \\mu_{i&#39;j&#39;} \\end{array} \\right. \\] L’estadístic de contrast és \\[ F_{Tr}=\\frac{MS_{Tr}}{MS_E}, \\] el qual, si \\(H_0\\) és certa, té distribució F de Fisher amb \\(ab-1\\) i \\(ab(n-1)\\) graus de llibertat i valor proper a 1. Contrast de no interacció: Contrastam si hi ha interacció entre els factors A i B: \\[ \\left\\{ \\begin{array}{l} H_0 : \\text{No hi ha interacció entre els nivells d&#39;$A$ i $B$} \\\\ H_1 : \\text{Hi ha interacció entre alguns nivells d&#39;$A$ i $B$} \\end{array} \\right. \\] L’estadístic de contrast és \\[ F_{AB} = \\frac{MS_{AB}}{MS_E}, \\] el qual, si \\(H_0\\) és certa, té distribució F de Fisher amb \\((a-1)(b-1)\\) i \\(ab(n-1)\\) graus de llibertat i valor proper a 1. Com a les ANOVA anteriors, els graus de llibertat de cada estadístic de contrast F són els denominadors emprats en les definicions dels quadrats mitjans del numerador i el denominador. En els quatre contrastos, el p-valor és \\[ P(F_{x,y}\\geqslant \\text{valor de l&#39;estadístic sobre la mostra}) \\] on \\(F_{x,y}\\) representa la distribució F de Fisher amb els graus de llibertat que pertoquin al contrast. Tota aquesta informació se recull en la taula ANOVA següent: \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; ab-1 &amp; SS_{Tr}&amp; MS_{Tr} &amp; F_{Tr} &amp; \\text{p-valor}_{Tr} \\\\ \\text{Factor A} &amp; a-1 &amp; SS_{A}&amp; MS_{A} &amp; F_A &amp; \\text{p-valor}_A \\\\ \\text{Factor B} &amp; b-1 &amp; SS_{B}&amp; MS_{B} &amp; F_B &amp; \\text{p-valor}_B \\\\ \\text{Interacció AB} &amp; (a-1)(b-1) &amp; SS_{AB}&amp; MS_{AB} &amp; F_{AB} &amp; \\text{p-valor}_{AB} \\\\ \\text{Residus} &amp; ab(n-1) &amp; SS_E &amp; MS_E &amp; \\\\\\hline \\end{array} \\] Exemple 10.21 Tornant a l’Exemple 10.17, tenim que \\(n=5\\), \\(a=b=2\\) i ja hem calculat els quadrats mitjans següents: \\[ \\begin{array}{ccccc} MS_A &amp; MS_B &amp; MS_{AB} &amp; MS_{Tr} &amp; MS_E\\\\ \\hline 3.0811 &amp; 5.1511 &amp; 0.6301 &amp; 2.9541 &amp; 0.142 \\end{array} \\] Realitzem els quatre contrastos: Hi ha diferència en la mitjana del GSI segons el foto-període? \\[ \\begin{array}{l} F_A=\\dfrac{MS_{A}}{MS_E}=21.7\\\\ \\text{p-valor}_A=P(F_{1,16}\\geqslant 21.7)=\\texttt{1-pf(21.7,1,16)}=0.0003 \\end{array} \\] Conclusió: Hem trobat evidència estadística que el GSI mitjà és diferent segons el foto-període (ANOVA de 2 vies, p-valor 0.0003) Hi ha diferència en la mitjana del GSI segons la temperatura? \\[ \\begin{array}{l} F_B=\\dfrac{MS_{B}}{MS_E}=36.3\\\\ \\text{p-valor}_B=P(F_{1,16}\\geqslant 36.3)=\\texttt{1-pf(36.3,1,16)}=2\\cdot 10^{-5} \\end{array} \\] Conclusió: Hem trobat evidència estadística que el GSI mitjà és diferent segons la temperatura (ANOVA de 2 vies, p-valor 2·10-5) Hi ha diferència en la mitjana del GSI segons les combinacions de foto-període i temperatura? \\[ \\begin{array}{l} F_{Tr}=\\dfrac{MS_{Tr}}{MS_E}=20.8\\\\ \\text{p-valor}_{Tr}=P(F_{3,16}\\geqslant 20.8)=\\texttt{1-pf(20.8,3,16)}=9\\cdot 10^{-6} \\end{array} \\] Conclusió: Hem trobat evidència estadística que no tots els GSI mitjans per a les combinacions de foto-període i temperatura són iguals (ANOVA de 2 vies, p-valor 9·10-6) Hi ha interacció entre el foto-període i la temperatura? \\[ \\begin{array}{l} F_{AB}=\\dfrac{MS_{AB}}{MS_E}=4.437\\\\ \\text{p-valor}_{AB}=P(F_{1,16}\\geqslant 4.437)=\\texttt{1-pf(4.437,1,16)}=0.051 \\end{array} \\] Conclusió: No hem trobat evidència estadística que hi hagi interacció entre el foto-període i la temperatura (ANOVA de 2 vies, p-valor 0.051) La taula ANOVA és \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp;3&amp;8.862&amp;2.954&amp;20.8 &amp; 9\\cdot 10^{-6} \\\\ \\text{Factor A} &amp;1&amp;3.081&amp;3.081&amp;21.7 &amp; 0.0003 \\\\ \\text{Factor B} &amp; 1&amp;5.151&amp;5.151&amp;36.3 &amp; 2\\cdot 10^{-5} \\\\ \\text{Interacció AB} &amp; 1&amp;0.630&amp;0.630&amp;4.44 &amp; 0.051 \\\\ \\text{Residus} &amp; 19&amp;11.134&amp;&amp; &amp; \\\\\\hline \\end{array} \\] Hem fet quatre contrastos. No hauríem d’ajustar els p-valors? No, perquè estam emprant les mateixes dades als quatre contrastos, no són contrastos independents. És a dir, o la mostra ens ha sortit representativa i totes les conclusions són més o menys fiables, o la mostra ens ha sortit rareta i totes les conclusions són poc fiables. 10.4.2 Amb R A l’ANOVA de 2 vies: Els contrastos de les mitjanes de cada un dels factors i de no interacció s’efectuen aplicant summary(aov( )) a la fórmula que separa la variable numèrica pel producte dels dos factors, indicat amb un asterisc *. El contrast dels tractaments, és a dir, de les mitjanes de les subpoblacions definides per les combinacions de nivells, un de cada factor, s’efectua aplicant summary(aov( )) a la fórmula que separa la variable numèrica per la combinació dels dos factors, indicada amb dos punts “:”. Així, l’ANOVA de 2 vies de l’Exemple 10.11 es fa amb summary(aov(GSI~llum*temp,data=peixos)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## llum 1 3.081 3.081 21.704 0.000262 *** ## temp 1 5.151 5.151 36.285 1.77e-05 *** ## llum:temp 1 0.630 0.630 4.439 0.051268 . ## Residuals 16 2.271 0.142 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(aov(GSI~llum:temp,data=peixos)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## llum:temp 3 8.862 2.954 20.81 9.06e-06 *** ## Residuals 16 2.271 0.142 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 La primera funció calcula les fileres “Factor A”, “Factor B”, “Interacció AB” i “Residus” de la taula ANOVA, i de la segona funció us heu de quedar amb la primera filera, que us dóna la filera “Tractaments” de la taula ANOVA. No confongueu les fileres llum:temp de la primera taula, que és la de les Interaccions, amb la de la segona, que és la dels Tractaments. 10.5 Test de la lliçó 10 (1) Per què serveix una Anàlisi de la Variància? Per contrastar si els valors mitjans d’una variable quantitativa sobre diverses poblacions són tots diferents o no Per contrastar si els valors mitjans d’una variable quantitativa sobre diverses poblacions són tots iguals o no Per contrastar si entre els valors mitjans d’una variable quantitativa sobre diverses poblacions n’hi ha exactament dos que siguin diferents o no. Per contrastar si les mitjanes mostrals d’una variable quantitativa sobre diverses mostres extretes de diferents subpoblacions són totes iguals o no Per contrastar si les mitjanes mostrals d’una variable quantitativa sobre diverses mostres extretes de diferents subpoblacions són totes diferents o no Per contrastar si les variàncies d’una variable quantitativa sobre diverses poblacions són totes diferents o no Per contrastar si les variàncies d’una variable contínua sobre diverses poblacions són totes iguals o no (2) Quina és la hipòtesi alternativa en el contrast que efectuam amb una ANOVA? Que totes les mitjanes mostrals són diferents. Que totes les mitjanes poblacionals són diferents. Que hi ha alguna parella de mitjanes mostrals que són diferents Que hi ha alguna parella de mitjanes poblacionals que són diferents Que hi ha exactament una parella de mitjanes mostrals que són diferents Que hi ha exactament una parella de mitjanes poblacionals que són diferents Cap de les anteriors (3) Un contrast d’homogeneïtat on comparam la probabilitat d’èxit d’una variable Bernoulli sobre diferents poblacions (per veure si sempre és la mateixa o no) es pot entendre com un contrast d’igualtat de mitjanes. Si les mostres són prou grans, podem emprar una ANOVA per efectuar-lo? Sí No (4) Què seria un error de tipus II en una ANOVA? Concloure que totes les mitjanes mostrals són iguals quan en realitat són totes diferents Concloure que hi ha una parella de mitjanes mostrals que són iguals quan en realitat són totes diferents Concloure que totes les mitjanes mostrals són iguals quan en realitat n’hi ha alguna parella que són diferents Concloure que totes les mitjanes poblacionals són iguals quan en realitat són totes diferents Concloure que hi ha una parella de mitjanes poblacionals que són iguals quan en realitat són totes diferents Concloure que totes les mitjanes poblacionals són iguals quan en realitat n’hi ha alguna parella que són diferents (5) Per poder efectuar una ANOVA d’1 via, cal que totes les mostres tenguin la mateixa mida? Sí No (6) Quines de les condicions següents són necessàries per poder efectuar una ANOVA d’1 via? Les variables poblacionals han de ser normals Les variables poblacionals han de ser normals o les mostres han de ser grans Les variàncies de les mostres han de ser totes iguals Les variàncies de les poblacions definides pels nivells han de ser totes iguals Les variàncies de les poblacions definides pels nivells no poden ser totes diferents Les distribucions de les poblacions definides pels nivells han de ser totes la mateixa (han de ser de la mateixa família i tenir els mateixos paràmetres) Les mostres han de ser independents Les mostres han de ser aparellades (7) Per contrastar si tres somnífers tenen el mateix efecte, prenc 10 persones i durant 3 dies consecutius a cada una li don cada dia un somnífer diferent, en un ordre escollit a l’atzar, a l’hora d’anar a dormir i mesur el temps que tarda en dormir-se. Aquest experiment, te el disseny experimental d’una ANOVA d’1 via? Sí No (8) Si en efectuar una ANOVA d’1 via va i resulta que la identitat de la suma de quadrats no se satisfà, què ha passat? Un error de tipus I Un error de tipus II Un error de càlcul (9) Quines de les afirmacions següents sobre l’ANOVA d’1 via són correctes? Marcau totes les respostes correctes. La variància total és igual a la suma de les variàncies dels tractaments més la suma de la variància dels residus. La suma total de quadrats és igual a la suma dels quadrats dels tractaments més la suma dels quadrats dels residus. La variància de les dades és igual a la suma del quadrat mitjà dels tractaments més el quadrat mitjà dels residus. La suma dels dos graus de llibertat de la distribució F de l’estadístic de contrast és igual al nombre total de dades. Les mostres dels diferents tractaments poden tenir mides diferents. Cap de les respostes anteriors és correcta. (10) Hem realitzat una ANOVA d’1 via. Les dues primeres columnes de la taula resultant són: \\[ \\begin{array}{|@{}l@{}|l@{}|l@{}|l@{}|l|l|} \\hline \\text{Font de}&amp;\\text{Graus de}\\hphantom{x} &amp;\\text{Suma de}\\hphantom{x}&amp;\\text{Quadrats}\\hphantom{x} &amp;\\text{Estadístic}\\hphantom{x} &amp; \\text{p-valor}\\\\ \\text{variació}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp; &amp; \\\\\\hline \\text{Tractament}&amp; 3 &amp; 215.1 &amp; &amp; &amp; \\\\[1ex] \\text{Error}&amp; 21 &amp; 147.3 &amp; &amp; &amp;\\\\\\hline \\end{array} \\] Quines de les afirmacions següents són vertaderes? Marcau totes les respostes correctes. \\(SS_{Total}= 215.1+147.3=362.4\\) El nombre de nivells del factor d’interès és 3 El nombre total de dades ha estat 24 El nombre total de dades ha estat 25 La distribució de l’estadístic de contrast és F de Fisher amb 3 i 21 graus de llibertat La distribució de l’estadístic de contrast és F de Fisher amb 21 i 3 graus de llibertat Cap de les altres respostes és correcta (11) Si volem realitzar un contrast posterior per parelles després d’una ANOVA d’1 via on hem comparat 5 tractaments, i empram el mètode d’ajust de Bonferroni, per quin valor hem de multiplicar els p-valors dels contrastos individuals? Per 5. Per 10. Per 20. Per 1/5. Per 1/10. Per 1/20. Cap de les respostes anteriors és correcta. (12) S’ha realitzat un assaig clínic dirigit a comparar l’efectivitat de tres tractaments alternatius en pacients cirròtics, provant-los sobre tres grups independents de 50 malalts cadascun. La variable de resposta ha estat el nivell de transaminasses, que és contínua i de distribució asimètrica a la dreta. Quina de les proves estadístiques següents és la més adequada per contrastar si els tres tractaments tenen la mateixa efectivitat o no?: 3 proves t per a mostres independents, una per a cada parell de tractaments Una anàlisi de la variància Un contrast d’homogeneïtat Un test de Kruskal-Wallis 3 proves de Mann-Whitney, una per a cada parell de tractaments (13) En una ANOVA de blocs, per calcular el p-valor hem emprat una distribució F amb 3 i 21 graus de llibertat. De quina mida era la mostra completa que hi hem emprat? De 21 individus De 24 individus De 32 individus De 63 individus No ho podem saber a partir d’aquests nombres de graus de llibertat Cap de les altres respostes és correcta (14) Hem realitzat una ANOVA de blocs. Hi comparàvem 3 tractaments i hem emprat 10 blocs; les dades no han estat totes iguals. Si haguéssim analitzat les mateixes dades, de manera incorrecta, amb una ANOVA d’1 via, quines de les afirmacions següents segur que serien vertaderes? Marcau totes les respostes correctes. La suma de quadrats total hagués estat més gran La suma de quadrats dels errors hagués estat més petita La suma de quadrats dels errors hagués estat més gran El quadrat mitjà dels errors hagués estat més petit El quadrat mitjà dels errors hagués estat més gran El segon nombre de graus de llibertat de l’estadístic F emprat per calcular el p-valor seria més petit El segon nombre de graus de llibertat de l’estadístic F emprat per calcular el p-valor seria més gran Cap de les altres respostes és correcta (15) És possible que una ANOVA de blocs, per calcular el p-valor hàgim d’emprar una distribució F amb 3 i 22 graus de llibertat? Sí No (16) És possible que una ANOVA d’1 via, per calcular el p-valor hàgim d’emprar una distribució F amb 3 i 22 graus de llibertat? Sí No (17) Respecte al test de Friedman, quines de les afirmacions següents són correctes? Marcau totes les respostes correctes. És un test no paramètric. S’utilitza per comparar les mitjanes (en realitat, les medianes) de tres o més poblacions a partir de mostres independents. S’utilitza per comparar les mitjanes (en realitat, les medianes) de tres o més poblacions a partir de mostres aparellades. Si l’aplicam a 2 mostres, és equivalent al test de Wilcoxon Si l’aplicam a 2 mostres, és equivalent al test de Mann-Whitney Requereix que les mostres provenguin de distribucions normals. Requereix que les mostres provenguin de distribucions NO normals. (18) En una ANOVA de 2 vies, en quantes fonts de variabilitat independents descompon la variabilitat total? 2 3 4 5 Cap de les altres respostes és correcta (19) Respecte al test de Kruskal-Wallis, quines de les afirmacions següents són correctes? Marcau totes les respostes correctes. És un test no paramètric. S’utilitza per comparar les mitjanes (en realitat, les medianes) de tres o més poblacions a partir de mostres independents. S’utilitza per comparar les mitjanes (en realitat, les medianes) de tres o més poblacions a partir de mostres aparellades. Si l’aplicam a 2 mostres, és equivalent al test de Wilcoxon Si l’aplicam a 2 mostres, és equivalent al test de Mann-Whitney Requereix que les mostres provenguin de distribucions normals. Requereix que les mostres provenguin de distribucions NO normals. (20) Hem realitzat una ANOVA de blocs. Les dues primeres columnes de la taula resultant són: \\[ \\begin{array}{|@{}l@{}|l@{}|l@{}|l@{}|l|l|} \\hline \\text{Font de}&amp;\\text{Graus de}\\hphantom{x} &amp;\\text{Suma de}\\hphantom{x}&amp;\\text{Quadrats}\\hphantom{x} &amp;\\text{Estadístic}\\hphantom{x} &amp; \\text{p-valor}\\\\ \\text{variació}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp; &amp; \\\\\\hline \\text{Tractament}&amp; 3 &amp; 6.75 &amp; &amp; &amp; \\\\[1ex] \\text{Blocs} &amp; 9 &amp;1.55&amp; &amp; &amp;\\\\[1ex] \\text{Error}&amp; 27 &amp;8.32&amp; &amp; &amp;\\\\\\hline \\end{array} \\] Quina o quines de les afirmacions següents són vertaderes? Marcau totes les respostes correctes. \\(SS_{Total}=6.75+8.32=15.07\\) El quadrat mitjà dels tractaments és aproximadament 2.25 El nombre total de dades ha estat 30 El nombre total de dades ha estat 40 Cap de les altres respostes és correcta (21) En una ANOVA de blocs hem obtingut un p-valor molt més petit que el nivell de significació. Quina és la conclusió correcta? Marcau només una resposta. Que hi ha qualque parella de mitjanes mostrals dels tractaments que han estat diferents. Que hi ha qualque parella de mitjanes poblacionals dels tractaments que són diferents. Que hi ha qualque parella de mitjanes poblacionals dels blocs que són diferents. Que hi ha qualque parella de mitjanes poblacionals dels blocs que han estat diferents. Que les mitjanes mostrals dels tractaments han estat totes diferents. Que les mitjanes poblacionals dels tractaments són totes diferents. Que les mitjanes mostrals dels blocs han estat totes diferents. Que les mitjanes poblacionals dels blocs són totes diferents. Cap de les respostes anteriors és correcta. (22) Quines de les afirmacions següents sobre l’ANOVA de blocs són correctes? Marcau totes les correctes: Rebutjarem la hipòtesi nul·la si la suma de quadrats dels residus és prou gran. Rebutjarem la hipòtesi nul·la si la suma de quadrats dels blocs és prou gran. Rebutjarem la hipòtesi nul·la si la suma de quadrats dels tractaments és prou gran. La suma de quadrats total és igual a la suma de quadrats dels tractaments més la suma dels quadrats dels residus. La suma de quadrats total és igual a la suma de quadrats dels tractaments més la suma dels quadrats dels blocs. (23) Què significa que hi hagi interacció entre els dos factors en una ANOVA de 2 factors? Que almenys en un dels factors hem trobat diferències estadísticament significatives Que hem trobat en els dos factors diferències estadísticament significatives entre les mitjanes Que les diferències entre les mitjanes poblacionals dels nivells d’un dels factors depenen del nivell de l’altre factor Que les diferències entre les mitjanes poblacionals dels nivells d’un dels factors són independents del nivell de l’altre factor Que els dos factors no són variables independents (24) En un assaig clínic es comparen 3 tractaments (placebo, tractament establert i un tractament nou) sobre 3 grups de pacients escollits de manera independent. Acceptam que la variable resposta té distribució normal i amb la mateixa variància sota cada un dels tractaments. Quina de les proves estadístiques següents és la més adequada per comparar aquesta resposta? Tres tests t de mitjanes Un test de Wilcoxon Una anàlisi de la variància Un test de Kruskal-Wallis Un test khi-quadrat (25) En un assaig clínic es comparen 3 tractaments (placebo, tractament establert i un tractament nou) sobre 3 grups de pacients escollits de manera independent. Acceptam que la variable resposta té distribució normal i quan aplicam a les mostres el test de Bartlett dóna un p-valor molt petit. Quina de les proves estadístiques següents és la més adequada per comparar aquesta resposta? Tres tests t de mitjanes Un test de Wilcoxon Una anàlisi de la variància Un test de Kruskal-Wallis Un test khi-quadrat "],
["regressió-lineal.html", "Tema 11 Regressió lineal 11.1 Regressió lineal simple 11.2 Regressió lineal múltiple 11.3 Test de la lliçó 11", " Tema 11 Regressió lineal Comencem recordant un exemple de Matemàtiques I. Exemple 11.1 La taula següent dóna l’alçada mitjana (en cm) dels nins a determinades edats (en anys): edat alçada 1 75 3 92 5 108 7 121 9 130 11 142 13 155 A Matemàtiques I aprenguéreu a calcular amb R la “millor” relació lineal \\[ \\text{alçada}= b_0+b_1\\cdot\\text{edat} \\] de la manera següent: edat=c(1,3,5,7,9,11,13) alçada=c(75,92,108,121,130,142,155) lm(alçada~edat) ## ## Call: ## lm(formula = alçada ~ edat) ## ## Coefficients: ## (Intercept) edat ## 72.321 6.464 Obteníeu d’aquesta manera la recta \\[ \\text{alçada}=72.321+6.464x \\] i la representàveu amb: plot(edat,alçada,pch=20) abline(lm(alçada~edat),col=&quot;red&quot;,xlab=&quot;Edat&quot;,ylab=&quot;Alçada&quot;) Ara podíeu emprar aquesta recta per estimar l’alçada d’un nin d’una edat concreta. Per exemple, ens permet estimar que l’alçada d’un nin de 10 anys és \\[ 72.321+6.464\\cdot 10=136.964, \\] uns 137 cm. En aquest tema estudiarem com es calcula aquella recta, què vol dir que sigui “la millor recta” que explica l’alçada dels nins en funció de l’edat, com trobar intervals de confiança per a les estimacions associades a aquesta recta i com tractar el problema més general de trobar “la millor funció lineal” que explica una variable \\(Y\\) en funció de diverses variables \\(X_1,\\ldots,X_k\\). 11.1 Regressió lineal simple El problema plantejat a l’Exemple 11.1 és una instància de la situació general en la qual tenim parelles d’observacions de dues variables \\(X\\) i \\(Y\\) sobre una mostra de subjectes, \\[ (x_i,y_i)_{i=1,2,\\ldots,n}, \\] i volem estudiar com depèn el valor de la variable \\(Y\\) del de \\(X\\). En aquest context: La variable \\(X\\) l’anomenam la variable de control o independent La variable \\(Y\\) l’anomenam la variable de resposta o dependent La variable de control no té per què ser aleatòria: nosaltres podem fixar el seu valor sobre els subjectes. Per exemple, la variable \\(X\\) podria ser la dosi d’una medicació i que nosaltres decidíssim a cada individu, de manera planificada i gens aleatòria, quina dosi li administram. En canvi, la variable de resposta ha de ser aleatòria. Si no, no té sentit estimar res sobre ella. En general, volem trobar la millor relació funcional (el millor model estadístic, amb la terminologia introduïda en el tema anterior) que expliqui la variable \\(Y\\) en funció de la variable \\(X\\). En aquest tema, cercarem un model lineal. Les tècniques que es fan servir per resoldre aquest problema s’anomenen genèricament de regressió lineal. Nosaltres n’estudiarem una de concreta: la regressió lineal per mínims quadrats. El nom “regressió” per parlar del tipus de tècniques que permeten ajustar una recta a un conjunt de punts prové del títol d’un article de Galton de 1886, Regression Towards Mediocrity in Hereditary Stature. En aquest article hi va analitzar les alçades d’una mostra de 928 adults i les alçades mitjanes dels seus pares. Hi observà que els pares alts tendien a tenir fills més baixos que ells i que els pares baixos tendien a tenir fills més alts que ells. D’aquest efecte en digué “regressió a la mediocritat” al títol de l’article. D’aquí s’adoptà el terme “regressió” per descriure la tècnica que emprà per obtenir la recta vermella del gràfic següent, amb la qual suportava la seva conclusió comparant-la amb la diagonal (la línia discontínua), i amb el temps el nom de l’efecte que observà es canvià al menys ofensiu “regressió a la mitjana”. Més endavant tornarem sobre aquest exemple. 11.1.1 El model En el model de regressió lineal suposam que existeixen \\(\\beta_0,\\beta_1\\in \\mathbb{R}\\) tals que \\[ \\mu_{Y|x}=\\beta_0+\\beta_1 x \\] on \\(\\mu_{Y|x}\\) és el valor esperat de \\(Y\\) sobre els subjectes per als quals \\(X\\) val \\(x\\). Volem estimar aquests paràmetres \\(\\beta_0\\) (el terme independent del model) i \\(\\beta_1\\) (la pendent del model) a partir d’una mostra. Recordau la interpretació d’una funció lineal \\(y=a_0+a_1x\\): El terme independent \\(a_0\\) és el valor de \\(y\\) quan \\(x=0\\) La pendent \\(a_1\\) és la variació de \\(y\\) quan \\(x\\) augmenta en 1 unitat Per tant, en el nostre model de regressió lineal: \\(\\beta_0\\) és el valor esperat de \\(Y\\) en els subjectes en els quals \\(X\\) val 0 \\(\\beta_1\\) és la variació del valor esperat de \\(Y\\) quan el valor de \\(X\\) augmenta 1 unitat Amb una mostra \\((x_i,y_i)_{i=1,2,\\ldots,n}\\), calcularem estimacions \\(b_0\\) i \\(b_1\\) de \\(\\beta_0\\) i de \\(\\beta_1\\). Això ens donarà la recta de regressió per a la nostra mostra: \\[ \\widehat{Y}=b_0+b_1 X. \\] Aquesta recta, donat un valor \\(x_0\\) de \\(X\\), permet estimar el valor \\(\\widehat{y}_0=b_0+b_1 x_0\\) de \\(Y\\) sobre un subjecte en el qual \\(X\\) valgui \\(x_0\\). Hi empram \\(\\widehat{Y}\\) a la dreta per posar èmfasi que no és que \\(Y\\) sigui \\(b_0+b_1X\\), sinó que això darrer estima el valor de \\(Y\\) a partir del valor de \\(X\\). En concret, si \\(\\widehat{y}_0=b_0+b_1 x_0\\), direm a \\(\\widehat{y}_0\\) el valor estimat de \\(Y\\) quan \\(X=x_0\\). Fixau-vos que, d’aquesta manera, donada una observació \\((x_i,y_i)\\) de la nostra mostra, distingim entre \\(y_i\\): el valor de \\(Y\\) sobre l’individu corresponent \\(\\widehat{y}_i=b_0+b_1 x_i\\): l’estimació del valor de \\(Y\\) sobre l’individu corresponent a partir del seu valor de \\(X\\) i la recta de regressió obtinguda El model anterior el reescrivim com a \\[ Y|x=\\mu_{Y|x}+ E_x=\\beta_0+\\beta_1 x+ E_x \\] on \\(Y|x\\) és la variable aleatòria “valor de \\(Y\\) quan \\(X\\) val \\(x\\)”: Prenem un subjecte en el qual \\(X\\) val \\(x\\) i hi mesuram \\(Y\\) \\(\\mu_{Y|x}\\) és el valor esperat de \\(Y|x\\) \\(E_x=Y|x -\\mu_{Y|x}\\) és la variable aleatòria error o residu, que dóna la diferència entre el valor de \\(Y\\) en un individu amb \\(X=x\\) i el seu valor esperat Prenent valors esperats als dos costats de la igualtat \\(Y|x=\\mu_{Y|x}+ E_x\\) obtenim que \\(\\mu_{Y|x}=\\mu_{Y|x}+ \\mu_{E_x}\\) i per tant que \\(\\mu_{E_x}=0\\). Així doncs, aquest model implica que els valors esperats de les variables error \\(E_x\\) són tots 0. 11.1.2 Mínims quadrats Si estimam que \\(\\beta_0\\) i \\(\\beta_1\\) valen \\(b_0\\) i \\(b_1\\), l’error que cometem amb l’estimació \\(\\widehat{y}_i=b_0+b_1x_i\\) a cada observació \\((x_i,y_i)\\) de la mostra és \\[ e_i=y_i-\\widehat{y}_i=y_i-(b_0+b_1 x_i) \\] La Suma dels Quadrats dels Errors d’aquesta estimació és \\[ SS_E=\\sum_{i=1}^n e_i^2=\\sum_{i=1}^n (y_i-b_0-b_1 x_i)^2 \\] A la regressió lineal per mínims quadrats, s’estimen \\(\\beta_0\\) i \\(\\beta_1\\) per mitjà dels valors de \\(b_0\\) i \\(b_1\\) que minimitzen aquesta \\(SS_E\\). Aquests valors són donats pel resultat següent: Teorema 11.1 Els estimadors \\(b_0\\) i \\(b_1\\) per mínims quadrats de \\(\\beta_0\\) i \\(\\beta_1\\) són \\[ b_1 =\\frac{{s}_{xy}}{{s}_x^2}=\\frac{\\widetilde{s}_{xy}}{\\widetilde{s}_x^2},\\quad b_0 = \\overline{y}-b_1 \\overline{x}. \\] Per trobar-los, empram que els valors de \\(b_0,b_1\\) que fan mínim \\[ SS_E=\\sum_{i=1}^n (y_i-b_0-b_1 x_i)^2 \\] anul·len les derivades de \\(SS_E\\) respecte de \\(b_0\\) i \\(b_1\\). Derivem: \\[ \\begin{array}{l} \\displaystyle\\dfrac{\\partial SS_E}{\\partial b_0}=-2\\sum\\limits_{i=1}^n (y_i -b_0-b_1 x_i)\\\\[2ex] \\displaystyle\\dfrac{\\partial SS_E}{\\partial b_1}=-2\\sum\\limits_{i=1}^n (y_i -b_0-b_1 x_i) x_i \\end{array} \\] El \\((b_0,b_1)\\) que cercam satisfà \\[ \\begin{array}{l} \\displaystyle 2\\sum\\limits_{i=1}^n (y_i -b_0-b_1 x_i)=0\\\\[2ex] \\displaystyle 2\\sum\\limits_{i=1}^n (y_i -b_0-b_1 x_i) x_i =0 \\end{array} \\] Ho reescrivim: \\[ \\begin{array}{rl} \\displaystyle n b_0 + \\Big(\\sum\\limits_{i=1}^n x_i\\Big) b_1 &amp; =\\sum\\limits_{i=1}^n y_i\\\\[1ex] \\displaystyle \\Big(\\sum\\limits_{i=1}^n x_i\\Big) b_0 + \\Big(\\sum\\limits_{i=1}^n x_i^2\\Big) b_1 &amp;=\\sum\\limits_{i=1}^n x_iy_i \\end{array} \\] Les solucions són \\[ \\begin{array}{rl} b_1&amp; \\displaystyle=\\frac{n \\sum\\limits_{i=1}^n x_i y_i-\\sum\\limits_{i=1}^n x_i\\sum\\limits_{i=1}^n y_i} {n\\sum\\limits_{i=1}^n x_i^2-\\big(\\sum\\limits_{i=1}^n x_i\\big)^2}\\\\[6ex] b_0&amp; \\displaystyle=\\frac{\\sum\\limits_{i=1}^n y_i -b_1 \\sum\\limits_{i=1}^n x_i}{n} \\end{array} \\] i es pot comprovar que donen el mínim de \\(SS_E\\). Ara, recordant que \\[ \\begin{array}{l} \\displaystyle\\overline{x}=\\frac{1}{n}\\sum\\limits_{i=1}^n x_i, \\quad \\overline{y}=\\frac{1}{n} \\sum\\limits_{i=1}^n y_i\\\\[2ex] \\displaystyle s_x^2 =\\frac{1}{n}\\Big(\\sum_{i=1}^n x_i^2\\Big) -\\overline{x}^2,\\quad \\displaystyle s_y^2 =\\frac{1}{n}\\Big(\\sum_{i=1}^n y_i^2\\Big) -\\overline{y}^2\\\\[2ex] \\displaystyle s_{xy} =\\frac{1}{n}\\Big(\\sum_{i=1}^n x_i y_i\\Big)-\\overline{x}\\cdot\\overline{y} \\end{array} \\] s’obté finalment que \\[ b_1 =\\frac{{s}_{xy}}{{s}_x^2},\\quad b_0 = \\overline{y}-b_1 \\overline{x} \\] La igualtat \\[ \\frac{{s}_{xy}}{{s}_x^2}=\\frac{\\widetilde{s}_{xy}}{\\widetilde{s}_x^2} \\] és conseqüència que, a les dues fraccions, els denominadors del numerador i el denominador se cancel·len: \\[ \\frac{{s}_{xy}}{{s}_x^2}=\\frac{\\frac{\\sum_{i=1}^n (x_i-\\overline{x})(y_i-\\overline{y})}{n}}{\\frac{\\sum_{i=1}^n (x_i-\\overline{x})^2}{n}}=\\frac{{\\sum_{i=1}^n (x_i-\\overline{x})(y_i-\\overline{y})}}{{\\sum_{i=1}^n (x_i-\\overline{x})^2}}=\\frac{\\frac{\\sum_{i=1}^n (x_i-\\overline{x})(y_i-\\overline{y})}{n-1}}{\\frac{\\sum_{i=1}^n (x_i-\\overline{x})^2}{n-1}}= \\frac{\\widetilde{s}_{xy}}{\\widetilde{s}_x^2} \\] Aquests \\(b_0\\) i \\(b_1\\) són els que calcula la funció lm. Exemple 11.2 Calculem la recta de regressió per mínims quadrats de les edats i alçades de l’Exemple 11.1, que eren edat alçada 1 75 3 92 5 108 7 121 9 130 11 142 13 155 Comencem obtenint els estadístics que ens calen per calcular els coeficents \\(b_0\\) i \\(b_1\\) (i la variància de les alçades, que per calcular-los no ens fa falta però més tard sí que la necessitarem): edat=c(1,3,5, 7, 9, 11, 13) alçada=c(75, 92, 108, 121, 130 , 142, 155) x.b=mean(edat) y.b=mean(alçada) s2.x=var(edat) s2.y=var(alçada) s.xy=cov(edat,alçada) round(c(x.b,y.b,s2.x,s2.y,s.xy),3) ## [1] 7.000 117.571 18.667 786.952 120.667 Obtenim \\[ \\begin{array}{cccccccc} \\overline{x} &amp; \\overline{y} &amp; \\widetilde{s}_x^2 &amp; \\widetilde{s}_y^2 &amp; \\widetilde{s}_{xy}\\\\ \\hline 7 &amp; 117.571 &amp; 18.667 &amp; 786.952 &amp; 120.667 \\end{array} \\] Aleshores \\[ \\begin{array}{l} \\displaystyle b_1 =\\frac{\\widetilde{s}_{xy}}{\\widetilde{s}_x^2}=\\frac{120.667}{18.667}=6.464\\\\[2ex] \\displaystyle b_0 = \\overline{y}-b_1 \\overline{x} =117.571-6.464\\cdot 7=72.321 \\end{array} \\] Trobam la recta de regressió \\[ \\widehat{Y}=72.321+6.464 X \\] que coincideix amb la recta que calcula lm: lm(alçada~edat) ## ## Call: ## lm(formula = alçada ~ edat) ## ## Coefficients: ## (Intercept) edat ## 72.321 6.464 Recordau que els coeficients \\(b_0,b_1\\) d’aquesta recta s’obtenen, respectivament, afegint els sufixos $coefficients[1] i $coefficients[2] al resultat de la funció lm. b0.edat=lm(alçada~edat)$coefficients[1] b0.edat ## (Intercept) ## 72.32143 b1.edat=lm(alçada~edat)$coefficients[2] b1.edat ## edat ## 6.464286 Segons aquesta estimació, l’alçada mitjana dels nins augmenta 6.46 cm anuals, partint d’una alçada mitjana de 72.3 cm en néixer. Els càlculs involucrats en la regressió lineal són molt poc robusts, en el sentit que els arrodoniments poden influir molt en el resultat final. A l’entrada sobre regressió lineal de la Wikipedia hi trobareu un exemple detallat d’una regressió de pes en funció d’alçada. Calculada en metres dóna: \\[ \\widehat{Y}=61.272X-39.062 \\] Si es passen les alçades a polzades, s’arrodoneixen, es calcula la recta de regressió, i es torna a passar el resultat a metres, dóna \\[ \\widehat{Y}=61.675X-39.746 \\] La moralitat d’aquesta història és que, si feu els càlculs a mà, procureu no arrodonir fins al resultat final. Exemple 11.3 En un experiment on es volia estudiar l’associació entre el consum de sal i la tensió arterial, a alguns individus se’ls assignà aleatòriament una quantitat diària constant de sal en la seva dieta, i al cap d’un mes se’ls mesurà la tensió mitjana. Alguns resultats varen ser els següents: X (sal, en g) Y (pressió, en mm de Hg) 1.8 100 2.2 98 3.5 110 4.0 110 4.3 112 5.0 120 Volem trobar la recta de regressió lineal per mínims quadrats de \\(Y\\) en funció de \\(X\\) a partir d’aquesta mostra. Calculem els estadístics que necessitam: sal=c(1.8, 2.2,3.5,4.0,4.3,5.0) tensió=c(100,98,110,110,112,120) x.b=mean(sal) y.b=mean(tensió) s2.x=var(sal) s2.y=var(tensió) s.xy=cov(sal,tensió) round(c(x.b,y.b,s2.x,s2.y,s.xy),3) ## [1] 3.467 108.333 1.543 66.267 9.773 \\[ \\begin{array}{ccccc} \\overline{x} &amp; \\overline{y} &amp; \\widetilde{s}_x^2 &amp; \\widetilde{s}_y^2 &amp; \\widetilde{s}_{xy}\\\\ \\hline 3.467 &amp; 108.333 &amp; 1.543 &amp; 66.267 &amp; 9.773 \\end{array} \\] Per tant els coeficients de la recta de regressió lineal per mínims quadrats de \\(Y\\) (la tensió) en funció de \\(X\\) (la quantitat de sal) són b1.sal=s.xy/s2.x b0.sal=y.b-b1.sal*x.b round(c(b0.sal,b1.sal),3) ## [1] 86.371 6.335 Obtenim la recta \\[ \\widehat{Y}= 86.371+6.335 X \\] Segons aquest model, a un augment d’1 g de sal consumida li correspon un augment mitjà de 6.3 mm Hg de pressió arterial. Així mateix, amb aquest model estimam, per exemple, que la pressió arterial d’una persona que consumeix 3 g diaris de sal és \\[ 86.371+6.335 \\cdot 3=105.377\\text{ mm Hg} \\] Comprovem que aquesta és la recta que obtenim amb la funció lm: lm(tensió~sal)$coefficients ## (Intercept) sal ## 86.37079 6.33535 Exemple 11.4 Estimem la recta de regressió de les alçades dels fills en funció de les dels pares emprant les dades recollides per Galton. Aquestes dades formen el dataframe Galton del paquet HistData. library(HistData) str(Galton) ## &#39;data.frame&#39;:\t928 obs. of 2 variables: ## $ parent: num 70.5 68.5 65.5 64.5 64 67.5 67.5 67.5 66.5 66.5 ... ## $ child : num 61.7 61.7 61.7 61.7 61.7 62.2 62.2 62.2 62.2 62.2 ... Cada filera del dataframe correspon a un adult: la variable child dóna la seva alçada i la variable parent la mitjana de les alçades dels seus pares, totes dues en polzades (recordau que 1 polzada són 2.54 cm). Calculem a mà i amb R la recta de regressió de la variable de reposta child en funció de la variable de control parent: x.b=mean(Galton$parent) y.b=mean(Galton$child) s2.x=var(Galton$parent) s2.y=var(Galton$child) s.xy=cov(Galton$parent,Galton$child) round(c(x.b,y.b,s2.x,s2.y,s.xy),3) ## [1] 68.308 68.088 3.195 6.340 2.065 \\[ \\begin{array}{ccccc} \\overline{x} &amp; \\overline{y} &amp; \\widetilde{s}_x^2 &amp; \\widetilde{s}_y^2 &amp; \\widetilde{s}_{xy}\\\\ \\hline 68.308 &amp; 68.088 &amp; 3.195 &amp; 6.34 &amp; 2.065 \\end{array} \\] Per tant els coeficients de la recta de regressió lineal per mínims quadrats de \\(Y\\) (l’alçada dels fills) en funció de \\(X\\) (la mitjana de les alçades dels pares) són b1.Galton=s.xy/s2.x b0.Galton=y.b-b1.Galton*x.b round(c(b0.Galton,b1.Galton),3) ## [1] 23.942 0.646 Obtenim la recta \\[ \\widehat{Y}= 23.942+0.646 X \\] Segons aquest model, a un augment d’1 polzada (2.54 cm) en l’alçada mitjana dels pares li correspon, de mitjana, un augment de 0.646 polzades (1.6 cm) de l’alçada del fill. Amb la funció lm obtenim la mateixa recta. Observau la sintaxi per especificar-hi el dataframe lm(child~parent, data=Galton)$coefficients ## (Intercept) parent ## 23.9415302 0.6462906 El fet que la pendent d’aquesta recta sigui més petita que 1 és el que dóna l’efecte de “regressió a la mediocritat” que observà Galton. En efecte, calculem per a quines alçades mitjanes dels pares esperam que els fills siguin més baixos que ells. Si resolem la desigualtat “alçada dels pares més gran que l’alçada esperada dels fills” \\[ X\\geq \\widehat{Y}= 23.942+0.646 X \\] obtenim \\[ X\\geq \\frac{23.942}{1-0.646}=67.69 \\] i això ens diu que si l’alçada mitjana dels pares és més gran que 67.69 polzades, uns 1.72 m, esperam que els fills siguin més baixos que els pares, mentre que, pel contrari, si l’alçada mitjana dels pares està per davall dels 1.72 m, esperam que els fills siguin més alts que els pares. Algunes de les propietats importants de la regressió per mínims quadrats són: Tal i com hem calculat el terme independent \\(b_0\\), la recta de regressió passa pel punt mitjà \\((\\overline{x},\\overline{y})\\) de la mostra: \\[ b_0+b_1 \\overline{x}=\\overline{y} \\] La mitjana dels valors estimats de la variable \\(Y\\) als nostres punts és igual a la mitjana dels valors observats: \\[ \\overline{\\widehat{y}}=\\frac{1}{n}\\sum_{i=1}^n\\widehat{y}_i =\\frac{1}{n}\\sum_{i=1}^n(b_0+b_1x_i)= b_0+b_1 \\overline{x}=\\overline{y} \\] Els errors \\((e_i)_{i=1,\\ldots,n}\\) de la mostra tenen mitjana 0: \\[ \\begin{array}{l} \\overline{e} &amp; \\displaystyle =\\frac{1}{n}\\sum_{i=1}^n e_i =\\frac{1}{n}\\sum_{i=1}^n (y_i-b_0-b_1x) =\\frac{1}{n}\\sum_{i=1}^n (y_i-\\widehat{y}_i)\\\\[2ex] &amp; \\displaystyle =\\frac{1}{n}\\sum_{i=1}^n{y}_i-\\frac{1}{n}\\sum_{i=1}^n\\widehat{y}_i= \\overline{y}-\\overline{\\widehat{y}} =0 \\end{array} \\] Els errors \\((e_i)_{i=1,\\ldots,n}\\) de la mostra tenen variància \\[ s_e^2=\\frac{1}{n}\\Big(\\sum_{i=1}^{n} e^2_i\\Big)-\\overline{e}^2=\\frac{\\sum_{i=1}^{n} e^2_i}{n}=\\frac{SS_E}{n} \\] perquè \\(\\overline{e}=0\\) (i recordau que hem dit a \\(\\sum_{i=1}^{n} e^2_i\\) la Suma de Quadrats dels Errors, \\(SS_E\\)). El teorema següent recull les propietats de la regressió lineal per mínims quadrats com a tècnica d’estimació dels coeficients \\(\\beta_0\\) i \\(\\beta_1\\): Teorema 11.2 Si les variables aleatòries error \\(E_{x_i}\\) tenen totes mitjana 0 i la mateixa variància \\(\\sigma^2_E\\) i són, dues a dues, incorrelades, aleshores: \\(b_0\\) i \\(b_1\\) són els estimadors lineals no esbiaixats més eficients (òptims) de \\(\\beta_0\\) i \\(\\beta_1\\) Un estimador no esbiaixat de \\(\\sigma_E^2\\) és \\[ S^2=\\frac{SS_E}{n-2} \\] Si a més les variables aleatòries error \\(E_{x_i}\\) són totes normals, aleshores: \\(b_0\\) i \\(b_1\\) són estimadors màxim versemblants de \\(\\beta_0\\) i \\(\\beta_1\\) (a més de no esbiaixats òptims). Exemple 11.5 Si suposam a l’Exemple 11.1 que els errors tenen la mateixa variància i són incorrelats, podem estimar aquesta variància de la manera següent: n=length(edat) alçada.cap=b0.edat+b1.edat*edat #Els valors estimats errors.edat=alçada-alçada.cap #Els errors SS.E=sum(errors.edat^2) #La suma dels quadrats dels errors S2.edat=SS.E/(n-2) #L&#39;estimació de la variància S2.edat ## [1] 8.314286 Tenim que \\(S^2=8.314\\), i estimam que \\(\\sigma_E^2\\) val això. Bé, fins ara hem explicat com s’estimen per mínims quadrats els coeficients \\(\\beta_0\\) i \\(\\beta_1\\) al model \\[ \\mu_{Y|x}=\\beta_0+\\beta_1 x \\] però ens pot interessar més: Com és de significativa l’estimació obtinguda? Quin és l’error típic d’aquests estimadors? Quins serien els intervals de confiança d’aquests coeficients per a un nivell de confiança donat? Com obtenim un interval de confiança per al valor estimat de \\(Y\\) sobre un subjecte a partir del seu valor de \\(X\\)? Amb la funció lm, R calcula molt més que els coeficients de la recta: summary(lm(alçada~edat)) ## ## Call: ## lm(formula = alçada ~ edat) ## ## Residuals: ## 1 2 3 4 5 6 7 ## -3.7857 0.2857 3.3571 3.4286 -0.5000 -1.4286 -1.3571 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 72.3214 2.1966 32.92 0.000000486 *** ## edat 6.4643 0.2725 23.73 0.000002477 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.883 on 5 degrees of freedom ## Multiple R-squared: 0.9912,\tAdjusted R-squared: 0.9894 ## F-statistic: 562.9 on 1 and 5 DF, p-value: 0.000002477 Veurem què és tot això que ens dóna R i per què serveix. D’entrada, pot ser útil saber que el vector Residuals (que s’obté amb el sufix $residuals) conté el vector dels errors \\((e_i)_i\\). Comprovem-ho amb les dades de l’Exemple 11.1. errors.edat ## [1] -3.7857143 0.2857143 3.3571429 3.4285714 -0.5000000 -1.4285714 -1.3571429 summary(lm(alçada~edat))$residuals ## 1 2 3 4 5 6 7 ## -3.7857143 0.2857143 3.3571429 3.4285714 -0.5000000 -1.4285714 -1.3571429 11.1.3 Coeficient de determinació Una primera pregunta que ens hem de fer és si la recta de regressió lineal que hem obtingut s’ajusta bé a la mostra obtinguda. Amb un enfocament proper al de l’ANOVA, Consideram que la recta de regressió \\(\\widehat{Y}=b_0+b_1X\\) ens dóna una bona aproximació de \\(Y\\) com a funció lineal de \\(X\\) sobre la nostra mostra quan la variabilitat dels valors estimats \\(\\widehat{y}_i\\) representa una fracció molt gran de la variabilitat dels valors observats \\(y_i\\). Això es quantifica amb el coeficient de determinació \\(R^2\\) que tot seguit definim. Siguin: \\(SS_{Total} =\\sum\\limits_{i=1}^n(y_i-\\overline{y})^2\\): és la Suma Total de Quadrats i representa la variabilitat dels valors observats \\(y_i\\). Fixau-vos que \\[ SS_{Total}=n\\cdot s_y^2 \\] \\(SS_R=\\sum\\limits_{i=1}^n(\\widehat{y}_i-\\overline{y})^2\\): és la Suma de Quadrats de la Regressió i representa la variabilitat dels valors estimats \\(\\widehat{y}_i\\). Fixau-vos que \\[ SS_R=n\\cdot s_{\\widehat{y}}^2 \\] Considerarem que la recta \\(\\widehat{y}=b_0+b_1x\\) és una bona aproximació de \\(Y\\) com a funció lineal de \\(X\\) sobre la nostra mostra quan \\(s^2_{\\widehat{y}}\\) sigui molt proper a \\(s^2_y\\). Per mesurar-ho, emprarem el coeficient de determinació \\(R^2\\), que és simplement el seu quocient: \\[ R^2=\\frac{SS_R}{SS_{Total}}=\\frac{s_{\\widehat{y}}^2}{s_y^2} \\] Recordau ara que hem definit la Suma de Quadrats dels Errors \\(SS_E=\\sum\\limits_{i=1}^n(y_i-\\widehat{y}_i)^2\\) i que \\[ SS_E=n\\cdot s_e^2 \\] on \\(s_e^2\\) és la variància dels errors. A la regressió lineal per mínims quadrats s’hi satisfà la identitat de les sumes de quadrats següent: Teorema 11.3 En una regressió lineal pel mètode de mínims quadrats, \\[ SS_{Total}=SS_R+SS_E \\] o equivalentment, \\[ s^2_y=s^2_{\\widehat{y}}+s^2_e. \\] Exemple 11.6 Comprovem aquesta igualtat amb les dades de l’Exemple 11.1: SS.Tot=sum((alçada-mean(alçada))^2) SS.R=sum((alçada.cap-mean(alçada))^2) SS.E=sum(errors.edat^2) c(SS.Tot,SS.R,SS.E) ## [1] 4721.71429 4680.14286 41.57143 SS.R+SS.E ## [1] 4721.714 Així, doncs, a la regressió per mínims quadrats la variabilitat dels valors observats de \\(Y\\) és igual a la suma de la variabilitat dels valors estimats de \\(Y\\) més la variabilitat dels errors. Llavors, el coeficient de determinació \\(R^2\\) és la fracció de la variabilitat de les \\(y_i\\) que queda explicada per la variabilitat de de les estimacions \\(\\widehat{y}_i\\). Aleshores, si la regressió lineal és per mínims quadrats, \\[ R^2=\\frac{SS_{Total}-SS_E}{SS_{Total}}=1-\\frac{SS_E}{SS_{Total}}=1-\\frac{s_e^2}{s_y^2} \\] En particular: En una regressió per mínims quadrats, \\(R^2\\leq 1\\), i \\(R^2= 1\\) exactament quan tots els \\(e_i\\) són 0, és a dir, quan \\(\\widehat{y}_i=y_i\\) per a tot \\(i=1,\\ldots,n\\). Com més gran (més proper a 1) sigui \\(R^2\\), més bona entendrem que és la regressió lineal. Per si de cas no hi heu caigut, observau que \\(R^2\\geq 0\\), perquè és un quocient de quadrats. Només val 0 quan \\(s^2_{\\widehat{y}}=0\\), és a dir, quan tots els valors estimats \\(\\widehat{y}_i\\) són iguals. R dóna el \\(R^2\\) en el summary(lm( )): és el valor Multiple R-squared a la penúltima línia de la seva sortida: summary(lm(alçada~edat)) ## ## Call: ## lm(formula = alçada ~ edat) ## ## Residuals: ## 1 2 3 4 5 6 7 ## -3.7857 0.2857 3.3571 3.4286 -0.5000 -1.4286 -1.3571 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 72.3214 2.1966 32.92 0.000000486 *** ## edat 6.4643 0.2725 23.73 0.000002477 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.883 on 5 degrees of freedom ## Multiple R-squared: 0.9912,\tAdjusted R-squared: 0.9894 ## F-statistic: 562.9 on 1 and 5 DF, p-value: 0.000002477 S’obté directament del summary(lm( )) amb el sufix $r.squared summary(lm(alçada~edat))$r.squared ## [1] 0.9911957 El resultat següent ja l’anunciàrem al Tema 9. Teorema 11.4 En una regressió per mínims quadrats, el coeficient de determinació és el quadrat de la correlació de Pearson de les mostres de les dues variables: \\[ R^2=r_{x,y}^2 \\] En efecte: \\[ \\begin{array}{rl} R^2 &amp; \\displaystyle =\\frac{SS_R}{SS_{Total}}=\\frac{\\sum\\limits_{i=1}^n(b_1x_i+b_0-\\overline{y})^2}{ns_y^2}\\\\[2ex] &amp; \\displaystyle =\\frac{\\sum\\limits_{i=1}^n(\\dfrac{s_{xy}}{s_x^2}x_i-\\dfrac{s_{xy}}{s_x^2}\\overline{x})^2}{ns_y^2} =\\frac{\\dfrac{s_{xy}^2}{s_x^4}\\sum\\limits_{i=1}^n(x_i-\\overline{x})^2}{ns_y^2}\\\\[2ex] &amp; \\displaystyle =\\dfrac{s_{xy}^2}{s_x^4}\\cdot \\frac{s_x^2}{s_y^2}=\\frac{s_{xy}^2}{s_x^2\\cdot s_y^2}=r_{xy}^2 \\end{array} \\] Exemple 11.7 Comprovem-ho a l’Exemple 11.1: summary(lm(alçada~edat))$r.squared ## [1] 0.9911957 cor(edat,alçada)^2 ## [1] 0.9911957 Exemple 11.8 Comprovem ara la identitat de les sumes de quadrats i la igualtat \\(R^2=r^2\\) a l’Exemple 11.3: tensió.cap=b0.sal+b1.sal*sal #Els valors estimats SS.Tot=sum((tensió-mean(tensió))^2) #La Suma Total de Quadrats SS.Tot ## [1] 331.3333 SS.R=sum((tensió.cap-mean(tensió))^2) #La Suma de Quadrats de la Regressió SS.R ## [1] 309.5874 SS.E=sum((tensió-tensió.cap)^2) #La suma de Quadrats dels Errors SS.E ## [1] 21.74589 Vegem que \\(SS_R+SS_E\\) és igual a \\(SS_{Total}\\): SS.R+SS.E ## [1] 331.3333 Calculem ara \\(R^2=SS_R/SS_{Total}\\) i comprovem que coincideix amb el valor que dóna R i amb el quadrat de la correlació de Pearson de les mostres de quantitats de sal i tensions: R2=SS.R/SS.Tot R2 ## [1] 0.9343685 summary(lm(tensió~sal))$r.squared ## [1] 0.9343685 cor(sal,tensió)^2 ## [1] 0.9343685 Fixau-vos que si coneixeu \\(\\widetilde{s}_y^2\\) (var(y)) i \\(r_{x,y}\\) (cor(x,y)), llavors \\[ r_{x,y}^2=R^2=1-\\frac{s_e^2}{s_y^2}\\Longrightarrow s_e^2=s_y^2(1-r_{x,y}^2) \\] i per tant podeu calcular la \\(S^2\\) que estima la variància comuna dels errors \\(E_{x_i}\\) de la manera següent: \\[ S^2=\\frac{SS_E}{n-2}=\\frac{n s_e^2}{n-2}=\\frac{ns_y^2(1-r_{x,y}^2)}{n-2}=\\frac{(n-1)\\widetilde{s}_y^2(1-r_{x,y}^2)}{n-2} \\] Això us pot ser útil als exercicis. El valor de \\(R^2\\) no és suficient per valorar la bondat d’un model de regressió lineal. És sempre convenient també dibuixar els punts i la recta de regressió i donar una ullada. Un exemple clàssic de les mancances del \\(R^2\\) són els quatre conjunts de dades \\((x_{1,i},y_{1,i})_{i=1,\\ldots,11}\\), \\((x_{2,i},y_{2,i})_{i=1,\\ldots,11}\\), \\((x_{3,i},y_{3,i})_{i=1,\\ldots,11}\\), \\((x_{4,i},y_{4,i})_{i=1,\\ldots,11}\\) que formen el dataframe anscombe de R i que ja empràrem al Tema 9: str(anscombe) ## &#39;data.frame&#39;:\t11 obs. of 8 variables: ## $ x1: num 10 8 13 9 11 14 6 4 12 7 ... ## $ x2: num 10 8 13 9 11 14 6 4 12 7 ... ## $ x3: num 10 8 13 9 11 14 6 4 12 7 ... ## $ x4: num 8 8 8 8 8 8 8 19 8 8 ... ## $ y1: num 8.04 6.95 7.58 8.81 8.33 ... ## $ y2: num 9.14 8.14 8.74 8.77 9.26 8.1 6.13 3.1 9.13 7.26 ... ## $ y3: num 7.46 6.77 12.74 7.11 7.81 ... ## $ y4: num 6.58 5.76 7.71 8.84 8.47 7.04 5.25 12.5 5.56 7.91 ... Les rectes de regressió per mínims quadrats dels quatre conjunts de dades són gairebé iguals i donen valors de \\(R^2\\) molt semblants: lm(y1~x1,data=anscombe)$coefficients ## (Intercept) x1 ## 3.0000909 0.5000909 summary(lm(y1~x1,data=anscombe))$r.squared ## [1] 0.6665425 lm(y2~x2,data=anscombe)$coefficients ## (Intercept) x2 ## 3.000909 0.500000 summary(lm(y2~x2,data=anscombe))$r.squared ## [1] 0.666242 lm(y3~x3,data=anscombe)$coefficients ## (Intercept) x3 ## 3.0024545 0.4997273 summary(lm(y3~x3,data=anscombe))$r.squared ## [1] 0.666324 lm(y4~x4,data=anscombe)$coefficients ## (Intercept) x4 ## 3.0017273 0.4999091 summary(lm(y4~x4,data=anscombe))$r.squared ## [1] 0.6667073 Però si els dibuixam veureu que els seus ajusts a la recta de regressió són molt diferents: par(mfrow=c(2,2)) plot(anscombe$x1,anscombe$y1,main=&quot;Conjunt de dades 1&quot;,pch=20) abline(lm(y1~x1,data=anscombe),col=&quot;red&quot;,lwd=1.5) plot(anscombe$x2,anscombe$y2,data=anscombe,main=&quot;Conjunt de dades 2&quot;,pch=20) abline(lm(y2~x2,data=anscombe),col=&quot;red&quot;,lwd=1.5) plot(anscombe$x3,anscombe$y3,main=&quot;Conjunt de dades 3&quot;,pch=20) abline(lm(y3~x3,data=anscombe),col=&quot;red&quot;,lwd=1.5) plot(anscombe$x4,anscombe$y4,main=&quot;Conjunt de dades 4&quot;,pch=20) abline(lm(y4~x4,data=anscombe),col=&quot;red&quot;,lwd=1.5) Al Tema 9 ja us parlàrem del paquet datasaurus, les funcions del qual us permeten crear conjunts de punts de “formes” diferents i els mateixos estadístics. Vegem com el dinosaure i l’estrella tenen rectes de regressió i valors de \\(R^2\\) molt semblants. datasaure=read.table(&quot;https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/Datasaurus.txt&quot;,header=TRUE,sep=&quot;\\t&quot;) dino=datasaure[datasaure$dataset==&quot;dino&quot;,2:3] star=datasaure[datasaure$dataset==&quot;star&quot;,2:3] par(mfrow=c(1,2)) plot(dino,pch=20) abline(lm(dino$y~dino$x),col=&quot;red&quot;,lwd=1.5) plot(star,pch=20) abline(lm(star$y~star$x),col=&quot;red&quot;,lwd=1.5) par(mfrow=c(1,1)) lm(dino$y~dino$x)$coefficients ## (Intercept) dino$x ## 53.3353196 -0.1011268 summary(lm(dino$y~dino$x))$r.squared ## [1] 0.0039641 lm(star$y~star$x)$coefficients ## (Intercept) star$x ## 53.326679 -0.101113 summary(lm(star$y~star$x))$r.squared ## [1] 0.0039641 11.1.4 Intervals de confiança dels coeficients Suposarem d’ara endavant que cada \\(E_{x_i}\\) segueix una distribució normal amb mitjana \\(\\mu_{E_{x_i}}=0\\) i totes amb la mateixa variància \\(\\sigma_E^2\\), i que \\(\\sigma_{E_{x_i},E_{x_j}}=0\\) per a cada parella \\(i,j\\). Recordau que sota aquestes condicions, els estimadors per mínims quadrats \\(b_0\\) i \\(b_1\\) de \\(\\beta_0\\) i \\(\\beta_1\\) són màxim versemblants i no esbiaixats òptims. Si tenim molt pocs valors \\(y\\) per a cada \\(x\\) a la mostra, això no es pot contrastar amb un mínim raonable de potència, però si és veritat, implica que els \\((e_i)_{i=1,\\ldots,n}\\) s’ajusten a una variable \\(N(0,\\sigma_E^2)\\), amb \\(\\sigma_E^2\\) estimada per \\(S^2\\), i això sí que ho podem contrastar. Si ho podem rebutjar, hem de rebutjar que els \\(E_{x_i}\\) satisfan les condicions requerides. Exemple 11.9 A l’Exemple 11.2: SS.E.edat=sum(errors.edat^2) S2.edat=SS.E.edat/(length(edat)-1) #L&#39;estimació de la variància comuna dels errors ks.test(errors.edat,&quot;pnorm&quot;,0,sqrt(S2.edat)) ## ## One-sample Kolmogorov-Smirnov test ## ## data: errors.edat ## D = 0.18463, p-value = 0.9373 ## alternative hypothesis: two-sided Podem acceptar que els errors s’ajusten a una variable normal de mitjana 0. Exemple 11.10 A l’Exemple 11.3: errors.sal=summary(lm(tensió~sal))$residuals SS.E.sal=sum(errors.sal^2) S2.sal=SS.E.sal/(length(sal)-2) ks.test(errors.sal,&quot;pnorm&quot;,0,sqrt(S2.sal)) ## ## One-sample Kolmogorov-Smirnov test ## ## data: errors.sal ## D = 0.25544, p-value = 0.7472 ## alternative hypothesis: two-sided També podem acceptar que els errors s’ajusten a una variable normal de mitjana 0. Per cert, R calcula la \\(S\\), l’arrel quadrada d’aquesta \\(S^2\\), en fer la lm. És el Residual standard error de la tercera línia començant per avall a la sortida del summary(lm( )) i s’obté amb el sufix $sigma: summary(lm(tensió~sal)) ## ## Call: ## lm(formula = tensió ~ sal) ## ## Residuals: ## 1 2 3 4 5 6 ## 2.226 -2.309 1.455 -1.712 -1.613 1.952 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 86.3708 3.0621 28.206 0.0000094 *** ## sal 6.3354 0.8395 7.546 0.00165 ** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.332 on 4 degrees of freedom ## Multiple R-squared: 0.9344,\tAdjusted R-squared: 0.918 ## F-statistic: 56.95 on 1 and 4 DF, p-value: 0.001652 summary(lm(tensió~sal))$sigma ## [1] 2.331625 sqrt(S2.sal) ## [1] 2.331625 Resulta que si se satisfan les condicions demanades sobre les variables \\(E_{x_i}\\), aleshores coneixem els errors típics dels estimadors \\(b_1\\) i \\(b_0\\) i uns estadístics associats a aquests estimadors segueixen lleis t de Student que permeten calcular intervals de confiança per a \\(\\beta_0\\) i \\(\\beta_1\\). En concret: Pel que fa a \\(b_1\\), El seu error típic de \\(b_1\\) és \\[ \\frac{\\sigma_E}{s_x\\sqrt{n}}. \\] L’estimació d’aquest error típic sobre una mostra concreta és \\[ \\frac{S}{s_x\\sqrt{n}} \\] La fracció \\[ T_1=\\frac{b_1-\\beta_1}{\\frac{S}{s_x\\sqrt{n}}} \\] segueix una llei \\(t\\) de Student amb \\(n-2\\) graus de llibertat. Observau que l’error típic de \\(b_1\\): Decreix amb \\(n\\): com més gran és la mostra, menys incertesa esperam en l’estimació de \\(\\beta_1\\). Això ens ha passat en totes les estimacions del curs, no és cap sorpresa. En general, com més dades tenim, millor. Decreix amb \\(s_x\\): com més dispersa és la mostra, menys incertesa esperam en l’estimació de \\(\\beta_1\\). Això és una novetat, en altres casos (per exemple, en estimar una mitjana) la incertesa creixia amb la desviació típica de la mostra. Però aquí és raonable. Pensau en termes físics: si voleu unir dos punts amb una recta, com és més fàcil que aquesta recta sigui estable, si els dos punts estan molt junts o si estan separats? Separats, no? Creix amb \\(\\sigma_E\\): com més variabilitat tenguin els errors residuals, més incertesa tendrem. Fixau-vos que si \\(\\sigma_E=0\\), aleshores no hi ha gens d’incertesa: significa que els punts \\((x_i,y_i)\\) estan sobre una recta i aquesta recta és la de regressió. Pel que fa a \\(b_0\\), El seu error típic és \\[ \\frac{\\sigma_E\\sqrt{s_x^2+\\overline{x}^2}}{s_x\\sqrt{n}} \\] L’estimació d’aquest error típic sobre una mostra concreta és \\[ \\frac{S\\sqrt{s_x^2+\\overline{x}^2}}{s_x\\sqrt{n}} \\] La fracció \\[ T_0=\\frac{b_0-\\beta_0}{\\frac{S\\sqrt{s_x^2+\\overline{x}^2}}{s_x\\sqrt{n}}} \\] també segueix una llei \\(t\\) de Student amb \\(n-2\\) graus de llibertat. És raonable que l’error típic de \\(b_0\\) sigui més gran que el de \\(b_1\\), perquè per calcular \\(b_0\\) hem de calcular primer \\(b_1\\) i a més emprar-hi la mitjana \\(\\overline{x}\\), la qual cosa fa que en estimar \\(\\beta_0\\) per mitjà de \\(b_0\\) hi hagi més incertesa que en estimar \\(\\beta_1\\) per mitjà de \\(b_1\\). Com que els estadístics \\(T_1\\) i \\(T_0\\) tenen distribucions t de Student, operant amb ells com en el cas de l’interval de confiança per a la mitjana poblacional \\(\\mu\\) obtenim fórmules per als intervals de confiança amb nivell de confiança \\(q\\) per a \\(\\beta_1\\) i \\(\\beta_1\\) de la forma que ens agrada: \\[ \\text{Estimador}\\pm \\frac{1+q}{2}\\text{-quantil}\\times \\text{Estimació de l&#39;error típic} \\] En concret, sota les hipòtesis imposades al principi d’aquesta secció Un interval de confiança amb nivell de confiança \\(q\\) per a \\(\\beta_1\\) és \\[ b_1\\pm t_{n-2,(1+q)/2}\\cdot \\frac{S}{s_x\\sqrt{n}} \\] Un interval de confiança amb nivell de confiança \\(q\\) per a \\(\\beta_0\\) és \\[ b_0\\pm t_{n-2,(1+q)/2}\\cdot \\frac{S\\sqrt{s_x^2+\\overline{x}^2}}{s_x\\sqrt{n}} \\] Exemple 11.11 Tornem a l’Exemple 11.1. Hi havíem obtingut la recta de regressió \\[ \\widehat{Y}=72.321+6.464X \\] i a més \\(n=7\\) i havíem calculat que \\(\\overline{x}=7\\), \\(s_x^2=18.667\\) i \\(S^2=3.624\\). Aleshores: Un interval de confiança al 95% per \\(\\beta_1\\) és \\[ \\begin{array}{l} \\displaystyle b_1\\pm t_{n-2,(1+0.95)/2}\\cdot \\frac{S}{s_x\\sqrt{n}} =6.464\\pm t_{5,0.975}\\cdot \\frac{\\sqrt{8.314}}{4\\sqrt{7}}\\\\[2ex] \\qquad = 6.464\\pm 2.5706 \\cdot 0.2724=6.464\\pm 0.7 \\end{array} \\] Obtenim l’interval \\([5.764,7.164]\\). Un interval de confiança al 95% per a \\(\\beta_0\\) és \\[ \\begin{array}{l} \\displaystyle b_0\\pm t_{n-2,(1+0.95)/2}\\cdot\\frac{S\\sqrt{s_x^2+\\overline{x}^2}}{s_x\\sqrt{n}} =72.321\\pm t_{5,0.975}\\cdot \\frac{\\sqrt{8.314}\\cdot\\sqrt{16+7^2}}{4\\sqrt{7}}\\\\[2ex] \\qquad = 72.321\\pm 2.5706 \\cdot 2.1966=72.321\\pm 5.647 \\end{array} \\] Obtenim l’interval \\([66.674,77.968]\\). Amb R aquests intervals de confiança s’obtenen amb la funció confint aplicada al resultat de la lm. El nivell de confiança s’hi indica amb el paràmetre level i el seu valor per defecte és, com sempre, 0.95. confint(lm(alçada~edat),level=0.95) ## 2.5 % 97.5 % ## (Intercept) 66.674769 77.968088 ## edat 5.763904 7.164668 Calculau “a mà”, amb les fórmules que hem donat, els intervals de confiança per als coeficients de la recta de regressió de l’Exemple 11.3. Us han de donar: confint(lm(tensió~sal)) ## 2.5 % 97.5 % ## (Intercept) 77.869064 94.872509 ## sal 4.004434 8.666266 11.1.5 Intervals de confiança per a les estimacions de la variable dependent També podem calcular intervals de confiança per al valor estimat de la \\(Y\\) sobre els individus amb un valor de \\(X\\) donat. En aquest cas, tenim dos intervals: L’interval per al valor esperat \\(\\mu_{Y|x_0}\\) de \\(Y\\) sobre els individus en els que \\(X\\) val \\(x_0\\), és a dir, per al valor mitjà de la \\(Y\\) sobre tots els individus de la població en els que \\(X\\) valgui \\(x_0\\). L’interval per al valor \\(y_0\\) de \\(Y\\) sobre un individu concret en el que \\(X\\) valgui \\(x_0\\). Tot i que tant el valor esperat \\(\\mu_{Y|x_0}\\) com el valor \\(y_0\\) de \\(Y\\) sobre un individu concret en el que \\(X\\) valgui \\(x_0\\) tenen el mateix valor estimat, \\[ \\widehat{y}_0=b_0+b_1x_0, \\] l’interval de confiança del valor esperat serà més estret que el del valor sobre un individu concret. Això reflecteix el fet que, naturalment, hi ha molta més incertesa en saber que val la \\(Y\\) sobre un individu concret que en saber quin és el valor mitjà de \\(Y\\) sobre tots els individus que tenguin el mateix valor de \\(X\\) que aquest individu concret. Bé passem a les fórmules. Sota les condicions sobre els errors que hem suposat al començament de la secció anterior (variables error normals de mitjana 0 i mateixa desviació típica, i incorrelades dues a dues): L’error típic de \\(\\widehat{y}_0\\) com a estimador de \\(\\mu_{Y|x_0}\\) és \\[ \\sigma_E\\cdot \\sqrt{\\frac{1}{n}+\\frac{(x_0-\\overline{x})^2}{ns^2_x}} \\] i la fracció \\[ \\frac{\\widehat{y}_0-\\mu_{Y/x_0}}{S\\cdot \\sqrt{\\frac{1}{n}+\\frac{(x_0-\\overline{x})^2}{n s^2_x}}} \\] segueix una llei \\(t\\) de Student amb \\(n-2\\) graus de llibertat. L’error típic de \\(\\widehat{y}_0\\) com a estimador de \\(y_0\\) és \\[ \\sigma_E\\cdot \\sqrt{1+\\frac{1}{n}+\\frac{(x_0-\\overline{x})^2}{ns^2_x}} \\] i la fracció \\[ \\frac{\\widehat{y}_0-y_0}{S\\cdot \\sqrt{1+\\frac{1}{n}+\\frac{(x_0-\\overline{x})^2}{n s^2_x}}} \\] segueix una llei \\(t\\) de Student amb \\(n-2\\) graus de llibertat. Aquests errors típics creixen amb la distància entre \\(x_0\\) i la mitjana de la mostra \\(\\overline{x}\\). És raonable: com més enfora està \\(x_0\\) de \\(\\overline{x}\\), petites variacions en el valor de la pendent de la recta donen lloc a diferències molt més grans en el valor de \\(b_0+b_1x_0\\). I quan \\(x_0=\\overline{x}\\) no hi ha cap variabilitat en la dispersió de les estimacions: estimam que \\(y_0=\\overline{y}\\) i punt! Fixau-vos que l’error típic de l’estimació de \\(\\mu_{Y|x_0}\\) és més petit que el de l’estimació de \\(y_0\\). Per tant, sota aquestes hipòtesis, Un interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu_{Y|x_0}\\) és \\[ \\widehat{y}_0\\pm t_{n-2,(1+q)/2}\\cdot S\\cdot \\sqrt{\\frac{1}{n}+\\frac{(x_0-\\overline{x})^2}{n s^2_x}} \\] Un interval de confiança de nivell de confiança \\(q\\) per a \\(y_0\\) és \\[ \\widehat{y}_0\\pm t_{n-2,(1+q)/2}\\cdot S\\cdot \\sqrt{1+\\frac{1}{n}+\\frac{(x_0-\\overline{x})^2}{n s^2_x}} \\] Exemple 11.12 Tornem una altra vegada a l’Exemple 11.1. Hi havíem obtingut la recta de regressió \\[ \\widehat{Y}=72.321+6.464X \\] i a més \\(n=7\\) i havíem calculat que \\(\\overline{x}=7\\), \\(s_x^2=18.667\\) i \\(S^2=3.624\\). Suposem que volem estimar l’alçada \\(y_0\\) d’un nin de \\(x_0=10\\) anys. L’estimació amb la recta de regressió és \\[ \\widehat{y}_0=72.321+6.464\\cdot 10=136.964 \\] Ara volem saber els intervals de confiança del 95% per a aquesta estimació: Un interval de confiança al 95% per a \\(y_0\\) és \\[ \\begin{array}{l} \\displaystyle \\widehat{y}_0\\pm t_{n-2,(1+0.95)/2}\\cdot S\\sqrt{1+\\frac{1}{n}+\\frac{(x_0-\\overline{x})^2}{ns^2_x}} \\\\[2ex] \\displaystyle\\qquad=136.961\\pm t_{5,0.975}\\cdot \\sqrt{8.314}\\cdot\\sqrt{1+\\frac{1}{7}+\\frac{(10-7)^2}{7\\cdot 16 }}\\\\[2ex] \\qquad = 136.961\\pm 2.5706 \\cdot 3.189=136.961\\pm 8.198 \\end{array} \\] Obtenim l’interval \\([128.8,145.2]\\). Per tant, estam molt segurs que si prenem un nin de 10 anys, la seva alçada estarà entre els 128.8 cm i els 145.2 cm. Un interval de confiança al 95% per al valor esperat \\(\\mu_{Y|x_0}\\) de \\(y_0\\) és \\[ \\begin{array}{l} \\displaystyle \\widehat{y}_0\\pm t_{n-2,(1+0.95)/2}\\cdot S\\sqrt{\\frac{1}{n}+\\frac{(x_0-\\overline{x})^2}{ns^2_x}} \\\\[2ex] \\displaystyle\\qquad=136.961\\pm t_{5,0.975}\\cdot \\sqrt{8.314}\\cdot\\sqrt{\\frac{1}{7}+\\frac{(10-7)^2}{7\\cdot 16 }}\\\\[2ex] \\qquad = 136.961\\pm 2.5706 \\cdot 1.362=136.961\\pm 3.501 \\end{array} \\] Obtenim l’interval \\([133.5, 140.5]\\). Per tant, estam molt segurs que l’alçada mitjana dels nins de 10 anys està entre els 133.5 cm i els 140.5 cm. Si en canvi volguéssim emprar aquesta recta per estimar l’alçada d’un nin de 15 anys, els intervals que obtenim són (comprovau-ho): Per a \\(y_0\\), \\([159.6, 179]\\) Per a \\(\\mu_{Y|x_0}\\), \\([163, 175.6]\\) Com veieu, són molt més amples que els intervals de confiança per als 10 anys. Amb R, aquests intervals es calculen amb la funció predict.lm aplicada a el resultat de la lm un data frame amb el valor (o els valors, si ho volem fer de cop per a més d’un valor) de \\(X\\) el paràmetre interval igualat al tipus d’interval que volem: \"prediction\" si és per al valor en un individu, \"confidence\" si és per al valor esperat A més, s’hi pot entrar el nivell de significació amb el paràmetre level; si és 0.95, no cal. En el nostre exemple, primer hem de definir un data frame amb l’edat o les edats. Calcularem els intervals de confiança per als 10 i 15 anys. Per tant, definim un data frame format per dues observacions de la variable edat, que valguin 10 i 15: nin=data.frame(edat=c(10,15)) Aleshores, els intervals de confiança del 95% per a les alçades d’un nin de 10 anys i d’un nin de 15 anys són, respectivament, predict.lm(lm(alçada~edat),nin,interval=&quot;prediction&quot;) ## fit lwr upr ## 1 136.9643 128.7665 145.1620 ## 2 169.2857 159.5809 178.9905 i els intervals de confiança del 95% per a les alçades mitjanes dels nins de 10 i de 15 anys ón, respectivament, predict.lm(lm(alçada~edat),nin,interval=&quot;confidence&quot;) ## fit lwr upr ## 1 136.9643 133.4624 140.4662 ## 2 169.2857 163.0213 175.5501 11.1.6 Té sentit una regressió lineal? Si \\(\\beta_1=0\\), el model de regressió lineal no té sentit, perquè en aquest cas \\[ Y|x=\\beta_0+E_x \\] i les variacions en els valors de \\(Y\\) són totes degudes a l’error. El contrast \\[ \\left\\{\\begin{array}{l} H_0:\\beta_1=0\\\\ H_1:\\beta_1 \\neq 0 \\end{array} \\right. \\] el podem realitzar amb l’interval de confiança per a \\(\\beta_1\\): si 0 no hi pertany, rebutjam la hipòtesi nul·la amb el nivell de significació corresponent al nivell de confiança de l’interval. Per exemple, a l’Exemple 11.11 hem obtingut l’IC 95% per a \\(\\beta_1\\) \\([5.764,7.164]\\). Com que no conté el 0, concloem (amb un nivell de significació de 0.05) que \\(\\beta_1\\neq 0\\). Si mirau la sortida del summary(lm( )) summary(lm(alçada~edat)) ## ## Call: ## lm(formula = alçada ~ edat) ## ## Residuals: ## 1 2 3 4 5 6 7 ## -3.7857 0.2857 3.3571 3.4286 -0.5000 -1.4286 -1.3571 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 72.3214 2.1966 32.92 0.000000486 *** ## edat 6.4643 0.2725 23.73 0.000002477 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.883 on 5 degrees of freedom ## Multiple R-squared: 0.9912,\tAdjusted R-squared: 0.9894 ## F-statistic: 562.9 on 1 and 5 DF, p-value: 0.000002477 a la matriu Coefficients: Els Estimate són les estimacions \\(b_0\\) i \\(b_1\\) Els Std. Error són (les estimacions de) els seus errors típics Els t value són els valors dels estadístics \\(T_0\\) i \\(T_1\\), que són justament els estadístics de contrast dels contrastos bilaterals amb hipòtesi nul·la \\(H_0:\\) “coeficient \\(=0\\)” Els Pr(&gt;|t|) són els p-valors d’aquests contrastos (que no us engani la notació, aquests p-valors es defineixen com toca: \\[ 2P(t_{n-2}\\geq |T_0|),\\quad 2P(t_{n-2}\\geq |T_1|) \\] respectivament). Com veiem, en aquest cas podem rebutjar amb \\(\\alpha=0.05\\) que \\(\\beta_1=0\\) (i també que \\(\\beta_0=0\\)). 11.2 Regressió lineal múltiple Comencem amb un exemple. Exemple 11.13 Es postula que l’alçada esperada d’un nadó en cm (\\(Y\\)) té una relació lineal amb la seva edat en dies (\\(X_1\\)), la seva alçada en néixer en cm (\\(X_2\\)), el seu pes en kg en néixer (\\(X_3\\)) i l’augment en tant per cent del seu pes actual respecte del seu pes en néixer (\\(X_4\\)). És a dir, es creu que existeixen coeficients \\(\\beta_0,\\ldots,\\beta_4\\in \\mathbb{R}\\) tals que el model \\[ \\mu_{Y|x_1,x_2,x_3,x_4}=\\beta_0+\\beta_1x_1+\\beta_2x_2+\\beta_3x_3+\\beta_4x_4 \\] és correcte, on \\(\\mu_{Y|x_1,x_2,x_3,x_4}\\) és l’alçada esperada, en cm, d’un nadó de \\(x_1\\) dies que en néixer va fer \\(x_2\\) cm i \\(x_3\\) kg i des de llavors el seu pes ha augmentat un \\(x_4\\)%. En una mostra de \\(n=9\\) nins, els resultats varen ser els de la taula següent: Alçada (en cm) Edat (en dies) Alçada en néixer (en cm) Pes en néixer (en kg) % d’increment de pes 57.5 78 8.2 2.75 29.5 52.8 69 45.5 2.15 26.3 61.3 77 46.3 4.41 32.2 67.0 88 49.0 5.52 36.5 53.5 67 43.0 3.21 27.2 62.7 80 48.0 4.32 27.7 56.2 74 48.0 2.31 28.3 68.5 94 53.0 4.30 30.3 79.2 102 58.0 3.71 28.7 A partir d’aquesta mostra, volem estimar els coeficients \\(\\beta_0,\\ldots,\\beta_4\\in \\mathbb{R}\\) de la relació lineal predita. Aquest és un problema de regressió lineal múltiple. Ara tenim \\(k\\) variables independents, o de control \\(X_1,\\ldots, X_k\\) (com al cas simple, no necessàriament aleatòries) i una variable aleatòria dependent, o de resposta, \\(Y\\). Suposam que el model \\[ \\mu_{Y|x_1,\\ldots,x_k}= \\beta_0+\\beta_1 x_1+\\cdots+\\beta_k x_k \\] o, equivalentment, \\[ Y|x_1,\\ldots,x_k=\\beta_0+\\beta_1 x_{1}+\\cdots+\\beta_{k} x_k+E_{x_1,\\ldots,x_k} \\] és correcte, on: \\(Y|x_1,\\ldots,x_k\\) és la variable aleatòria que dóna el valor de \\(Y\\) sobre subjectes en els quals \\(X_i=x_i\\) per a cada \\(i=1,\\ldots,k\\) \\(\\mu_{Y|x_1,\\ldots,x_k}\\) és el valor esperat de \\(Y|x_1,\\ldots,x_k\\) Les \\(E_{x_1,\\ldots,x_k}\\) són les variables aleatòries error, o residu, i representen l’error aleatori de la variable \\(Y\\) sobre un individu en el qual \\((X_1,\\ldots,X_k)=(x_1,\\ldots,x_k)\\) \\(\\beta_0,\\beta_1,\\ldots,\\beta_{k}\\in \\mathbb{R}\\): \\(\\beta_0\\) és el valor esperat de \\(Y\\) quan \\(X_1=\\cdots=X_k=0\\) Cada \\(\\beta_i\\) és la variació del valor esperat de \\(Y\\) quan \\(X_i\\) augmenta una unitat i les altres variables \\(X_j\\) no varien Els paràmetres \\(\\beta_0,\\beta_1,\\ldots,\\beta_{k}\\) són desconeguts, i els volem estimar a partir d’una mostra \\[ (x_{1i},x_{2i},\\ldots,x_{ki},y_i)_{i=1,\\ldots,n} \\] d’observacions del vector aleatori \\((X_1,\\ldots,X_k,Y)\\) sobre \\(n\\) individus. Requerirem que \\(n&gt;k\\) (el nombre d’observacions ha de ser més gran que el nombre de variables) a fi que el sistema d’equacions lineals amb incògnites els coeficients \\(\\beta_0,\\beta_1,\\ldots,\\beta_{k}\\) \\[ \\left\\{ \\begin{array}{l} y_1=\\beta_0+\\beta_1x_{11}+\\cdots +\\beta_kx_{k1}\\\\ \\quad\\vdots\\\\ y_n=\\beta_0+\\beta_1x_{1n}+\\cdots +\\beta_kx_{kn} \\end{array} \\right. \\] no sigui indeterminat. Direm \\(b_0,b_1,\\ldots,b_k\\) a les estimacions dels paràmetres \\(\\beta_0,\\beta_1,\\ldots,\\beta_k\\) a partir d’una mostra, i per escurçar escriurem \\(\\underline{x}_i\\) per indicar \\((x_{1i},x_{2i},\\ldots,x_{ki})\\). Per a cada \\(i=1,\\ldots,n\\), diguem \\[ \\begin{array}{l} \\widehat{y}_i= b_0+b_1 x_{1i}+\\cdots+b_{k} x_{ki}\\\\ e_i=y_i-\\widehat{y}_i=y_i-(b_0+b_1 x_{1i}+\\cdots+b_{k} x_{ki}) \\end{array} \\] Amb aquestes notacions: \\(\\widehat{y}_i\\) és el valor predit de \\(Y\\) sobre l’individu \\(i\\)-èsim de la mostra a partir del seu vector de valors \\(\\underline{x}_{i}\\) i de les estimacions \\(b_0,b_1,\\ldots,b_k\\) dels paràmetres \\(e_i\\) és l’error que es comet amb aquesta estimació sobre aquest individu Direm la Suma de Quadrats dels Errors a: \\[ \\begin{array}{rl} SS_E= &amp;\\displaystyle\\sum\\limits_{i=1}^n e^2_i=\\sum\\limits_{i=1}^n (y_i-\\widehat{y}_i)^2 \\\\ = &amp;\\displaystyle\\sum\\limits_{i=1}^n (y_i-b_0-b_1 x_{1i}-\\cdots -b_{k} x_{ki})^2. \\end{array} \\] 11.2.1 Mínims quadrats Els estimadors de \\(\\beta_0,\\beta_1,\\ldots, \\beta_k\\) pel mètode de mínims quadrats són els valors \\(b_0,b_1,\\ldots, b_k\\) que minimitzen \\(SS_E\\) sobre la nostra mostra. Per calcular-los, calculam les derivades parcials de \\(SS_E\\) respecte de cada \\(b_i\\), les igualam a 0, resolem el sistema resultant, comprovam que la solució \\((b_0,\\ldots,b_k)\\) trobada dóna un mínim… Tot plegat, al final s’obté el resultat següent: Teorema 11.5 Siguin \\[ \\mathbf{y}= \\left( \\begin{array}{l} y_1\\\\ y_2\\\\ \\vdots\\\\ y_n \\end{array} \\right),\\ \\mathbf{X}=\\left( \\begin{array}{lllll} 1&amp;x_{11}&amp;x_{21}&amp;\\ldots&amp;x_{k1}\\\\ 1&amp;x_{12}&amp;x_{22}&amp;\\ldots&amp;x_{k2}\\\\ \\vdots&amp;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\ 1&amp;x_{1n}&amp;x_{2n}&amp;\\ldots&amp;x_{kn} \\end{array} \\right) \\] Aleshores, els estimadors per mínims quadrats \\(\\mathbf{b}=(b_0,b_1,\\ldots,b_k)^t\\) de \\(\\beta_0,\\beta_1,\\ldots,\\beta_k\\) a partir de la mostra \\((\\underline{x}_{i},y_i)_{i=1,2,\\ldots,n}\\) són donats per l’equació següent: \\[ \\mathbf{b}=\\left(\\mathbf{X}^t\\cdot \\mathbf{X}\\right)^{-1}\\cdot \\left(\\mathbf{X}^t \\cdot \\mathbf{y}\\right). \\] Amb una mica de paciència podeu comprovar que si \\(k=1\\), aquesta fórmula dóna la de \\((b_0,b_1)\\) a la regressió lineal simple. Com al cas simple, la funció resultant l’escriurem \\[ \\widehat{Y}=b_0+b_1X_1+\\cdots b_kX_k \\] i en direm la funció de regressió lineal per mínims quadrats de \\(Y\\) en funció de \\(X_1,\\ldots,X_k\\). Exemple 11.14 Tornem a l’Exemple 11.13. Recordau les dades: Alçada (en cm) Edat (en dies) Alçada en néixer (en cm) Pes en néixer (en kg) % d’increment de pes 57.5 78 8.2 2.75 29.5 52.8 69 45.5 2.15 26.3 61.3 77 46.3 4.41 32.2 67.0 88 49.0 5.52 36.5 53.5 67 43.0 3.21 27.2 62.7 80 48.0 4.32 27.7 56.2 74 48.0 2.31 28.3 68.5 94 53.0 4.30 30.3 79.2 102 58.0 3.71 28.7 Anem a calcular la funció lineal de regressió per mínims quadrats de l’alçada en funció de les altres variable. Pel teorema anterior, si diem \\[ \\mathbf{X}=\\left( \\begin{array}{ccccc} 1&amp;78&amp;48.2&amp;2.75&amp;29.5\\\\ 1&amp;69&amp;45.5&amp;2.15&amp;26.3\\\\ 1&amp;77&amp;46.3&amp;4.41&amp;32.2\\\\ 1&amp;88&amp;49&amp;5.52&amp;36.5\\\\ 1&amp;67&amp;43&amp;3.21&amp;27.2\\\\ 1&amp;80&amp;48&amp;4.32&amp;27.7\\\\ 1&amp;74&amp;48&amp;2.31&amp;28.3\\\\ 1&amp;94&amp;53&amp;4.3&amp;30.3\\\\ 1&amp;102&amp;58&amp;3.71&amp;28.7 \\end{array} \\right),\\ \\mathbf{y}=\\left( \\begin{array}{c} 57.5\\\\ 52.8\\\\ 61.3\\\\ 67\\\\ 53.5\\\\ 62.7\\\\ 56.2\\\\ 68.5\\\\ 79.2 \\end{array} \\right) \\] aleshores \\((b_0,b_1,b_2,b_3,b_4)\\) s’obté mitjançant \\[ \\left(\\begin{array}{c} b_0 \\\\ \\vdots \\\\ b_4\\end{array}\\right)=\\left(\\mathbf{X}^t\\cdot \\mathbf{X} \\right)^{-1}\\cdot \\left(\\mathbf{X}^t \\cdot \\mathbf{y}\\right) \\] Per calcular aquest vector, primer entram les dades i definim aquestes matrius y=c(57.5,52.8,61.3,67,53.5,62.7,56.2,68.5,79.2) x1=c(78,69,77,88,67,80,74,94.0,102) x2=c(8.2,45.5,46.3,49,43,48,48,53,58) x3=c(2.75,2.15,4.41,5.52,3.21,4.32,2.31,4.3,3.71) x4=c(29.5,26.3,32.2,36.5,27.2,27.7,28.3,30.3,28.7) X=cbind(1,x1,x2,x3,x4) X ## x1 x2 x3 x4 ## [1,] 1 78 8.2 2.75 29.5 ## [2,] 1 69 45.5 2.15 26.3 ## [3,] 1 77 46.3 4.41 32.2 ## [4,] 1 88 49.0 5.52 36.5 ## [5,] 1 67 43.0 3.21 27.2 ## [6,] 1 80 48.0 4.32 27.7 ## [7,] 1 74 48.0 2.31 28.3 ## [8,] 1 94 53.0 4.30 30.3 ## [9,] 1 102 58.0 3.71 28.7 Ara ja podem estimar els coeficients de la funció de regressió lineal: B=solve(t(X)%*%X)%*%(t(X)%*%y) round(B,4) ## [,1] ## 9.9464 ## x1 0.6626 ## x2 0.0483 ## x3 1.0618 ## x4 -0.2543 Obtenim \\[ \\begin{array}{ccccc} b_0 &amp; b_1 &amp; b_2 &amp; b_3&amp; b_4\\\\ \\hline 9.9464 &amp; 0.6626 &amp; 0.0483 &amp; 1.0618 &amp; -0.2543 \\end{array} \\] i per tant la funció de regressió lineal per mínims quadrats \\[ \\widehat{Y}=9.9464+0.6626X_1+0.0483X_2+1.0618X_3-0.2543X_4 \\] Fixau-vos que les igualtats \\[ \\widehat{y}_i=b_0+b_1x_{1i}+b_2x_{2i}+\\cdots +b_nx_{ni} \\] es tradueixen en la igualtat matricial \\[ \\left( \\begin{array}{l} \\widehat{y}_1\\\\ \\widehat{y}_2\\\\ \\vdots\\\\ \\widehat{y}_n \\end{array} \\right)=\\left( \\begin{array}{lllll} 1&amp;x_{11}&amp;x_{21}&amp;\\ldots&amp;x_{k1}\\\\ 1&amp;x_{12}&amp;x_{22}&amp;\\ldots&amp;x_{k2}\\\\ \\vdots&amp;\\vdots&amp;\\vdots&amp;\\ddots&amp;\\vdots\\\\ 1&amp;x_{1n}&amp;x_{2n}&amp;\\ldots&amp;x_{kn} \\end{array} \\right)\\cdot \\left( \\begin{array}{l} b_0 \\\\ b_1\\\\ b_2\\\\ \\vdots\\\\ b_k \\end{array} \\right) \\] En el nostre exemple, els valors estimats de \\(Y\\) sobre els nins de la nostra mostra serien Y.cap=X%*%B t(round(Y.cap,1)) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] ## [1,] 57.4 53.5 59.7 67.2 52.9 62.8 56.6 71.7 77 i per tant els errors \\(e_i=y_i-\\widehat{y}_i\\) són e.i=y-Y.cap t(e.i) ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] ## [1,] 0.05698925 -0.6579705 1.603446 -0.2006111 0.5914 -0.1154555 -0.3529814 ## [,8] [,9] ## [1,] -3.150977 2.22616 Amb R, la regressió lineal múltiple per mínims quadrats també es fa amb la funció lm, aplicada a la fórmula que agrupa la variable resposta en funció de la suma de les variables de control. Al nostre exemple 11.13 seria lm(y~x1+x2+x3+x4) ## ## Call: ## lm(formula = y ~ x1 + x2 + x3 + x4) ## ## Coefficients: ## (Intercept) x1 x2 x3 x4 ## 9.9464 0.6626 0.0483 1.0618 -0.2543 Obtenim la mateixa funció lineal de regressió que abans: \\[ \\widehat{Y}=9.9464+0.6626X_1+0.0483X_2+1.0618X_3-0.2543X_4 \\] A més, com al cas simple, aquesta funció també calcula els errors \\(e_i\\): summary(lm(y~x1+x2+x3+x4))$residuals ## 1 2 3 4 5 6 ## 0.05698925 -0.65797046 1.60344630 -0.20061111 0.59140004 -0.11545548 ## 7 8 9 ## -0.35298144 -3.15097741 2.22616031 La regressió lineal múltiple per mínims quadrats satisfà les mateixes propietats que la simple: La recta de regressió passa pel vector mitjà \\((\\overline{x}_1,\\overline{x}_2,\\ldots,\\overline{x}_k,\\overline{y})\\): \\[ \\overline{y}=b_0+b_1 \\overline{x}_1+\\cdots+b_1 \\overline{x}_k \\] La mitjana dels valors estimats és igual a la mitjana dels observats: \\[ \\overline{\\widehat{y}}=\\overline{y} \\] Els errors \\((e_i)_{i=1,\\ldots,n}\\) tenen mitjana 0 i variància \\[ s_e^2=\\frac{SS_E}{n} \\] Si les variables aleatòries error \\(E_{\\underline{x}_i}\\) tenen totes mitjana 0 i la mateixa variància \\(\\sigma^2_E\\) i són, dues a dues, incorrelades, aleshores els \\(b_i\\) són els estimadors lineals no esbiaixats òptims dels \\(\\beta_i\\) i \\[ S^2=\\frac{SS_E}{n-k-1} \\] és un estimador no esbiaixat de \\(\\sigma_E^2\\) Si a més les variables aleatòries error \\(E_{\\underline{x}_i}\\) són totes normals, aleshores els \\(b_i\\) són els estimadors màxim versemblants dels \\(\\beta_i\\) Se satisfà la mateixa identitat de les sumes de quadrats \\[ SS_{Total}=SS_R+SS_E \\] o, equivalentment, \\[ s^2_y=s^2_{\\widehat{y}}+s^2_e \\] on: \\(SS_{Total}=\\sum_{i=1}^n (y_i-\\overline{y})^2\\) és la Suma de Quadrats Total, mesura la variabilitat dels valors observats \\(y_i\\) de la \\(Y\\) i satisfà que \\(SS_{Total}=n\\cdot s_y^2\\), on \\(s_y^2\\) és la variància de les \\(y_i\\). \\(SS_R=\\sum_{i=1}^n(\\widehat{y}_i-\\overline{y})^2\\) és la Suma de Quadrats de la Regressió, mesura la variabilitat de les estimacions \\(\\widehat{y}_i\\) de la \\(Y\\) sobre la nostra mostra i satisfà que \\(SS_R=n\\cdot s_{\\widehat{y}}^2\\), on \\(s_{\\widehat{y}}^2\\) és la variància de les \\(\\widehat{y}_i\\). \\(SS_E=\\sum_{i=1}^n (y_i-\\widehat{y}_i)^2\\) és la de Suma de Quadrats dels Errors que ja hem definit i satisfà que \\(SS_E=n\\cdot s_{e}^2\\), on \\(s_{e}^2\\) és la variància dels errors \\(e_i\\). Com al cas simple, quan R calcula una funció de regressió lineal per mínims quadrats també calcula un munt de coses més: summary(lm(y~x1+x2+x3+x4)) ## ## Call: ## lm(formula = y ~ x1 + x2 + x3 + x4) ## ## Residuals: ## 1 2 3 4 5 6 7 8 ## 0.05699 -0.65797 1.60345 -0.20061 0.59140 -0.11546 -0.35298 -3.15098 ## 9 ## 2.22616 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.94645 11.06339 0.899 0.41946 ## x1 0.66261 0.07996 8.287 0.00116 ** ## x2 0.04830 0.06346 0.761 0.48899 ## x3 1.06180 1.30587 0.813 0.46179 ## x4 -0.25434 0.42424 -0.600 0.58113 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.146 on 4 degrees of freedom ## Multiple R-squared: 0.968,\tAdjusted R-squared: 0.9359 ## F-statistic: 30.21 on 4 and 4 DF, p-value: 0.003015 Anem a estudiar què és i per què serveix tota aquesta informació. 11.2.2 Coeficient de determinació múltiple Com al cas simple, consideram que la funció lineal de regressió \\[ \\widehat{Y}=b_0+b_1X_1+\\cdots+b_kX_k \\] ens dóna una bona aproximació de \\(Y\\) com a funció lineal de \\(X_1,\\ldots,X_k\\) sobre la nostra mostra quan la variabilitat dels valors estimats \\(\\widehat{y}_i\\) representa una fracció molt gran de la variabilitat dels valors observats \\(y_i\\). Això es quantifica amb el coeficient de determinació (múltiple) \\(R^2\\), que es defineix exactament igual que al cas simple i es calcula igual: \\[ R^2=\\frac{SS_R}{SS_{Total}}=\\frac{s^2_{\\widehat{y}}}{s^2_y} \\] Exemple 11.15 Al nostre Exemple 11.13, el coeficient de determinació és summary(lm(y~x1+x2+x3+x4))$r.squared ## [1] 0.9679545 Suposam que encara recordau que, en el cas simple, el coeficient de determinació era el quadrat del coeficient de correlació de Pearson. En el cas múltiple, el que es fa és definir el coeficient de correlació múltiple d’un vector \\(y\\) respecte d’uns vectors \\(x_1,\\ldots, x_k\\) (tots ells mesures de diferents variables aleatòries sobre els mateixos individus) com \\[ R= \\sqrt{R^2} \\] i així també se té que el coeficient de determinació múltiple és el quadrat del coeficient de correlació múltiple. 11.2.3 Coeficient de determinació ajustat \\(R^2\\) tendeix a créixer si afegim variables independents al model, fins i tot quan les variables que afegim són irrellevants. Vegem-ne un exemple. Exemple 11.16 Imaginau que a la taula de dades de l’Exemple 11.13 li afegim una nova variable \\(X_5\\) que mesura la distància (en km) a vol d’ocell de la llibreria on la mare sol comprar els llibres a la consulta del pediatra que ha mesurat l’alçada \\(Y\\). Ens inventarem els valors d’aquesta nova variable, generant-los amb distribució normal \\(N(2000,1000)\\) set.seed(200) x5=round(rnorm(9,2000,1000)) x5 ## [1] 2085 2226 2433 2558 2060 1885 979 1703 2168 Per tant, les dades ara són ## [1] 2085 2226 2433 2558 2060 1885 979 1703 2168 Alçada (en cm) Edat (en dies) Alçada en néixer (en cm) Pes en néixer (en kg) % d’increment de pes Distància llibreria-pediatra (en m) 57.5 78 8.2 2.75 29.5 2085 52.8 69 45.5 2.15 26.3 2226 61.3 77 46.3 4.41 32.2 2433 67.0 88 49.0 5.52 36.5 2558 53.5 67 43.0 3.21 27.2 2060 62.7 80 48.0 4.32 27.7 1885 56.2 74 48.0 2.31 28.3 979 68.5 94 53.0 4.30 30.3 1703 79.2 102 58.0 3.71 28.7 2168 Ara calculem el \\(R^2\\) de la regressió de \\(Y\\) en funció de \\(X_1,\\ldots,X_5\\) i comparem-lo amb l’obtingut amb \\(X_1,\\ldots,X_4\\): summary(lm(y~x1+x2+x3+x4+x5))$r.squared ## [1] 0.974853 summary(lm(y~x1+x2+x3+x4))$r.squared ## [1] 0.9679545 Com veieu, la regressió tenint en compte la distància de ca’l llibreter a ca’l pediatra té coeficient de determinació més gran que sense tenir-lo en compte. Però imaginam que teniu clar que aquesta variable és irrellevant a l’hora d’explicar l’alçada d’un nin. Per tenir en compte aquest fet i compensar el nombre de variables emprat en la regressió, en lloc d’emprar el coeficient de determinació \\[ R^2=\\frac{SS_R}{SS_{Total}}=\\frac{SS_{Total}-SS_E}{SS_{Total}} \\] s’empra el coeficient de determinació ajustat \\[ R^2_{adj}=\\frac{MS_{Total}-MS_E}{MS_{Total}} \\] on \\[ MS_{Total}=\\frac{SS_{Total}}{n-1}\\text{ i } MS_E=\\frac{SS_E}{n-k-1}. \\] Fa una estona a \\(MS_E\\) li hem dit \\(S^2\\), i hem dit que estimava la variància comuna de les variables error \\(E_{\\underline{x}_i}\\) quan totes aquestes variables tenen la mateixa variància. Operant, queda \\[ R^2_{adj}=\\frac{(n-1)R^2-k}{n-k-1} \\] A la sortida del summary(lm( )) és el Adjusted R-squared de la penúltima línia: summary(lm(y~x1+x2+x3+x4)) ## ## Call: ## lm(formula = y ~ x1 + x2 + x3 + x4) ## ## Residuals: ## 1 2 3 4 5 6 7 8 ## 0.05699 -0.65797 1.60345 -0.20061 0.59140 -0.11546 -0.35298 -3.15098 ## 9 ## 2.22616 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.94645 11.06339 0.899 0.41946 ## x1 0.66261 0.07996 8.287 0.00116 ** ## x2 0.04830 0.06346 0.761 0.48899 ## x3 1.06180 1.30587 0.813 0.46179 ## x4 -0.25434 0.42424 -0.600 0.58113 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.146 on 4 degrees of freedom ## Multiple R-squared: 0.968,\tAdjusted R-squared: 0.9359 ## F-statistic: 30.21 on 4 and 4 DF, p-value: 0.003015 Es considera que una regressió lineal múltiple per mínims quadrats és “millor” que una altra quan té el coeficient de determinació ajustat més gran. Això només té interés per a regressions amb diferents nombres de variables independents i la mateixa mostra d’individus, perquè fixats \\(n\\) i \\(k\\), la funció \\[ R^2\\mapsto R^2_{adj}=\\frac{(n-1)R^2-k}{n-k-1} \\] és creixent, i per tant si fixam els valors de \\(n\\) i de \\(k\\), comparar \\(R^2\\) és equivalent a comparar \\(R^2_{adj}\\). Amb R es calcula amb el sufix $adj.r.squared. Calculem els del nostre exemple, amb i sense la variable “falsa”, a veure què passa: summary(lm(y~x1+x2+x3+x4))$adj.r.squared ## [1] 0.9359091 summary(lm(y~x1+x2+x3+x4+x5))$adj.r.squared ## [1] 0.9329412 Com veieu, sense tenir en compte la distància de la llibreria de capçalera de la mare a la consulta del pediatra obtenim un valor més gran de \\(R^2_{adj}\\) i per tant consideram que és una regressió millor que tenint-la en compte. Ja que hi som, comprovem l’equació \\[ R^2_{adj}=\\frac{(n-1)R^2-k}{n-k-1} \\] per al model amb 4 variables independents: n=9 k=4 R2=summary(lm(y~x1+x2+x3+x4))$r.squared ((n-1)*R2-k)/(n-k-1) ## [1] 0.9359091 11.2.4 Intervals de confiança per als coeficients Suposarem en el que queda de tema que les variables aleatòries error \\(E_i=E_{\\underline{x}_{i}}\\) són totes normals de mitjana 0 i la mateixa variància, \\(\\sigma_E^2\\), i dues a dues incorrelades. Recordem que, sota aquestes hipòtesis: Els estimadors \\(b_0,\\ldots, b_k\\) de \\(\\beta_0,\\ldots,\\beta_k\\) són màxim versemblants i a més no esbiaixats òptims. Un estimador no esbiaixat de \\(\\sigma_E^2\\) és \\[ S^2(=MS_E)=\\frac{SS_E}{n-k-1} \\] A l’Exemple 11.13, aquesta estimació de la variància comuna dels errors \\(\\sigma_E^2\\) és S2=sum(e.i^2)/(n-k-1) S2 ## [1] 4.604896 Com al cas simple, la sortida de summary(lm( )) dóna el valor de la \\(S\\) (és a dir, l’arrel quadrada de \\(S^2\\), que per tant estima la desviació típica comuna de les variables error) com a Residual standard error i s’obté amb el sufix $sigma: summary(lm(y~x1+x2+x3+x4)) ## ## Call: ## lm(formula = y ~ x1 + x2 + x3 + x4) ## ## Residuals: ## 1 2 3 4 5 6 7 8 ## 0.05699 -0.65797 1.60345 -0.20061 0.59140 -0.11546 -0.35298 -3.15098 ## 9 ## 2.22616 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.94645 11.06339 0.899 0.41946 ## x1 0.66261 0.07996 8.287 0.00116 ** ## x2 0.04830 0.06346 0.761 0.48899 ## x3 1.06180 1.30587 0.813 0.46179 ## x4 -0.25434 0.42424 -0.600 0.58113 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.146 on 4 degrees of freedom ## Multiple R-squared: 0.968,\tAdjusted R-squared: 0.9359 ## F-statistic: 30.21 on 4 and 4 DF, p-value: 0.003015 summary(lm(y~x1+x2+x3+x4))$sigma ## [1] 2.145902 (summary(lm(y~x1+x2+x3+x4))$sigma)^2 ## [1] 4.604896 Resulta que sota les condicions imposades al principi d’aquesta secció sobre les variables \\(E_i\\), podem calcular intervals de confiança per als coeficients \\(\\beta_i\\) de la funció de regressió lineal. Donam les fórmules per pura completesa, no us demanarem que les calculeu amb aquestes fórmules. L’error típic de cada estimador \\(b_i\\) és l’arrel quadrada de la \\(i\\)-èsima entrada de la diagonal de la matriu \\(\\sigma_E^2\\cdot (\\mathbf{X}^t \\mathbf{X})^{-1}\\), començant a comptar amb \\(i=0\\): \\[ \\sqrt{(\\sigma_E^2\\cdot (X^t X)^{-1})_{ii}} \\] L’estimam sobre una mostra substituint-hi \\(\\sigma_E^2\\) per \\(S^2\\). R ens dóna aquestes estimacions a la columna Std. Error de la matriu Coefficients a la sortida de summary(lm( )): summary(lm(y~x1+x2+x3+x4)) ## ## Call: ## lm(formula = y ~ x1 + x2 + x3 + x4) ## ## Residuals: ## 1 2 3 4 5 6 7 8 ## 0.05699 -0.65797 1.60345 -0.20061 0.59140 -0.11546 -0.35298 -3.15098 ## 9 ## 2.22616 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.94645 11.06339 0.899 0.41946 ## x1 0.66261 0.07996 8.287 0.00116 ** ## x2 0.04830 0.06346 0.761 0.48899 ## x3 1.06180 1.30587 0.813 0.46179 ## x4 -0.25434 0.42424 -0.600 0.58113 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.146 on 4 degrees of freedom ## Multiple R-squared: 0.968,\tAdjusted R-squared: 0.9359 ## F-statistic: 30.21 on 4 and 4 DF, p-value: 0.003015 summary(lm(y~x1+x2+x3+x4))$coefficients[,2] ## (Intercept) x1 x2 x3 x4 ## 11.06339306 0.07996131 0.06346116 1.30586646 0.42423970 Cada fracció \\[ T_i=\\frac{\\beta_i-b_i}{\\sqrt{(S^2\\cdot (X^t X)^{-1})_{ii}}} \\] segueix un llei t de Student amb \\(n-k-1\\) graus de llibertat Un interval de confiança de nivell de confiança \\(q\\) per a \\(\\beta_i\\) és \\[ b_i\\pm t_{n-k-1,(1+q)/2}\\cdot \\sqrt{(S^2\\cdot (X^t X)^{-1})_{ii}} \\] Amb R, aquests intervals de confiança s’obtenen com al cas simple, aplicant la mateixa funció confint al resultat de la lm: confint(lm(y~x1+x2+x3+x4)) ## 2.5 % 97.5 % ## (Intercept) -20.7704551 40.6633520 ## x1 0.4406012 0.8846176 ## x2 -0.1278951 0.2244978 ## x3 -2.5638682 4.6874649 ## x4 -1.4322167 0.9235397 Els podem calcular “a mà” a partir de les estimacions dels errors típics que dóna summary(lm( )) amb la fórmula genèrica “estimació més-menys quantil per error típic”. Per exemple, l’IC 95% per a \\(\\beta_1\\) seria n=9 k=4 b1=lm(y~x1+x2+x3+x4)$coefficients[2] Error.Tip.b1=summary(lm(y~x1+x2+x3+x4))$coefficients[2,2] IC=b1+qt(0.975,n-k-1)*Error.Tip.b1*c(-1,1) IC ## [1] 0.4406012 0.8846176 11.2.5 Intervals de confiança per a les estimacions de la variable resposta Si les variables error \\(E_i\\) satisfan les condicions imposades al principi de la secció anterior, també podem calcular intervals de confiança per al valor estimat de la \\(Y\\) sobre els individus amb valors de \\((X_1,\\ldots,X_k)\\) donats. Com al cas simple, tenim dos intervals: L’interval per al valor esperat \\(\\mu_{Y|x_{10},\\ldots,x_{k0}}\\) de \\(Y\\) sobre els individus en els que \\((X_1,\\ldots,X_k)\\) val \\((x_{10},\\ldots,x_{k0})\\), és a dir, per al valor mitjà de la \\(Y\\) sobre tots els individus de la població en els que \\((X_1,\\ldots,X_k)\\) valgui \\((x_{10},\\ldots,x_{k0})\\) L’interval per al valor \\(y_0\\) de \\(Y\\) sobre un individu concret en el que \\((X_1,\\ldots,X_k)\\) valgui \\((x_{10},\\ldots,x_{k0})\\). La discussió sobre les diferències entre una i altra estimació i per què el segon interval és més ample que el primer són les mateixes que al cas simple, no la repetirem aquí. I, contràriament, al cas simple, us estalviarem les fórmules. Simplement heu de saber que aquests intervals també es calculen amb R amb la funció predict.lm aplicada a: un data frame amb els valors de les variables independents sobre l’individu, o els individus, per al que volem estimar la \\(Y\\); el resultat de la lm; i el paràmetre interval igualat al tipus d’interval que volem: \"prediction\" si és per al valor en un individu, \"confidence\" si és per al valor esperat. Exemple 11.17 Suposem que volem estimar amb un 95% de confiança l’alçada d’un infant de \\(X_1=69\\) dies que en néixer va fer \\(X_2=45.5\\) cm i va pesar \\(X_3=2.55\\) kg i des de llavors el seu pes ha augmentat un \\(X_4=26.3\\)%. Primer definim un data frame que reculli les dades d’aquest infant: infant=data.frame(x1=69,x2=45.5,x3=2.55,x4=26.3) Aleshores: Un interval de confiança del 95% per al valor estimat de l’alçada d’aquest infant és predict.lm(lm(y~x1+x2+x3+x4), infant, interval=&quot;prediction&quot;) ## fit lwr upr ## 1 53.88269 46.99166 60.77372 Un interval de confiança del 95% per al valor estimat de l’alçada mitjana de tots els infants amb les mateixes característiques \\(X_1,\\ldots,X_4\\) que aquest és predict.lm(lm(y~x1+x2+x3+x4), infant, interval=&quot;confidence&quot;) ## fit lwr upr ## 1 53.88269 50.4202 57.34518 Obtenim que: Estimam que l’alçada d’aquest infant és 53.9 cm Estimam amb un 95% de confiança que l’alçada d’aquest infant està entre els 47 i els 60.8 cm Estimam amb un 95% de confiança que l’alçada mitjana dels infants amb les mateixes característiques que aquest està entre els 50.4 i els 57.3 cm 11.2.6 L’ANOVA de la regressió lineal múltiple Com en el cas simple, en una regressió lineal múltiple ens interessa realitzar el contrast \\[ \\left\\{\\begin{array}{l} H_0: \\beta_1=\\beta_2=\\cdots=\\beta_k=0 \\\\ H_1: \\text{hi ha qualque }\\beta_i\\not= 0 \\end{array} \\right. \\] perquè si \\(\\beta_1=\\beta_2=\\cdots=\\beta_k=0\\), el model esdevé \\[ Y|{x_1,\\ldots,x_k}=\\beta_0+E_{x_1,\\ldots,x_k} \\] i la \\(Y\\) no depèn de les \\(X_i\\), de manera que el model lineal no és adequat. Això es pot fer amb \\(k\\) contrastos \\[ \\left\\{\\begin{array}{l} H_0: \\beta_i=0 \\\\ H_1: \\beta_i\\neq 0 \\end{array} \\right. \\] emprant els estadístics \\(T_i\\) que hem definit fa una estona, que segueixen lleis t de Student amb \\(n-k-1\\) graus de llibertat. Els p-valors d’aquests contrastos són els de la columna Pr(&gt;|t|) a la matriu de Coefficients de la sortida de summary(lm( )). No cal ajustar-los, el nombre \\(n-k-1\\) de graus de llibertat ja té en compte que fem \\(k+1\\) contrastos. summary(lm(y~x1+x2+x3+x4)) ## ## Call: ## lm(formula = y ~ x1 + x2 + x3 + x4) ## ## Residuals: ## 1 2 3 4 5 6 7 8 ## 0.05699 -0.65797 1.60345 -0.20061 0.59140 -0.11546 -0.35298 -3.15098 ## 9 ## 2.22616 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.94645 11.06339 0.899 0.41946 ## x1 0.66261 0.07996 8.287 0.00116 ** ## x2 0.04830 0.06346 0.761 0.48899 ## x3 1.06180 1.30587 0.813 0.46179 ## x4 -0.25434 0.42424 -0.600 0.58113 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.146 on 4 degrees of freedom ## Multiple R-squared: 0.968,\tAdjusted R-squared: 0.9359 ## F-statistic: 30.21 on 4 and 4 DF, p-value: 0.003015 Només obtenim evidència estadística que \\(\\beta_1\\neq 0\\). Una altra possibilitat és emprar una ANOVA. Fixau-vos que si \\[ \\beta_1=\\beta_2=\\cdots=\\beta_k=0, \\] aleshores \\[ \\mu_{Y|x_{11},\\ldots,x_{k1}}=\\cdots=\\mu_{Y|x_{1n},\\ldots,x_{kn}}=\\beta_0 \\] Per tant, si al contrast \\[ \\left\\{\\begin{array}{l} H_0:\\mu_{Y|x_{11},\\ldots,x_{1k}}=\\cdots=\\mu_{Y|x_{n1},\\ldots,x_{nk}}\\\\ H_1:\\text{no és veritat que }\\mu_{Y|x_{11},\\ldots,x_{1k}}=\\cdots=\\mu_{Y|x_{n1},\\ldots,x_{nk}} \\end{array} \\right. \\] rebutjam la hipòtesi nul·la, això implicarà que podem rebutjar que \\(\\beta_1=\\beta_2=\\cdots=\\beta_k=0\\) i el model lineal tendrà sentit. La taula d’aquesta ANOVA és \\[ \\begin{array}{llllll}\\hline \\text{Font de} &amp; \\text{Graus de} &amp; \\text{Suma de} &amp; \\text{Quadrats} &amp; \\text{Estadístic} &amp; \\text{p-valor}\\\\ \\text{variació} &amp; \\text{llibertat} &amp; \\text{quadrats} &amp; \\text{mitjans} &amp;\\text{de contrast} &amp; \\\\\\hline \\text{Regressió} &amp; k &amp; SS_R &amp; MS_R &amp; F &amp; p\\\\ \\text{Error} &amp; n-k-1 &amp; SS_E &amp; MS_E &amp; &amp;\\\\ \\hline \\end{array} \\] on \\[ MS_R=\\frac{SS_R}{k},\\quad MS_E=\\frac{SS_E}{n-k-1} \\] i, com a les altres ANOVA, l’estadístic de contrast \\(F\\) és \\[ F=\\frac{MS_R}{MS_E} \\] i satisfà que, si la hipòtesi nul·la és vertadera (i els errors satisfan les condicions establertes al començament de la secció anterior), segueix una llei F de Fisher amb \\(k\\) i \\(n-k-1\\) graus de llibertat i té valor proper a 1, de manera que se pren com a p-valor \\[ \\text{p-valor}=P(F_{k,n-k-1}\\geq F). \\] Calculem la taula ANOVA de l’Exemple 11.13 SS.R=sum((Y.cap-mean(y))^2) SS.R ## [1] 556.376 SS.E=sum(lm(y~x1+x2+x3+x4)$residuals^2) SS.E ## [1] 18.41959 MS.R=SS.R/k MS.R ## [1] 139.094 MS.E=SS.E/(n-k-1) MS.E ## [1] 4.604896 F=MS.R/MS.E F ## [1] 30.20567 p.val=1-pf(F,k,n-k-1) p.val ## [1] 0.003014918 \\[ \\begin{array}{llllll}\\hline \\text{Font de} &amp; \\text{Graus de} &amp; \\text{Suma de} &amp; \\text{Quadrats} &amp; \\text{Estadístic} &amp; \\text{p-valor}\\\\ \\text{variació} &amp; \\text{llibertat} &amp; \\text{quadrats} &amp; \\text{mitjans} &amp;\\text{de contrast} &amp; \\\\\\hline \\text{Regressió} &amp; 4 &amp; 556.376 &amp; 139.094 &amp; 30.21 &amp; 0.003\\\\ \\text{Error} &amp; 4 &amp; 18.42 &amp; 4.605 &amp; &amp;\\\\ \\hline \\end{array} \\] Hem trobat evidència estadística que el model lineal és adequat. Podeu creure que no hi ha cap funció de cap paquet de R que calculi aquesta taula per a la regressió lineal múltiple? L’estadístic de contrast i el p-valor d’aquesta ANOVA els podeu trobar a la darrera línia de la sortida summary(lm( )); són el F-statistic (i a més us diu els graus de llibertat, DF, de la seva distribució) i el p-value: summary(lm(y~x1+x2+x3+x4)) ## ## Call: ## lm(formula = y ~ x1 + x2 + x3 + x4) ## ## Residuals: ## 1 2 3 4 5 6 7 8 ## 0.05699 -0.65797 1.60345 -0.20061 0.59140 -0.11546 -0.35298 -3.15098 ## 9 ## 2.22616 ## ## Coefficients: ## Estimate Std. Error t value Pr(&gt;|t|) ## (Intercept) 9.94645 11.06339 0.899 0.41946 ## x1 0.66261 0.07996 8.287 0.00116 ** ## x2 0.04830 0.06346 0.761 0.48899 ## x3 1.06180 1.30587 0.813 0.46179 ## x4 -0.25434 0.42424 -0.600 0.58113 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 ## ## Residual standard error: 2.146 on 4 degrees of freedom ## Multiple R-squared: 0.968,\tAdjusted R-squared: 0.9359 ## F-statistic: 30.21 on 4 and 4 DF, p-value: 0.003015 Podeu creure que no podem extreure el p-valor del summary(lm(y~x1+x2+x3+x4)) amb un sufix, sinó que l’hem de calcular? Per sort és fàcil, emprant el contingut de summary(lm( ))$fstatistic, que és un vector de 3 entrades: el valor de l’estadístic \\(F\\) i els seus dos graus de llibertat. Per tant, per calcular el p-valor, podem fer el següent: FF=summary(lm(y~x1+x2+x3+x4))$fstatistic 1-pf(FF[1],FF[2],FF[3]) ## value ## 0.003014918 Una altra opció és emprar la funció glance del paquet broom, que aplicada a un objecte dóna un dataframe (de fet, una adaptació del concepte de dataframe a l’anàlisi de dades massives, un tibble) amb els seus continguts més importants; vaja, que us permet “donar una ullada” a l’objecte. library(broom) glance(lm(y~x1+x2+x3+x4)) ## # A tibble: 1 x 12 ## r.squared adj.r.squared sigma statistic p.value df logLik AIC BIC ## &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; ## 1 0.968 0.936 2.15 30.2 0.00301 4 -16.0 44.0 45.2 ## # … with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt; 11.3 Test de la lliçó 11 (1) En una regressió lineal d’una variable Y respecte d’una variable independent X, hem emprat les observacions (x,y) de 100 individus i hem obtingut la recta de regressió per mínims quadrats y=3.02-0.96x. El valor mitjà de la variable X a la mostra que hem emprat ha estat 0.8. Quines de les afirmacions següents són vertaderes? Amb les dades que ens donen, no podem saber el valor mitjà de la variable Y a la mostra que hem emprat. El valor mitjà de la variable Y a la mostra que hem emprat ha estat 2.252. El valor mitjà de la variable Y a la mostra que hem emprat ha estat 3.02. Segons aquest model, en els individus de la població objecte d’estudi, quan la variable X augmenta una unitat, el valor esperat de la variable Y augmenta 0.96 Segons aquest model, en els individus de la població objecte d’estudi, quan la variable X augmenta una unitat, el valor esperat de la variable Y disminueix 0.96 Cap de les altres afirmacions és correcta. (2) En una regressió lineal per mínims quadrats d’una variable Y respecte d’una variable independent X, hem emprat les observacions (x,y) de 100 individus. A la nostra mostra, la mitjana de X ha estat 0.05, la mitjana de Y ha estat -1.3, la variància de X ha estat 2.56, la variància de Y ha estat 8.36 i la covariància de X i Y ha estat 4.54. Què val el coeficient de determinació de la regressió per mínims quadrats de Y respecte de X (arrodonit a 3 xifres decimals)? 0.212 0.963 0.981 1.773 No el podem calcular amb les dades que ens donen Cap de les altres respostes és correcta (3) Quines de les afirmacions següents sobre la regressió per mínims quadrats és vertadera? Quan es fa a mà, primer s’estima la pendent de la recta i després el terme independent Quan es fa a mà, primer s’estima el terme independent de la recta i després la pendent La suma de quadrats total és la suma de quadrats dels tractaments més la suma de quadrats dels errors La suma de quadrats total és la suma de quadrats de la regressió més la suma de quadrats dels errors Els coeficients de la recta són els que fan mínima la suma de quadrats de la regressió Els coeficients de la recta són els que fan màxima la suma de quadrats de la regressió Cap de les altres respostes és correcta (4) Sota hipòtesis adients per als errors, els estimadors \\(b_0\\) i \\(b_1\\) de \\(\\beta_0\\) i \\(\\beta_1\\) són màxim versemblants. Però, … què significa que un estimador sigui màxim versemblant? Que aplicat a una m.a.s. sempre dóna el p-valor més gran en els contrastos bilaterals del paràmetre que volem estimar Que aplicat a una m.a.s. sempre dóna el p-valor més petit en els contrastos bilaterals del paràmetre que volem estimar Que aplicat a una m.a.s. sempre dóna el valor més probable del paràmetre. Que aplicat a una m.a.s. sempre dóna el valor del paràmetre que fa més probable la m.a.s. Que aplicat a una m.a.s. sempre dóna el valor més probable de l’estimador. Que té valor esperat el valor real del paràmetre (5) Quines de les afirmacions següents sobre el coeficient de determinació en una regressió per mínims quadrats són vertaderes? El seu quadrat és la covariància dels vectors x, y de la mostra El seu quadrat és la correlació dels vectors x, y de la mostra La seva arrel quadrada positiva és la covariància dels vectors x, y de la mostra La seva arrel quadrada positiva és la correlació dels vectors x, y de la mostra Cap de les altres respostes és correcta (6) Quines de les afirmacions següents sobre el coeficient de determinació de la regressió lineal per mínims quadrats són vertaderes? Marcau totes les vertaderes. En el cas de la regressió lineal simple, el seu quadrat és la correlació entre els valors de la variable independent i els de la variable dependent a la nostra mostra En el cas de la regressió lineal simple, és el quadrat de la correlació entre els valors de la variable independent i els de la variable dependent a la nostra mostra En el cas de la regressió lineal múltiple, si afegim al nostre model variables independents, el valor del coeficient de determinació no decreix. En el cas de la regressió lineal múltiple, si empram un nombre més gran de variables independents (però no necessàriament mantenint les variables anteriors) el valor del coeficient de determinació no decreix. Cap de les altres respostes és correcta. (7) En fer la regressió lineal d’una variable Y respecte d’una variable X, hem obtingut la recta y=0.8+1.2x. Quina de les conclusions següents és la més correcta segons aquest model? Un augment de 1 unitat de la variable X causa un augment de 1.2 unitats de la variable Y Un augment de 1 unitat de la variable X està associada a un augment de 1.2 unitats de la variable Y Un augment de 1 unitat de la variable X causa un augment de 0.8 unitats de la variable Y Un augment de 1 unitat de la variable X està associada a un augment de 0.8 unitats de la variable Y (8) Quines de les afirmacions següents són sempre veritat per una recta de regressió lineal simple? Passa sempre per l’origen de coordenades És sempre creixent El seu pendent no canvia si canviam les unitats amb les que mesuram la variable dependent però no canviam les unitats amb les que mesuram la variable independent El seu pendent segur que canvia si canviam les unitats amb les que mesuram la variable dependent però no canviam les unitats amb les que mesuram la variable independent Passa sempre pel punt mig de les observacions Els seus coeficients determinen el valor de la \\(R^2\\) Cap de les altres respostes és correcta. (9) Quines de les afirmacions següents sobre l’estimació de la variable dependent Y a partir de la variable independent X per mitjà d’una recta de regressió per mínims quadrats són vertaderes (quan se satisfan les condicions adients sobre els errors)? L’estimació puntual del valor de Y sobre un individu concret on X valgui x0 i l’estimació de valor mitjà de Y sobre tots els individus on X valgui x0 sempre coincideixen L’estimació puntual del valor de Y sobre un individu concret on X valgui x0 sempre és estrictament més gran que l’estimació del valor mitjà de Y sobre tots els individus on X valgui x0 L’interval de confiança del 95% per al valor de Y sobre un individu concret on X valgui x0 i l’interval de confiança del 95% per al valor mitjà de Y sobre tots els individus on X valgui x0 sempre coincideixen L’interval de confiança del 95% per al valor de Y sobre un individu concret on X valgui x0 sempre és estrictament més ample que l’interval de confiança del 95% per al valor mitjà de Y sobre tots els individus on X valgui x0 L’interval de confiança del 95% per al valor de Y sobre un individu concret on X valgui x0 sempre és estrictament més estret que l’interval de confiança del 95% per al valor mitjà de Y sobre tots els individus on X valgui x0 Cap de les altres respostes és correcta. (10) Emprant un model de regresió lineal per mínims quadrats d’una variable Y respecte d’una variable X, hem estimat el valor de Y quan X=5 amb la funció predict.lm de R, i hem obtingut els intervals de confiança del 95% [2,5] i [3,9], però no sabem quin és l’interval de confiança per al valor predit de Y sobre un individu per al qual X=5 i quin és l’interval de confiança per al valor esperat de Y sobre els individus per al quals X=5. [2,5] és l’interval de confiança per al valor predit de Y sobre un individu per al qual X=5 i [3,9] és l’interval de confiança per al valor esperat de Y sobre els individus per al quals X=5. [2,5] és l’interval de confiança per al valor esperat de Y sobre els individus per al quals X=5 i [3,9] és l’interval de confiança per al valor predit de Y sobre un individu per al qual X=5. No podem saber quin interval és quin En realitat, hi ha un error: és impossible que [2,5] i [3,9] (en l’ordre que sigui) siguin intervals de confiança per al valor predit de Y sobre un individu per al qual X=5 i per al valor esperat de Y sobre els individus per al quals X=5 (11) En fer la regressió lineal d’una variable Y respecte d’una variable X, hem obtingut la recta Y=0.8+1.2X. Quina de les conclusions següents és la més correcta segons aquest model? Un augment de 1 unitat de la variable X causa un augment de 1.2 unitats de la variable Y Un augment de 1 unitat de la variable X està associada a un augment de 1.2 unitats de la variable Y Un augment de 1 unitat de la variable X causa un augment de 0.8 unitats de la variable Y Un augment de 1 unitat de la variable X està associada a un augment de 0.8 unitats de la variable Y (12) Quines de les afirmacions següents sobre la recta de regressió per mínims quadrats és vertadera? Sempre passa per l’origen de coordenades Sempre és creixent El coeficient \\(b_1\\) no canvia si canviam les unitats amb les que mesuram la variable independent multiplicant-les per una constant (com ara si canviam cm per m), però no canviam les unitats amb les que mesuram la variable dependent El coeficient \\(b_0\\) no canvia si canviam les unitats amb les que mesuram la variable independent multiplicant-les per una constant (com ara si canviam cm per m), però no canviam les unitats amb les que mesuram la variable dependent Sempre passa pel punt mig de les observacions que formen la mostra Els valors de \\(b_0\\) i \\(b_1\\) determinen el valor de \\(R^2\\) Cap de les altres respostes és correcta (13) Quines de les afirmacions següents sobre el coeficient de determinació en una regressió per mínims quadrats són vertaderes? El seu signe és sempre el del coeficient b1 de la recta de regressió El seu signe és sempre el de la covariància dels vectors x i y de la mostra És el quadrat de la correlació poblacional de les variables X i Y Si sabeu el seu valor i la recta de regressió, podeu saber el valor de la correlació dels vectors x i y de la mostra Cap de les altres respostes és correcta (14) Hem mesurat dues variables X i Y sobre 100 subjectes. La variància de la mostra x de X obtinguda ha estat 3 i la variància de la mostra x de X ha estat 12. Quin, o quins, dels valors següents no poden ser el de la covariància de x i y? 0 1.5 6 9 \\(-\\sqrt{2}\\) -6 -9 La covariància d’aquests vectors x i y pot ser qualsevol número real (15) En una regressió lineal simple per mínims quadrats, en el contrast sobre si \\(\\beta_0=0\\) o no obtenim un p-valor 0.018 i en el contrast sobre si \\(\\beta_1=0\\) o no obtenim un p-valor 0.005. Si se satisfan les condicions sobre les variables error perquè aquests p-valors siguin fiables, quines de les afirmacions següents són correctes? Hem obtingut evidència estadística que \\(\\beta_0=0\\) i \\(\\beta_1=0\\) No hem obtingut evidència estadística que \\(\\beta_0=0\\) i \\(\\beta_1=0\\) Hem obtingut evidència estadística que \\(\\beta_0\\neq 0\\) i \\(\\beta_1\\neq 0\\) No hem obtingut evidència estadística que \\(\\beta_0\\neq 0\\) i \\(\\beta_1\\neq 0\\) En la realitat, la probabilitat que \\(\\beta_0=0\\) és més petita que la de \\(\\beta_1=0\\) En la realitat, la probabilitat que \\(\\beta_0=0\\) és més gran que la de \\(\\beta_1=0\\) Estam segurs que \\(b_0\\) i \\(b_1\\) han donat diferent de 0 Cap de les altres respostes és correcta (16) En una regressió lineal simple per mínims quadrats d’una variable Y respecte d’una variable X, hem obtingut \\(b_1=0.18\\) i un interval de confiança del 95% per a \\(\\beta_1\\) entre 0.1 i 0.26. Si se satisfan les condicions sobre les variables error perquè aquest interval de confiança sigui fiable, quines de les afirmacions següents són correctes? Com que 0.18 pertany a [0.1,0.26], estam molt segurs que \\(\\beta_1=0.18\\) Amb nivell de significació 0.05 segur que rebutjarem que \\(\\beta_1\\neq 0\\) Si calculàssim l’IC del 90% per a \\(\\beta_1\\) amb la mateixa mostra, seria més ample que el del 95% Si calculàssim l’IC del 90% per a \\(\\beta_1\\) amb la mateixa mostra, seria més estret que el del 95% Per a un 95% de les mostres de la mateixa mida que la nostra, el coeficient \\(b_1\\) estaria entre 0.1 i 0.26 Amb nivell de significació 0.05, podem concloure que el model lineal té sentit, en el sentit que la variable Y|x no és la variable error Ex més una constant Cap de les altres respostes és correcta (17) Quines de les afirmacions següents sobre la regressió lineal múltiple per mínims quadrats són vertaderes? Marcau totes les vertaderes. La funció que s’obté sempre passa per l’origen de coordenades La funció que s’obté sempre passa pel punt mig de les observacions que formen la mostra La mitjana dels valors estimats de la variable dependent sobre els subjectes de la mostra coincideix amb la mitjana dels valors observats d’aquesta variable sobre aquests subjectes La mitjana dels valors estimats de la variable dependent sobre els subjectes de la mostra coincideix amb la variància dels valors observats d’aquesta variable sobre aquests subjectes La suma de quadrats total és la suma de quadrats dels tractaments més la suma de quadrats dels errors La suma de quadrats total és la suma de quadrats de la regressió més la suma de quadrats dels errors Els coeficients de la funció lineal són els que fan mínima la suma de quadrats dels errros La mitjana dels valors estimats de la variable dependent sobre els subjectes de la mostra coincideix amb la mitjana dels errors en l’estima ció d’aquesta variable sobre aquests subjectes La mitjana dels errors en l’estimació de la variable dependent sobre els subjectes de la mostra és 0 La variància dels errors en l’estimació de la variable dependent sobre els subjectes de la mostra és 0 (18) En una regressió lineal, hem obtingut la funció de regressió lineal \\(Y=2+3X_1-5X_2+4X_3\\). Quines de les afirmacions són vertaderes? Segons aquest model, si en un subjecte A el valor de \\(X_1\\) és més gran que en un subjecte B, el valor esperat de \\(Y\\) en el subjecte A és més gran que el valor esperat de \\(Y\\) en el subjecte B Segons aquest model, si en un subjecte A el valor de \\(X_1\\) és més gran que en un subjecte B, pot passar que el valor esperat de \\(Y\\) en el subjecte A sigui més petit que el valor esperat de \\(Y\\) en el subjecte B Segons aquest model, si \\(X_1\\) i \\(X_3\\) romanen constants i \\(X_2\\) augmenta en 1 unitat, el valor esperat de \\(Y\\) disminueix 3 unitats Segons aquest model, si \\(X_1\\) i \\(X_3\\) romanen constants i \\(X_2\\) augmenta en 1 unitat, el valor esperat de \\(Y\\) disminueix 5 unitats Segons aquest model, si \\(X_1\\) i \\(X_3\\) romanen constants i \\(X_2\\) augmenta en 1 unitat, el valor esperat de \\(Y\\) augmenta 5 unitats Cap de les altres respostes és vertadera (19) Quines de les afirmacions següents sobre el coeficient de determinació de la regressió lineal per mínims quadrats són vertaderes? Marcau totes les vertaderes. En el cas de la regressió lineal simple, el seu quadrat és la correlació entre els valors de la variable independent i els de la variable dependent a la nostra mostra En el cas de la regressió lineal simple, és el quadrat de la correlació entre els valors de la variable independent i els de la variable dependent a la nostra mostra En el cas de la regressió lineal múltiple, si afegim al nostre model variables independents, el valor del coeficient de determinació no decreix. En el cas de la regressió lineal múltiple, si empram un nombre més gran de variables independents (però no necessàriament mantenint les variables anteriors) el valor del coeficient de determinació no decreix. No pot valer 0 No pot ser estrictament negatiu Cap de les altres respostes és correcta. (20) En la regressió lineal múltiple de Y en funció de les variables independents \\(X_1,X_2,X_3,X_4,X_5\\) a partir d’una certa mostra hem obtingut que \\(R^2=0.92\\) i \\(R^2_{adj}=0.82\\), mentre que si fem la regressió lineal múltiple de Y en funció només de les variables independents \\(X_1,X_2,X_3\\) a partir de la mateixa mostra hem obtingut que \\(R^2=0.91\\) i \\(R^2_{adj}=0.865\\). Quina de les afirmacions següents és vertadera? Això no pot ser, perquè \\(R^2_{adj}\\) sempre és més gran o igual que R2. Això no pot ser, perquè quan \\(R^2\\) decreix, \\(R^2_{adj}\\) també decreix. Això no pot ser, perquè quan eliminam variables independents, la \\(R^2\\) sempre creix. Això sí que pot ser, i llavors consideram que el model amb 5 variables independents és millor, perquè té el valor de \\(R^2\\) més gran Això sí que pot ser, i llavors consideram que el model amb 3 variables independents és millor, perquè té el valor de \\(R^2_{adj}\\) més gran Això sí que pot ser, i llavors consideram que el model amb 3 variables independents és millor, perquè té el valor de \\(R^2\\) més petit Cap de les altres respostes és correcta. (21) Quines de les afirmacions següents sobre \\(R^2_{adj}\\) són vertaderes? Sempre és més petit que \\(R^2\\) Pot ser més petit o més gran que \\(R^2\\) Pot ser estrictament negatiu Pot valer 0 Si afegim variables independents a la regressió lineal, el seu valor no decreix Si afegim variables independents a la regressió lineal, el seu valor no creix Cap de les altres respostes és vertadera (22) En una regressió lineal múltiple per mínims quadrats d’una variable Y respecte d’una variable X, hem obtingut \\(b_2=0.18\\) i un interval de confiança del 95% per a \\(\\beta_2\\) entre -0.1 i 0.46. Si se satisfan les condicions sobre les variables error perquè aquest interval de confiança sigui fiable, quines de les afirmacions següents són correctes? Com que 0.18 pertany a [-0.1,0.46], estam molt segurs que \\(\\beta_2=0.18\\) Amb nivell de significació 0.05 hem de rebutjar que \\(\\beta_2=0\\) Amb nivell de significació 0.05 no podem rebutjar que \\(\\beta_2=0\\) Si calculàssim l’IC del 99% per a \\(\\beta_2\\) amb la mateixa mostra, seria més ample que el del 95% Si calculàssim l’IC del 99% per a \\(\\beta_2\\) amb la mateixa mostra, seria més estret que el del 95% Si calculàssim l’IC del 99% per a \\(\\beta_2\\) amb una altra mostra de la mateixa mida, seria més ample que el del 95% que hem obtingut nosaltres Per a un 95% de les mostres de la mateixa mida que la nostra, el coeficient \\(b_2\\) estaria entre -0.1 i 0.46 Cap de les altres respostes és correcta (23) En el contrast d’hipòtesis sobre si un coeficient \\(\\beta_i\\) és 0 o no, la conclusió amb nivell de significació 0.1 ha estat que hem d’acceptar la hipòtesi nul·la. Quines de les afirmacions següents són vertadera en aquesta situació? Hem acceptat la hipòtesi nul·la perquè hem obtingut evidència estadística que la hipòtesi nul·la és vertadera. Hem acceptat la hipòtesi nul·la perquè no hem obtingut evidència estadística que la hipòtesi nul·la sigui falsa. Hem acceptat que \\(\\beta_i=0\\) Hem acceptat la hipòtesi nul·la perquè hem obtingut evidència estadística que la probabilitat que la hipòtesi alternativa sigui vertadera és 0.1 o menys. Assumím una probabilitat d’equivocar-nos acceptant la hipòtesi nul·la quan és falsa de 0.1. Assumim una probabilitat d’equivocar-nos rebutjant la hipòtesi nul·la quan és vertadera de 0.1. Cap de les altres respostes és correcta (24) Quina o quines de les afirmacions següents sobre la regressió lineal per mínims quadrats d’una variable Y respecte d’un conjunt de variables independents són vertaderes? Si el nombre de variables independents és el mateix, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la mitjana dels valors de Y dels punts de la mostra entre la mitjana dels valors estimats de Y sobre els punts de la mostra. Si el nombre de variables independents és el mateix, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la variància dels valors de Y dels punts de la mostra entre la variància dels valors estimats de Y sobre els punts de la mostra. Si el nombre de variables independents és el mateix, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la variància dels valors estimats de Y sobre els punts de la mostra entre la variància dels valors de Y dels punts de la mostra Independentment del nombre de variables independents, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la mitjana dels valors de Y dels punts de la mostra entre la mitjana dels valors estimats de Y sobre els punts de la mostra. Independentment del nombre de variables independents, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la variància dels valors de Y dels punts de la mostra entre la variància dels valors estimats de Y sobre els punts de la mostra. Independentment del nombre de variables independents, consideram més bona una funció de regressió lineal de Y com més gran és el quocient de la variància dels valors estimats de Y sobre els punts de la mostra entre la variància dels valors de Y dels punts de la mostra (25) Roda el món i torna al Born. Quan diem que el 0.975-quantil d’una variable aleatòria normal estàndard Z és 1.96, això significa que: P(Z=0.975)=1.96 P(Z&lt;0.975)=1.96 P(Z&gt;0.975)=1.96 P(Z=1.96)=0.975 P(Z&lt;1.96)=0.975 P(Z&gt;1.96)=0.975 En realitat no significa res de tot això. "]
]
