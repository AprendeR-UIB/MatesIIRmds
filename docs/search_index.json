[
["index.html", "Matemàtiques II Presentació", " Matemàtiques II 2020-02-15 Presentació Això és una edició en línea dels apunts de Matemàtiques II dels graus de Biologia i Bioquímica de la UIB. Aquests apunts no són autocontinguts pel que fa al R: suposam que l’estudiant va llegint les lliçons de R corresponents a cada tema a la 2a part del manual AprendeR, que trobareu per ara a https://aprender-uib.github.io/AprendeR2/. Aquests apunts estan en construcció. A la llista següent hi anirem anunciant les actualitzacions. 17-02-2020: Pujats temes 1 i 2 Significats d’algunes capses: Material molt important. Alerta! Exercici. Detalls matemàtics que us poden interessar, però que no cal saber. Comentari que volem emfatitzar. Acabam de matar un moixet. El llibre està escrit en R Markdown, emprant RStudio com a editor de textos i el paquet bookdown per convertir els fitxers markdown en un llibre Aquest treball se publica sota llicència Atribució-No Comercial-SenseDerivats 4.0 "],
["repas-de-la-distribucio-normal.html", "Tema 1 Repàs de la distribució normal 1.1 Propietats de la distribució normal 1.2 Amb R 1.3 Combinacions lineals 1.4 Intervals de referència 1.5 El z-score", " Tema 1 Repàs de la distribució normal 1.1 Propietats de la distribució normal Una variable aleatòria contínua \\(X\\) és normal de paràmetres \\(\\mu\\) i \\(\\sigma\\), i ho indicarem escrivint \\(X\\sim N(\\mu,\\sigma)\\), quan la seva funció de densitat és Naturalment, no cal saber aquesta fórmula. El que cal saber és que: Una variable aleatòria normal \\(X\\) és contínua, i per tant \\(P(X=x)=0\\), \\(P(X\\leqslant x)=P(X&lt;x)\\) etc. Si \\(X\\sim N(\\mu,\\sigma)\\), aleshores el seu valor esperat és \\(E(X)=\\mu\\) i la seva desviació típica és \\(\\sigma_X=\\sigma\\) Una variable aleatòria normal és típica (o estàndard) quan \\(\\mu=0\\) i \\(\\sigma=1\\); la indicarem usualment amb \\(Z\\). Per tant, si \\(Z\\sim N(0,1)\\), \\(E(Z)=0\\) i \\(\\sigma_Z=1\\). La gràfica de la densitat d’una variable aleatòria normal és la famosa campana de Gauss: La gràfica de la densitat d’una variable aleatòria normal és també la menys famosa gràfica del capell del gendarme: La distribució normal és una distribució teòrica, no la trobareu exacta en la pràctica. I malgrat el seu nom, no és més “normal” que les altres distribucions que estudiarem. La distribució normal és important perquè aproxima bé moltes distribucions reals, perquè: Moltes variables aleatòries que consisteixen a prendre \\(n\\) observacions independents d’una o diverses variables aleatòries i sumar-les, tenen distribució aproximadament normal quan \\(n\\) és gran, encara que les variables aleatòries de partida no ho siguin. Per exemple: Si \\(X\\) és una variable aleatòria binomial B(n,p), amb \\(n\\) gran, alehores \\(X\\) és aproximadament \\(N(np,\\sqrt{np(1-p)})\\), en el sentit que les dues funcions de densitat (salvant la diferència pel fet que la binomial és discreta i la normal contínua) són semblants: Si \\(X\\) és una variable aleatòria de Poisson \\(Po(\\lambda)\\) i \\(\\lambda\\) és gran, aleshores \\(X\\) és aproximadament \\(N(\\lambda,\\sqrt{\\lambda})\\) Quan s’aproxima una variable binomial o Poisson \\(X\\) per mitjà d’una variable normal \\(Y\\), és convenient aplicar l’anomenada correcció de continuïtat: per a cada \\(n\\in \\mathbb{N}\\), interpretar \\(P(X\\leqslant n)\\) com \\(P(X&lt; n+1/2)\\) i aleshores aproximar: \\(P(X\\leqslant n)\\) per mitjà de \\(P(Y&lt; n+1/2)\\) \\(P(X=n)\\) per mitjà de \\(P(n-1/2&lt; Y&lt; n+1/2)\\) Vegeu l’Exemple 1.1 a la propera secció. Una de les propietats clau de la distribució normal és la seva simetria: Si \\(X\\sim N(\\mu,\\sigma)\\), la seva densitat \\(f_X\\) és simètrica respecte de \\(x=\\mu\\), és a dir, \\[ f_{X}(\\mu-x)=f_{X}(\\mu+x), \\] i té el màxim en \\(x=\\mu\\). Diem aleshores que \\(\\mu\\) és la moda de \\(X\\). Recordem que no té sentit definir la moda d’una variable contínua \\(X\\) com el valor \\(x_0\\) tal que \\(P(X=x_0)\\) sigui màxim, perquè \\(P(X=x)=0\\) per a tot \\(x\\in \\mathbb{R}\\). Es defineix llavors la moda d’una variable contínua \\(X\\) com el valor (o els valors) \\(x_0\\) tal(s) que \\(f_X(x_0)\\) és màxim. En particular, si \\(Z\\sim N(0,1)\\), llavors \\(f_{Z}\\) és simètrica al voltant de \\(x=0\\), és a dir, \\(f_{Z}(-x)=f_{Z}(x)\\), i la moda de \\(Z\\) és 0. Si la \\(\\mu\\) creix, el màxim es desplaça a la dreta, i amb ell tota la corba de manera rígida. Si la \\(\\sigma\\) creix, la corba s’aplata: en augmentar la desviació típica, els valors s’allunyen més del valor mitjà. Vegem l’efecte combinat: Recordem que la funció de distribució d’una variable aleatòria contínua \\(X\\) \\[ F_X(x)=P(X\\leqslant x) \\] és l’àrea compresa entre la corba definida per la densitat \\(y=f_X(x)\\) i l’eix d’abscisses a l’esquerra de \\(x\\). La simetria de \\(f_X\\) fa que les àrees a l’esquerra de \\(\\mu-x\\) i a la dreta de \\(\\mu+x\\) siguin iguals. És a dir, \\[ P(X\\leqslant\\mu-x) = P(X\\geqslant\\mu+x)=1-P(X\\leqslant\\mu+x) \\] En particular (prenent \\(x=0\\)) \\[ P(X\\leqslant\\mu)=1-P(X\\leqslant\\mu)\\Rightarrow P(X\\leqslant\\mu)=0.5, \\] i per tant \\(\\mu\\) és també la mediana de \\(X\\). Si \\(X\\sim N(\\mu,\\sigma)\\), \\(\\mu\\) és la moda, la mitjana, o esperança, i la mediana de \\(X\\). En particular, si \\(Z\\sim N(0,1)\\), les àrees a l’esquerra de \\(-z\\) i a la dreta de \\(z\\) són iguals, \\[ P(Z\\leqslant-z)=P(Z\\geqslant z)=1-P(Z\\leqslant z), \\] i la mediana de \\(Z\\) és 0. Indicarem amb \\(z_q\\) el \\(q\\)-quantil d’una variable normal estàndard \\(Z\\). És a dir, \\(z_q\\) és el valor tal que \\(P(Z\\leqslant z_q)=q\\). A banda del fet que \\(z_{0.5}=0\\) (la mediana de \\(Z\\) és 0), hi ha dos quantils més de la normal estándard que heu de saber “de memòria”: \\(z_{0.95}=1.64\\); és a dir, \\(P(Z\\leqslant 1.64)=0.95\\) i per tant \\(P(Z\\leqslant-1.64)=P(Z\\geqslant 1.64)=0.05\\). \\(z_{0.975}=1.96\\); és a dir, \\(P(Z\\leqslant 1.96)=0.975\\) i per tant \\(P(Z\\leqslant-1.96)=P(Z\\leqslant 1.96)=0.025\\) Molt sovint el valor 1.96 de \\(z_{0.975}\\) s’aproxima per 2. Teniu permís per fer-ho quan no disposeu de mitjans (R, aplis de mòbil) per calcular quantils. 1.2 Amb R Per calcular probabilitats d’una variable normal emprant R, heu de recordar que la normal és norm. Per tant, si \\(X\\sim N(\\mu,\\sigma)\\): dnorm(x,mu,sigma) dóna el valor de la densitat \\(f_X(x)\\) pnorm(x,mu,sigma) dóna el valor de la distribució \\(F_X(x)=P(X\\leqslant x)\\); afegint-hi el paràmetre lower.tail=FALSE dóna el valor de \\(P(X&gt;x)\\) qnorm(q,mu,sigma) dóna el \\(q\\)-quantil de \\(X\\) rnorm(N,mu,sigma) dóna un vector de \\(n\\) nombres aleatoris generats amb aquesta distribució A la normal estàndard no és necessari entrar-hi \\(\\mu=0\\) i \\(\\sigma=1\\), són els valors per defecte d’aquests paràmetres. Vegem-ne alguns exemples: Si \\(X\\sim N(3,0.5)\\), què val \\(P(X\\leqslant 2)\\)? pnorm(2,3,0.5) ## [1] 0.02275013 Si \\(X\\sim N(-2,0.3)\\), què val \\(P(X\\geqslant-1.8)\\)? 1-pnorm(-1.8,-2,0.3) ## [1] 0.2524925 pnorm(-1.8,-2,0.3,lower.tail=FALSE) ## [1] 0.2524925 Si \\(X\\sim N(0,1)\\), què val \\(P(-1\\leqslant X\\leqslant 1)\\)? Com que \\(P(-1\\leqslant X\\leqslant 1)=P(X\\leqslant 1)-P(X\\leqslant-1)\\), pnorm(1)-pnorm(-1) ## [1] 0.6826895 Què val el primer quartil d’una variable \\(N(3,0.5)\\)? qnorm(0.25,3,0.5) ## [1] 2.662755 Comprovau els valors de \\(z_{0.95}\\) i \\(z_{0.975}\\) donats al final de la secció anterior. Exemple 1.1 A la secció anterior, us hem dit que una variable binomial \\(B(n,p)\\) amb \\(n\\) gran s’aproxima per mitjà d’una variable normal \\(N(np,\\sqrt{np(1-p)})\\). Així, per exemple, una variable \\(X\\sim B(400,0.2)\\) s’aproxima per mitjà d’una variable \\(Y\\sim N(400\\cdot 0.2,\\sqrt{400\\cdot 0.2\\cdot 0.8})=N(80,8)\\). Vegem amb alguns exemples que aquesta aproximació és millor aplicant-hi la correcció de continuïtat: \\(P(X\\leqslant 70)\\): pbinom(70,400,0.2) ## [1] 0.1163917 \\(P(Y&lt; 70+1/2)\\): pnorm(70.5,80,8) ## [1] 0.1175152 \\(P(Y\\leqslant 70)\\): pnorm(70,80,8) ## [1] 0.1056498 \\(P(X=70)\\): dbinom(70,400,0.2) ## [1] 0.02338443 \\(P(70-1/2&lt; Y&lt; 70+1/2)\\): pnorm(70.5,80,8)-pnorm(69.5,80,8) ## [1] 0.02283949 \\(P(Y=70)\\): dnorm(70,80,8) ## [1] 0.02283114 NO! dnorm(70,80,8) és la funció de densitat de \\(Y\\) (la fórmula que hem censurat al començament d’aquest tema) aplicada a 70, i no és igual a la probabilitat que \\(Y\\) valgui 70. Recordau que \\(P(Y=70)=0\\) perquè \\(Y\\) és contínua. 1.3 Combinacions lineals El resultat següent descriu el comportament de la mitjana i la variància d’una combinació lineal de variables aleatòries: Teorema 1.1 Siguin \\(Y_1,\\ldots,Y_n\\) variables aleatòries, cada \\(Y_i\\) de mitjana \\(\\mu_i\\) i variància \\(\\sigma_i^2\\), i siguin \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\). Sigui \\(Y\\) la variable aleatòria \\[ Y=a_1Y_1+\\cdots+a_nY_n+b. \\] Aleshores La mitjana de \\(Y\\) és \\[ \\mu_Y=a_1\\mu_1+\\cdots+a_n\\mu_n+b. \\] Si \\(Y_1,\\ldots,Y_n\\) són independents, aleshores la variància de \\(Y\\) és \\[ \\sigma_Y^2=a_1^2\\sigma_1^2+\\cdots+a_n^2\\sigma_n^2 \\] i per tant la seva desviació típica és \\[ \\sigma_Y=\\sqrt{a_1^2\\sigma_1^2+\\cdots+a_n^2\\sigma_n^2}. \\] Una altra propietat destacada de la distribució normal és que tota combinació lineal de variables aleatòries normals independents torna a ser normal: Teorema 1.2 Si \\(Y_1,\\ldots,Y_n\\) son variables aleatòries normals independents, cada \\(Y_i\\sim N(\\mu_i,\\sigma_i)\\), i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), aleshores \\[ Y=a_1Y_1+\\cdots+a_nY_n+b \\] és una variable aleatòria \\(N(\\mu,\\sigma)\\) amb \\(\\mu\\) i \\(\\sigma\\) els que toquin pel teorema anterior: \\(\\mu=a_1\\mu_1+\\cdots+a_n\\mu_n+b\\) \\(\\sigma=\\sqrt{a_1^2\\sigma_1^2+\\cdots+a_n^2\\sigma_n^2}\\) Com a cas particular, obtenim que una transformació afí d’una variable aleatòria normal torna a ser normal: Teorema 1.3 Si \\(X\\sim N(\\mu,\\sigma)\\) i \\(a,b\\in \\mathbb{R}\\), llavors \\(aX+b\\) també és normal, i en concret és \\(N(a\\mu+b,|a|\\cdot\\sigma)\\). En particular, si \\(X\\sim N(\\mu,\\sigma)\\), llavors la seva tipificada \\[ Z=\\dfrac{X-\\mu}{\\sigma} \\] és \\(N(0,1)\\). Les probabilitats de la normal tipificada determinen les de la normal original, perquè si \\(X\\sim N(\\mu,\\sigma)\\), \\[ \\begin{array}{rl} P(a\\leqslant X\\leqslant b) &amp; \\displaystyle =P\\Big( \\frac{a-\\mu}{\\sigma}\\leqslant\\frac{X-\\mu}{\\sigma}\\leqslant\\frac{b-\\mu}{\\sigma}\\Big)\\\\ &amp; \\displaystyle =P\\Big(\\frac{a-\\mu}{\\sigma}\\leqslant Z\\leqslant\\frac{b-\\mu}{\\sigma}\\Big) \\end{array} \\] Que tota combinació lineal de variables normals torni a ser del mateix tipus, és a dir, normal, és una propietat molt útil de les variables normals que pocs altres tipus de variables aleatòries tenen. Per exemple, si \\(X\\) és una variable binomial \\(B(n,p)\\) amb \\(p\\neq 0\\), \\(2X\\) no és cap variable binomial, perquè només pren valors parells i una variable binomial \\(B(m,q)\\) pot prendre tots els valors entre 0 i \\(m\\). 1.4 Intervals de referència Un interval de referència del \\(100q\\%\\) per a una variable aleatòria \\(X\\) és un interval \\([a,b]\\) tal que \\[ P(a\\leqslant X\\leqslant b)=q. \\] És a dir, un interval de referència del \\(100q\\%\\) per a \\(X\\) és un interval que conté els valors de \\(X\\) del \\(100q\\%\\) de subjectes de la població on està definida. Els més comuns són els intervals de referència del 95% (\\(q=0.95\\)), que satisfan que \\[ P(a\\leqslant X\\leqslant b)=0.95 \\] i són els, que per exemple, us donen com a valors de referència a les analítiques: Quan es parla d’un interval de referència sense donar-ne la probabilitat, se sobreentén sempre que és l’interval de referència del 95%. Quan \\(X\\sim N(\\mu,\\sigma)\\), aquests intervals de referència es prenen sempre centrats en la mitjana \\(\\mu\\), és a dir, de la forma \\([\\mu-x,\\mu+x]\\). Per calcular-los fàcilment, podem emprar el resultat següent: Teorema 1.4 Si \\(X\\sim N(\\mu,\\sigma)\\), un interval de referència del \\(100q\\%\\) és \\[ [\\mu- z_{(1+q)/2}\\cdot \\sigma, \\mu+ z_{(1+q)/2}\\cdot \\sigma] \\] on \\(z_{(1+q)/2}\\) indica el \\((1+q)/2\\)-quantil de \\(Z\\sim N(0,1)\\). L’escriurem \\[ \\mu\\pm z_{(1+q)/2}\\cdot \\sigma. \\] En efecte: \\[ \\begin{array}{l} P(\\mu-x\\leqslant X\\leqslant\\mu+x)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P\\Big(\\frac{\\mu-x-\\mu}{\\sigma}\\leqslant\\frac{X-\\mu}{\\sigma}\\leqslant\\frac{\\mu+x-\\mu}{\\sigma}\\Big)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(-x/{\\sigma}\\leqslant Z\\leqslant{x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant{x}/{\\sigma})-P(Z\\leqslant-{x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant{x}/{\\sigma})-(1-P(Z\\leqslant{x}/{\\sigma}))=q\\\\ \\qquad \\mbox{(per la simetria de $f_Z$ al voltant de 0)}\\\\ \\qquad \\Longleftrightarrow \\displaystyle 2P(Z\\leqslant{x}/{\\sigma})=q+1\\\\ \\qquad \\Longleftrightarrow P(Z\\leqslant{x}/{\\sigma})=(1+q)/2\\\\ \\qquad \\Longleftrightarrow x/\\sigma= z_{(1+q)/2}\\\\ \\qquad \\Longleftrightarrow x=z_{(1+q)/2}\\cdot \\sigma \\end{array} \\] En particular, com que si \\(q=0.95\\), aleshores \\((1+q)/2=0.975\\) i llavors \\(z_{0.975}=1.96\\), i això sovint s’aproxima per 2, l’interval de referència del 95% per a \\(X\\sim N(\\mu,\\sigma)\\) és \\[ \\mu\\pm 1.96\\sigma \\] o simplement, per simplificar, \\[ \\mu\\pm 2\\sigma. \\] Això diu, bàsicament, que si una població segueix una distribució normal \\(N(\\mu,\\sigma)\\), un 95% dels seus individus tenen el seu valor de \\(X\\) a distància como a màxim \\(2\\sigma\\) (“a dues sigmes”) de \\(\\mu\\). Exemple 1.2 Segons l’OMS, les alçades de les dones europees de 18 anys segueixen una llei \\(N(163.1,18.53)\\). Vull trobar un interval d’alçades centrat en la mitjana que contengui les de la meitat de les europees de 18 anys. És, a dir, vull trobar l’interval de referència del 50% per a la variable aleatòria \\(X\\) definida per les alçades de les dones europees de 18 anys. Com que \\(X\\sim N(163.1,18.53)\\) i si \\(q=0.5\\), aleshores \\((1+q)/2=0.75\\), aquest interval és 163.1+qnorm(0.75)*18.53*c(-1,1) ## [1] 150.6017 175.5983 Arrodonint a cm, és l’interval [151, 176]. Per tant, la meitat de les dones europees de 18 anys fan entre 1.51 m i 1.76 m d’alçada. Exemple 1.3 Quin és l’interval de referència per a les alçades de les dones europees de 18 anys? Com que sobreentenem que es tracta de l’interval de referència del 95%, és \\[ 163.1\\pm 1.96\\times 18.53\\Longrightarrow [127, 199] \\] 1.5 El z-score El z-score (o valor z, puntuació z) d’un valor \\(x_0\\) respecte d’una distribució \\(N(\\mu,\\sigma)\\) és \\[ \\frac{x_0-\\mu}{\\sigma}. \\] És a dir, el z-score de \\(x_0\\) és el resultat de “tipificar” \\(x_0\\) en el sentit del Teorema 1.3. Si la variable poblacional és normal, com més gran és el valor absolut del z-score de \\(x_0\\), més “rar” és \\(x_0\\); el signe ens diu si és més gran o més petit que el valor esperat \\(\\mu\\). Exemple 1.4 Recordau que, segons l’OMS, les altures de les dones europees de 18 anys segueixen una llei \\(N(163.1,18.53)\\). Quin és el z-score d’una jugadora de bàsket de 18 anys que faci 191 cm? Serà: \\[ \\frac{191-163.1}{18.53}=1.5 \\] Això normalment es llegeix dient que aquesta alçada “està a 1.5 sigmes de l’alçada mitjana.” "],
["estimacio-puntual.html", "Tema 2 Estimació puntual 2.1 Definicions bàsiques 2.2 Mitjana mostral 2.3 Proporció mostral 2.4 Variància mostral 2.5 La t de Student 2.6 “Bons” estimadors 2.7 Estimació de poblacions", " Tema 2 Estimació puntual L’objectiu principal de la inferència estadística és intentar obtenir informació sobre tota una població a partir de només una mostra, com quan volem saber si un brou és fat o salat tastant-ne només una culleradeta. El primer tipus d’informació que ens sol interessar és el valor concret d’alguna característica numèrica (una proporció, una mitjana…) d’una població, per exemple per poder escriure un titular com el següent: Figura 2.1: https://www.efesalud.com/miopia-estudio-universitarios Aquest 60% no s’ha obtingut fent passar a tots els universitaris espanyols un test de miopia, ni tan sols demanant-los a tots si són miops o no, sinó que simplement s’ha pres una mostra d’universitaris, s’hi ha observat un 60% de miops i s’ha extrapolat aquesta proporció a tot el col·lectiu d’universitaris espanyols. El procés d’intentar endevinar el valor d’un paràmetre d’una població a partir d’una mostra se’n diu estimació puntual, i és el que tractarem en aquest tema. Al tema següent ens centrarem en intentar endevinar el valor d’un paràmetre amb un cert marge d’error i de seguretat. 2.1 Definicions bàsiques Una població és un conjunt d’individus o objectes sobre el que volem obtenir informació. Una mostra de mida \\(n\\) d’una població és simplement un conjunt de \\(n\\) individus (possiblement repetits) de la població. Una població inclou tots els membres d’un grup específic, mentre que una mostra està formada per alguns membres de la població, els que mesuram al nostre estudi. Una mostra aleatòria simple de mida \\(n\\) d’una població s’obté repetint \\(n\\) vegades, cada una de manera independent de les altres, el procés d’escollir equiprobablement un individu de la població; els individus triats es poden repetir. D’aquesta manera, totes les mostres possibles de \\(n\\) individus (possiblement repetits: en diem multiconjunts) tenen la mateixa probabilitat d’obtenir-se. Un estimador (puntual) o estadístic és una funció que aplicada a una mostra d’una població dóna un valor que ens permet estimar alguna cosa que vulguem saber de tota la població. Figura 2.2: Població versus mostra Exemple 2.1 Si escollim a l’atzar, un rere l’altre i permetent que es repeteixin, 30 estudiants de la UIB i mesuram les seves alçades, obtenim una mostra aleatòria simple de mida 30 d’alçades de la població formada pels estudiants de la UIB. Si llavors calculam la mitjana aritmètica d’aquestes alçades amb l’objectiu d’estimar la mitjana de les alçades de tots els estudiants de la UIB, aquesta mitjana és el valor sobre aquesta mostra de l’estimador que anomenarem “mitjana mostral”. Per què prenem una mostra, en lloc d’estudiar directament la població? Doncs perquè sovint és impossible accedir a tota la població: La població pot ser massa gran: per exemple, si volem calcular l’alçada mitjana dels europeus que avui tenen 18 anys, és pràcticament impossible midar-los tots La població pot ser virtual en el sentit que pot contenir membres que en aquest moment ni existeixin: per exemple, si volem saber qualque cosa sobre els diabètics, això hauria d’incloure els passats, que ja són morts, els presents, que n’hi haurà molts que ni saben que ho són, i els futurs, que encara no ho són o per ventura no hagin ni nascut. Simplement, pot ser difícil accedir a tota la població: per exemple, els estudiants de la UIB són relativament pocs, uns 12000, però seria molt difícil aconseguir midar-los tots. I tanmateix, per provar si el brou ha quedat fat, en provau una cullerada (una mostra), no us bebeu tota l’olla (la població), no? Si basta una mostra per als nostres propòsits, no cal esforçar-se en accedir a tota la població. Formalment: Una població és un conjunt on està definida una variable aleatòria (poblacional) \\(X\\). Una mostra aleatòria simple de mida \\(n\\) de la variable aleatòria \\(X\\) és un vector \\((X_1,\\ldots,X_n)\\) format per \\(n\\) còpies independents de \\(X\\). Una realització de la mostra aleatòria simple \\((X_1,\\ldots,X_n)\\) és un vector \\((x_1,\\ldots,x_n)\\) de valors presos per aquestes variables aleatòries. Un estimador és una variable aleatòria \\(f(X_1,\\ldots,X_n)\\) obtinguda aplicant una funció \\(f\\) a una mostra aleatòria simple \\(X_1,\\ldots,X_n\\). Aquest estimador s’aplica a les realitzacions de la mostra i dóna nombres reals. Com que és una variable aleatòria, té distribució (en diem la distribució mostral de l’estimador), esperança, desviació típica (en diem l’error estàndard, o típic, de l’estimador), etc. Exemple 2.2 Podem formalitzar l’Exemple 2.1 de la manera següent: Població: El conjunt dels estudiants de la UIB Variable aleatòria poblacional \\(X\\): Prenem un estudiant de la UIB i midam la seva alçada Mostra aleatòria simple de mida 30: Un vector \\((X_1,\\ldots,X_{30})\\) format per 30 còpies independents de \\(X\\) Una realització d’aquesta mostra aleatòria simple: Un vector \\((x_1,\\ldots,x_{30})\\) obtingut repetint 30 vegades, de manera independent cada una de les altres, el procés d’escollir un estudiant de la UIB i midar-li l’alçada Estimador: La mitjana aritmètica que farem servir sobre aquesta mostra és \\[ \\overline{X}=\\frac{X_1+\\cdots+X_{30}}{30} \\] i sobre la realització concreta obtinguda pren el valor \\[ \\overline{x}=\\frac{x_1+\\cdots+x_{30}}{30} \\] A partir d’ara, quan no hi hagi necessitat de filar prim, cometrem l’abús de llenguatge de dir mostra aleatòria simple tant al vector de variables aleatòries \\((X_1,\\ldots,X_n)\\) com a una realització \\((x_1,\\ldots,x_n)\\in \\mathbb{R}^n\\); i hi ometrem els parèntesis. A la vida real, les mostres aleatòries se solen prendre prohibint les repeticions (sense reposició). No són mostres aleatòries simples, però la situació encara pot tenir salvació. Si la mida \\(N\\) de la població és MOLT més gran que la mida \\(n\\) de la mostra, els resultats per a mostres aleatòries simples valen (aproximadament) per a mostres aleatòries sense reposició, perquè les variables aleatòries que formen la mostra sense reposició són gairebé idèntiques i independents i les repeticions són improbables. Exemple 2.3 Imaginau que teniu una població de 106 individus i en voleu extreure una mostra aleatòria de 10. Si la treieu escollint els individus un a un a l’atzar sense repeticions, la probabilitat a cada moment d’escollir un individu concret dels que quedin és gairebé la mateixa que si permetéssiu repeticions. Per exemple, quan ja portau 9 individus escollits, la probabilitat de triar un individu concret dels que queden és 1/999991=10-6+9·10-12, mentre que si permeteu que surti qualcun dels ja escollits és 1/106=10-6. Observau també que si prenem una mostra aleatòria de 10 individus sense reposició de la nostra població de 106 individus, gairebé és com si hagués estat presa permetent repeticions, perquè per molt que les permetéssim, seria molt improbable que s’hi donàs alguna repetició. Recordau que si una població té \\(N\\) individus, la probabilitat que una mostra aleatòria simple de mida \\(n\\) tingui tots els seus membres diferents és \\[ \\frac{N(N-1)\\cdots (N-n+1)}{N^n}. \\] Per tant, la probabilitat que una mostra aleatòria simple de mida 10 d’una població de mida 106 tengui algun membre repetit és \\[ 1-\\frac{10^6(10^6-1)\\cdots (10^6-9)}{(10^6)^{10}}=0.000045. \\] Molt petita. Per tant, si ens trobam al davant d’una mostra aleatòria de 10 individus d’aquesta població escollida sense permetre repeticions, ens podem creure perfectament que l’hem obtinguda permetent repeticions i que simplement no n’hi ha hagut cap per pur atzar. Ara bé, quan \\(n\\) és relativament gran per comparació amb \\(N\\), ja és mal de creure que una mostra sense repeticions hagi estat escollida permetent-les. Per exemple, si prenem una mostra aleatòria simple (permetent repeticions) de 10 individus d’una població de 100 individus, la probabilitat que escollim qualque individu més d’una vegada és \\[ 1-\\frac{100\\cdot 99\\cdots 91}{100^{10}}=0.37. \\] Més d’una de cada 3 mostres aleatòries simples de 10 individus d’una població de 100 individus contenen qualque repetició, per tant no podem acceptar amb els ulls clucs que si no tenim cap repetició, les hàgim permeses. Exemple 2.4 La UIB té uns 12000 estudiants. El gràfic següent mostra la probabilitat que si prenem una mostra aleatòria simple de \\(n\\) estudiants d’una població de 12000 individus, com ara la UIB, siguin tots diferents, en funció de \\(n\\): f=function(N,i){prod((N:(N-i+1))/N)} prob=sapply(1:200,f,N=1200) plot(1:200, prob, type=&quot;l&quot;, lwd=2, xlab=&quot;n&quot;, ylab=&quot;probabilitat&quot;, xaxp=c(0,200,20),yaxp=c(0,1,10)) El gràfic següent mostra la mida màxima \\(n\\) d’una mostra aleatòria simple extreta d’una població de mida \\(N\\) per que la probabilitat de repeticions sigui menor que 0.05, en funció de \\(N\\): h=function(n){max(which(sapply(1:(n/50),f,N=n)&gt;0.95))} fites=sapply(500+100*(0:150),h) plot(500+100*(0:150), fites, pch=20, xlab=&quot;N&quot;, ylab=&quot;n&quot;, xaxp=c(500,15500,30)) En resum: Si prenem una mostra sense reposició de mida \\(n\\) d’una població de mida \\(N\\) MOLT més gran que n, la tractarem com si fos una mostra aleatòria simple (i direm sense manies que és una mostra aleatòria simple). Per fixar una fita, en aquest curs entendrem que \\(N\\) és prou MOLT més gran que \\(n\\) com per poder aplicar aquesta regla quan \\(N\\) és com a mínim unes 1000 vegades més gran que \\(n\\). A la pràctica, en realitat gairebé mai no disposarem d’una mostra aleatòria. Fixau-vos, per exemple, que per poder obtenir una mostra aleatòria, necessitam una llista de tota la població, per poder sortejar qui cau i qui no cau dins la mostra, i aquesta llista normalment no existeix. Una llista de tots els conills de Mallorca, o de tots els arbres afectats per la Xyllella fastidiosa? Complicat. Així que ens haurem de conformar amb una mostra oportunista (o de conveniència: la que poguem obtenir). Heu de tenir clar que, en principi, els resultats que donarem NO són vàlids per a mostres no aleatòries, però si no tenim res millor… El que es fa aleshores és explicar amb detall com s’ha obtingut la mostra i descriure amb detall les seves característiques, a fi que altres investigadors puguin decidir si els individus “són típics” i podrien passar per una mostra aleatòria, i si poden extrapolar les estimacions al seu context. Per exemple, si per saber l’opinió dels estudiants de Biologia espanyols sobre un tema, ho deman als meus estudiants, serà una mostra clarament oportunista i caldrà llavors esbrinar si podria passar per una mostra aleatòria simple a efectes de l’estudi que vull portar a terme. Els estimadors tenen sempre sentit per a mostres en general, però gairebé tots els teoremes que estableixen les seves propietats són vertaders només sota determinades restriccions (mostra aleatòria simple, condicions extra sobre \\(X\\), …), per la qual cosa les seves conseqüències tan sols són segures sota aquestes restriccions. 2.2 Mitjana mostral La mitjana mostral \\(\\overline{X}\\) d’una mostra aleatòria de mida \\(n\\) d’una variable aleatòria \\(X\\) és simplement la seva mitjana artimètica. Formalment, la mitjana mostral és una variable aleatòria obtinguda prenent \\(n\\) còpies \\(X_1,\\ldots,X_n\\) de la variable aleatòria \\(X\\) i calculant \\[ \\overline{X}=\\frac{X_1+\\cdots+X_n}{n} \\] Com a conseqüència del Teorema 1.1, tenim el següent: Teorema 2.1 Siguin \\(X\\) una variable aleatòria d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\), \\(X_1,\\ldots,X_n\\) una mostra aleatòria de \\(X\\) i \\(\\overline{X}\\) la seva mitjana mostral. Aleshores El valor esperat de \\(\\overline{X}\\) és \\(\\mu_{\\overline{X}}=\\mu_X\\). Si la mostra aleatòria és simple, l’error estàndard o típic de \\(\\overline{X}\\) (la desviació típica de \\(\\overline{X}\\)) és \\(\\sigma_{\\overline{X}}={\\sigma_X}/{\\sqrt{n}}\\). En efecte, com que \\[ \\overline{X}=\\frac{1}{n}X_1+\\cdots +\\frac{1}{n}X_n \\] i les variables \\(X_1,\\ldots,X_n\\) són còpies de \\(X\\), i per tant tenen totes esperança \\(\\mu_X\\) i variància \\(\\sigma^2_X\\), aplicant el Teorema 1.1 tenim que \\[ \\mu_{\\overline{X}}=\\overbrace{\\frac{1}{n}\\mu_X+\\cdots +\\frac{1}{n}\\mu_X}^n=\\mu_X \\] i, si \\(X_1,\\ldots,X_n\\) són independents, \\[ \\sigma_{\\overline{X}}=\\sqrt{\\overbrace{\\frac{1}{n^2}\\sigma^2_X+\\cdots+ \\frac{1}{n^2}\\sigma^2_X}^n}=\\sqrt{\\frac{n}{n^2}\\sigma^2_X}=\\frac{\\sigma_X}{\\sqrt{n}} \\] Per tant: \\(\\overline{X}\\) és un estimador puntual de \\(\\mu_X\\). \\(\\mu_{\\overline{X}}=\\mu_X\\) (esperam que la mitjana mostral doni \\(\\mu_X\\)) significa que si repetíssim moltes vegades el procés de prendre una mostra aleatòria simple de mida \\(n\\) i calcular-ne la mitjana mostral, molt probablement el valor mitjà d’aquestes mitjanes s’acostaria molt a \\(\\mu_X\\). \\(\\sigma_{\\overline{X}}= \\sigma_X/\\sqrt{n}\\) indica que la dispersió dels resultats de \\(\\overline{X}\\) creix amb la variabilitat de \\(X\\) i decreix amb la mida \\(n\\) de la mostra, tendint a 0 quan \\(n\\to\\infty\\). Exemple 2.5 El fitxer tests.txt que trobareu a l’url https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt conté les notes (sobre 100) de tests dels estudiants de Matemàtiques I de fa uns cursos. El guardam en un vector anomenat tests: tests=scan(&quot;https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt&quot;) head(tests) ## [1] 70 44 90 64 76 68 la mida de la població és N=length(tests) N ## [1] 185 La seva mitjana, que és la mitjana poblacional, és mu=mean(tests) mu ## [1] 55.43243 Si en prenem una mostra aleatòria simple, per exemple de mida \\(n=40\\), la seva mitjana mostral no té per què coincidir amb la mitjana poblacional: n=40 MAS=sample(tests,n,replace=TRUE) # Una mostra aelatòria simple x.barra=mean(MAS) # La mitjana mostral x.barra ## [1] 53.5 Però si prenem moltes mostres aleatòries simples, la mitjana de les seves mitjanes és molt probable que sí que s’acosti a la mitjana poblacional. Vegem si tenim sort: mitjanes=replicate(10^5,mean(sample(tests,n,replace=TRUE))) mean(mitjanes) ## [1] 55.4187 Vegem ara que la desviació típica d’aquesta mostra de mitjanes s’acosta a l’error típic de la mitjana mostral, no a la desviació típica de la població: La desviació típica poblacional: sigma=sd(tests) sigma ## [1] 21.44044 La desviació típica de la mostra de mitjanes: sd(mitjanes) ## [1] 3.384683 L’error típic de la mitjana mostral: sigma/sqrt(n) ## [1] 3.390031 Recordau del Teorema 1.2 que una combinació lineal de variables aleatòries normals independents torna a ser normal. Com que la mitjana mostral d’una mostra aleatòria simple és una combinació lineal de variables aleatòries independents, obtenim el resultat següent: Teorema 2.2 Siguin \\(X\\) una variable aleatòria normal \\(N(\\mu_X,\\sigma_X)\\) i \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de \\(X\\). Aleshores, la seva mitjana mostral \\(\\overline{X}\\) és normal, i en concret \\[ \\overline{X}\\sim N\\Big(\\mu_X,\\frac{\\sigma_X}{\\sqrt{n}}\\Big) \\] i per tant \\[ Z=\\frac{\\overline{X}-\\mu_X}{{\\sigma_X}/{\\sqrt{n}}}\\sim N(0,1) \\] El teorema següent diu que la conclusió del teorema anterior és aproximadament vertadera si la mida \\(n\\) de les mostres aleatòries simples és gran: Teorema 2.3 (Teorema Central del Límit) Siguin \\(X\\) una variable aleatòria qualsevol d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\) i \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de \\(X\\). Quan \\(n\\to \\infty\\), la distribució de probabilitats de la seva mitjana mostral \\(\\overline{X}\\) tendeix a la d’una varianle normal \\[ N\\Big(\\mu_X,\\frac{\\sigma_X}{\\sqrt{n}}\\Big) \\] i per tant la distribució de probabilitats de \\[ Z=\\frac{\\overline{X}-\\mu_X}{{\\sigma_X}/{\\sqrt{n}}} \\] tendeix a la d’una variable normal estàndard \\(N(0,1)\\). Com us podeu imaginar, quan un resultat l’anomenen Teorema Central de qualque cosa és perquè és molt important. Normalment aplicarem el Teorema Central del Límit de la manera següent: Siguin \\(X\\) una variable aleatòria qualsevol d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\) i \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de \\(X\\). Si la mida \\(n\\) de la mostra és gran, la seva mitjana mostral \\(\\overline{X}\\) és aproximadament normal \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\). En aquest curs, entendrem que \\(n\\) és prou gran com per poder aplicar aquest “resultat” si és més gran o igual que 30 o 40, potser menys com més se sembli \\(X\\) a una normal i potser més si la \\(X\\) és molt diferent d’una normal. A partir d’ara, sovint cometrem l’abús de llenguatge d’ometre l’adverbi “aproximadament” de l’expressió anterior, i direm simplement que si \\(n\\) és gran, \\(\\overline{X}\\) és normal. Però hem de recordar que aquest “és normal” en realitat vol dir “la seva distribució és aproximadament la d’una variable normal”. Exemple 2.6 Suposem que tenim una variable aleatòria \\(X\\) de mitjana poblacional \\(\\mu_X=3\\) i desviació típica poblacional \\(\\sigma_X=0.2\\) i que en prenem mostres aleatòries simples de mida 100. Pel Teorema Central del Límit, la distribució de la mitjana mostral \\(\\overline{X}\\) és \\[ N\\Big(3,\\frac{0.2}{\\sqrt{100}}\\Big)=N(3,0.02) \\] Exemple 2.7 Tornem a la situació de l’Exemple 2.5. Teníem les notes guardades en un vector anomenat tests. Amb l’histograma següent podem veure que aquestes notes no tenen pinta de seguir una distribució normal. fact.trans=hist(tests,plot=FALSE)$counts[1]/hist(tests,plot=FALSE)$density[1] hist(tests,col=&quot;light blue&quot;,xlab=&quot;Notes dels tests&quot;, ylab=&quot;Freqüències&quot;,main=&quot;Histograma de notes de tests&quot;) curve(fact.trans*dnorm(x,mean(tests),sd(tests)),col=&quot;red&quot;,lwd=2,add=TRUE) A l’Exemple 2.5 també hem construit un vector anomenat mitjanes format per 105 mitjanes mostrals de mostres aleatòries simples de notes de mida 40. Pel Teorema Central del Límit, aquestes mitjanes mostrals haurien de seguir aproximadament una distribució normal, malgrat que la “població original” (les notes dels tests) no sigui normal. Vegem-ho amb un histograma, on hem afegit la densitat de la normal \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\) predita pel Teorema Central del Límit. fact.trans.m=hist(mitjanes,plot=FALSE)$counts[1]/hist(mitjanes,plot=FALSE)$density[1] hist(mitjanes,col=&quot;light blue&quot;,xlab=&quot;Mitjanes&quot;, ylab=&quot;Freqüències&quot;,main=&quot;Histograma de la mostra de mitjanes&quot;) curve(fact.trans.m*dnorm(x,mu,sigma/sqrt(n)),col=&quot;red&quot;,lwd=2,add=TRUE) L’exemple següent és un tipus de pregunta que més endavant ens preocuparà molt. Exemple 2.8 L’alçada d’una espècie de matolls té valor mitjà 115 cm, amb una desviació típica de 25 cm. Si prenem una mostra aleatòria simple de 100 matolls d’aquesta espècie, quina és la probabilitat que la mitjana mostral de les alçades sigui més petita que 110 cm? Diguem \\(X\\) a la variable aleatòria definida per les alçades d’aquests matolls. Pel Teorema Central del Límit, la mitjana mostral \\(\\overline{X}\\) de mostres aleatòries simples de 100 alçades segueix una distribució \\(N(115,25/\\sqrt{100})=N(115,2.5)\\). Llavors, la probabilitat que ens demanen és \\[ P(\\overline{X}&lt; 110) \\] que podem calcular amb round(pnorm(110,115,2.5),4) ## [1] 0.0228 Un 2.28% de les mostra aleatòries simples de 100 matolls d’aquesta espècie tenen la mitjana de les alçades més petita que 110 cm. Sigui ara \\(X_1,\\ldots, X_n\\) una mostra aleatòria sense reposició de mida \\(n\\) d’una variable aleatòria \\(X\\) d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\). Si \\(n\\) és molt petit en relació a la mida \\(N\\) de la població, ja hem explicat que podem suposar que aquesta mostra aleatòria és simple i per tant tot funciona com fins ara; en particular, en aquest cas entendrem que els tres teoremes anteriors són vertaders. Si \\(n\\) és gran en relació a \\(N\\), aleshores el resultat per l’esperança segueix essent vertader (al Teorema 2.1.a no suposàvem que la mostra fos simple), i per tant encara tenim que \\[ \\mu_{\\overline{X}}=\\mu_X. \\] Però en aquest cas cal modificar la fórmula del Teorema 2.1.b per a la desviació típica, que ara és: \\[ \\sigma_{\\overline{X}}=\\frac{\\sigma_X}{\\sqrt{n}}\\cdot\\sqrt{\\frac{N-n}{N-1}} \\] A més, en aquest cas les conclusions dels Teoremes 2.2 i 2.3 no són certes, ni tan sols amb aquesta correcció de l’error típic. Al terme \\[ \\sqrt{\\frac{N-n}{N-1}} \\] que apareix a la fórmula anterior li diuen el factor de població finita. Si us en recordau, aquest factor de població finita és el factor que passava de la desviació típica d’una distribució binomial a la d’una hipergeomètrica. En efecte: Si \\(X_B\\sim B(n,p)\\), \\(\\sigma^2_{X_B}=np(1-p)\\) i per tant \\(\\sigma_{X_B}=\\sqrt{np(1-p)}\\) Si \\(X_H\\sim H(A,B,n)\\), amb \\(A+B=N\\) i \\(p=A/N\\), \\[ \\begin{array}{rl} \\sigma^2_{X_H} &amp; \\displaystyle =\\dfrac{nAB}{(A+B)^2}\\cdot\\dfrac{A+B-n}{A+B-1}\\\\ &amp; \\displaystyle =n\\cdot\\frac{A}{N}\\cdot\\frac{N-A}{N}\\cdot\\dfrac{N-n}{N-1}\\\\ &amp; \\displaystyle = np(1-p)\\cdot \\dfrac{N-n}{N-1} \\end{array} \\] i per tant \\[ \\sigma_{X_H}=\\sqrt{np(1-p)}\\cdot \\sqrt{\\dfrac{N-n}{N-1}}=\\sigma_{X_B}\\cdot \\sqrt{\\dfrac{N-n}{N-1}}. \\] Exemple 2.9 Tornem a la situació dels Exemples 2.5 i 2.7. Què passa si prenem les mostres aleatòries de notes de tests sense reposició? Prenguem ara 105 mostres aleatòries sense reposició de 40 notes de tests. mitjanes.norep=replicate(10^5,mean(sample(tests,40))) Un altre cop, la mitjana d’aquest vector de mitjanes hauria de ser propera a la mitjana de la població original, que era 55.43: round(mean(mitjanes.norep),2) ## [1] 55.42 Calculem ara la desviació típica d’aquest vector de mitjanes: round(sd(mitjanes.norep),2) ## [1] 3 Aquesta desviació típica no s’apropa a la desviació típica de la població partida per l’arrel quadrada de la mida de les mostres, que hem calculat abans i era 3.39. Pel que acabam d’explicar, la desviació típica d’aquest vector de mitjanes de mostres sense reposició hauria de ser molt propera a la desviació típica de la població partida per l’arrel quadrada de la mida de les mostres i tot multiplicat pel factor de població finita \\(\\sqrt{(N-n)/(N-1)}\\), on \\(N\\) és la mida de la població, és a dir, la longitud del vector tests, i \\(n\\) la mida de les mostres. Vegem si és veritat: round((sd(tests)/sqrt(n))*sqrt((N-n)/(N-1)),2) ## [1] 3.01 Això ja s’acosta més a la desviació típica del vector de mitjanes de mostres sense reposició, que ha valgut 3. 2.3 Proporció mostral Suposem que ara tenim una variable aleatòria poblacional \\(X\\) que és Bernoulli amb probabilitat d’èxit (o proporció d’èxits) \\(p_X\\). Entendrem que \\(X\\) pren els valors 1 (èxit) o 0 (fracàs). Recordau que \\(E(X)=p_X\\) i \\(\\sigma_X=\\sqrt{p_X(1-p_X)}\\). Sigui \\(X_1,\\ldots,X_n\\) una mostra aleatòria de mida \\(n\\) de \\(X\\) i sigui \\(S=\\sum_{i=1}^n X_i\\) el nombre d’èxits observats en aquesta mostra aleatòria. La proporció mostral d’èxits de la nostra mostra és \\[ \\widehat{p}_X=\\frac{S}{n}=\\frac{\\sum_{i=1}^n X_i}{n}. \\] Recordau que si prenem mostres aleatòries simples, la \\(S\\) és una variable aleatòria binomial \\(B(n,p_X)\\). Però és un doi dir que la proporció mostral \\(\\widehat{p}_X\\) és una variable aleatòria binomial, ni que només sigui perquè les variables aleatòries binomials prenen valors nombres naturals i els valors que pot prendre \\(\\widehat{p}_X\\) són fraccions entre 0 i 1. Fixau-vos que \\(\\widehat{p}_X\\) és un cas particular de la mitjana mostral \\(\\overline{X}\\), per tant per a les proporcion mostrals val tot el que hem dit fins ara per a mitjanes mostrals: Teorema 2.4 Si \\(X\\) és una variable aleatòria Bernoulli amb probabilitat d’èxit \\(p_X\\) i \\(X_1,\\ldots,X_n\\) és una mostra aleatòria de mida \\(n\\) de \\(X\\), de proporció mostral \\(\\widehat{p}_X\\), aleshores \\(\\mu_{\\widehat{p}_X}=p_X\\) Si la mostra aleatòria és simple, \\(\\sigma_{\\widehat{p}_X}=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) Si la mostra aleatòria és sense reposició i \\(n\\) és relativament gran per comparació amb la mida de la població \\(N\\), \\[ \\sigma_{\\widehat{p}_X}=\\sqrt{\\frac{p_X(1-p_X)}{n}}\\cdot \\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] Pel Teorema Central del Límit, si la mostra és aleatòria simple i la seva mida \\(n\\) és gran, la distribució de \\(\\widehat{p}_X\\) és aproximadament la d’una variable normal \\[ N\\left({p}_X,\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}\\right) \\] i per tant \\[ \\frac{\\widehat{p}_X-p_X}{\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}} \\] és aproximadament \\(N(0,1)\\). Alguns comentaris: \\(\\mu_{\\widehat{p}_X}=p_X\\): Si repetíssim moltes vegades el procés de prendre una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria de Bernoulli \\(X\\) i calcular-ne la proporció mostral d’èxits, molt probablement la mitjana d’aquestes proporcions mostrals s’acostaria molt a \\(p_X\\) En particular, \\(\\widehat{p}_X\\) serveix per estimar \\(p_X\\) \\(\\sigma_{\\widehat{p}_X}= \\sqrt{{p_X(1-p_X)}/{n}}\\): la variabilitat dels resultats de \\(\\widehat{p}_X\\) decreix amb \\(n\\) i tendeix a 0 quan \\(n\\to \\infty\\) \\(\\sqrt{{p_X(1-p_X)}/{n}}\\) és l’error típic de \\(\\widehat{p}_X\\). L’estimam amb l’error típic de l’estimació \\(\\sqrt{{\\widehat{p}_X(1-\\widehat{p}_X)}/{n}}\\). A partir d’ara, sovint cometrem l’abús de llenguatge d’ometre l’adverbi “aproximadament” de l’apartat (4) del teorema anterior, i direm simplement que si \\(n\\) és gran, \\(\\widehat{p}_X\\) és normal. Però hem de recordar que aquest “és normal” en realitat vol dir “la seva distribució és aproximadament la d’una variable normal”. Exemple 2.10 Tornem una altra vegada a la situació dels Exemples 2.5 i 2.7. Vaig a traduir el fitxer de notes de tests en un vector binari: 0 per suspens (haver tret menys de 50) i 1 per aprovat (haver tret 50 o més): # Iniciam totes les notes a 1 aprovs=rep(1,length(tests)) # Posam 0 on la nota del test és suspesa aprovs[which(tests&lt;50)]=0 Aquest vector aprovs el podem entendre com una població de Bernoulli de probabilitat poblacional d’èxit (aprovat) \\(p_X\\). Les proporcions de suspesos i aprovats són: round(prop.table(table(aprovs)),4) ## aprovs ## 0 1 ## 0.4054 0.5946 Per tant, \\(p_X\\) és: p_X=as.numeric(prop.table(table(aprovs))[2]) round(p_X,4) ## [1] 0.5946 Ara n’extreurem 105 mostres aleatòries simples de mida 40, en calcularem les proporcions mostrals d’aprovats i comprovarem si es confirmen les conclusions del teorema anterior. set.seed(100) props.mostrals=replicate(10^5,mean(sample(aprovs,40,rep=TRUE))) La mitjana d’aquest vector de proporcions hauria de ser propera a la proporció poblacional d’aprovats \\(p_X=0.5946\\). round(mean(props.mostrals),4) ## [1] 0.5942 Vegem ara la seva desviació típica: round(sd(props.mostrals),4) ## [1] 0.0774 Pel Teorema 2.4, sabem que això hauria de ser proper a \\(\\sqrt{p_X(1-p_X)/n}\\) round(sqrt(p_X*(1-p_X)/40),4) ## [1] 0.0776 I pel Teorema Central del Límit, aquestes proporcions mostrals haurien de seguir aproximadament una distribució normal. Vegem-ho amb un histograma: fact.trans.p=hist(props.mostrals,plot=FALSE)$counts[1]/hist(props.mostrals,plot=FALSE)$density[1] hist(props.mostrals,col=&quot;light blue&quot;,xlab=&quot;Proporcions mostrals&quot;, ylab=&quot;Freqüències&quot;,main=&quot;Histograma de la mostra de proporcions&quot;) curve(fact.trans.p*dnorm(x,mean(props.mostrals),sd(props.mostrals)), col=&quot;red&quot;,lwd=2,add=TRUE) I això que la mida de les mostres, 40, no és especialment gran. Exemple 2.11 Un 59.1% dels estudiants de la UIB són dones. Hem pres una mostra més o menys aleatòria de 60 estudiants de la UIB i hi hem trobat 40 dones, un 66.67%. Ens demanam si 40 de 60 és una quantitat raonable de dones en una mostra aleatòria simple d’estudiants de la UIB, o si són moltes (atès que hi esperaríem al voltant d’un 59% de dones). Aquesta pregunta, que serà molt típica d’aquí a pocs temes, la traduïm en la següent pregunta: Si prenem una mostra aleatòria simple de 60 estudiants, quina és la probabilitat que la proporció mostral de dones sigui superior al 66.67%? Una manera senzilla de respondre aquesta pregunta és aprofitar el Teorema Central del Límit, segons el qual la proporció mostral \\(\\widehat{p}_X\\) de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix una distribució aproximadament normal amb \\(\\mu=0.591\\) i \\[ \\sigma=\\sqrt{\\dfrac{0.591(1-0.591)}{60}}=0.0635 \\] Per tant, la probabilitat que \\(\\widehat{p}_X\\geqslant 0.6667\\) és (recordau, aproximadament) round(1-pnorm(0.6667,0.591,0.0635),4) ## [1] 0.1166 Això ens diu que, de mitjana, aproximadament 1 de cada 9 mostres aleatòries simples de 60 estudiants de la UIB conté almenys 40 dones. Naturalment, si tenim R o qualsevol altra manera de calcular probabilitats, també podem fer servir la distribució binomial per calcular aquesta probabilitat, i de fet és més correcte, ja que la probabilitat anterior ha emprat una aproximació de la distribució de \\(\\widehat{p}_X\\) i en canvi sabem que el nombre de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix de manera exacta una distribució binomial \\(B(60,0.591)\\). Com que el 66.67% de la pregunta en realitat representa 40 dones, la probabilitat exacta demanada és round(1-pbinom(39,60,0.591),4) ## [1] 0.1441 Recordau que si \\(X\\) és una variable aleatòria discreta que pren valors enters, com ara la binomial, \\(P(X\\geqslant 40)=1-P(X\\leqslant 39)\\). Aquesta probabilitat exacta (exacta, si el 59.1% és el percentatge exacte de dones a la UIB) ens diu que, de mitjana, 1 de cada 7 mostres aleatòries simples de 60 estudiants de la UIB conté almenys 40 dones. 2.4 Variància mostral Sigui \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria \\(X\\) d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\). La variància mostral d’aquesta mostra aleatòria simple és \\[ \\widetilde{S}_{X}^2=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n-1} \\] La seva desviació típica mostral és \\[ \\widetilde{S}_{X}=+\\sqrt{\\widetilde{S}_{X}^2} \\] A més, de tant en tant també farem servir la variància i la desviació típica “a seques”: \\[ \\begin{array}{l} \\displaystyle S^2_{X}=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n}=\\frac{(n-1)}{n}\\widetilde{S}^2_{X}\\\\ \\displaystyle S_X=+\\sqrt{S_X^2} \\end{array} \\] La variància a seques admet la següent expressió senzilla: \\[ S^2_X=\\frac{\\sum_{i=1}^n X_{i}^2}{n}-\\overline{X}^2 \\] En efecte: \\[ \\begin{array}{l} \\displaystyle \\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n}=\\frac{1}{n}\\sum_{i=1}^n (X_{i}^2-2\\overline{X}X_i+\\overline{X}^2)\\\\ \\displaystyle\\qquad = \\frac{1}{n}\\Big(\\sum_{i=1}^n X_{i}^2-2\\overline{X}\\sum_{i=1}^n X_{i}+n\\overline{X}^2\\Big)\\\\ \\displaystyle\\qquad =\\frac{\\sum_{i=1}^n X_{i}^2}{n}-2\\overline{X}\\frac{\\sum_{i=1}^n X_{i}}{n}+\\frac{n\\overline{X}^2}{n}\\\\ \\displaystyle\\qquad =\\frac{\\sum_{i=1}^n X_{i}^2}{n}-2\\overline{X}\\cdot\\overline{X} + \\overline{X}^2=\\frac{\\sum_{i=1}^n X_{i}^2}{n}- \\overline{X}^2 \\end{array} \\] Teorema 2.5 Si \\(X\\) és una variable aleatòria normal de desviació típica \\(\\sigma_X\\) i \\(X_1,\\ldots,X_n\\) és una mostra aleatòria simple de mida \\(n\\) de \\(X\\), amb variància mostral \\(\\widetilde{S}_{X}^2\\), aleshores \\(\\mu_{\\widetilde{S}_{X}^2}=\\sigma_{X}^2\\) i la variable aleatòria \\[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2} \\] té distribució coneguda: \\(\\chi_{n-1}^2\\) (es llegeix khi quadrat amb \\(n-1\\) graus de llibertat). La lletra \\(\\chi\\) en català es diu khi; en castellà, ji; i en anglès, chi, pronunciat xai. De la distribució \\(\\chi_n^2\\), on \\(n\\) són els graus de llibertat, heu de saber que: Per definició, és la distribució de la suma dels quadrats de \\(n\\) variables aleatòries normals estàndard independents. És a dir, si \\(Z_{1},Z_{2},\\ldots, Z_{n}\\sim N(0,1)\\) són independents, la variable \\[ Z_{1}^{2}+Z_{2}^{2}+\\cdots +Z_{n}^{2} \\] té distribució \\(\\chi_n^2\\). La \\(n\\) és un paràmetre del que depèn la seva distribució Amb R és chisq Si \\(X\\) és una variable aleatòria amb distribució \\(\\chi_n^2\\), aleshores \\(\\mu_X=n\\) i \\(\\sigma_X^2=2 n\\) Per a \\(n\\) petits, la distribució d’una \\(\\chi_{n}^2\\) presenta una cua a la dreta, i a mida que \\(n\\) creix, pel Teorema Central del Límit, es va aproximant a una distribució normal \\(N(n,\\sqrt{2n})\\), com podeu veure als gràfics següents curve(dchisq(x,1),col=1,lwd=2,xlim=c(0,20),xlab=&quot;&quot;,ylab=&quot;&quot;,ylim=c(0,0.3),main=&quot;Algunes khi quadrat&quot;) curve(dchisq(x,2),col=2,lwd=2,add=TRUE) curve(dchisq(x,3),col=3,lwd=2,add=TRUE) curve(dchisq(x,4),col=4,lwd=2,add=TRUE) curve(dchisq(x,5),col=5,lwd=2,add=TRUE) curve(dchisq(x,10),col=6,lwd=2,add=TRUE) legend(&quot;topright&quot;,col=1:6,lty=c(1,1), lwd=c(2,2),legend=paste(&quot;n=&quot;,c(1:5,10),sep=&quot;&quot;),cex=0.8) curve(dchisq(x,300),xlim=c(150,450),lwd=2,xlab=&quot;&quot;,ylab=&quot;&quot;,main=&quot;Khi quadrat vs Normal&quot;) curve(dnorm(x,300,sqrt(600)),lwd=2,col=&quot;red&quot;,add=TRUE) legend(&quot;topleft&quot;,col=c(&quot;black&quot;,&quot;red&quot;),lty=c(1,1), lwd=c(2,2),legend=c(&quot;Khi quadrat amb n=300&quot;,&quot;Normal&quot;),cex=0.7) Tornem un instant a això dels graus de llibertat. Per què diem que la variància (mostral) té \\(n-1\\) graus de llibertat? Doncs perquè si volem construir un conjunt de \\(n\\) nombres \\(x_1,\\ldots,x_n\\) que tenguin variància un valor donat, posem \\(y_0\\), aleshores en principi podem escollir \\(n-1\\) d’ells, \\(x_1,\\ldots,x_{n-1}\\), com volguem i aleshores el darrer, \\(x_n\\), queda bastant fixat. En matemàtiques això se sol expressar dient que “tenim \\(n-1\\) graus de llibertat a l’hora d’escollir \\(x_1,\\ldots,x_n\\) amb variància fixada \\(y_0\\)”. En efecte, si fixam el valor \\(y_0\\geqslant 0\\) de la variància i volem trobar \\(x_1,\\ldots,x_{n}\\) tals que \\[ y_0=\\frac{\\sum_{i=1}^n (x_i-\\overline{x})^2}{n}=\\frac{\\sum_{i=1}^n x_i^2}{n}-\\overline{x}^2 \\] vegem que per a qualssevol valors de \\(x_1,\\ldots,x_{n-1}\\), el valor de \\(x_n\\) queda fixat per una equació quadràtica: \\[ \\begin{array}{l} ny_0 &amp; =\\displaystyle \\sum_{i=1}^n x_i^2-n\\overline{x}^2= \\sum_{i=1}^n x_i^2-n\\Big(\\frac{\\sum_{i=1}^n x_i}{n}\\Big)^2\\\\ &amp; =\\displaystyle \\sum_{i=1}^n x_i^2-\\frac{(\\sum_{i=1}^n x_i)^2}{n}\\\\ &amp; \\displaystyle =\\frac{1}{n}\\left(n\\sum_{i=1}^n x_i^2-\\Big(\\sum_{i=1}^{n} x_i\\Big)^2\\right)\\\\ &amp; =\\displaystyle \\frac{1}{n}\\left(n\\sum_{i=1}^{n-1} x_i^2+n\\mathbf{x_n}^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2\\right.\\\\ &amp; \\displaystyle\\qquad\\qquad \\left. -2\\Big(\\sum_{i=1}^{n-1} x_i\\Big)\\mathbf{x_n}-\\mathbf{x_n}^2\\right)\\\\ &amp; =\\displaystyle \\frac{1}{n}\\left((n-1)\\mathbf{x_n}^2-2\\Big(\\sum_{i=1}^{n-1} x_i\\Big)\\mathbf{x_n}\\right.\\\\ &amp; \\displaystyle\\qquad\\qquad \\left.+n\\sum_{i=1}^{n-1} x_i^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2 \\right) \\end{array} \\] d’on (multiplicant els dos costats de la igualtat per \\(n\\) i dividint-los per \\(n-1\\)) obtenim, finalment, l’equació de segon grau en \\(\\mathbf{x_n}\\) \\[ \\mathbf{x_n}^2-\\frac{2\\sum_{i=1}^{n-1} x_i}{n-1}\\mathbf{x_n}+\\frac{n\\sum_{i=1}^{n-1} x_i^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2-n^2y_0^2}{n-1}=0 \\] Per tant, fixat \\(y_0\\) i un cop escollits \\(x_1,\\ldots,x_{n-1}\\), el darrer valor \\(x_n\\) ha de ser per força una solució d’aquesta equació de segon grau. Fixau-vos que aquesta equació no sempre té solució real, perquè pot tenir el discriminant negatiu. Per tant exageràvem un poc dient que podíem triar \\(x_1,\\ldots,x_{n-1}\\) “com vulguem”. Per exemple, si voleu que la variància sigui 0 i preneu \\(x_1,\\ldots,x_{n-1}\\) no tots iguals, podeu estar ben segurs que no trobareu cap \\(x_n\\) que satisfaci aquesta equació: per tenir variància 0, \\(x_1,\\ldots,x_n\\) han de ser tots iguals. Però el que ha de quedar clar és que un cop escollits \\(x_1,\\ldots,x_{n-1}\\), \\(x_n\\) ja no pot ser qualsevol, pot prendre com a màxim dos valors diferents. 2.5 La t de Student Tornem a les mitjanes mostrals de variables normals. Teorema 2.6 Sigui \\(X\\) una variable \\(N(\\mu_X,\\sigma_X)\\) i sigui \\(X_1,\\ldots,X_n\\) una mostra aleatòria simple de \\(X\\), amb mitjana \\(\\overline{X}\\) i desviació típica mostral \\(\\widetilde{S}_{X}\\). Aleshores, la variable aleatòria \\[ T=\\frac{\\overline{X}-\\mu_X}{\\widetilde{S}_{X}/\\sqrt{n}} \\] segueix una distribució coneguda, anomenada t de Student amb \\(n-1\\) graus de llibertat, \\(t_{n-1}\\). A \\(\\widetilde{S}_{X}/\\sqrt{n}\\) li diem l’error típic, o estàndard, de la mostra: estima l’error típic \\(\\sigma_X/\\sqrt{n}\\) de \\(\\overline{X}\\). De la distribució t de Student amb \\(n\\) graus de llibertat, \\(t_{n}\\), heu de saber que: Amb R és t La \\(n\\) és un paràmetre del que depèn la seva distribució Si \\(T_{n}\\) és una variable amb distribució \\(t_{n}\\), aleshores \\(\\mu_{T_{n}}=0\\) si \\(n\\geqslant 2\\) i \\(\\sigma_{T_{n}}^2=n/(n-2)\\) si \\(n\\geqslant 3\\) La funció de densitat d’una variable \\(T_{n}\\) amb distribució \\(t_{n}\\) és simètrica al voltant de 0 (com la d’una \\(N(0,1)\\)): \\[ P(T_{n}\\leqslant-x)=P(T_{n}\\geqslant x)=1-P(T_{n}\\leqslant x) \\] Si \\(n\\) és gran, la distribució d’una variable \\(T_{n}\\) amb distribució \\(t_{n}\\) és aproximadament la d’una \\(N(0,1)\\) (però amb més variància: un poc més aplatada), com podeu veure als gràfics següents: curve(dnorm(x),col=1,lwd=2,xlim=c(-4,4),xlab=&quot;&quot;,ylab=&quot;&quot;,ylim=c(0,0.4), main=&quot;Algunes t de Student&quot;) curve(dt(x,2),col=2,lwd=2,add=TRUE) curve(dt(x,3),col=3,lwd=2,add=TRUE) curve(dt(x,4),col=4,lwd=2,add=TRUE) curve(dt(x,5),col=5,lwd=2,add=TRUE) curve(dt(x,10),col=6,lwd=2,add=TRUE) legend(&quot;topleft&quot;,col=1:6,lty=rep(1,6), lwd=rep(2,6), legend=c(&quot;Normal estàndard&quot;, paste(&quot;Student amb g.l.=&quot;,c(2:5,10),sep=&quot;&quot;)),cex=0.7) curve(dnorm(x),col=1,lwd=2,xlim=c(-4,4),xlab=&quot;&quot;,ylab=&quot;&quot;,ylim=c(0,0.4), main=&quot;t vs Normal estàndard&quot;) curve(dt(x,50),col=2,lwd=2,add=TRUE) legend(&quot;topleft&quot;,col=1:2,lty=rep(1,2), lwd=rep(2,2), legend=c(&quot;Normal estàndard&quot;, &quot;Student amb g.l.=50&quot;),cex=0.7) El fet que una t de Student sigui més aplatada que una normal estàndard \\(Z\\) implica que les cues de la t tenen major probabilitat que les de \\(Z\\) (fixau-vos que als gràfics anteriors els extrems de les densitats de les t estan per damunt dels de la de \\(Z\\)), la qual cosa es tradueix en el fet que és més probable obtenir valors lluny del 0 amb una t de Student que amb una \\(N(0,1)\\). Indicarem amb \\(t_{n,q}\\) el \\(q\\)-quantil d’una variable aleatòria \\(T_{n}\\) que segueix una distribució \\(t_n\\). És a dir, \\(t_{n,q}\\) és el valor tal que \\[ P(T_{n}\\leqslant t_{n,q})=q \\] Per la simetria de la distribució \\(t_n\\), \\[ t_{n,q}=-t_{n,1-q}. \\] Hi ha algunes propietats dels quantils de la t de Student que heu de saber, per poder aplicar-les quan no tingueu a l’abast R o una apli per calcular quantils: \\(t_{n ,q}\\approx z_{q}\\) si \\(n\\) és molt gran, posem \\(n \\geqslant 200\\). Per exemple qt(0.975,300) # t_{300,0.975} ## [1] 1.967903 qnorm(0.975) # z_0.975 ## [1] 1.959964 \\(t_{n,0.95}\\) (per a \\(10\\leqslant n\\leqslant 200\\)) està entre 1.65 i 1.8; ho podeu aproximar \\(t_{n,0.95}\\approx 1.7\\) \\(t_{n,0.975}\\) (per a \\(10\\leqslant n\\leqslant 200\\)) està entre 1.97 i 2.2; ho podeu aproximar \\(t_{n,0.95}\\approx 2\\) Comprovau amb R les afirmacions sobr els quantils de la t de Student dels darrers dos punts. Abans de tancar aquesta secció, recordau que, donada una variable aleatòria \\(X\\), no heu de confondre: Desviació típica (o estàndard) de la variable aleatòria, \\(\\sigma_X\\): El paràmetre poblacional, normalment desconegut Desviació típica (o estàndard) (sigui mostral, \\(\\widetilde{S}_X\\), o a seques, \\(S_X\\)) d’una mostra: L’estadístic que calculam sobre la mostra i que quantifica la variabilitat de la mostra Error típic (o estàndard) d’un estimador: La desviació típica de la variable aleatòria que defineix l’estimador, normalment desconeguda Error típic (o estàndard) d’una mostra: Estimació de l’error típic de la mitjana mostral (o de la proporció mostral) a partir d’una mostra; servirà per calcular intervals de confiança. És \\(\\widetilde{S}_X/\\sqrt{n}\\). 2.6 “Bons” estimadors 2.6.1 Estimadors no esbiaixats Un estimador puntual \\(\\widehat{\\theta}\\) d’un paràmetre poblacional \\(\\theta\\) és no esbiaixat (insesgado, en castellà) quan el seu valor esperat és precisament el valor poblacional del paràmetre, és a dir, quan \\[ \\mu_\\widehat{\\theta}=\\theta \\] Es diu aleshores que l’estimació puntual és no esbiaixada. El biaix d’un estimador \\(\\widehat{\\theta}\\) d’un paràmetre \\(\\theta\\) és la diferència \\(\\mu_\\widehat{\\theta}-\\theta\\) Exemples: Ja hem vist a les seccions anteriors que \\(\\mu_{\\overline{X}}=\\mu_X\\). Per tant, \\(\\overline{X}\\) és sempre un estimador no esbiaixat de \\(\\mu_X\\) \\(\\mu_{\\widehat{p}_X}=p_X\\). Per tant, \\(\\widehat{p}_X\\) és sempre un estimador no esbiaixat de \\(p_X\\) \\(\\mu_{\\widetilde{S}_{X}^2}=\\sigma_X^2\\) si \\(X\\) és normal. Per tant, \\(\\widetilde{S}_{X}^2\\) és un estimador no esbiaixat de \\(\\sigma_X^2\\) quan \\(X\\) és normal Com que \\({S}_{X}^2=\\dfrac{n-1}{n}\\widetilde{S}_{X}^2\\), tenim que \\(\\mu_{{S}_{X}^2}=\\dfrac{n-1}{n}\\sigma_X^2\\) si \\(X\\) és normal. Per tant, en aquest cas, \\({S}_{X}^2\\) és un estimador esbiaixat de \\(\\sigma_X^2\\), amb biaix \\[ \\mu_{{S}_{X}^2}-\\sigma_X^2=\\dfrac{n-1}{n}\\sigma_X^2-\\sigma_X^2=-\\dfrac{\\sigma_X^2}{n}\\ \\mathop{\\longrightarrow}_{\\scriptscriptstyle n\\to\\infty}\\ 0 \\] Diem en aquest cas que el biaix tendeix a 0. \\(\\mu_{\\widetilde{S}_{X}}, \\mu_{{S}_{X}}\\neq \\sigma_X\\) ni tan sols quan \\(X\\) és normal. Per tant, \\(\\widetilde{S}_{X}\\) i \\({S}_{X}\\) són estimadors esbiaixats de \\(\\sigma_X\\) 2.6.2 Estimadors eficients Donats dos estimadors \\(\\widehat{\\theta}_1\\), \\(\\widehat{\\theta}_2\\) del mateix paràmetre \\(\\theta\\), direm que \\(\\widehat{\\theta}_1\\) és més eficient, o més precís, que \\(\\widehat{\\theta}_2\\) quan l’error típic de \\(\\widehat{\\theta}_1\\) és més petit que el de \\(\\widehat{\\theta}_2\\): \\[ \\sigma(\\widehat{\\theta}_1)&lt; \\sigma(\\widehat{\\theta}_2). \\] Normalment, només comparam l’eficiència de dos estimadors quan són no esbiaixats (o, com a molt, quan el seu biaix tendeix a 0). En aquest cas, que \\(\\widehat{\\theta}_1\\) sigui més eficient que \\(\\widehat{\\theta}_2\\) significa que la seva variabilitat és menor i que per tant les estimacions amb \\(\\widehat{\\theta}_1\\) es concentren més al voltant del seu valor esperat, que és el paràmetre \\(\\theta\\) que volem estimar, que les estimacions amb \\(\\widehat{\\theta}_2\\). Exemples: Si \\(X\\) és normal, \\(\\overline{X}\\) és l’estimador no esbiaixat més eficient de la mitjana poblacional \\(\\mu_X\\). Si \\(X\\) és Bernoulli, \\(\\widehat{p}_X\\) és l’estimador no esbiaixat més eficient de la proporció poblacional \\(p_X\\). Si \\(X\\) és normal, \\(\\widetilde{S}_X^2\\) és l’estimador no esbiaixat més eficient de la variància poblacional \\(\\sigma_X^2\\). Exemple 2.12 Sigui \\(X\\) una variable aleatòria normal \\(N(\\mu_X,\\sigma_X)\\). Considerem la mediana \\(\\mathit{Me}=Q_{0.5}\\) d’una mostra aleatòria simple de \\(X\\) com a estimador puntual de \\(\\mu_X\\), que coincideix amb la mediana de \\(X\\) per la simetria de les variables normals. Resulta que \\(\\mu_{\\mathit{Me}}=\\mu_X\\) però \\[ \\sigma^2(\\mathit{Me})\\approx \\dfrac{\\pi}{2}\\cdot \\dfrac{\\sigma_{X}^2}{n}\\approx 1.57 \\cdot \\frac{\\sigma_{X}^2}{n}=1.57\\sigma^2_{\\overline{X}} \\] Per tant, si \\(X\\) és normal, la mediana \\(\\mathit{Me}\\) és un estimador no esbiaixat de \\(\\mu_X\\), però menys eficient que \\(\\overline{X}\\). Per això preferim emprar la mitjana mostral per estimar \\(\\mu_X\\). Hem dit que si la població és normal, \\(\\widetilde{S}_X^2\\) és l’estimador no esbiaixat més eficient de la variància poblacional \\(\\sigma_X^2\\). La variància a seques \\[ S_X^2=\\frac{(n-1)}{n} \\widetilde{S}_X^2 \\] és més eficient, perquè \\[ \\sigma(S_X^2)=\\sqrt{\\frac{(n-1)}{n}}\\sigma(\\widetilde{S}_X^2)&lt;\\sigma(\\widetilde{S}_X^2), \\] però és un estimador esbiaixat de \\(\\sigma_X^2\\), amb biaix que tendeix a 0. Si \\(n\\) és petit (per davall de 30), és millor fer servir la variància mostral \\(\\widetilde{S}_X^2\\) per estimar la variància, ja que el biaix pot desplaçar l’estimació, però si \\(n\\) és gran, el biaix de \\(S_X^2\\) ja és petit i es pot fer servir \\(S_X^2\\): de fet, si \\(n\\) és molt gran, dividir per \\(n\\) o per \\(n-1\\) no varia gaire el resultat i per tant \\(\\widetilde{S}_X^2\\) i \\(S_X^2\\) donen valors molt semblants. 2.6.3 Estimadors màxim versemblants Un estimador d’un paràmetre és màxim versemblant quan, aplicat a una mostra aleatòria simple d’una mida \\(n\\) fixada, dóna el valor del paràmetre que fa màxima la probabilitat d’obtenir aquesta mostra. Exemple 2.13 Suposem que tenim una variable aleatòria Bernoulli \\(X\\) de probabilitat d’èxit \\(p_X\\) desconeguda. Donada una mostra aleatòria simple \\(x_1,\\ldots,x_n\\) de \\(X\\), siguin \\(\\widehat{p}_x\\) la seva proporció mostral i \\[ P(x_1,\\ldots,x_n\\mid p_X=p) \\] la probabilitat d’obtenir la mostra quan la probabilitat poblacional \\(p_X\\) és igual \\(p\\). Un estimador per a \\(p_X\\) és màxim versemblant quan, aplicat a cada mostra aleatòria simple \\(x_1,\\ldots,x_n\\) de \\(X\\), ens dóna el valor de \\(p\\) que fa que \\[ P(x_1,\\ldots,x_n\\mid p_X=p) \\] sigui el màxim possible. Quin creieu que és l’estimador màxim versemblant de \\(p_X\\)? Doncs sí, la proporció mostral \\(\\widehat{p}_X\\). Teorema 2.7 El valor de \\(p\\) per al qual \\(P(x_1,\\ldots,x_n\\mid p)\\) és màxim és \\(\\widehat{p}_x\\). La demostració és senzilla. Suposau que dins \\(x_1,\\ldots,x_n\\) hi ha \\(m\\) 1s i \\(n-m\\) 0s, de manera que \\(\\widehat{p}_X=m/n\\). Aleshores, la probabilitat d’obtenir \\(x_1,\\ldots,x_n\\) és \\[ P(x_1,\\ldots,x_n\\mid p)=p^m(1-p)^{n-m} \\] Per trobar el valor de \\(p\\) que fa aquest probabilitat màxima, derivau respecte de \\(p\\) i estudiau el signe de la derivada, i concloureu que el màxim es dóna efectivament a \\(p=m/n\\). Alguns altres estimadors màxim versemblants: \\(\\overline{X}\\) és l’estimador màxim versemblant del paràmetre \\(\\lambda\\) d’una variable aleatòria Poisson \\(\\overline{X}\\) és l’estimador màxim versemblant de la mitjana \\(\\mu\\) d’una variable aleatòria normal 2.7 Estimació de poblacions 2.7.1 Estimació de poblacions numerades Exemple 2.14 Un dia vaig voler estimar quants taxis hi havia a Palma. Per fer-ho, assegut en un bar del Passeig Marítim vaig apuntar les llicències dels 40 primers taxis que passaren. Els entraré directament en un vector de R. taxis=c(1217,600,883,1026,150,715,297,137,508,134,38,961,538,1154,314,1121,823,158,940,99, 977,286,1006,1207,264,1183,1120,498,606,566,1239,860,114,701,381,836,561,494,858,187) sort(taxis) ## [1] 38 99 114 134 137 150 158 187 264 286 297 314 381 494 ## [15] 498 508 538 561 566 600 606 701 715 823 836 858 860 883 ## [29] 940 961 977 1006 1026 1120 1121 1154 1183 1207 1217 1239 Puc estimar quants taxis hi ha a Palma a partir d’aquesta mostra? Us pot semblar una beneitura de pregunta, però aquest és un problema de rellevància històrica, com podeu consultar en aquest article. La solució d’aquest problema és donada pel resultat següent: Teorema 2.8 Sigui \\(X\\) una variable aleatòria uniforme sobre \\(\\{1,2,\\ldots,N\\}\\), i sigui \\(x_1,\\ldots,x_n\\) una mostra aleatòria de \\(X\\). Sigui \\(m=\\max(x_1,\\ldots,x_n)\\). Aleshores, l’estimador no esbiaixat més eficient de \\(N\\) és \\[ \\widehat{N}=m+\\frac{m-n}{n} \\] La idea que hi ha sota aquesta fórmula és que si suposau que teniu \\(x_1,\\ldots,x_n\\) ordenats en ordre creixent, de manera que \\(x_n=m\\), i calculau la mitjana de la longitud dels “forats” a l’esquerra de cada valor \\(x_i\\), tenim que a l’esquerra de \\(x_1\\) hi ha \\(x_1-1\\) nombres i entre cada \\(x_{i-1}\\) i \\(x_{i}\\) hi ha \\(x_{i}-x_{i-1}-1\\) nombres, i per tant aquesta mitjana és \\[ \\begin{array}{l} \\displaystyle \\frac{(x_1-1)+(x_2-x_1-1)+\\cdots+(x_{n}-x_{n-1}-1)}{n}\\\\ \\displaystyle \\qquad\\quad =\\frac{x_n-n}{n}=\\frac{m-n}{n} \\end{array} \\] i el que fa l’estimador \\(\\widehat{N}\\) és sumar al màxim de la mostra, \\(m\\), la mitjana dels forats entre membres de la mostra. És a dir, estimam que la mida de la població és tal que a la dreta del màxim de la nostra mostra hi ha un “forat” de mida la mitjana dels forats de la mostra. Exemple 2.15 Continuem amb l’Exemple 2.14. Emprant la fórmula anterior, obtenim max(taxis)+(max(taxis)-length(taxis))/length(taxis) ## [1] 1268.975 la qual cosa ens permet estimar que hi havia 1269 taxis a Palma. En realitat, consultant la web de l’Ajuntament, després vaig saber que en aquell moment n’hi havia 1246. 2.7.2 Marca-recaptura Suposem que en una població hi ha \\(N\\) individus, en capturam \\(K\\) (tots diferents), els marcam i els tornam a amollar. Al cap de poc temps, en capturam \\(n\\), dels quals \\(k\\) estan marcats. A partir d’aquestes dades, volem estimar \\(N\\). Si suposam que \\(N\\) i \\(K\\) no han canviat de la primera a la segona captura (cap individu no ha abandonat la població ni s’hi ha incorporat), aleshores la variable aleatòria \\(X\\) definida per “Capturam un individu i miram si està marcat” és Bernoulli \\(Be(p)\\) amb \\(p=K/N\\), on coneixem la \\(K\\) i volem estimar la \\(N\\). Sigui ara \\(x_1,\\ldots,x_n\\) la mostra capturada en segon lloc. La seva proporció mostral d’individus marcats és \\(\\widehat{p}_X=k/n\\). Com que \\(\\widehat{p}_X\\) és l’estimador màxim versemblant de \\(p\\), estimam que \\[ \\dfrac{K}{N}=\\dfrac{k}{n} \\] d’on, aïllant la \\(N\\), estimam que \\[ N=\\frac{n\\cdot K}{k}. \\] En resum, l’estimador \\[ \\widehat{N}=\\frac{n\\cdot K}{k} \\] maximitza la probabilitat d’obtenir \\(k\\) individus marcats en una mostra aleatòria de \\(n\\) individus. És l’estimador màxim versemblant de \\(N\\) a partir de \\(K\\), \\(k\\) i \\(n\\); també se li diu estimador de Lincoln-Petersen. Fixau-vos que aquest estimador no fa res més que traduir la proporció “Si he trobat \\(k\\) individus marcats en un conjunt de \\(n\\) individus, què ha de valer el nombre total \\(N\\) de individus perquè hi hagi en total \\(K\\) individus marcats?” Exemple 2.16 Suposem que hem marcat 15 peixos d’un llac, i que en una captura posterior de 10 peixos, n’hi ha 4 de marcats. Quants peixos conté el llac? Ho estimarem amb l’estimador de Lincoln-Petersen: \\[ \\widehat{N}=\\frac{15\\cdot 10}{4}=37.5 \\] Per tant, estimam que hi haurà entre 37 i 38 peixos al llac. En aquest cas podem comprovar la màxima versemblança d’aquesta estimació, calculant la probabilitat d’obtenir 4 individus marcats en una mostra aleatòria de 10 individus d’una població de \\(N\\) individus on n’hi ha 15 de marcats i trobant la \\(N\\) que maximitza aquesta probabilitat. Per fer-ho, recordem que si una població està formada per \\(K\\) subjectes marcats i \\(N-K\\) subjectes no marcats, el nombre de subjectes marcats en mostres aleatòries sense reposició de mida \\(n\\) segueix una distribució hipergeomètrica \\(H(K, N-K,n)\\). Per tant, per a cada possible \\(N\\), la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats serà dhyper(4,15,N-15,10). N=15:1000 #Possibles valors de N p=dhyper(4,15,N-15,10) #Probabilitats de 4 marcats en 10 Nmax=N[which(p==max(p))] # N que maximitza la probabilitat Nmax ## [1] 37 Aquest Nmax és la \\(N\\) que fa màxima la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats. Vegem-ho en un gràfic: plot(N[1:86],p[1:86],type=&quot;h&quot;,xaxp=c(15,100,17),xlab=&quot;N&quot;,ylab=&quot;p&quot;) points(Nmax,dhyper(4,15,Nmax-15,10),type=&quot;h&quot;,col=&quot;red&quot;,lwd=1.5) Un altre estimador per a \\(N\\) a partir de \\(K\\), \\(n\\) i \\(k\\) és l’estimador de Chapman: \\[ \\widehat{N}=\\frac{(n+1)\\cdot (K+1)}{k+1}-1 \\] La idea és que afegim a la població un individu extra i marcat, que suposam que també capturam a la segona mostra. Llavors, aplicam l’estimador anterior i finalment restam 1, per descomptar l’individu marcat extra que realment no pertany a la població que volem estimar. En la situació de l’Exemple 2.16, aquest estimador dóna \\[ \\widehat{N}=\\frac{16\\cdot 11}{5}-1=34.2 \\] i ens fa estimar una població total d’uns 34 peixos. Abans hem obtingut entre 37 i 38 peixos. Quina de les dues estimacions s’acosta més a la realitat? Ni idea, no ho podem saber. Amb una altra recaptura segurament haguéssim obtingut resultats diferents. L’estimador de Lincoln-Petersen \\[ \\widehat{N}=\\frac{n\\cdot K}{k} \\] és esbiaixat, amb biaix que tendeix a 0. L’estimador de Chapman és menys esbiaixat però no és màxim versemblant. "]
]
