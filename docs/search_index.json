[
["index.html", "Matemàtiques II v.2021 Presentació", " Matemàtiques II v.2021 2021-02-11 Presentació Això és una edició en línea dels apunts de Matemàtiques II dels graus de Biologia i Bioquímica de la UIB. Aquests apunts no són autocontinguts pel que fa al R: suposam que l’estudiant va llegint les lliçons de R corresponents a cada tema a la 2a part del manual AprendeR. Aquests apunts estan en construcció. A la llista següent hi anirem anunciant les actualitzacions. 17-02-2021: Pujats temes 1, 2 i 3 Significats d’algunes capses: Material molt important. Alerta! Exercici. Detalls matemàtics que us poden interessar, però que no cal saber. Comentari que volem emfatitzar. Comentari que volem que recordeu. Qüestió en què volem que caigueu. Acabam de matar un moixet. El llibre està escrit en R Markdown, emprant RStudio com a editor de textos i el paquet bookdown per convertir els fitxers markdown en un llibre Aquest treball se publica sota llicència Atribució-No Comercial-SenseDerivats 4.0 "],
["chap-conceptes.html", "Tema 1 Alguns conceptes bàsics 1.1 Tipus de dades 1.2 Població 1.3 Variable aleatòria 1.4 Mostra 1.5 Mostreig aleatori 1.6 Mostres de conveniència 1.7 Test de la lliçó 1", " Tema 1 Alguns conceptes bàsics 1.1 Tipus de dades Els tipus bàsics de dades que consideram en aquest curs són els següents: Dades qualitatives. Són les que expressen una qualitat, com ara el sexe anatòmic (mascle, femella), el gènere d’una persona (home, dona, lesbiana, gai, bisexual, transsexual, intersexual, asexual, sestosexual…), el tipus de càncer (de mama, de còlon, de pròstata…), l’espècie d’un ésser viu, la soca d’un bacteri o un virus… Si només poden prendre dos valors (per exemple “Sí” i “No”, o “Home” i “Dona”) diem que són binàries o dicotòmiques, depenent del que volguem complicar l’adjectiu. Les dades qualitatives poden ser iguals o diferents, i no admeten cap altre tipus de comparació. Dades ordinals. Són dades similars a les qualitatives, en el sentit que expressen una qualitat, però amb la diferència que les ordinals es poden ordenar de manera natural. Per exemple, els nivells de gravetat d’una malaltia (sa, lleu, greu, molt greu, …) o les qualificacions en un examen (suspens, aprovat, notable, excel·lent) són dades ordinals. En canvi, no es poden ordenar de manera significativa les malalties de les persones o les espècies dels animals: per això són dades qualitatives, no ordinals. Dades quantitatives. Són mesures que són nombres genuïns, “de veritat”, amb els quals té sentit operar, com ara edats, longituds, pesos, temps, nombres d’individus, etc. En distingim dos tipus: Discretes: Prenen valors que avancen a salts i que podem identificar amb nombres naturals: nombre de germans d’una persona, nombre d’exemplars d’una espècie en una regió, nombre de fulles en una branca… Contínues: Podrien prendre qualsevol valor real dins d’un interval si es poguessin mesurar amb precisió infinita: longituds, alçades, temperatures, temps… Exemple 1.1 Hem anotat algunes característiques d’un grup de nins i nines: el nom, l’alçada (en cm), el nombre de germans, el color dels cabells, i el nombre setmanal de refrescs que solen prendre. Hem recollit aquestes dades a la Taula 1.1, on cada filera representa un nin o una nina i cada columna recull una de les característiques que hem anotat: Taula 1.1: Una petita taula de dades Nom Alçada Germans Cabell Refrescs setmanals 1 Marta 135 2 ros 2-3 2 Laura 132 1 negre 2-3 3 Xavier 138 0 negre 0-1 4 Joan 141 3 castany 4-5 5 Maria 134 2 vermell 0-1 6 Maria 136 1 castany 5 o més Aleshores: Les dades de la columna “Nom” són qualitatives. Les dades de la columna “Alçada” són quantitatives contínues. Les dades de la columna “Germans” són quantitatives discretes. Les dades de la columna “Cabell” són qualitatives. Les dades de la columna “Refrescs setmanals” són ordinals. L’anàlisi, tant descriptiva com inferencial, d’un conjunt de dades és diferent segons el seu tipus. Així, per a dades qualitatives només té interès estudiar i representar les freqüències amb què apareixen els seus diferents valors, mentre que l’anàlisi de dades quantitatives sol involucrar el càlcul de mesures estadístiques, com ara la mitjana o la desviació típica, que expressin numèricament les seves propietats. Dos punts rellevants a tenir en compte: No tot nombre és una dada quantitativa. Només els consideram quantitatius quan són nombres genuïns. Per exemple, si demanam a un pacient que qualifiqui el seu dolor amb un nombre natural de 0 a 10, no és una dada quantitativa, sinó ordinal: No és una mesura precisa del dolor; no són números “de veritat”, sinó abreviatures de “Res”, “Una miqueta”,…, “Matau-me”. Tenir dolor 6 no significa “tenir el doble de dolor” que tenir dolor 3 (si ho significàs, quin seria el valor corresponent “al doble de dolor” que 6?). En canvi, una persona amb 6 germans sí que en té el doble que una amb 3 germans. No té sentit sumar-los o operar-los en general. Per exemple, si jo tenc dolor de nivell 6 i tu tens dolor de nivell 5, entre tots dos no tenim dolor de nivell 11. En canvi, si jo tenc 6 germans i tu 5, entre tots dos si que tenim 11 germans. La distinció discret-continu és purament teòrica. En realitat, tota dada és discreta perquè no podem mesurar res amb precisió infinita, però les eines matemàtiques “contínues” (derivades, integrals, etc.) són molt més potents que les discretes, per la qual cosa sempre que tengui sentit, és convenient considerar una variable com a contínua. Observau, per exemple, la diferència entre l’alçada mesurada en cm i arrodonida a unitats i el nombre de germans tal i com les hem recollit a la Taula 1.1. Les dues dades es presenten com a nombres naturals, però els nombres de germans no admeten més precisió, mentre que les alçades les podríem mesurar, amb els aparells adequats, en mm, en µm, en nm…. Com que, a més, les eines per a tractar dades contínues són molt més potents, consideram les alçades com a dades contínues, mentre que els nombres de germans no hi ha més remei que tractar-los com a discrets. En concret, és convenient considerar en la pràctica com a dades contínues aquelles que donen lloc a nombres naturals molt grans, com per exemple el nombre de glòbuls vermells en un litre de sang, de bases nuclèiques en un genoma, o de persones d’un país: la diferència entre 10000000, 10000001, 10000002… pot considerar-se com a contínua: de fet, si prenem el milió com a unitat de mesura, la diferència entre aquests nombres està en la setena xifra decimal: 1.0000000, 1.0000001, 1.0000002. 1.2 Població En general, una població és simplement un conjunt d’individus o objectes sobre els quals volem conèixer alguna informació. Una població pot estar perfectament definida en un lloc i temps: per exemple, els habitants d’Espanya just avui. Però normalment la seva definició serà difusa. Si, per exemple, volem estimar alguna cosa sobre una espècie de plantes, de qui estam parlant exactament? De les plantes que estan vives just ara? De totes les plantes d’aquesta espècie de la història del món? Hi hem d’incloure les que encara no han nascut? Tranquils, no ens trencarem gens el cap amb això. Però almenys heu de ser conscients que una població pot contenir objectes que en realitat no existeixen ni hagin existit ni vagin a existir, sinó simplement que “podrien existir”. Parlarem llavors d’una població virtual (en altres llocs en diuen una població metafòrica). Per exemple, quan diem que “La probabilitat que surti cara en llançar una moneda equilibrada és 1/2”, el que significa és que “Si prenem la població formada per tots els possibles llançaments individuals de totes les possibles monedes equilibrades, en la meitat dels seus membres el resultat és Cara.” Els membres d’aquesta població són tots els “possibles” llançaments de monedes equilibrades, els que s’han realitzat al llarg de la història, els que es realitzaran en el futur, i els que es podrien haver realitzat o es podrien realitzar en el futur però en realitat no s’han fet ni s’arribaran a fer mai. 1.3 Variable aleatòria Una variable aleatòria definida sobre una població \\(\\Omega\\) és simplement una funció \\[ X: \\Omega\\to \\mathbb{R} \\] que assigna a cada subjecte de \\(\\Omega\\) un nombre real. La idea intuïtiva que hi ha al darrera d’aquesta definició és que una variable aleatòria mesura una característica dels subjectes de \\(\\Omega\\) que varia a l’atzar d’un subjecte a un altre. Per exemple: Prenem una persona d’una població i mesuram el seu nivell de colesterol, o la seva alçada, o el seu nombre de fills… En aquest cas, \\(\\Omega\\) és la població sota estudi, de la qual prenem la persona que mesuram. Llançam una moneda equilibrada 3 vegades i comptam les cares que obtenim. En aquest cas, \\(\\Omega\\) és la població “virtual” formada per totes les seqüències de 3 llançaments d’una moneda equilibrada passades, presents, futures i hipotètiques. Procurau adquirir la disciplina de descriure sempre les variables aleatòries mitjançant una plantilla de l’estil de “Prenem … i mesuram …” perquè us quedi clar quina és la població i quina la funció. A més, afegiu-hi les unitats si és necessari. Per exemple: \\(X\\): “Prenem una persona de Mallorca i mesuram la seva alçada (en cm)”. Fixau-vos que aquesta variable aleatòria no és la mateixa que \\(Y\\): “Prenem una persona de Mallorca i mesuram la seva alçada (en m)” perquè, encara que totes dues mesuren el mateix sobre els mateixos subjectes, els assignen números diferents. I \\(X\\) també és diferent de \\(Z\\): “Prenem una persona de Suècia i mesuram la seva alçada (en cm)” perquè ha canviat la població. En canvi a “Llançam una moneda 3 vegades i comptam les cares” no hi ha necessitat d’especificar unitats, tret que volgueu emprar una unitat inesperada (jo què sé, que compteu les cares en fraccions de dotzena). Per a més informació sobre variables aleatòries, consultau la Lliçó 2. 1.4 Mostra En un estudi inferencial, volem deduir (inferir) informació sobre una o diverses variables aleatòries definides sobre una població a partir d’una mostra: La població objectiu, o d’interès és el conjunt de subjectes sobre les quals desitjam obtenir informació. La mostra de la població es el grup de subjectes concrets en els quals mesuram les característiques d’interès, usualment molt petit per comparació amb la població. Una mostra d’una variable aleatòria és el conjunt de valors obtinguts prenent una mostra de la població i mesurant la variable sobre aquests subjectes. Procurau tenir sempre present que, per molta cura que posem en obtenir una mostra d’una població, sempre serà només una aproximació imperfecta d’aquesta. Figura 1.1: Població versus mostra Exemple 1.2 Si volem saber si un brou és fat, no ens el bebem tot, perquè ens quedaríem sense brou i ja tant faria si era fat o salat. El que fem és tastar-ne només una cullerada. El brou és la població, la cullarada la mostra. Exemple 1.3 En un estudi recent es volgué determinar si la llum artificial a la nit afecta el ritme circadià dels ocells cantors. Per fer-ho, s’exposà un grup de 34 ferrericos (Parus major) a diferents intensitats de llum artificial durant la nit i s’anotà com els afectava tant a nivell de comportament com a nivell metabòlic o d’expressió gènica. Aquí la població d’interès és la formada per tots els ocells cantors (passats, presents i futurs) i la mostra són els 34 pobres ferrericos. Exemple 1.4 Una sèrie de 10 llançaments d’una moneda equilibrada concreta és una mostra de la població dels “possibles llançaments de monedes equilibrades”. Si podem mesurar tots els individus de la població, no ens fa falta emprar estadística inferencial per mirar d’endevinar el que volem saber sobre la població: ho mesuram sobre tothom i per avall. Però el més normal és que no poguem mesurar tots els individus de la població. La població pot ser massa gran. Per exemple, si volem calcular l’alçada mitjana dels europeus que avui tenen 18 anys, és pràcticament impossible amidar-los tots. Com ja hem comentat, la població pot ser virtual o metafòrica en el sentit que pot contenir membres que en aquest moment ni existeixin. Per exemple, per saber si la llum artificial a la nit afecta els ocells cantors, els autors de la investigació citada a l’Exemple 1.3 no podien accedir a tots els ocells cantors actuals, i molt menys als que ja no són entre nosaltres o als que encara no han nascut. Pot ser que per obtenir la informació d’un subjecte l’hàgim de sacrificar. En aquest cas, per mesurar tota la població l’hauríem d’exterminar. Pot ser simplement que sigui difícil accedir a tota la població: per exemple, els estudiants de la UIB són relativament pocs, uns 12000, però seria complicat aconseguir amidar-los tots. Exemple 1.5 Vosaltres què sou: una població o una mostra? Doncs depèn: Sou una població quan el que interessa és saber qualque cosa sobre vosaltres i només vosaltres. Sou una mostra si a partir d’informació sobre vosaltres miram d’inferir informació sobre un grup més gran de subjectes: sobre els estudiants de primer curs de Biologia i Bioquímica d’Espanya, o sobre els estudiants de la UIB d’aquest curs, o sobre els joves europeus, o sobre els mamífers bípedes, o… En aquest curs sobrecarregarem el terme variable, en el sentit que tendrà dos significats diferents que hauríeu de poder distingir segons el context: D’una banda, direm variable a una característica que pot prendre diferents valors sobre diferents individus; quan tengui aquest sentit, de vegades li afegirem l’adjectiu poblacional. Per exemple, l’alçada de les persones (de tot el món, d’un país, d’una ciutat…) és una variable poblacional. D’altra banda, també direm variable a un vector format per una mostra d’una variable poblacional sobre una mostra concreta d’individus. Per exemple, les alçades recollides en la Taula 1.1 formen una variable en aquest sentit. 1.5 Mostreig aleatori Com ja hem explicat, en un estudi estadístic inferencial, es pren una mostra d’individus d’una població i s’estimen algunes característiques de la població a partir de les de la mostra. Perquè això tengui sentit, és necessari que la mostra sigui representativa de la població. Però, és clar, sense conèixer les característiques de la població, no podem saber si una mostra és representativa o no. Per sortir d’aquest atzucac, la solució acceptada és prendre una mostra aleatòria, és a dir, triant els seus subjectes a l’atzar i tots amb la mateixa probabilitat de ser escollits. En fer-ho així: S’eviten preferències en l’elecció, per la qual cosa esperam que la mostra sigui representativa de la població. Naturalment, això no està garantit: per pura mala sort ens pot sortir una mostra súper rara, és el que té l’atzar. Però almenys hem fet “el que tothom considera que és el que toca” per intentar que sigui representativa. Figura 1.2: http://dilbert.com/strip/2001-10-25 Es poden usar tècniques estadístiques per delimitar errors en l’estimació i la seva probabilitat; per exemple, podrem calcular la probabilitat que la nostra mostra sigui súper rara en algun sentit concret. Exemple 1.6 Per tastar el brou, abans de prendre’n una cullerada el remenam bé. D’aquesta manera esperam que les molècules del brou s’organitzin de manera aleatòria dins l’olla i que la cullerada que en prenguem sigui representativa del brou. Específicament, el mostreig aleatori consisteix a seleccionar una mostra de la població de manera que totes les mostres de la mateixa mida siguin equiprobables; és a dir, que si fixam el nombre de subjectes de la mostra, tots els conjunts d’aquest nombre de subjectes tenguin la mateixa probabilitat de ser seleccionats. Hi ha dos tipus bàsics de mostreig aleatori que hem de distingir: amb i sense reposició. Per fixar idees, suposem que disposam d’una població de la qual volem extreure una mostra de mida \\(n\\). Una manera de fer-ho seria repetir \\(n\\) vegades el procés d’escollir, a l’atzar i de manera equiprobable, un individu de la població, anotar qui és i “retornar-lo a la població”, de manera que pugui tornar a ser triat dins la mateixa mostra. El tipus de mostra obtenguda d’aquesta manera rep el nom de mostra aleatòria amb reposició, o mostra aleatòria simple. Observau que amb aquest procediment un mateix individu pot aparèixer diverses vegades en una mostra, i que tots els subconjunts “amb possibles repeticions” (el seu nom tècnic és multiconjunts) de \\(n\\) individus de la població tenen la mateixa probabilitat d’obtenir-se. El mostreig aleatori simple és l’estándard d’excel·lència entre els mètodes de mostreig, i gairebé tots els resultats que explicarem en aquest curs pressuposen que la mostra és aleatòria simple. Sí, ja sabem que sembla contradictori que quan, per exemple, volgueu conèixer l’opinió de la població sobre un tema, el mètode recomanat per construir la mostra d’individus que entrevistar permeti comptar més d’una vegada l’opinió d’un mateix subjecte. Una altra manera d’extreure la nostra mostra seria repetir \\(n\\) vegades el procés d’escollir, a l’atzar i de manera equiprobable, un individu de la població, anotar qui és i “retirar-lo de la població”, de manera que ja no pugui tornar a ser triat dins la mateixa mostra. Això és equivalent a extreure de cop \\(n\\) individus diferents de la població. Aquestes mostres no tenen individus repetits, i qualsevol selecció de \\(n\\) individus diferents té la mateixa probabilitat de ser l’obtinguda. En aquest cas es parla d’una mostra aleatòria sense reposició. Quan la mida de la població és MOLT gran per comparació amb la mostra, com sol ser el cas en ciències de la vida, la probabilitat que hi hagi repeticions en una mostra aleatòria simple és molt petita. Recordau que si una població té \\(N\\) individus, la probabilitat que una mostra aleatòria simple de mida \\(n\\) tingui tots els seus membres diferents és \\[ \\frac{N(N-1)\\cdots (N-n+1)}{N^n} \\] i per tant la probabilitat que tengui qualque membre repetit és \\[ 1-\\frac{N(N-1)\\cdots (N-n+1)}{N^n}. \\] Amb R: La funció pbirthday(n,N) ens dóna la probabilitat que en una mostra aleatòria simple de mida \\(n\\) d’una població de mida \\(N\\) hi hagi algun element repetit. La funció qbirthday(p,N) ens dóna la mida mínima d’una mostra aleatòria simple d’una població de mida \\(N\\) perquè la probabilitat que hi hagi algun element repetit sigui com a mínim \\(p\\). El nom birthday fa referència a la paradoxa de l’aniversari: el típic problema de calcular la probabilitat que dos estudiants d’una classe celebrin l’aniversari el mateix dia i sorprendre’s que en una classe de 50 estudiants hi hagi més d’un 95% de probabilitats que hi hagi algun aniversari repetit. En efecte, podem entendre una classe de 50 estudiants com una mostra aleatòria simple de 50 dies de l’any (els aniversaris dels estudiants) triats d’un conjunt de 366 possibles dies. La probabilitat que almenys 2 estudiants celebrin l’aniversari el mateix dia és la probabilitat que es doni almenys una repetició en aquesta mostra. Podem calcular-la amb R: pbirthday(50,366) ## [1] 0.9700731 1-prod((366:(366-49))/366) # Amb la fórmula de la probabilitat ## [1] 0.9700731 Emprau la funció qbirthday per trobar el nombre mínim d’estudiants que hi ha d’haver en una classe perquè la probabilitat que es repeteixi una data d’aniversari arribi al 95%. I comprovau que el valor trobat és correcte. Per exemple, si triam 100 individus de les Balears (que tenen al voltant de 1,150,000 habitants) a l’atzar permetent repeticions, la probabilitat que surti qualque individu repetit és pbirthday(100,1150000) ## [1] 0.004295221 Només en 1 de cada 250 mostres de 100 balears triats a l’atzar permetent repeticions hi hauria qualque repetició. En canvi, si triam 100 estudiants de la UIB (que té al voltant de 12000 estudiants) a l’atzar permetent repeticions, la probabilitat que surti qualque estudiant repetit és de pbirthday(100,12000) ## [1] 0.3387643 En 1 de cada 3 mostres de 100 estudiants de la UIB triats a l’atzar permetent repeticions hi hauria qualque repetició. Però si triam 10 estudiants de la UIB a l’atzar permetent repeticions, la probabilitat que surti qualque estudiant repetit ja és pbirthday(10,12000) ## [1] 0.003743964 Exemple 1.7 El gràfic següent mostra la probabilitat que si prenem una mostra aleatòria simple de mida \\(n\\) d’una població de 12000 individus, com ara la formada pels estudiants de la UIB, els seus membres siguin tots diferents: f=function(n,N){1-pbirthday(n,N)} prob=sapply(1:300,f,N=12000) plot(1:300, prob, type=&quot;l&quot;, lwd=2, xlab=&quot;n&quot;, ylab=&quot;probabilitat&quot;, xaxp=c(0,300,30),yaxp=c(0,1,10)) El gràfic següent mostra la mida màxima \\(n\\) d’una mostra aleatòria simple extreta d’una població de mida \\(N\\) perquè la probabilitat de repeticions sigui menor que 0.01 (és a dir, perquè més del 99% de les mostres aleatòries simples tenguin tots els seus elements diferents), en funció de \\(N\\): fites=sapply(500+100*(0:150), qbirthday, prob=0.01) plot(500+100*(0:150), fites, pch=20, xlab=&quot;N&quot;, ylab=&quot;n&quot;, cex=0.5, xaxp=c(500,15500,30),yaxp=c(0,20,20)) Així doncs, si la mida de la població és molt gran en relació a la de la mostra, és molt probable que els elements d’una mostra aleatòria simple siguin tots diferents. Això implica que, quan la població és molt gran en relació a la mostra, els mostrejos aleatoris amb i sense reposició són aproximadament equivalents en el sentit següent: Si la població és molt, molt gran, un mostreig amb reposició donaria gairebé segur una mostra amb tots els seus elements diferents. Per tant, podem prendre directament la mostra sense reposició i suposar que permetíem repeticions, però que no n’hi ha hagut, i que per tant la mostra és simple. Una mostra aleatòria de 100 individus diferents de les Balears, o de 10 estudiants diferents de la UIB, pot passar perfectament per una mostra presa permetent repeticions, perquè encara que les permetéssim, només obtendríem qualque repetició en 1 de cada 250 mostres com aquesta. Però en canvi ja és més mal de creure que una mostra aleatòria de 100 estudiants diferents de la UIB hagi estat presa permetent repeticions, perquè si les permetéssim, en 1 de cada 3 vegades sortiria qualcú repetit. A més, si la mida de la població és molt més gran que \\(n\\), quan construïu una mostra aleatòria de mida \\(n\\) escollint els individus un a un a l’atzar sense repeticions, la probabilitat a cada moment d’escollir un individu concret dels que quedin és gairebé la mateixa que si permetéssiu repeticions. Exemple 1.8 Imaginau que teniu una població de 106 individus i en voleu extreure una mostra aleatòria de 10. Llavors, per exemple, quan ja portau 9 individus escollits, la probabilitat de triar un individu concret dels que queden és \\(1/999991=10^{-6}+9·10^{-12}\\), mentre que si permeteu que surti qualcun dels ja escollits aquesta probabilitat és \\(1/10^6=10^{-6}\\). En resum: Si prenem una mostra aleatòria sense reposició de mida \\(n\\) d’una població de mida \\(N\\) MOLT més gran que n, podem suposar que és una mostra aleatòria simple. Per fixar una fita, en aquest curs entendrem que \\(N\\) és prou MOLT més gran que \\(n\\) com per poder aplicar aquesta regla quan \\(N\\) és com a mínim unes 1000 vegades més gran que \\(n\\). Hi ha un tipus de mostreig aleatori que caldrà tenir present més endavant i volem esmentar ara. Es tracta del mostreig aleatori estratificat. S’utilitza quan la població està classificada en estrats que són d’interès per a la propietat estudiada. Aquests estrats seran grups d’individus definits per una característica concreta, de manera que individus del mateix estrat tenguin aquesta característica en comú i individus d’estrats diferents tenguin aquesta característica diferent. Per exemple: sexes, franges d’edat, zones geogràfiques, subespècies d’una espècie… En aquest cas, es pren una mostra aleatòria (amb o sense repetició) d’una mida prefixada de cada estrat i s’uneixen en una mostra global: el resultat és una mostra aleatòria (amb repetició o sense) estratificada. Pel que fa a les mides de les mostres de cada estrat, se sol optar per una de les dues estratègies següents: Imposar que la composició per estrats de la mostra global mantengui les proporcions de la població original, de manera que la mida de la mostra de cada estrat representi el mateix percentatge del total de la mostra que l’estrat corresponent en la població completa. Prendre les mides de manera que els estrats que representin una fracció molt petita de la població (tan petita que no esperaríem que tenguessin representació en una mostra aleatòria transversal de la població, és a dir, presa del total de la població sense tenir en compte la seva composició en estrats) tenguin una representació en la mostra molt més gran que la que els tocaria. Per exemple, els estrats podrien ser grups d’edat i podríem prendre la mostra de cada grup d’edat de mida proporcional a la fracció que representa aquest grup d’edat en la població total. O podrien ser els sexes i procuraríem que la nostra mostra estigués formada per un 50% d’homes i un 50% de dones. O, a les Illes Balears, els estrats podrien ser les illes, i llavors podríem imposar que el nombre de representants de cada illa en la mostra fos proporcional a la seva població relativa dins del conjunt total de la comunitat autònoma, o podríem triar la mateixa quantitat d’individus de cada illa, independentment de la seva població. L’avantatge del mostreig aleatori estratificat respecte del transversal és que, com que l’investigador pren una mostra de cada estrat de la mida que desitja: Permet estimar la informació d’interès per a cada estrat per separat, com si es tractàs d’estudis independents. Permet estimar la informació sobre subpoblaciones minoritàries que en una mostra aleatòria transversal apareixerien subrepresentades. L’inconvenient és que, òbviament, si preneu una mostra amb nombres prefixats i artificials de subjectes de cada estrat, amb aquesta mostra no podeu estimar la proporció de subjectes de cada estrat dins el total de la població. El que volem dir és que si, per exemple, construïu una mostra escollint a l’atzar 100 mallorquins, 100 menorquins i 100 pitiüsos, no la podeu emprar per estimar la proporció de mallorquins en el total de la població de les Balears. Gairebé mai és factible efectuar un mostreig aleatori. El motiu és que, per poder prendre una mostra aleatòria d’una població en el sentit d’aquest apartat, amb o sense reposició, és necessari disposar d’una llista completa de tots els seus individus per poder sortejar a qui seleccionarem. Això sol ser impossible, o almenys difícil d’aconseguir. Qualcú té la llista completa de, per exemple, tots els diabètics d’Espanya? Que inclogui els que no saben que ho són? I ja no en parlem si a més ha d’incloure tots els espanyols diabètics del passat i del futur… Per tant, gairebe mai no podrem prendre mostres aleatòries en aquest sentit. Tenim una població classificada en dos estrats, A i B. La subpoblació A representa un 20% de la població i la B el 80% restant. Hem pres una mostra aleatòria estratificada formada per 100 subjectes de cada subpoblació. Hem mesurat una certa característica X d’aquests subjectes. La mitjana dels valors de X dels subjectes d’A ha donat 5 i la mitjana dels valors de X dels subjectes de B ha donat 10. (a) Què val la mitjana dels valors de X de tota la mostra de 200 subjectes? (b) A partir d’aquestes dades, què estimau que val la mitjana de X en el total de la població? Trobareu més tipus de tècniques de mostreig aleatori i les funcions de R relacionades amb mostrejos a la lliçó sobre mostreig del manual de R. 1.6 Mostres de conveniència Malgrat que tots els resultats que donarem en aquest curs siguin per a mostres aleatòries i la gran majoria per a mostres aleatòries simples, a la vida real les mostres gairebé mai no ho són, aleatòries: normalment ens hem de conformar amb els subjectes disponibles, que formen una mostra de conveniència. Per exemple, a la UIB, per estimar l’opinió que d’un professor tenen els alumnes d’una classe, només es té en compte les respostes dels estudiants que voluntàriament emplenen l’enquesta d’opinió, que de cap manera formen una mostra aleatòria: el perfil de l’estudiant que contesta voluntàriament una enquesta d’aquest tipus és molt específic i no ve determinat per l’atzar. En aquest cas es tractaria d’una mostra auto-seleccionada. Un altre tipus de mostres no aleatòries són les oportunistes. Aquest és el cas, per exemple, si per estimar l’opinió que d’un professor tenen els alumnes d’una assignatura es visita un dia la classe i es passa l’enquesta als estudiants que aquest dia assistiren a classe. Un altre cop, pot ser que els alumnes presents no siguin representatius de l’alumnat de l’assignatura (poden ser els més aplicats, o els que no tenen el grip, o els no repetidors). Les tècniques d’estadística inferencial no es poden aplicar a mostres no aleatòries. Però normalment només podem aconseguir mostres de conveniència. En aquest cas, el que s’ha de fer és descriure detalladament les característiques de la mostra per justificar que, malgrat no ser aleatòria, és raonablement representativa de la població i podria passar per aleatòria. Exemple 1.9 No perquè sigui oportunista una mostra deixa forçosament de ser vàlida. El nostre exemple preferit és el que podríem titular El cas d’Abraham Wald i els forats que faltaven. Figura 1.3: Abraham Wald. Durant la Segona Guerra Mundial es va fer palesa la necessitat de reforçar el blindatge dels bombarders aliats. Però un blindatge excessiu augmentaria el pes del bombarder i faria que consumís més carburant i perdés autonomia de vol o fins i tot que no pogués enlairar-se. Per tant calia blindar només les parts més delicades de l’avió. El problema es passà llavors al Statistical Research Group (SRG), un grup “secret” d’estadístics que assessorava els militars nord americans i que molts historiadors comparen amb el projecte Manhattan, canviant bombes per equacions. Els militars els passaren gràfics dels bombarders que tornaven de missions per Europa amb les marques dels forats de bala que duien. Aquests impactes no estaven uniformement distribuïts pel fuselatge, com podeu veure a l’exemple de la Figura 1.4 que recull els forats d’alguns avions que tornaren d’una missió concreta. La idea dels militars era reforçar les zones més castigades, i el que volien que el SRG els calculàs era quant reforç havien d’afegir a cada zona. Figura 1.4: Diagrama dels impactes de projectil sobre el fuselatge d’un bombarder en tornar d’una missió. La resposta d’Abraham Wald, un dels estadístics més brillants del SRG, va ser “Senyors, on necessiten afegir blindatge és on no hi ha forats, perquè és aquí on eren els forats als avions que no tornaren” Vaja, que no havien de reforçar les zones amb més impactes: havien de reforçar les zones amb molt pocs impactes. El seu raonament era que els avions rebien els impactes distribuïts de manera uniforme per tot el seu fuselatge. Si els avions que tornaven de les missions eren els que no tenien impactes a determinades zones, o n’hi tenien molt pocs, era segurament perquè els avions que rebien molt càstig en aquestes zones no tornaven. En canvi, els impactes a les zones que mostraven més càstig en els avions que pogueren inspeccionar no impedien que l’avió tornàs. Naturalment, tot això justificat amb un càlcul molt enginyós de la probabilitat que un avió fos abatut en funció del nombre d’impactes de bala rebuts a les diferents zones del fuselatge: enginyós, perquè només podia emprar la informació dels avions que no havien estat abatuts. Si us interessen les butzes matemàtiques del seu treball, les trobareu explicades en aquest article. El que us volem vendre és que la mostra de bombarders era oportunista: els que retornaven de les seves missions. Però fins i tot d’aquesta mostra es pogué obtenir informació amb les tècniques adients. 1.7 Test de la lliçó 1 (1) Quina, o quines, de les dades següents són quantitatives discretes? La pressió arterial sistòlica. L’estadi d’un càncer (que s’indica amb un número del 0 al 4) El nombre d’ingressos hospitalaris a través d’urgències al llarg d’un dia. El nombre de dones en un grup de persones. La proporció de dones en un grup de persones. (2) Quina, o quines, de les dades següents (podem entendre que) són quantitatives contínues? La pressió arterial sistòlica. L’estadi d’un càncer (que s’indica amb un número del 0 al 4) El nombre d’ingressos hospitalaris a través d’urgències al llarg d’un dia. El nombre de dones en un grup de persones. La proporció de dones en un grup de persones. (3) En termes estadístics, una població (marcau totes les respostes correctes): Només pot estar formada per persones Pot ser finita Pot ser infinita Pot ser qualsevol conjunt de coses en les quals estiguem interessats Pot incloure coses que no existeixin Les altres respostes són totes falses (4) En un estudi es volgué determinar el percentatge mitjà d’increment del temps de resposta a un estímul auditiu sota els efectes d’una intoxicació alcohòlica aguda. Per fer-ho, es reclutaren 6 voluntaris, es mesura el seu temps de resposta (en segons) a una sèrie d’estímuls auditius, a continuació se’ls administrà una quantitat alta d’alcohol i es tornà a mesurar el seu temps de resposta als mateixos estímuls auditius. Quina és la variable aleatòria d’interès? Prenem una persona, l’intoxicam amb alcohol i mesuram el seu temps de resposta a un estímul auditiu Prenem una persona, l’intoxicam amb alcohol i mesuram el seu temps de resposta a un estímul auditiu (en segons) Prenem una persona i calculam el seu percentatge d’increment del temps de resposta a un estímul auditiu sota els efectes d’una intoxicació alcohòlica aguda Prenem un grup de 6 persones i calculam la mitjana dels seus percentatges d’increment del temps de resposta a un estímul auditiu sota els efectes d’una intoxicació alcohòlica aguda Prenem una persona i calculam la diferència (en segons) entre el seu temps de resposta a un estímul auditiu abans i després d’una intoxicació alcohòlica aguda El percentatge mitjà d’increment del temps de resposta a un estímul auditiu sota els efectes d’una intoxicació alcohòlica aguda (5) Què sou vosaltres? Marcau l’única resposta correcta. Una mostra aleatòria simple dels estudiants de 1r curs d’algun grau de ciències d’Espanya. Una mostra aleatòria sense reposició dels estudiants de 1r curs d’algun grau de ciències d’Espanya. Una mostra de conveniència dels estudiants de 1r curs d’algun grau de ciències d’Espanya. Cap de les altres respostes és correcta. (6) Quan diem que una mostra aleatòria d’una població és simple? Marcau una sola resposta. Quan la prenem de cop. Quan és l’única mostra aleatòria que prenem. Quan la prenem de manera que els subjectes no es poden repetir. Quan la prenem de manera que els subjectes es poden repetir. Quan no és “múltiple”, és a dir, quan no conté subjectes repetits (encara que l’hàgim presa de manera que es puguin repetir). Cap de les altres respostes és correcta. (7) En un mostreig aleatori simple (marcau totes les respostes correctes): Cada membre de la població té la mateixa probabilitat de ser triat Si tenim els individus de la població ordenats en una llista, no es poden triar dos membres adjacents en aquesta llista No es pot estimar la probabilitat que la mostra triada sigui molt diferent del típic en la població Cada mostra possible d’una mida donada té la mateixa probabilitat de ser triada La decisió d’incloure o no un individu en una mostra depèn només de les característiques de l’individu Les altres respostes són totes falses (8) Els avantatges del mostreig aleatori inclouen (marcau totes les respostes correctes): Que es pot aplicar a qualsevol població Que permet estimar la probabilitat que la mostra triada sigui molt diferent del típic en la població Que no hi ha cap subpoblació els subjectes de la qual tenguin major probabilitat de ser triats Que és fàcil de dur a terme Que garanteix que la mostra triada serà representativa de la població original Les altres respostes són totes falses (9) En un estudi sobre pacients d’hospitals, es va prendre una mostra aleatòria de 20 hospitals diferents a partir d’una llista de tots els hospitals d’un país. A continuació, es va triar a l’atzar un 10% dels pacients hospitalitzats en un dia concret a cadascun d’aquests 20 hospitals. Quina, o quines, de les afirmacions següents són vertaderes en aquesta situació? Tots els hospitals tenen la mateixa probabilitat de ser triats Tots els pacients hospitalitzats aquest dia tenien la mateixa probabilitat de ser triats Totes les possibles mostres de pacients hospitalitzats aquest dia tenien la mateixa probabilitat de ser triades La mostra de pacients va ser estratificada Les altres respostes són totes falses (10) En un estudi sobre pacients d’hospitals, es va prendre una mostra aleatòria de 20 hospitals diferents a partir d’una llista de tots els hospitals d’un país. A continuació, es va triar a l’atzar 10 pacients hospitalitzats diferents en un dia concret a cadascun d’aquests 20 hospitals. Quina, o quines, de les afirmacions següents són vertaderes en aquesta situació? Tots els hospitals tenen la mateixa probabilitat de ser triats Tots els pacients hospitalitzats aquest dia tenien la mateixa probabilitat de ser triats Totes les possibles mostres de 200 pacients hospitalitzats aquest dia tenien la mateixa probabilitat de ser triades La mostra de pacients va ser estratificada Les altres respostes són totes falses "],
["chap-varal.html", "Tema 2 Variables aleatòries 2.1 Generalitats sobre variables aleatòries 2.2 Variables aleatòries discretes 2.3 Famílies importants de variables aleatòries discretes 2.4 Variables aleatòries contínues 2.5 Variables aleatòries normals 2.6 Test de la lliçó 2", " Tema 2 Variables aleatòries 2.1 Generalitats sobre variables aleatòries Una variable aleatòria definida sobre una població \\(\\Omega\\) és simplement una funció \\[ X: \\Omega\\to \\mathbb{R} \\] que assigna a cada subjecte de \\(\\Omega\\) un nombre real. La idea intuïtiva que hi ha al darrera d’aquesta definició és que una variable aleatòria mesura una característica dels subjectes de \\(\\Omega\\) que varia a l’atzar d’un subjecte a un altre. Per exemple: Prenem una persona d’una població i mesuram el seu nivell de colesterol, o la seva alçada, o el seu nombre de fills… En aquest cas, \\(\\Omega\\) és la població sota estudi, de la qual prenem la persona que mesuram. Llançam una moneda equilibrada 3 vegades i comptam les cares que obtenim. En aquest cas, \\(\\Omega\\) és la població formada per totes les seqüències de 3 llançaments d’una moneda equilibrada passades, presents i futures. El que més ens interessarà d’una variable aleatòria són les probabilitats dels esdeveniments que defineix. I quin tipus d’esdeveniments són els que ens interessen quan mesuram característiques numèriques? Doncs bàsicament esdeveniments definits mitjançant igualtats i desigualtats. Per exemple, si \\(X\\) és la variable aleatòria “Prenem una persona i mesuram el seu nivell de colesterol en plasma (en mg/dl)”, ens poden interessar esdeveniments de l’estil de: El conjunt de les persones amb nivell de colesterol entre 200 i 240. L’indicarem amb \\[ 200\\leqslant X\\leqslant 240 \\] El conjunt de les persones amb nivell de colesterol més petit o igual que 200: \\[ X\\leqslant 200 \\] El conjunt de les persones amb nivell de colesterol més gran que 180: \\[ X&gt;180 \\] El conjunt de les persones amb nivell de colesterol exactament 180: \\[ X=180 \\] Etc. Com dèiem, el que ens interessarà d’aquests esdeveniments serà la seva probabilitat, i llavors emprarem notacions de l’estil de les següents: \\(P(200\\leqslant X\\leqslant 240)\\). Això indica la probabilitat que una persona tengui el nivell de colesterol entre 200 i 240. Per abreujar, ho llegirem la “probabilitat que \\(X\\) estigui entre 200 i 240” i representa la proporció de persones (de la població \\(\\Omega\\) on hàgim definit la variable \\(X\\)) amb nivell de colesterol entre 200 i 240. \\(P(X\\leqslant 200)\\). Això indica la probabilitat que una persona tengui el nivell de colesterol més petit o igual que 200 (per abreujar, la probabilitat que “\\(X\\) sigui més petit o igual que 200”). És a dir, la proporció de persones amb nivell de colesterol més petit o igual que 200. Etc. En aquest context, indicarem normalment la unió amb una o i la intersecció amb una coma. Per exemple, si \\(X\\) és la variable aleatòria “Llançam una moneda 6 vegades i comptam les cares”: \\(P(X\\leqslant 2\\text{ o }X\\geqslant 5)\\): Probabilitat de treure com a màxim 2 cares o com a mínim 5. \\(P(2\\leqslant X, X&lt; 5)\\): Probabilitat de treure un nombre de cares que sigui més gran o igual que 2 i més petit que 5; és a dir, \\(P(2\\leqslant X&lt; 5)\\). Dues variables aleatòries \\(X,Y\\) són independents quan, per a tots els parells de valors \\(a,b\\in \\mathbb{R}\\), els esdeveniments \\[ X\\leqslant a, Y\\leqslant b \\] són independents. És a dir, intuïtivament, quan el valor que pren \\(X\\) sobre un subjecte no afecta per res el valor que hi pren \\(Y\\), i viceversa. Per exemple, si prenem una persona i: \\(X\\): li demanam que llanci una moneda 3 vegades i comptam les cares \\(Y\\): mesuram el seu nivell de colesterol en plasma (en mg/dl) (segurament) \\(X\\) i \\(Y\\) són independents. Recordau que els esdeveniments \\(X\\leqslant a\\) i \\(Y\\leqslant b\\) són independents quan satisfan les tres condicions equivalents següents: \\[ \\begin{array}{l} P(X\\leqslant a|Y\\leqslant b)=P(X\\leqslant a)\\\\ P(Y\\leqslant b|X\\leqslant a)=P(Y\\leqslant b)\\\\ P(X\\leqslant a, Y\\leqslant b)=P(X\\leqslant a)\\cdot P(Y\\leqslant b) \\end{array} \\] Més en general, unes variables aleatòries \\(X_1,X_2,\\ldots,X_n\\) són independents quan, per a tots \\(a_1,a_2,\\ldots,a_n\\in \\mathbb{R}\\), els esdeveniments \\[ X_1\\leqslant a_1, X_2\\leqslant a_2,\\ldots, X_n\\leqslant a_n \\] són independents. És a dir, quan el valor que pren una d’aquestes variables sobre un subjecte no afecta per res els valors que hi prenen les altres. 2.2 Variables aleatòries discretes Una variable aleatòria és discreta quan els seus possibles valors són dades quantitatives discretes. Per exemple, Nombre de cares en 3 llançaments d’una moneda Nombre de fills d’una dona Nombre de casos nous de COVID-19 en un dia a Mallorca 2.2.1 Densitat i distribució Sigui \\(X: \\Omega\\to \\mathbb{R}\\) una variable aleatòria discreta. El seu domini \\(D_X\\) és el conjunt dels valors que pot prendre: més concretament, és el conjunt dels \\(x\\in \\mathbb{R}\\) tals que \\(P(X=x)&gt;0\\). La seva funció de densitat és la funció \\(f_X:\\mathbb{R}\\to [0,1]\\) que assigna a cada \\(x\\in \\mathbb{R}\\) la probabilitat que \\(X\\) valgui \\(x\\): \\[ f_X(x)=P(X=x) \\] És a dir, \\(f_X(x)\\) és la proporció de subjectes de la població en els quals \\(X\\) val \\(x\\). La seva funció de distribució és la funció \\(F_X:\\mathbb{R}\\to [0,1]\\) que assigna a cada \\(x\\in \\mathbb{R}\\) la probabilitat que \\(X\\) sigui més petit o igual que \\(x\\): \\[ F_X(x)=P(X\\leqslant x) \\] És a dir, \\(F_X(x)\\) és la proporció de subjectes de la població en els quals \\(X\\) pren un valor \\(\\leqslant x\\). A la funció de distribució també se li sol dir funció de probabilitat acumulada per posar èmfasi en el fet que \\(F_X(x)\\) mesura la “freqüència relativa acumulada” de \\(x\\) en el total de la població. Exemple 2.1 Sigui \\(X\\) la variable aleatòria “Llançam 3 vegades una moneda equilibrada i comptam les cares”. Aleshores: El seu domini és el conjunt dels seus possibles valors: \\(D_X=\\{0,1,2,3\\}\\). La seva funció de densitat és definida per \\(f_X(x)=P(X=x)\\): \\(f_X(0)=P(X=0)=1/8\\) (la probabilitat de treure 0 cares en 3 llançaments) \\(f_X(1)=P(X=1)=3/8\\) (la probabilitat de treure 1 cara en 3 llançaments) \\(f_X(2)=P(X=2)=3/8\\) (la probabilitat de treure 2 cares en 3 llançaments) \\(f_X(3)=P(X=3)=1/8\\) (la probabilitat de treure 3 cares en 3 llançaments) \\(f_X(x)=P(X=x)=0\\) per a qualsevol altre valor de \\(x\\) (si \\(x\\notin\\{0,1,2,3\\}\\), la probabilitat de treure \\(x\\) cares en 3 llançaments és 0) En resum, la funció de densitat de \\(X\\) és \\[ f_X(x) =\\left\\{ \\begin{array}{ll} 1/8 &amp; \\text{ si $x=0$}\\\\ 3/8 &amp; \\text{ si $x=1$}\\\\ 3/8 &amp; \\text{ si $x=2$}\\\\ 1/8 &amp; \\text{ si $x=3$}\\\\ 0 &amp; \\text{ si $x\\neq 0,1,2,3$} \\end{array} \\right. \\] Figura 2.1: Funció de densitat de la variable aleatòria que compta el nombre de cares en 3 llançaments Si \\(X\\) és una variable aleatòria discreta, \\(P(X\\in A)=0\\) per a qualsevol subconjunt \\(A\\) disjunt amb \\(D_X\\), perquè, per la definició del domini \\(D_X\\), \\(X\\) no pot prendre cap valor fora de \\(D_X\\). Per exemple, quina és la probabilitat de treure entre 2.5 i 2.7 cares en llançar 3 vegades una moneda? 0. I la de treure \\(\\pi\\) cares? 0 un altre cop. Vegem ara la seva funció de distribució \\(F_X\\). Recordau que \\(F_X(x)=P(X\\leqslant x)\\) i que la nostra variable només pot prendre els valors 0, 1, 2 i 3. Si \\(x&lt;0\\), \\(F_X(x)=P(X\\leqslant x)=0\\) perquè \\(X\\) no pot prendre cap valor estrictament negatiu. Si \\(0\\leqslant x&lt;1\\), \\(F_X(x)=P(X\\leqslant x)=P(X=0)=f_X(0)=1/8\\), perquè si \\(0\\leqslant x&lt;1\\), l’únic valor \\(\\leqslant x\\) que pot prendre \\(X\\) és el 0. Si \\(1\\leqslant x&lt;2\\), \\(F_X(x)=P(X\\leqslant x)=P(X=0\\text{ o }X=1)\\) \\(=f_X(0)+f_X(1)=4/8=1/2\\), perquè si \\(1\\leqslant x&lt;2\\), els únics valors \\(\\leqslant x\\) que pot prendre \\(X\\) són 0 i 1. Si \\(2\\leqslant x&lt;3\\), \\(F_X(x)=P(X\\leqslant x)=P(X=0\\text{ o }X=1\\text{ o }X=2)\\) \\(=f_X(0)+f_X(1)+f_X(2)=7/8\\), perquè si \\(2\\leqslant x&lt;3\\), els únics valors \\(\\leqslant x\\) que pot prendre \\(X\\) són 0, 1 i 2. Si \\(3\\leqslant x\\), \\(F_X(x)=P(X\\leqslant x)=1\\), perquè si \\(x\\geqslant 3\\), segur que obtenim un nombre de cares \\(\\leqslant x\\). Per tant, la funció \\(F_X\\) és la funció \\[ F_X(x) =\\left\\{ \\begin{array}{ll} 0 &amp; \\text{ si $x&lt;0$}\\\\ 1/8 &amp; \\text{ si $0\\leqslant x&lt; 1$}\\\\ 4/8 &amp; \\text{ si $1\\leqslant x&lt; 2$}\\\\ 7/8 &amp; \\text{ si $2\\leqslant x&lt; 3$}\\\\ 1 &amp; \\text{ si $3\\leqslant x$} \\end{array} \\right. \\] El seu gràfic és el següent: Figura 2.2: Funció de distribució de la variable aleatòria que compta el nombre de cares en 3 llançaments Observau en aquest gràfic que aquesta funció de distribució \\(F_X\\) és creixent i escalonada. Això és general. Si \\(X\\) és una variable aleatòria discreta: \\(F_X\\) és una funció escalonada, amb bots en els valors de \\(D_X\\), que són els únics amb probabilitat estrictament més gran que 0 i per tant els únics que “sumen” probabilitat. Més en concret: Si \\(x_0,y_0\\in D_X\\) i \\(x_0&lt;y_0\\), llavors \\(F_X(x_0)&lt; F_X(y_0)\\), perquè, com que \\(P(X=y_0)&gt;0\\), \\[ \\begin{array}{rl} F_X(x_0)\\!\\!\\!\\!\\! &amp; =P(X\\leqslant x_0)&lt;P(X\\leqslant x_0)+P(X=y_0)\\\\ &amp; =P(X\\leqslant x_0\\text{ o }X=y_0)\\leqslant P(X\\leqslant y_0)=F_X(y_0) \\end{array} \\] Si \\(x_0\\in D_X\\) i dins \\((x_0,x]\\) no hi ha cap element de \\(D_X\\), aleshores \\(F_X(x_0)=F_X(x)\\), perquè \\[ \\begin{array}{rl} F_X(x)\\!\\!\\!\\!\\! &amp; =P(X\\leqslant x)=P(X\\leqslant x_0)+P(x_0&lt;X\\leqslant x)\\\\ &amp; =P(X\\leqslant x_0)+0= P(X\\leqslant x_0)=F_X(x_0) \\end{array} \\] ja que, com que \\((x_0,x]\\cap D_X=\\emptyset\\), \\(P(x_0&lt;X\\leqslant x)=0\\). Si \\(x_0\\in D_X\\), \\(P(X&lt;x_0)&lt;P(X\\leqslant x_0)\\), perquè \\[ P(X\\leqslant x_0)=P(X&lt;x_0)+P(X=x_0)&gt;P(X&lt;x_0) \\] \\(F_X\\) és creixent, perquè si \\(x\\leqslant y\\), tots els subjectes de \\(X\\leqslant x\\) també pertanyen a \\(X\\leqslant y\\), i per tant \\[ P(X\\leqslant x)\\leqslant P(X\\leqslant y). \\] Com que els valors que pren \\(F_X\\) són probabilitats, no poden ser ni més petits que 0 ni més grans que 1. El coneixement de \\(f_X\\), més les regles del càlcul de probabilitats, permet calcular la probabilitat de qualsevol esdeveniment relacionat amb \\(X\\): \\[ P(X\\in A) =\\sum_{x\\in A} P(X=x) = \\sum_{x\\in A} f_X(x) \\] En particular \\[ F_X(x_0)=P(X\\leqslant x_0)=\\sum_{x\\leqslant x_0} f_X(x) \\] La moda d’una variable aleatòria discreta \\(X\\) és el valor (o els valors) \\(x_0\\) tal que \\(f_X(x_0)=P(X=x_0)\\) és màxim. Per tant, la moda és el valor de \\(X\\) més probable o més freqüent en la població. Per exemple, per a la nostra variable aleatòria que compta el nombre de cares en 3 llançaments d’una moneda equilibrada, la moda són els valors 1 i 2. Exemple 2.2 Una variable aleatòria discreta \\(X\\) és uniforme quan el seu domini \\(D_X\\) és finit i tots els seus elements tenen la mateixa probabilitat. És a dir, si \\(D_X\\) té \\(m\\) elements, aleshores \\(P(X=x)=1/m\\) per a cada \\(x\\in D_X\\). Per exemple, el resultat de llançar un dau equilibrat és una variable aleatòria discreta. Com que tots els resultats del domini d’una variable aleatòria discreta uniforme tenen la mateixa probabilitat, tots en són la moda (o cap no ho és, depèn de si veieu el tassó mig ple o mig buit). Considerau la variable aleatòria \\(X\\) “Llançam una moneda equilibrada tantes vegades com sigui necessari fins que surti una cara per primera vegada, i comptam quantes vegades l’hem haguda de llançar”. Quin és el seu domini? Quina és la seva funció de densitat? Quina és la seva moda? Què significa? Quina és la seva funció de distribució? (Indicació: Calculau primer \\(P(X&gt;x)\\), tenint en compte que \\(X&gt;x\\) significa que en els primer \\(x\\) llançaments ha sortit creu, i per això hem hagut de llançar la moneda més de \\(x\\) vegades per obtenir una cara.) 2.2.2 Esperança Quan prenem una mostra d’una variable aleatòria \\(X\\) definida sobre una població, podem calcular la mitjana i la desviació típica dels seus valors a fi i efecte d’obtenir una idea de quin és el valor central de la mostra i si els seus valors estan tots molt a prop d’aquest valor central o no. Naturalment, també ens podem preguntar per aquesta mena d’informació per al total de la població: Quin és el “valor mitjà” de \\(X\\) sobre tota la població? Aquesta variable, pren valors molt dispersos, o més aviat els pren concentrats al voltant del seu valor mitjà? La primera pregunta la responem amb la mitjana, o esperança, de \\(X\\), i la segona amb la seva variància i la seva desviació típica. Comencem amb la primera. La mitjana, o esperança (o valor esperat, valor mitjà…), d’una variable aleatòria discreta \\(X\\) amb densitat \\(f_X:D_X\\to [0,1]\\) és \\[ E(X)=\\sum_{x\\in D_X} x\\cdot f_X(x) \\] Sovint també l’indicarem amb \\(\\mu_X\\). La interpretació natural de \\(E(X)\\) és que és la mitjana dels valors de la variable \\(X\\) en el total de la població \\(\\Omega\\). En efecte, com que \\(P(X=x)\\) és la proporció de subjectes de \\(\\Omega\\) en els quals \\(X\\) val \\(x\\), \\[ E(X)=\\sum_{x\\in D_X} x\\cdot P(X=x) \\] és la mitjana del valor de \\(X\\) sobre tots els subjectes de \\(\\Omega\\). Comparau-ho amb l’exemple següent. Exemple 2.3 Si, en una classe, un 10% dels estudiants han tret un 4 en un examen, un 20% un 6, un 50% un 8 i un 20% un 10, quina ha estat la nota mitjana obtinguda? Segurament calcularíeu aquesta mitjana de la manera següent: \\[ 4\\cdot 0.1+6\\cdot 0.2+8\\cdot 0.5+10\\cdot 0.2=7.6 \\] Doncs aquest valor és la mitjana de la variable aleatòria \\(X\\) “Prenc un estudiant d’aquesta classe i mir quina nota ha tret en aquest examen”: \\[ \\begin{array}{rl} E(X)\\!\\!\\!\\!\\! &amp;=4\\cdot P(X=4)+6\\cdot P(X=6)+8\\cdot P(X=8)+10\\cdot P(X=10)\\\\ &amp; = 4\\cdot 0.1+6\\cdot 0.2+8\\cdot 0.5+10\\cdot 0.2=7.6 \\end{array} \\] A banda de la seva interpretació com a “la mitjana de \\(X\\) en el total de la població”, \\(E(X)\\) és també el valor esperat de \\(X\\), en el sentit següent: Suposau que prenem a l’atzar una mostra de \\(n\\) subjectes de la població, mesuram \\(X\\) sobre ells i calculam la mitjana aritmètica dels \\(n\\) valors obtinguts. Aleshores, quan la mida \\(n\\) de la mostra tendeix a \\(\\infty\\), aquesta mitjana aritmètica tendeix a valer \\(E(X)\\) “gairebé sempre”, en el sentit que la probabilitat que el seu límit sigui \\(E(X)\\) és 1. És a dir: si mesuràssim \\(X\\) sobre molts subjectes triats a l’atzar i calculàssim la mitjana dels valors obtinguts, és gairebé segur que obtendríem un valor molt proper a \\(E(X)\\). Exemple 2.4 Seguim amb la variable aleatòria \\(X\\) “Llançam una moneda equilibrada 3 vegades i comptam les cares”. La seva esperança és \\[ E(X)= 0\\cdot \\frac{1}{8}+1\\cdot \\frac{3}{8}+2\\cdot \\frac{3}{8}+3\\cdot \\frac{1}{8}=1.5 \\] Això ens diu que: La mitjana de \\(X\\) és 1.5: El valor mitjà de la variable \\(X\\) sobre tota la població de seqüències de 3 llançaments d’una moneda equilibrada és 1.5. El valor esperat de \\(X\\) és 1.5: Si repetíssim moltes vegades l’experiment de llançar la moneda 3 vegades i comptar les cares, de mitjana obtendríem, molt probablement, un valor molt pròxim a 1.5. Abreujam això dient que si llançam la moneda 3 vegades, esperam treure 1.5 cares. Més en general, si \\(X\\) és una variable aleatòria i \\(g:\\mathbb{R}\\to \\mathbb{R}\\) és una funció, l’esperança de \\(g(X)\\) és \\[ E(g(X))=\\sum_{x\\in D_X} g(x)\\cdot f_X(x). \\] Un altre cop, la interpretació natural d’aquest valor és que és la mitjana de \\(g(X)\\) sobre la població, i també que és el valor “esperat” de \\(g(X)\\) en el sentit anterior. Exemple 2.5 Si llançam una moneda equilibrada 3 vegades, comptam les cares i elevam aquest nombre de cares al quadrat, quin valor esperam obtenir? Serà l’esperança de \\(X^2\\), on \\(X\\) és la variable aleatòria “Llançam una moneda equilibrada 3 vegades i comptam les cares” (és a dir, aquesta \\(X^2\\) és la variable aleatòria “Llançam una moneda equilibrada 3 vegades, comptam les cares i elevam aquest número al quadrat”): \\[ E(X^2)= 0\\cdot \\frac{1}{8}+1\\cdot \\frac{3}{8}+2^2\\cdot \\frac{3}{8}+3^2\\cdot \\frac{1}{8}=3 \\] Fixau-vos que \\(E(X^2) \\neq E(X)^2\\). Per exemple, en els dos darrers exemples hem vist que si \\(X\\) és la variable aleatòria que compta el nombre de cares en 3 llançaments d’una moneda equilibrada, \\(E(X^2)=3\\) però \\(E(X)^2=1.5^2=2.25\\). En general, donades una variable aleatòria \\(X\\) i una aplicació \\(g:\\mathbb{R}\\to \\mathbb{R}\\), el més habitual és que \\(E(g(X))\\neq g(E(X))\\). L’esperança de les variables aleatòries discretes té les propietats següents, totes molt raonables si les interpretau en termes del valor mitjà de \\(X\\) sobre la població: Sigui \\(b\\) una variable aleatòria constant, que sobre tots els individus de la població pren el mateix valor \\(b\\in \\mathbb{R}\\). Aleshores, \\(E(b)=b\\). Si en una classe tothom treu un 8 d’un examen, la nota mitjana és un 8, no? Sí, ja sabem que parlar de variables constants és un oxímoron, però de vegades una variable aleatòria pren el mateix valor sobre tots els subjectes d’una població. Per exemple “Prenc un estudiant de Biologia o Bioquímica del curs 2019/20 i compt el seu nombre de cames”. L’esperança és lineal: Si \\(X\\) és una variable aleatòria i \\(a,b\\in \\mathbb{R}\\), \\(E(aX+b)=aE(X)+b\\) Si en una classe la mitjana d’un examen ha estat un 6 i decidim multiplicar per 1.2 totes les notes i sumar-les 1 punt, la mitjana de la nova nota serà 1.2·6+1=8.2, no? Si \\(X,Y\\) són dues variables aleatòries, \\(E(X+Y)=E(X)+E(Y)\\). Si en una classe la mitjana de la part de qüestions d’un examen ha estat un 3.5 (sobre 5) i la de la part d’exercicis ha estat un 3 (sobre 5), la nota mitjana de l’examen serà un 3.5+3=6.5, no? Combinant les dues propietats anteriors, si \\(X_1,\\ldots,X_n\\) són variables aleatòries i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ E(a_1X_1+\\cdots+a_nX_n+b)=a_1E(X_1)+\\cdots+a_nE(X_n)+b \\] L’esperança és monòtona creixent: Si \\(X\\leqslant Y\\) (en el sentit que el valor de \\(X\\) sobre cada subjecte de la població \\(\\Omega\\) és més petit o igual que el valor de \\(Y\\) sobre ell), llavors \\(E(X)\\leqslant E(Y)\\). Si tots traieu millor nota de Matemàtiques II que de Matemàtiques I, la nota mitjana de Matemàtiques II serà més gran que la de Matemàtiques I, no? Siguin \\(N\\) un nombre natural estrictament positiu i \\(X\\) una variable aleatòria discreta uniforme amb domini \\(D_X=\\{1,\\ldots,N\\}\\). Què val el seu valor esperat? 2.2.3 Variància i desviació típica La variància d’una variable aleatòria discreta \\(X\\) és \\[ \\sigma(X)^2 =E((X-\\mu_X)^2) =\\sum_{x\\in D_X} (x-\\mu_X)^2\\cdot f_X(x) \\] És a dir, és la mitjana del quadrat de la diferència entre \\(X\\) i la seva mitjana \\(\\mu_X\\). També l’indicarem amb \\(\\sigma_X^2\\). Fixau-vos que es tracta de la traducció “poblacional” de la definició de variància per a una mostra, i per tant serveix per mesurar el mateix que aquella: la dispersió dels resultats de \\(X\\) respecte de la mitjana. Només que ara és per a tota la població, i no per a una mostra. La identitat següent vos pot ser útil. Teorema 2.1 \\(\\sigma(X)^2=E(X^2)-\\mu_X^2\\). Operem (i recordau que \\(E(X)=\\mu_X\\)) \\[ \\begin{array}{rl} \\sigma(X)^2\\!\\!\\!\\!\\! &amp; =E((X-\\mu_X)^2)=E(X^2-2\\mu_X\\cdot X+\\mu_X^2)\\\\ &amp; = E(X^2)-2\\mu_X\\cdot E(X)+\\mu_X^2\\\\ &amp; \\text{(per la linealitat d&#39;$E$)}\\\\ &amp; = E(X^2)-2\\mu_X^2+\\mu_X^2=E(X^2)-\\mu_X^2 \\end{array} \\] La desviació típica (o desviació estàndard) d’una variable aleatòria discreta \\(X\\) és l’arrel quadrada positiva de la seva variància: \\[ \\sigma(X)=+\\sqrt{\\sigma(X)^2} \\] També mesura la dispersió dels valors de \\(X\\) respecte de la mitjana. Sovint l’indicarem amb \\(\\sigma_X\\). En el context de les variables aleatòries, no hi ha “variància” i “variància mostral”, només “variància”. El mateix nom us hauria de donar la pista que la “variància mostral” està definida només per a mostres. El motiu per introduir la variància i la desviació típica per mesurar la dispersió dels valors de \\(X\\) és la mateixa que en estadística descriptiva: la variància és més fàcil de manejar (no involucra arrels quadrades) però les seves unitats són les de \\(X\\) al quadrat, mentre que les unitats de la desviació típica són les de \\(X\\), i per tant el seu valor és més fàcil d’interpretar. Exemple 2.6 Seguim amb la variable aleatòria \\(X\\) “Llançam una moneda equilibrada 3 vegades i comptam les cares”. Recordem que \\(\\mu_X=E(X)=1.5\\). Aleshores, la seva variància és: \\[ \\begin{array}{rl} \\sigma(X)^2 \\!\\!\\!\\!\\! &amp; \\displaystyle=(0-1.5)^2\\cdot \\frac{1}{8}+(1-1.5)^2\\cdot \\frac{3}{8}\\\\ &amp;\\displaystyle\\qquad +(2-1.5)^2\\cdot \\frac{3}{8}+(3-1.5)^2\\cdot \\frac{1}{8}=0.75 \\end{array} \\] Si recordam que \\(E(X^2)=3\\), podem veure que \\[ E(X^2)-\\mu_X^2=3-1.5^2=0.75=\\sigma(X)^2 \\] La seva desviació típica és \\[ \\sigma(X) =\\sqrt{\\sigma(X)^2}=\\sqrt{0.75}= 0.866 \\] Vegem algunes propietats de la variància i la desviació típica: Si \\(b\\) és una variable aleatòria constant que sobre tots els individus de la població pren el valor \\(b\\in \\mathbb{R}\\), aleshores \\(\\sigma(b)^2=\\sigma(b)=0\\). Una variable aleatòria constant té zero dispersió. El recíproc també és cert: si \\(\\sigma(X)^2=0\\), la variable \\(X\\) és constant. En efecte, observau a \\[ \\sigma(X)^2 =\\sum_{x\\in D_X} (x-\\mu_X)^2\\cdot f_X(x) \\] que \\(\\sigma(X)^2\\) és una suma de nombres positius. Per tant, si és 0, tots els sumands \\((x-\\mu_X)^2\\cdot f_X(x)\\) han de ser 0. Però \\(f_X(x)&gt;0\\) per a cada \\(x\\in D_X\\). Per tant, si \\(\\sigma(X)^2=0\\), tots els \\(x-\\mu_X\\), amb \\(x\\in D_X\\), han de ser 0, és a dir, \\(D_X=\\{\\mu_X\\}\\): \\(X\\) només pot prendre un valor. \\(\\sigma(aX+b)^2=a^2\\cdot \\sigma(X)^2\\). En efecte \\[ \\begin{array}{l} \\sigma(aX+b)^2 =E((aX+b)^2)-E(aX+b)^2\\\\ \\quad = E(a^2X^2+2abX+b^2)-(aE(X)+b)^2\\\\ \\quad \\text{(per la linealitat de $E$)}\\\\ \\quad = a^2E(X^2)+2abE(X)+b^2-a^2E(X)^2-2abE(X)-b^2\\\\ \\quad \\text{(una altre cop, per la linealitat de $E$)}\\\\ \\quad = a^2(E(X^2)-E(X)^2)=a^2\\sigma(X)^2 \\end{array} \\] \\(\\sigma(aX+b)=|a|\\cdot \\sigma(X)\\) (recordau que la desviació típica és positiva, i \\(+\\sqrt{a^2}=|a|\\)). Si \\(X,Y\\) són variables aleatòries independents, \\[ \\sigma(X+Y)^2=\\sigma(X)^2+\\sigma(Y)^2 \\] i per tant \\[ \\sigma(X+Y)=\\sqrt{\\sigma(X)^2+\\sigma(Y)^2} \\] Si no són independents, en general aquesta igualtat és falsa. Per posar un exemple extrem, \\[ \\sigma(X+X)^2=4\\sigma(X)^2 \\neq \\sigma(X)^2+\\sigma(X)^2. \\] Més en general, si \\(X_1,\\ldots,X_n\\) són variables aleatòries independents (i, en principi, només en aquest cas) i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ \\begin{array}{l} \\sigma(a_1X_1+\\cdots+a_nX_n+b)^2=a_1\\cdot\\sigma(X_1)^2+\\cdots+a_n\\cdot\\sigma(X_n)^2\\\\ \\sigma(a_1X_1+\\cdots+a_nX_n+b)=\\sqrt{a_1\\cdot\\sigma(X_1)^2+\\cdots+a_n\\cdot\\sigma(X_n)^2} \\end{array} \\] 2.2.4 Quantils Sigui \\(p\\in [0,1]\\). El quantil d’ordre \\(p\\) (o \\(p\\)-quantil) d’una variable aleatòria discreta \\(X\\) és el valor \\(x_p\\in D_X\\) tal que \\(P(X\\leqslant x_p)\\geqslant p\\) però \\(P(X&lt; x_p)&lt;p\\). És a dir, el valor \\(x_p\\in D_X\\) més petit tal que \\(P(X\\leqslant x_p)\\geqslant p\\). Per exemple, que el 0.25-quantil d’una variable aleatòria discreta \\(X\\) sigui, jo què sé, 8, significa que almenys un 25% de la població té un valor de \\(X\\) més petit o igual que 8, però menys d’un 25% de la població té un valor de \\(X\\) estrictament més petit que 8. És a dir, 8 és el valor més petit per al qual la probabilitat acumulada arriba al 25%. Si existeix algun \\(x_p\\in D_X\\) tal que \\(P(X\\leqslant x_p)=p\\), llavors el \\(p\\)-quantil és aquest \\(x_p\\), perquè, per a tot altre \\(x\\in D_x\\): Si \\(x&lt;x_p\\), \\(P(X\\leqslant x)&lt;P(X\\leqslant x_p)=F_X(x_p)=p\\) i per tant \\(x\\) no pot ser el \\(p\\)-quantil de \\(X\\). Si \\(x&gt;x_p\\), \\(p=P(X\\leqslant x_p)\\leqslant P(X&lt;x)\\), i per tant \\(x\\) tampoc no pot ser el \\(p\\)-quantil de \\(X\\). Com en estadística descriptiva, alguns quantils de variables aleatòries tenen noms propis. Per exemple: La mediana de \\(X\\) és el seu 0.5-quantil. El primer i el tercer quartils de \\(X\\) són els seus \\(0.25\\)-quantil i \\(0.75\\)-quantil, respectivament. Etc. Exemple 2.7 Seguim amb la variable aleatòria \\(X\\) “Llançam una moneda equilibrada 3 vegades i comptam les cares”. Recordem que la seva funció de distribució és \\[ F_X(x)=\\left\\{ \\begin{array}{ll} 0 &amp; \\text{ si $x&lt;0$}\\\\ 0.125 &amp; \\text{ si $0\\leqslant x&lt;1$}\\\\ 0.5 &amp; \\text{ si $1\\leqslant x&lt;2$}\\\\ 0.875 &amp; \\text{ si $2\\leqslant x&lt;3$}\\\\ 1 &amp; \\text{ si $3\\leqslant x $} \\end{array} \\right. \\] Llavors, per exemple: El seu 0.125-quantil és 0 El seu 0.25-quantil és 1 La seva mediana és 1 El seu 0.75-quantil és 2 Siguin \\(N\\) un nombre natural estrictament positiu i \\(X\\) una variable aleatòria discreta uniforme amb domini \\(D_X=\\{1,\\ldots,N\\}\\). Què val la seva mediana? Encara que emprem “mitjana”, “variància”, “quantils”, etc. tant per a variables aleatòries com per a mostres, no heu de confondre-les. Una variable aleatòria representa una característica numèrica dels subjectes d’una població: “Prenem un estudiant de la UIB i mesuram la seva alçada en m.” La mitjana i la variància d’aquesta variable són les de tota la població d’estudiants de la UIB i descriuen propietats de tota la població d’estudiants de la UIB. Una mostra d’una variable aleatòria són els valors de la variable sobre un subconjunt de la població. Mesuram les alçades (en m) de 50 estudiants de la UIB d’aquest curs. La mitjana i la variància d’aquesta mostra són només les d’aquestes 50 alçades, i poden servir per descriure aquest conjunt de 50 alçades o per estimar els valors de la mitjana i la variància de la població d’estudiants de la UIB Quan volguem destacar que una mitjana, una variància etc. són les d’una variable aleatòria sobre tota una població, les qualificarem de poblacionals. 2.3 Famílies importants de variables aleatòries discretes En aquesta secció descriurem tres famílies de variables aleatòries “distingides” que heu de conèixer: Binomial Hipergeomètrica Poisson Cadascuna d’aquestes famílies tenen un tipus específic de funció de densitat que depèn d’un o diversos paràmetres. De cadascuna d’aquestes famílies de variables heu de saber: Distingir quan una variable aleatòria és d’aquest tipus. Les seves propietats bàsiques, com ara quins són els seus paràmetres, quin és el seu valor esperat i si la seva densitat és simètrica o té una cua a qualque costat. Emprar R per calcular coses quan sigui necessari. 2.3.1 Variables aleatòries binomials Un experiment de Bernoulli és una acció amb només dos resultats possibles, que identificam amb “Èxit” (\\(E\\)) i “Fracàs” (\\(F\\)), i de la qual, en principi, no podem predir el seu resultat per mor de la influència de l’atzar. Per exemple, llançar un dau cúbic i mirar si ha sortit un 6 (\\(E\\): treure un 6; \\(F\\): no treure un 6). La probabilitat d’èxit \\(p\\) d’un experiment de Bernoulli és la probabilitat d’obtenir un èxit \\(E\\). És a dir, \\(P(E)=p\\). Naturalment, llavors, \\(P(F)=1-p\\). A l’exemple del llançament d’un dau, on \\(E\\) és treure un 6, \\(p=1/6\\). Més exemples d’experiments de Bernoulli: Llançar una moneda equilibrada i mirar si dóna cara. \\(E\\): donar cara \\(p=1/2\\) Realitzar un test PCR de COVID-19 a una persona i mirar si dóna positiu \\(E\\): donar positiu \\(p\\): la proporció de persones que donen positiu en el test a la població de la qual hem extret el nostre subjecte No confongueu la proporció de persones que donen positiu en el test PCR de COVID-19 amb la proporció de persones que tenen la COVID-19. Una variable aleatòria de Bernoulli de paràmetre \\(p\\) (abreujadament, \\(Be(p)\\)) és una variable aleatòria \\(X\\) que consisteix a efectuar un experiment de Bernoulli i donar 1 si s’obté un èxit i 0 si s’obté un fracàs. Una variable aleatòria binomial de paràmetres \\(n\\) i \\(p\\) (abreujadament, \\(B(n,p)\\)) és una variable aleatòria \\(X\\) que compta el nombre d’èxits \\(E\\) en una seqüència de \\(n\\) repeticions independents d’un mateix experiment de Bernoulli de probabilitat d’èxit \\(p\\). Independents significa que les \\(n\\) variables aleatòries de Bernoulli, una per a cada repetició de l’experiment de Bernoulli, són independents; és a dir, que el resultat de cada experiment en la seqüència no depèn dels resultats dels altres. Direm a \\(n\\) la mida de les mostres i a \\(p\\) la probabilitat (poblacional) d’èxit. De vegades també direm d’una variable \\(X\\) de tipus \\(B(n,p)\\) que té distribució binomial de paràmetres \\(n\\) i \\(p\\). Per exemple: Una variable de Bernoulli \\(Be(p)\\) és una variable binomial \\(B(1,p)\\). Llançar una moneda equilibrada 10 vegades i comptar les cares és una variable binomial \\(B(10,0.5)\\). Triar 20 estudiants de la UIB a l’atzar, l’un rere l’altre, permetent repeticions i cada tria independent de les altres, i mirar si al primer semestre han aprovat totes les assignatures o no, és una variable binomial \\(B(20,p)\\) amb \\(p\\) la proporció d’estudiants de la UIB que han aprovat totes les assignatures del primer semestre. El tipus més comú de variables binomials que ens interessaran és aquest darrer: Tenim un subconjunt \\(A\\) d’una població \\(\\Omega\\) (per exemple, \\(\\Omega\\) els estudiants de la UIB i \\(A\\) els que han aprovat totes les assignatures del primer semestre). Sigui \\(p\\) la proporció poblacional d’individus de la població que pertanyen a \\(A\\), és a dir \\(p=P(A)\\). Prenem mostres aleatòries simples de mida \\(n\\) de la població i comptam quants subjectes de la mostra són de \\(A\\). Aquesta variable aleatòria és binomial \\(B(n,p)\\). Tenim el resultat següent. Teorema 2.2 Si \\(X\\) és una variable \\(B(n,p)\\): El seu domini és \\(D_X=\\{0,1,\\ldots,n\\}\\) La seva funció de densitat és \\[ f_X(k)=\\left\\{\\begin{array}{ll} \\displaystyle\\binom{n}{k}p^k(1-p)^{n-k} &amp; \\text{ si $k\\in D_X$}\\\\ 0 &amp; \\text{ si $k \\notin D_X$} \\end{array} \\right. \\] El seu valor esperat és \\(E(X)=np\\) La seva variància és \\(\\sigma(X)^2=np(1-p)\\) Recordau que: El factorial \\(m!\\) d’un nombre natural \\(m\\) és \\(m!=m(m-1)\\cdots 2\\cdot 1\\) si \\(m\\geqslant 1\\). Si \\(m=0\\), es pren \\(0!=1\\). El nombre combinatori \\(\\binom{n}{k}\\), amb \\(k,n\\) nombres naturals tals que \\(0\\leqslant k\\leqslant n\\), és \\[ \\binom{n}{k}=\\frac{\\overbrace{n\\cdot (n-1)\\cdots (n-k+1)}^k}{k\\cdot (k-1)\\cdots 2\\cdot 1}=\\frac{n!}{k!(n-k)!} \\] i ens dóna el nombre de subconjunts de \\(k\\) elements de \\(\\{1,\\ldots,n\\}\\). Si \\(k&gt;n\\) o \\(k&lt;0\\), es pren \\(\\binom{n}{k}=0\\). Suposem que efectuam \\(n\\) repeticions consecutives i independents d’un experiment de Bernoulli de probabilitat d’èxit \\(p\\) i comptam el nombre d’èxits \\(E\\); direm \\(X\\) a la variable aleatòria resultant. Per seguir la demostració, si no us sentiu molt còmodes amb el raonament amb enes i kas abstractes, anau repetint-lo prenent, per exemple, \\(n=4\\). Els possibles resultats són totes les paraules possibles de \\(n\\) lletres formades per \\(E\\)’s i \\(F\\)’s. Com que els experiments successius són independents, la probabilitat de cadascuna d’aquestes paraules és el producte de les probabilitats dels seus resultats individuals. Per tant, si una paraula concreta té \\(k\\) lletres \\(E\\) i \\(n-k\\) lletres \\(F\\) (s’han obtingut \\(k\\) èxits i \\(n-k\\) fracassos), la seva probabilitat és \\(p^k(1-p)^{n-k}\\), independentment de l’ordre en el qual hàgim obtingut els resultats. Per calcular la probabilitat d’obtenir una seqüència amb \\(k\\) èxits, sumarem les probabilitats d’obtenir cadascuna de les seqüències de \\(n\\) lletres amb \\(k\\) \\(E\\)’s. Com que totes tenen la mateixa probabilitat, el resultat serà la probabilitat d’una paraula amb \\(k\\) \\(E\\)’s i \\(n-k\\) \\(F\\)’s multiplicada pel nombre total de paraules diferents amb \\(k\\) \\(E\\)’s i \\(n-k\\) \\(F\\)’s. Ara, quantes paraules hi ha amb \\(k\\) \\(E\\)’s i \\(n-k\\) \\(F\\)’s? Cada una d’elles queda caracteritzada per les posicions de les \\(k\\) \\(E\\)’s, per tant és el nombre de possibles eleccions de conjunts de \\(k\\) posicions per a les \\(E\\)’s. Això darrer és el nombre de possibles subconjunts de \\(k\\) elements (les posicions on hi haurà les \\(E\\)’s) de \\(\\{1,\\ldots,n\\}\\), que és el nombre combinatori \\(\\binom{n}{k}\\). Per tant ja tenim \\[ P(X=k)=\\binom{n}{k}p^k(1-p)^{n-k}. \\] A partir d’aquí, el càlcul del valor esperat i la variància és sumar \\[ \\begin{array}{l} \\displaystyle E(X)=\\sum_{k=0}^n k\\cdot \\binom{n}{k}p^k(1-p)^{n-k}\\\\ \\displaystyle \\sigma(X)^2=\\sum_{k=0}^n k^2\\cdot \\binom{n}{k}p^k(1-p)^{n-k}-\\Big(\\sum_{k=0}^n k\\cdot \\binom{n}{k}p^k(1-p)^{n-k})^2 \\end{array} \\] Us podeu fiar de nosaltres, donen \\(np\\) i \\(np(1-p)\\), respectivament. Si ho pensau, veureu que el valor de \\(E(X)\\) és l’“esperat”. Vegem, si preneu una mostra aleatòria de \\(n\\) subjectes d’una població en la qual la proporció de subjectes \\(E\\) és \\(p\\), quants subjectes \\(E\\) “esperau” obtenir en la vostra mostra? Doncs una proporció \\(p\\) de la mostra, és a dir \\(p\\cdot n\\), no? La funció de distribució d’una variable binomial no té una fórmula explícita. Només podem dir que si \\(X\\) és \\(B(n,p)\\), \\[ F_X(x)=\\sum_{k=0}^{\\lfloor x\\rfloor} \\binom{n}{k}p^k(1-p)^{n-k} \\] És un doi, però, per si de cas, us volem fer observar que si \\(X\\) és \\(B(n,p)\\), \\(P(X=k)\\) no només depèn de \\(k\\) sinó també dels paràmetres \\(n\\) i \\(p\\). Això serà general. Totes les variables aleatòries d’una mateixa família tenen la funció de densitat de la mateixa forma, i només hi varien els valors dels paràmetres. El tipus de teorema anterior és el que fa que ens interessi conèixer algunes famílies distingides freqüents de variables aleatòries. Si, per exemple, reconeixem que una variable aleatòria és binomial i coneixem els seus valors de \\(n\\) i \\(p\\) i sabem el teorema anterior, automàticament sabem la seva funció de densitat, i amb ella la seva funció de distribució, el seu valor esperat, la seva variància etc., sense necessitat de deduir tota aquesta informació cada vegada que trobem una variable d’aquestes. Saber coses estalvia temps. Naturalment, conèixer les propietats de les variables aleatòries binomials només és útil si sabem reconèixer quan estam al davant d’una. Fixau-vos que en una variable aleatòria binomial: Comptam quantes vegades ocorre un esdeveniment (l’èxit \\(E\\)) en una seqüència d’intents. En cada intent, l’esdeveniment que ens interessa passa o no passa, sense grisos. El nombre d’intents és fix, \\(n\\). Cada intent és independent dels altres. En cada intent, la probabilitat que passi l’esdeveniment que ens interessa és sempre la mateixa, \\(p\\). Així, per exemple: Una dona té 4 fills. La probabilitat que un fill sigui nina és fixa, 0.51. El sexe de cada fill és independent dels altres. Comptam quantes filles té. És una variable binomial \\(B(4,0.51)\\). En una aula hi ha 5 homes i 45 dones. Triam 10 estudiants, un rere l’altre i sense repetir-los, per fer-los una pregunta. Cada elecció és independent de les altres. Comptam quants homes hem interrogat. No és una variable binomial: com que no podem repetir estudiants, en cada ronda la probabilitat de triar un home depèn del sexe dels estudiants triats abans que ell. Per tant la \\(p\\) no és la mateixa en cada elecció. Per exemple, en la primera ronda la probabilitat de triar un home és 5/50=0.1. Ara, si en la primera ronda surt triat un home, la probabilitat que en la segona ronda tornem a triar un home es redueix a 4/49=0.0816, mentre que si en la primera elecció surt una dona, la probabilitat de triar un home en la segona ronda puja a 5/49=0.102. En una aula hi ha 5 homes i 45 dones. Triam 10 estudiants, un rere l’altre però cada estudiant pot ser triat més d’una vegada, per a fer-los una pregunta. Cada elecció és independent de les altres. Comptam quants homes hem interrogat. Ara sí que és una variable binomial \\(B(10,0.9)\\). En una aula hi ha 5 homes i 45 dones. Triam estudiants un rere l’altre i cada estudiant pot ser triat més d’una vegada, per fer-los una pregunta. Cada elecció és independent de les altres. Comptam quants estudiants hem hagut de triar per arribar a interrogar 5 homes. No és una variable binomial: no compta el nombre d’èxits en una seqüència d’un nombre fix d’intents, sinó quants intents hem necessitat per arribar a un nombre fix d’èxits. En una aula hi ha 5 homes i 45 dones. Llançam una moneda equilibrada: si surt cara triam 10 estudiants i si surt creu en triam 20, per a fer-los una pregunta. Tant en un cas com en l’altre, els triarem un rere l’altre, cada estudiant podrà ser triat més d’una vegada i cada elecció serà independent de les altres. Comptam quants homes hem interrogat. No és una variable binomial: el nombre d’intents no és fix. La probabilitat que un dia de novembre plogui és d’un 32%. Triam una setmana de novembre i comptam quants dies ha plogut. No és d’una variable binomial. Encara que a priori cada dia tengui la mateixa probabilitat de pluja, que plogui un dia no és independent que plogui l’anterior. Per què fos binomial, hauríem d’haver triat 7 dies de novembre a l’atzar, permetent que sortissin repetits. A Espanya hi ha 46,700,000 persones, de les quals un 11.7% són diabètics. Triam 100 espanyols diferents a l’atzar (de manera independent els uns dels altres) i comptam quants són diabètics. No és binomial, pel mateix motiu que no ho era quan elegíem estudiants sense permetre repeticions. Però pràcticament sí que ho és, perquè les probabilitats gairebé no varien d’una elecció a la següent. Per exemple, quan ja duim 99 individus escollits, la probabilitat de triar un individu concret dels que queden és \\(1/(46700000-99)=2.141332\\times 10^{-8}\\) mentre que si permetem repeticions, aquesta probabilitat és \\(1/46700000=2.141328\\times 10^{-8}\\). Coincideixen fins la dotzena xifra decimal. En aquest cas farem la trampa de considerar-la binomial. Vegem alguns gràfics de la funció de densitat de variables aleatòries binomials. Primer, per a \\(n=10\\) i diferents valors de \\(p\\). Ara per a \\(n=100\\): Com podeu veure, la moda d’una binomial \\(B(n,p)\\) és la seva mitjana \\(np\\) o, si aquest nombre no és enter, un dels dos enters que l’envolten. Si \\(p=0.5\\), la funció de densitat és simètrica respecte de \\(n/2\\): com que \\(E\\) i \\(F\\) tenen la mateixa probabilitat, 0.5, la probabilitat de treure \\(k\\) \\(E\\)’s és la mateixa que la de treure \\(k\\) \\(F\\)’s, és a dir, la de treure \\(n-k\\) \\(E\\)’s. En canvi, si \\(p\\neq 0.5\\), la funció de densitat no és simètrica, com podeu veure als gràfics de més a dalt. Per agilitzar els tests de COVID-19, s’ha proposat l’estratègia següent (anomenada pooled sample testing o simplement pooling). Unim grups de 10 mostres en una sola mostra i l’analitzam. Si dóna negatiu, serà senyal que totes la mostres originals eren negatives. Declararem llavors negatius els 10 subjectes de les mostres originals. Si dóna positiu, serà perquè almenys una de les mostres originals era positiva. En aquest cas, analitzarem les 10 mostres per separat. Observau llavors que si les 10 mostres eren negatives, fem un sol test, mentre que si alguna mostra és positiva, en fem 11. Amb l’enfocament tradicional, un test per mostra i per avall, faríem sempre 10 tests. Suposem que el test és exacte: dóna positiu sempre que ha de donar positiu i negatiu sempre que ha de donar negatiu. Sigui \\(p\\) la prevalença de la COVID-19 en un moment i població donats. Donades 10 mostres preses en aquest moment en aquesta població, quin és el valor esperat de tests que hem de realitzar? Si \\(p\\) fos petita, de l’ordre de l’1% al 5%, significaria el pooling un estalvi esperat considerable de tests? Com efectuar càlculs amb una variable aleatòria d’una família donada? Una possibilitat és usar una aplicació de mòbil o tauleta. La nostra preferida és Probability distributions, disponible tant per a Android com per a iOS. Figura 2.3: L’apli Probability Distributions. Una altra possibilitat és usar R. R coneix totes la distribucions de variables aleatòries importants; per exemple, per a R la binomial és binom. Aleshores Afegint al nom de la distribució el prefix d, tenim la seva funció de densitat: de la binomial serà dbinom. Afegint al nom de la distribució el prefix p, tenim la seva funció de distribució: de la binomial, pbinom. Afegint al nom de la distribució el prefix q, tenim els seus quantils: per a la binomial, qbinom. Afegint al nom de la distribució el prefix r, tenim una funció que produeix mostres aleatòries de nombres amb aquesta distribució de probabilitat: per a la binomial, rbinom. Aquestes funcions s’apliquen a l’argument de la funció i els paràmetres de la variable aleatòria en el seu ordre usual. Per exemple, per a la binomial, s’apliquen a (argument, \\(n\\), \\(p\\)). Per a més detalls sobre tot això, consultau la lliçó de R sobre el tema. Vegem alguns exemples. Si llançam 20 vegades un dau cúbic equilibrat, quina és la probabilitat de treure exactament 5 uns? Diguem \\(X\\) a la variable aleatòria que compta el nombre d’uns en seqüències de 20 llançaments d’un dau equilibrat. És una variable binomial \\(B(20,1/6)\\). Ens demanen \\(P(X=5)\\), i aquesta probabilitat ens la dóna la funció de densitat de \\(X\\). És \\(f_X(5)\\): dbinom(5,20,1/6) ## [1] 0.1294103 Si llançam 20 vegades un dau cúbic equilibrat, quina és la probabilitat de treure com a màxim 5 uns? Amb les notacions anteriors, ens demanen \\(P(X\\leqslant 5)\\), i aquesta probabilitat ens la dóna la funció de distribució de \\(X\\). És \\(F_X(5)\\): pbinom(5,20,1/6) ## [1] 0.8981595 Si llançam 20 vegades un dau cúbic equilibrat, quina és la probabilitat de treure menys de 5 uns? Amb les notacions anteriors, ens demanen \\(P(X&lt; 5)\\), és a dir, \\(P(X\\leqslant 4)=F_X(4)\\): pbinom(4,20,1/6) ## [1] 0.7687492 Si llançam 20 vegades un dau cúbic equilibrat, quina és la probabilitat de treure 8 uns o més? Amb les notacions anteriors, ens demanen \\(P(X\\geqslant 8)\\). Com que el contrari de treure 8 uns o més és treure 7 uns o menys, tenim que \\(P(X\\geqslant 8)=1-P(X\\leqslant 7)=1-F_X(7)\\): 1-pbinom(7,20,1/6) ## [1] 0.01125328 Si llançam 20 vegades un dau equilibrat, quin és el més petit nombre \\(N\\) d’uns per al qual la probabilitat de treure com a màxim \\(N\\) uns arriba al 25%? Ens demanen el més petit valor \\(N\\) tal que \\(P(X\\leqslant N)\\geqslant 0.25\\), i això per definició és el 0.25-quantil de \\(X\\): qbinom(0.25,20,1/6) ## [1] 2 Vegem que en efecte \\(N=2\\) compleix el demanat: la probabilitat de treure com a màxim 2 uns és pbinom(2,20,1/6) ## [1] 0.3286591 i la probabilitat de treure’n com a màxim 1 és pbinom(1,20,1/6) ## [1] 0.1304203 Veiem per tant que amb 1 no arribam al 25% de probabilitat i amb 2 sí. Volem simular 50 rondes de llançar 20 vegades un dau equilibrat i comptar els uns, és a dir, volem una mostra aleatòria de mida 50 de la nostra variable \\(X\\): rbinom(50,20,1/6) ## [1] 1 1 5 3 1 5 3 2 1 5 5 0 3 2 3 1 2 4 2 3 4 2 3 3 0 3 5 1 2 2 3 2 3 2 4 4 8 6 ## [39] 2 4 4 7 3 1 2 3 2 5 3 5 Cada vegada que repetim aquesta instrucció segurament obtendrem una mostra aleatòria nova: rbinom(50,20,1/6) ## [1] 3 6 4 5 4 6 4 5 0 6 3 5 3 3 2 0 2 3 2 6 3 2 5 4 3 5 5 6 4 5 3 3 4 6 3 4 5 7 ## [39] 2 5 2 4 3 4 6 4 3 5 4 6 rbinom(50,20,1/6) ## [1] 2 4 3 1 7 4 4 2 4 2 3 6 1 1 5 1 6 5 0 4 3 3 2 2 5 5 4 5 3 6 7 2 8 4 3 4 2 4 ## [39] 3 0 3 4 0 3 1 3 3 2 0 6 rbinom(50,20,1/6) ## [1] 6 6 2 5 3 4 5 2 3 2 2 6 4 8 4 3 1 4 3 5 4 1 1 3 3 6 0 4 5 4 6 3 5 1 2 5 1 3 ## [39] 4 2 5 7 6 2 4 2 3 4 7 3 2.3.2 Variables aleatòries hipergeomètriques Recordau que el paradigma de variable aleatòria binomial és: tenc una població amb una proporció \\(p\\) de subjectes que satisfan una condició \\(E\\), en prenc una mostra aleatòria simple de mida \\(n\\) i compt el nombre de subjectes \\(E\\) en la meva mostra. Si canviam “mostra aleatòria simple” per “mostra aleatòria sense reposició”, la distribució de la variable aleatòria que obtenim és una altra: és hipergeomètrica. Una variable aleatòria és hipergeomètrica (o té distribució hipergeomètrica) de paràmetres \\(N\\), \\(M\\) i \\(n\\) (abreujadament, \\(H(N,M,n)\\)) quan es pot identificar amb el procés següent. Tenim una població formada per \\(N\\) subjectes que satisfan una condició \\(E\\) i \\(M\\) subjectes que no la satisfan (per tant, en total, \\(N+M\\) subjectes), prenem una mostra aleatòria sense reposició de mida \\(n\\) i comptam el nombre de subjectes \\(E\\) en aquesta mostra. Direm a \\(N\\) el nombre poblacional d’èxits, a \\(M\\) el nombre poblacional de fracassos i a \\(n\\) la mida de les mostres. Fixau-vos llavors que \\(N+M\\) és la mida total de la població i que \\(N/(N+M)\\) és la probabilitat poblacional d’èxit (la fracció de subjectes que satisfan \\(E\\) en el total de la població). Amb R, igual que la distribució binomial era binom, la distribució hipergeomètrica és hyper. Tenim el resultat següent: Teorema 2.3 Si \\(X\\) és una variable \\(H(N,M,n)\\): El seu domini és \\(D_X=\\{0,1,\\ldots,\\text{min}(N,n)\\}\\) La seva funció de densitat és \\[ f_X(k)=\\left\\{\\begin{array}{ll} \\displaystyle\\dfrac{\\binom{N}{k}\\cdot \\binom{M}{n-k}}{\\binom{N+M}{n}} &amp; \\text{ si $k\\in D_X$}\\\\ 0 &amp; \\text{ si $k\\notin D_X$} \\end{array} \\right. \\] El seu valor esperat és \\(E(X)=\\dfrac{nN}{N+M}\\) La seva variància és \\(\\sigma(X)^2=\\dfrac{nNM(N+M-n)}{(N+M)^2(N+M-1)}\\) La demostració de la fórmula per a la densitat és senzilla, en termes de casos favorables partit per casos possibles. Vegem: \\(f_X(k)\\) és la probabilitat que un subconjunt de \\(n\\) subjectes (diferents) de la població contingui \\(k\\) subjectes \\(E\\) i \\(n-k\\) subjectes dels altres (en direm \\(F\\)). Casos possibles: Tots els possibles subconjunts de \\(n\\) elements de la població. El nombre de tots els subconjunts de \\(n\\) elements d’una població de mida \\(N+M\\) és \\(\\binom{N+M}{n}\\). Ja tenim el denominador. Casos favorables: Tots els possibles subconjunts formats per \\(k\\) subjectes \\(E\\) i \\(n-k\\) subjectes \\(F\\). Cada un d’aquests subconjunts s’obté Triant un subconjunt de \\(k\\) subjectes \\(E\\): com que n’hi ha \\(N\\), d’aquests subconjunts n’hi ha \\(\\binom{N}{k}\\) Triant un subconjunt de \\(n-k\\) subjectes \\(F\\): com que n’hi ha \\(M\\), d’aquests subconjunts n’hi ha \\(\\binom{M}{n-k}\\) Per cada tria d’un subconjunt de \\(k\\) subjectes \\(E\\) i un subconjunt de \\(n-k\\) subjectes \\(F\\), obtenim un subconjunt “favorable” diferent. Per tant, el seu nombre és el producte \\(\\binom{N}{k}\\cdot\\binom{M}{n-k}\\) Això ens dóna el numerador. Fixau-vos que si diem \\(p\\) a la probabilitat poblacional d’èxit, \\(p=N/(N+M)\\), llavors \\[ E(X)=np. \\] És la mateixa fórmula que per a les variables binomials \\(B(n,p)\\) (i si ho pensau una estona veureu que, un altre cop i pel mateix argument, és el que la intuïció ens diu que ha de valer). D’altra banda, si diem \\(\\mathbf{P}\\) a la mida total de la població, \\(\\mathbf{P}=N+M\\), llavors \\[ \\sigma(X)^2=n\\cdot\\dfrac{N}{N+M}\\cdot\\dfrac{M}{N+M}\\cdot\\frac{N+M-n}{N+M-1}=np(1-p)\\cdot\\dfrac{\\mathbf{P}-n}{\\mathbf{P}-1} \\] que és la variància d’una variable \\(B(n,p)\\) multiplicada per un factor de correcció a causa del fet que ara prenem mostres sense repetició i la variància és més petita que si les prenem amb repetició. A aquest factor \\((\\mathbf{P}-n)/(\\mathbf{P}-1)\\) se’n diu factor de població finita. Fixau-vos que si \\(\\mathbf{P}\\) és molt més gran que \\(n\\), tendrem que \\(\\mathbf{P}-n\\approx \\mathbf{P}-1\\) i per tant \\((\\mathbf{P}-n)/(\\mathbf{P}-1)\\approx 1\\) i la variància de la hipergeomètrica serà aproximadament la de la binomial. Això és consistent amb el que ja hem comentat: si la població és molt més gran que la mostra, prendre les mostres amb o sense reposició no afecta massa a les mostres obtingudes, per la qual cosa la distribució de probabilitat ha de ser molt semblant. Recordau els exemples següents: A Espanya hi ha 46,700,000 persones, de les quals un 11.7% són diabètics. Triam 100 espanyols diferents i comptam quants són diabètics. Aquesta variable és, en realitat, hipergeomètrica amb \\(N=0.117\\cdot 46700000=5463900\\), \\(M=46700000-N=41236100\\) i \\(n=100\\), però en la pràctica la consideram binomial \\(B(100,0.117)\\). El factor de població finita és \\[ \\frac{46700000-100}{46700000-1}=0.9999979 \\] Pràcticament 1. En canvi: En una aula hi ha 5 homes i 45 dones. Triam 10 estudiants, un rere l’altre i sense repetir-los, per fer-los una pregunta. Cada elecció és independent de les altres. Comptam quants homes hem interrogat. Aquesta variable és \\(H(5,45,10)\\). El factor de població finita en aquesta cas no és aproximadament 1: dóna \\[ \\frac{50-10}{50-1}=0.8163 \\] No és correcte aproximar-la per una binomial \\(B(10,0.1)\\). El gràfic següent compara la funció de densitat d’una variable \\(B(10,0.1)\\) amb les de variables hipergeomètriques \\(H(5,45,10)\\), \\(H(50,450,10)\\) i \\(H(5000,45000,10)\\) perquè vegeu com a mesura que la mida de la població creix (mantenint constant la proporció poblacional d’èxits), la distribució hipergeomètrica s’aproxima a la binomial. 2.3.3 Variables aleatòries de Poisson Una variable aleatòria \\(X\\) és de Poisson (o té distribució de Poisson) de paràmetre \\(\\lambda&gt;0\\) (abreujadament, \\(Po(\\lambda)\\)) quan: El seu domini és \\(D_X=\\mathbb{N}\\), el conjunt de tots els nombres naturals (és a dir, pot prendre com a valor qualsevol nombre natural). La seva funció de densitat és \\[ f_X(k)=\\left\\{\\begin{array}{ll} e^{-\\lambda}\\cdot \\dfrac{\\lambda^k}{k!} &amp; \\text{ si $k\\in \\mathbb{N}$}\\\\ 0 &amp; \\text{ si $k \\notin \\mathbb{N}$} \\end{array} \\right. \\] Per a R, la distribució de Poisson és pois. Teorema 2.4 Si \\(X\\) és una variable \\(Po(\\lambda)\\), aleshores \\(E(X)= \\sigma(X)^2= \\lambda\\). És a dir, el paràmetre \\(\\lambda\\) d’una variable de Poisson és el seu valor esperat, i coincideix amb la seva variància. Us deveu estar demanant: per a què ens serveix definir una variable de Poisson mitjançant la seva densitat, si el que ens interessa és poder classificar una variable com a Poisson (o binomial, o hipergeomètrica etc.) per a així saber “gratis” la seva densitat? La resposta és que la família de Poisson inclou un tipus de variables aleatòries molt freqüent que tot seguit descrivim. Suposem que tenim un tipus d’objectes que poden donar-se en una regió contínua de temps o espai. Per exemple, defuncions de persones per una determinada malaltia en el decurs del temps, exemplars d’una espècie de planta en un terreny, mutacions en bocins de cromosoma, o nombres de bacteris en bocins d’una superfície. Suposem a més que les aparicions d’aquests objectes satisfan les propietats següents (per simplificar el llenguatge, hi suposarem que observam aparicions d’aquests objectes en el temps; si es tracta d’una variable que compta objectes en regions de l’espai, canviau-hi “instant” per “punt”): Les aparicions dels objectes són aleatòries: en cada instant, un objecte es dóna, o no, a l’atzar, amb una probabilitat fixa i constant. Les aparicions dels objectes són independents: que es doni un objecte en un instant concret, no depèn per a res que s’hagi donat o no un objecte en un altre instant. Les aparicions dels objectes no són simultànies: és pràcticament impossible que dos objectes d’aquests es donin en el mateix instant exacte, mesurat amb precisió infinita. En aquesta situació, la variable \\(X_t\\) que pren un interval de temps de durada \\(t\\) i compta el nombre d’objectes que s’hi donen és de Poisson \\(Po(\\lambda_t)\\), amb \\(\\lambda_t\\) el nombre esperat d’objectes en aquest interval de temps, és a dir, el nombre mitjà d’objectes en intervals de temps d’aquesta mida. Per exemple, quan el que compten ocorre a l’atzar, són variables de Poisson: El nombre de malalts admesos en urgències en un dia (o en 12 hores, o en una setmana…) El nombre de defuncions per una malaltia concreta en un dia (o en una setmana, o en un any…) El nombre d’albiraments de dofins en una hora durant un vol d’inspecció El nombre de bacteris en un quadrat d’1 cm de costat (o d’1 m de costat…) Fixau-vos que aquest tipus de coneixement ens serveix per a dues coses: Si sabem que aquestes variables són de Poisson, coneixem la seva densitat i per tant podem calcular el que volguem per a elles. Si les dades que observam haurien de seguir una distribució de Poisson però sembla que no (per exemple, perquè la seva variància sigui molt diferent de la seva mitjana, tan diferent que sigui difícil de creure que la mitjana i la variància poblacionals siguin iguals), llavors és senyal que qualque cosa “estranya” està passant que afecta la seva aparició. Exemple 2.8 Observau la diferència entre les dues variables següents: Nombres mensuals de defuncions per un tipus de càncer en un país. El moment exacte de les defuncions es produeix a l’atzar, segurament mai no es donen dues defuncions exactament en el mateix instant, si els poguéssim mesurar amb precisió infinita, i les defuncions es produeixen de manera independent. És de Poisson. Nombres mensuals de defuncions per una malatia infecciosa en un país. Un altre cop, el moment exacte de les defuncions es produeix a l’atzar i segurament mai no es donen dues defuncions exactament en el mateix instant, si els poguéssim mesurar amb precisió infinita. Però les infeccions no són independents, precisament perquè es tracta d’una malaltia infecciosa, i per tant les defuncions tampoc: com ens hem cansat d’observar amb la COVID-19, en un mateix cluster de la malaltia es poden produir diverses morts associades. No és de Poisson. Com que les aparicions dels objectes que compta una variable de Poisson són aleatòries i independents, el nombre mitjà d’objectes és lineal en la mida de la regió. És a dir, per exemple, en un interval de dos dies esperam veure el doble d’objectes que en un dia, i en una setmana 7 vegades els d’un dia. Vegem alguns gràfics de la funció de densitat de variables aleatòries de Poisson. Com veieu, la densitat d’una variable Poisson és asimètrica, amb un màxim al voltant de \\(\\lambda\\) i una cua a la dreta, però a mida que \\(\\lambda\\) creix, l’asimetria va minvant. El nombre d’estudiants que entren en el bar del vostre edifici al Campus en un interval de 5 minuts, creieu que segueix una distribució de Poisson? 2.4 Variables aleatòries contínues Una variable aleatòria és contínua quan els seus possibles valors són dades quantitatives contínues. Per exemple: Pes Nivell de colesterol en sang Diàmetre d’un tumor En aquest curs ens restringirem a variables aleatòries contínues \\(X: \\Omega\\to \\mathbb{R}\\) que satisfan la propietat extra següent: la seva funció de distribució \\[ \\begin{array}{rcl} F_X: \\mathbb{R} &amp; \\to &amp; [0,1]\\\\ x &amp;\\mapsto &amp;P(X\\leqslant x) \\end{array} \\] és contínua. Totes les variables aleatòries contínues que us puguin interessar en algun moment satisfan aquesta propietat, així que no perdem res imposant-la. I el que hi guanyam és que: Si \\(X\\) és una variable aleatòria contínua amb funció de distribució contínua, la probabilitat que prengui cada valor concret és 0: \\[ P(X=a)=0 \\text{ per a tot $a \\in \\mathbb{R}$}. \\] Per si passa per aquí qualcú que en necessiti una demostració: \\[ \\begin{array}{l} \\displaystyle P(X=a) = P(X\\leqslant a)-P(X&lt;a)=P(X\\leqslant a)-P\\Big(\\bigcup_{n\\geqslant 1} \\Big(X\\leqslant a-\\frac{1}{n}\\Big)\\Big)\\\\ \\displaystyle \\qquad= P(X\\leqslant a)-\\lim_{n\\geqslant 1}P\\Big(X\\leqslant a-\\frac{1}{n}\\Big)= F_X(a)-\\lim_{n\\geqslant 1}F_X\\Big(a-\\frac{1}{n}\\Big)=0 \\end{array} \\] perquè \\(F_X\\) és contínua. En particular: Per a una variable aleatòria contínua, probabilitat 0 no significa impossible. Cada valor de \\(X\\) té probabilitat 0, però si prenem un subjecte de la població, \\(X\\) tendrà qualque valor sobre ell, no? Per tant, aquest valor de \\(X\\) és possible, malgrat tengui probabilitat 0. De \\(P(X=a)=0\\) es dedueix que la probabilitat d’un esdeveniment definit amb una desigualtat és exactament la mateixa que la de l’esdeveniment corresponent definit amb una desigualtat estricta. En particular, contràriament al que passava a les variables aleatòries discretes, per a una variable aleatòria contínua sempre tenim que \\[ P(X\\leqslant a)=P(X&lt;a) \\] perquè \\[ P(X\\leqslant a)=P(X&lt;a)+P(X=a)=P(X&lt;a)+0=P(X&lt;a). \\] Més exemples: \\(P(X\\geqslant a)=P(X&gt; a)+P(X=a)=P(X&gt; a)\\) \\(P(a \\leqslant X\\leqslant b)=P(a&lt;X &lt;b)+P(X=a)+P(X=b)\\) \\(=P(a&lt;X &lt;b)\\) 2.4.1 Densitat i distribució Sigui \\(X\\) una variable aleatòria contínua. Com ja hem dit, la seva funció de distribució \\(F_X\\) torna a ser \\[ x\\mapsto F_X(x)=P(X\\leqslant x) \\] Però com que ara tenim que \\(P(X=x)=0\\) per a tot \\(x\\in \\mathbb{R}\\), no podem definir la funció de densitat de \\(X\\) com a \\(f_X(x)=P(X=x)\\). Què podem fer? Recordau que, a les variables aleatòries discretes, \\[ F_X(a)=\\sum_{x\\leqslant a} f_X(x) \\] En el context de matemàtiques “contínues”, la suma \\(\\sum\\) es tradueix en una integral \\(\\int\\). Definim aleshores la funció de densitat d’una variable aleatòria contínua \\(X\\) com la funció \\(f_X:\\mathbb{R}\\to \\mathbb{R}\\) tal que: \\(f_X(x)\\geqslant 0\\), per a tot \\(x\\in \\mathbb{R}\\) \\(\\displaystyle F_X(a)=\\int_{-\\infty}^a f_{X}(x)\\, dx\\) per a tot \\(a \\in \\mathbb{R}\\). Recordau que la integral té una interpretació senzilla en termes d’àrees. En concret, donats \\(a \\in \\mathbb{R}\\) i una funció \\(f(x)\\), el valor de la integral \\[ \\int_{-\\infty}^a f(x)\\, dx \\] és igual a l’àrea de la regió compresa entre la corba \\(y=f(x)\\) i l’eix d’abscisses \\(y=0\\) a l’esquerra de la recta vertical \\(x=a\\). Per tant, la funció de densitat \\(f_X\\) de \\(X\\) és la funció positiva tal que, per a tot \\(a\\in \\mathbb{R}\\), \\(F_X(a)\\) és igual a l’àrea sota la corba \\(y=f_X(x)\\) (és a dir, entre aquesta corba i l’eix d’abscisses) a l’esquerra de \\(x=a\\). Quina és la idea intuïtiva que hi ha al darrere d’aquesta definició de densitat? Suposau que dibuixam histogrames de freqüències relatives dels valors de \\(X\\) sobre tota la població. Com que estam parlant de tota la població, la freqüència relativa de cada classe és la proporció d’individus de la població en els quals el valor de \\(X\\) pertany a aquesta classe: és a dir, la probabilitat que \\(X\\) caigui dins la classe. Recordau que, en un histograma de freqüències relatives: La freqüència relativa (ara, la probabilitat) de cada classe és l’àrea de la seva barra, és a dir, l’amplada de la classe per l’alçada de la barra. Diem a l’alçada d’una barra la densitat de la classe (i per tant, qualque cosa tendrà a veure amb la densitat de \\(X\\), no ho trobau?). Si \\(a\\) és un extrem d’una classe, la freqüència relativa acumulada fins \\(a\\) (la probabilitat que \\(X\\leqslant a\\)) és la suma de les àrees de les barres a l’esquerra d’\\(a\\). Si dibuixam els histogrames de \\(X\\) prenent classes cada vegada més estretes, els seus polígons de freqüències tendeixen a dibuixar una corba, que hem acolorit en vermell en el darrer histograma de la seqüència següent: Quan l’amplada de les classes tendeix a 0, obtenim una corba que és el límit d’aquests polígons de freqüències: En el límit, la probabilitat que \\(X\\leqslant a\\) serà el límit de les sumes de les àrees de les barres a l’esquerra d’\\(a\\), i per tant l’àrea sota aquesta corba límit a l’esquerra d’\\(a\\). Això ens diu que que aquesta corba és precisament la funció de densitat \\(y=f_X(x)\\). La funció de densitat \\(f_X\\) d’una variable aleatòria contínua \\(X\\) és la funció límit dels polígons de freqüències d’histogrames de \\(X\\) quan l’amplada de les classes tendeix a 0. Vegem algunes propietats que es dedueixen del fet que \\(F_X(a)=P(X\\leqslant a)\\) sigui igual a l’àrea sota la corba \\(y=f_X(x)\\) a l’esquerra de \\(x=a\\): Com que \\(P(X&lt;\\infty)=P(\\Omega)=1\\), l’àrea sota tota la corba \\(y=f_X(x)\\) és 1. \\(P(a\\leqslant X\\leqslant b)=P(X\\leqslant b)-P(X&lt;a)\\) és l’àrea sota la corba \\(y=f_X(x)\\) a l’esquerra de \\(x=b\\) menys l’àrea sota la corba \\(y=f_X(x)\\) a l’esquerra de \\(x=a\\). Per tant, \\(P(a\\leqslant X\\leqslant b)\\) és igual a l’àrea sota la corba \\(y=f_X(x)\\) entre \\(x=a\\) i \\(x=b\\). Si \\(\\varepsilon&gt;0\\) és molt, molt petit, l’àrea sota la corba \\(y=f_X(x)\\) entre \\(a-\\varepsilon\\) i \\(a+\\varepsilon\\) és aproximadament igual a la del rectangle de base l’interval \\([a-\\varepsilon,a+\\varepsilon]\\) i alçada \\(f_X(a)\\), és a dir, a \\(2\\varepsilon\\cdot f_X(a)\\) (vegeu la Figura 2.4). És a dir, \\[ P(a-\\varepsilon\\leqslant X\\leqslant a+\\varepsilon)\\approx 2\\varepsilon\\cdot f_X(a). \\] Per tant, \\(f_X(a)\\) ens dóna una indicació de la probabilitat que \\(X\\) valgui aproximadament \\(a\\) (però no és \\(P(X=a)\\), que val 0). És a dir, per exemple, si \\(f_X(a)=0.1\\) i \\(f_X(b)=0.5\\), la probabilitat que \\(X\\) prengui un valor proper a \\(b\\) és 5 vegades més gran que la probabilitat que prengui un valor proper a \\(a\\). Figura 2.4: L’àrea sota la corba al voltant d’\\(a\\) és aproximadament igual a la del rectangle d’alçada fX(a) Però \\(P(X=a)=P(X=b)=0\\), així que, per favor, evitau dir que “la probabilitat que \\(X\\) valgui \\(b\\) és 5 vegades més gran que la probabilitat que valgui \\(a\\)”. Sí, ja sabem que \\(5\\cdot 0=0\\), però la frase és enganyosa: la probabilitat que \\(X\\) valgui \\(b\\) no més gran que la probabilitat que valgui \\(a\\). A les variables aleatòries discretes, definíem la moda com el valor (o els valors) més probable. Però ara no té sentit definir la moda d’una variable contínua \\(X\\) com el valor \\(x_0\\) tal que \\(P(X=x_0)\\) sigui màxim, perquè… \\(P(X=x)=0\\) per a tot \\(x\\in \\mathbb{R}\\). Aleshores, es defineix la moda d’una variable aleatòria contínua \\(X\\) com el valor (o els valors) \\(x_0\\) tal que \\(f_X(x_0)\\) és màxim. Com que \\(f_X(x_0)\\) mesura la probabilitat que \\(X\\) valgui “aproximadament” \\(x_0\\), tenim que la moda de \\(X\\) és el valor prop del qual és més probable que caigui el valor de \\(X\\). Unes consideracions finals: Ho hem dit en la definició, i ho hem emprat implícitament en tota la secció, però ho tornam a repetir: \\(f_X(x)\\geqslant 0\\) per a tot \\(x\\in \\mathbb{R}\\). En realitat, que \\(f_X(x)\\) sigui \\(\\geqslant 0\\) per a tot \\(x\\in \\mathbb{R}\\) és conseqüència del fet que la funció \\(F_X(x)\\) sigui positiva i creixent (les funcions de distribució són sempre creixents, perquè si \\(x&lt;y\\), \\(F_X(x)=P(X\\leqslant x)\\leqslant P(X\\leqslant y)=F_X(y)\\)) i coincideixi amb \\(\\int_{-\\infty}^x f_X(x)\\,dx\\). Però és més senzill donar-ho com a part de la definició i així ens estalviam la demostració. \\(f_X(x)\\) no és una probabilitat, i per tant pot ser més gran que 1. Per exemple, el gràfic següent mostra la densitat d’una variable normal \\(N(0,0.01)\\) (vegeu la Secció 2.5), que arriba a valer gairebé 40. La funció de densitat \\(f_X\\) no té per què ser contínua, malgrat la funció de distribució \\(F_X\\) ho sigui. 2.4.2 Esperança, variància, quantils… L’esperança i la variància d’una variable aleatòria contínua \\(X\\), amb funció de densitat \\(f_X\\), es defineixen com en el cas discret, substituint la suma \\(\\sum_{x\\in D_x}\\) per una integral, i tenen les mateixes propietats. La mitjana, o esperança (o valor mitjà, valor esperat…), de \\(X\\) és \\[ E(X)=\\int_{-\\infty}^{\\infty}x \\cdot f_{X}(x)\\, dx \\] És a dir, és l’àrea compresa entre l’eix d’abscisses i la corba \\(y=xf_X(x)\\). Com en el cas discret, també l’indicarem de vegades amb \\(\\mu_X\\). Aquest valor té la mateixa interpretació que en el cas discret: Representa el valor mitjà de \\(X\\) sobre el total de la població. És (amb probabilitat 1) el límit de les mitjanes aritmètiques de mostres aleatòries de mida \\(n\\) de valors de \\(X\\), quan \\(n\\to \\infty\\). Si \\(g:\\mathbb{R}\\to \\mathbb{R}\\) és una funció contínua, l’esperança de \\(g(X)\\) és \\[ E(g(X))=\\int_{-\\infty}^{+\\infty} g(x) f_X(x)dx \\] La variància de \\(X\\) és \\[ \\sigma(X)^2=E((X-\\mu_X)^2)=\\int_{-\\infty}^{+\\infty} (x-\\mu_X)^2 f_X(x)dx \\] i es pot demostrar que és igual a \\[ \\sigma(X)^2=E(X^2)-\\mu_X^2. \\] També l’indicarem de vegades amb \\(\\sigma_X^2\\). La desviació típica de \\(X\\) és \\[ \\sigma(X)=+\\sqrt{\\sigma(X)^2} \\] i també l’indicarem de vegades amb \\(\\sigma_X\\). Com en el cas discret, la variància i la desviació típica quantifiquen la variabilitat dels resultats de \\(X\\) respecte del seu valor mitjà \\(\\mu_X\\). Aquests paràmetres de \\(X\\) tenen les mateixes propietats en el cas continu que en el discret. Les recordam: Si \\(b\\) és una variable aleatòria constant, \\(E(b)=b\\) i \\(\\sigma(b)^2=0\\). Si \\(\\sigma(X)^2=0\\), \\(X\\) és constant. I és clar, si \\(X\\) només pot prendre un valor, aleshores ja no és contínua, sino discreta. Per tant, per conveni, d’ara endavant suposarem que les nostres variables aleatòries contínues tenen variància no nul·la. Si \\(X_1,\\ldots,X_n\\) són variables aleatòries i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ E(a_1X_1+\\cdots+a_nX_n+b)=a_1E(X_1)+\\cdots+a_nE(X_n)+b \\] Si \\(X\\leqslant Y\\), aleshores \\(E(X)\\leqslant E(Y)\\). Si \\(a,b\\in \\mathbb{R}\\), \\(\\sigma(aX+b)^2=a^2 \\sigma(X)^2\\) i \\(\\sigma(aX+b)=|a|\\cdot \\sigma(X)\\). Si \\(X_1,\\ldots,X_n\\) són variables aleatòries independents (i, en principi, només en aquest cas) i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), \\[ \\begin{array}{l} \\sigma(a_1X_1+\\cdots+a_nX_n+b)^2=a_1\\cdot\\sigma(X_1)^2+\\cdots+a_n\\cdot\\sigma(X_n)^2\\\\ \\sigma(a_1X_1+\\cdots+a_nX_n+b)=\\sqrt{a_1\\cdot\\sigma(X_1)^2+\\cdots+a_n\\cdot\\sigma(X_n)^2} \\end{array} \\] Si no són independents, aquestes igualtats poden ser falses. El quantil d’ordre \\(p\\) (o \\(p\\)-quantil) d’una variable aleatòria contínua \\(X\\) és el valor \\(x_p\\in \\mathbb{R}\\) més petit tal que \\[ F_X(x_p)=P(X\\leqslant x_p)=p \\] Observau que, com que \\(F_X(x)\\) tendeix a 0 (la probabilitat del conjunt buit) quan \\(x\\to -\\infty\\) i tendeix a 1 (la probabilitat de tot \\(\\mathbb{R}\\)) quan \\(x\\to +\\infty\\) i és contínua (no pega bots), pren tots els valors de l’interval \\((0,1)\\) i per tant, per a qualsevol \\(p\\in (0,1)\\), existeix qualque \\(x\\) tal que \\(F_X(x)=p\\). La mediana de \\(X\\) és el seu 0.5-quantil, el primer i tercer quartils són el seu 0.25-quantil i el seu 0.75-quantil, etc. 2.5 Variables aleatòries normals Una variable aleatòria contínua \\(X\\) és normal (o té distribució normal) de paràmetres \\(\\mu\\) i \\(\\sigma\\) (per abreujar, \\(N(\\mu,\\sigma)\\)) quan la seva funció de densitat és \\[ f_{X}(x)=\\frac{1}{\\sqrt{2\\pi}\\sigma} e^{{-(x-\\mu)^2}/(2\\sigma^{2})} \\] Naturalment, no us heu de saber aquesta fórmula. Però sí que heu de saber que: Una variable aleatòria normal \\(X\\) és contínua, i per tant \\(P(X=x)=0\\), \\(P(X\\leqslant x)=P(X&lt;x)\\) etc. Si \\(X\\) és normal, la seva funció de distribució \\(F_X\\) és injectiva i creixent: si \\(x&lt;y\\), \\(F_X(x)&lt;F_X(y)\\). Si \\(X\\) és \\(N(\\mu,\\sigma)\\), aleshores \\(\\mu_X=\\mu\\) i \\(\\sigma_X=\\sigma\\). Una variable aleatòria normal diem que és estàndard (o típica) quan és \\(N(0,1)\\). Normalment indicarem les variables normals estàndard amb \\(Z\\). Observau, doncs, que si \\(Z\\) és normal estàndard, \\(\\mu_Z=0\\) i \\(\\sigma_Z=1\\). La gràfica de la densitat d’una variable aleatòria normal és la famosa campana de Gauss: Figura 2.5: Densitat d’una variable normal estàndard La distribució normal és una distribució teòrica, no la trobareu exacta en la vida real. I malgrat el seu nom, no és més “normal” que altres distribucions contínues. Però és molt important, pel fet que moltes distribucions de la vida real són aproximadament normals. El motiu és que: Si una variable aleatòria consisteix a prendre un nombre molt gran \\(n\\) de mesures independents d’una o diverses variables aleatòries i sumar-les, aleshores té distribució aproximadament normal, encara que les variables aleatòries de partida no ho siguin. Exemple 2.9 Una variable binomial \\(B(n,p)\\) s’obté prenent \\(n\\) mesures independents d’una variable Bernoulli \\(Be(p)\\) i sumant-les. Per tant, per la “regla” anterior, una \\(B(n,p)\\) hauria de ser aproximadament normal si \\(n\\) és gran. Doncs sí, si \\(n\\) és gran (posem a partir de 40, encara que si \\(p\\) és molt propera a 0 o 1, la mida de les mostres ha de ser més gran), una variable \\(X\\) binomial \\(B(n,p)\\) és aproximadament normal \\(N(np,\\sqrt{np(1-p)})\\), on recordau que, si \\(X\\) és \\(B(n,p)\\), aleshores \\(\\mu_X=np\\) i \\(\\sigma_X=\\sqrt{np(1-p)}\\). Aquest “aproximadament” significa que la densitat i la distribució de \\(X\\) són aproximadament les de la normal. Per exemple, el gràfic següent compara les funcions de distribució d’una binomial \\(B(40,0.3)\\) i una normal \\(N(40\\cdot 0.3,\\sqrt{40\\cdot 0.3\\cdot 0.7})\\). En els propers temes emprarem sovint que una variable \\(B(n,p)\\) amb \\(n\\) és gran és aproximadament \\(N(np,\\sqrt{np(1-p)})\\). Exemple 2.10 Podem entendre que, amb una variable de Poisson, observam tots els punts d’un espai o tots els instants d’un període de temps i sumam tots els Èxits que hi trobam. Doncs, un altre cop, si \\(X\\) és una variable aleatòria de Poisson \\(Po(\\lambda)\\) i \\(\\lambda\\) és gran, aleshores \\(X\\) és aproximadament \\(N(\\lambda,\\sqrt{\\lambda})\\). Per exemple, el gràfic següent compara les funcions de distribució d’una Poisson \\(Po(70)\\) i una normal \\(N(70,\\sqrt{70})\\). Quan s’aproxima per mitjà d’una variable normal \\(Y\\) una variable discreta \\(X\\) que només pot prendre com a valors nombres naturals, com ara una binomial o una Poisson, és convenient aplicar l’anomenada correcció de continuïtat: per a cada \\(n\\in \\mathbb{N}\\), aproximar: \\(P(X\\leqslant n)\\) per mitjà de \\(P(Y&lt; n+1/2)\\) \\(P(X=n)\\) per mitjà de \\(P(n-1/2&lt; Y&lt; n+1/2)\\) Vegeu l’Exemple 2.11 més a baix. 2.5.1 Amb R Per calcular probabilitats d’una \\(N(\\mu,\\sigma)\\), cal calcular les integrals a mà. O podeu emprar R, per a qui la normal és norm. Per tant, si \\(X\\sim N(\\mu,\\sigma)\\): dnorm(x,mu,sigma) dóna el valor de la densitat \\(f_X(x)\\) pnorm(x,mu,sigma) dóna el valor de la distribució \\(F_X(x)=P(X\\leqslant x)\\) qnorm(q,mu,sigma) dóna el \\(q\\)-quantil de \\(X\\) rnorm(n,mu,sigma) dóna un vector de \\(n\\) nombres aleatoris generats amb aquesta distribució Així, per exemple, si \\(X\\) és \\(N(1,2)\\) \\(P(X\\leqslant 1.5)\\) és pnorm(1.5,1,2) ## [1] 0.5987063 El 0.4-quantil de \\(X\\), és a dir, el valor \\(q\\) tal que \\(P(X\\leqslant q)=0.4\\) és qnorm(0.4,1,2) ## [1] 0.4933058 \\(P(X=1.5)\\) és dnorm(1.5,1,2) ## [1] 0.1933341 No! Com que \\(X\\) és contínua, \\(P(X=1.5)=0\\). El que us dóna dnorm(1.5,1,2) és el valor de la funció de densitat de \\(X\\) en 1.5, que no creiem que us interessi gaire. Si la normal és estàndard, no fa falta entrar la \\(\\mu=0\\) i la \\(\\sigma=1\\) (són els valors per defecte d’aquests paràmetres per a norm). Així, si \\(Z\\) és \\(N(0,1)\\): \\(P(Z\\leqslant 1.5)\\) és pnorm(1.5) ## [1] 0.9331928 El seu 0.95-quantil és qnorm(0.95) ## [1] 1.644854 Què val \\(P(-1\\leqslant Z\\leqslant 1)\\)? Com que \\(P(-1\\leqslant Z\\leqslant 1)=P(Z\\leqslant 1)-P(Z\\leqslant -1)\\), és pnorm(1)-pnorm(-1) ## [1] 0.6826895 Exemple 2.11 A la secció anterior, us hem dit que una variable binomial \\(B(n,p)\\) amb \\(n\\) gran s’aproxima per mitjà d’una variable normal \\(N(np,\\sqrt{np(1-p)})\\). Així, per exemple, una variable \\(X\\) binomial \\(B(400,0.2)\\) s’aproxima per mitjà d’una variable \\(Y\\) normal \\(N(400\\cdot 0.2,\\sqrt{400\\cdot 0.2\\cdot 0.8})=N(80,8)\\). Vegem amb alguns exemples que aquesta aproximació és millor aplicant-hi la correcció de continuïtat: \\(F_X(70)=P(X\\leqslant 70)\\): pbinom(70,400,0.2) ## [1] 0.1163917 \\(F_Y(70)=P(Y\\leqslant 70)\\): pnorm(70,80,8) ## [1] 0.1056498 La correcció de continuïtat ens diu que és millor aproximar \\(P(X\\leqslant 70)\\) per mitjà de \\(P(Y&lt; 70+1/2)\\): pnorm(70.5,80,8) ## [1] 0.1175152 \\(f_X(70)=P(X=70)\\): dbinom(70,400,0.2) ## [1] 0.02338443 \\(f_Y(70)\\) (que no és \\(P(Y=70)\\)): dnorm(70,80,8) ## [1] 0.02283114 La correcció de continuïtat ens diu que és millor aproximar \\(P(X=70)\\) per mitjà de \\(P(70-1/2&lt;Y&lt; 70+1/2)\\): pnorm(70.5,80,8) -pnorm(69.5,80,8) ## [1] 0.02283949 Exemple 2.12 La pressió sistòlica, mesurada en mm Hg, es distribueix com una variable normal amb valor mitjà i desviació típica que depenen del sexe i l’edat. Per a la franja d’edat 16-24 anys, aquests valors (s’estima que) són: Per a homes, \\(\\mu=124\\) i \\(\\sigma=13.7\\) Per a dones, \\(\\mu=117\\) i \\(\\sigma=13.7\\) El model d’hipertensió-hipotensió acceptat és el descrit en la Figura 2.6. Volem calcular els límits de cada classe per a cada sexe en aquest grup d’edat. Figura 2.6: Model d’hipertensió-hipotensió. Vegem: El límit superior del grup d’hipotensió serà el valor que deixa a l’esquerra un 5% de les tensions: el 0.05-quantil de la distribució. El límit superior del grup de risc d’hipotensió serà el valor que deixa a l’esquerra un 10% de les tensions: el 0.1-quantil de la distribució. El límit inferior del grup de risc d’hipertensió serà el valor que deixa a l’esquerra un 90% de les tensions: el 0.9-quantil de la distribució. El límit inferior del grup d’hipertensió serà el valor que deixa a l’esquerra un 95% de les tensions: el 0.95-quantil de la distribució. En els homes, la tensió sistòlica és una variable aleatòria \\(N(124,13.7)\\). Aleshores, aquests quantils són: El 0.05-quantil: round(qnorm(0.05,124,13.7),1) ## [1] 101.5 El 0.1-quantil: round(qnorm(0.1,124,13.7),1) ## [1] 106.4 El 0.9-quantil: round(qnorm(0.9,124,13.7),1) ## [1] 141.6 El 0.95-quantil: round(qnorm(0.95,124,13.7),1) ## [1] 146.5 En resum, per als homes de 16 a 24 anys tenim els límits de la Taula 2.1. Taula 2.1: Límits d’hipotensió-hipertensió en homes joves. Grup Interval Hipotens &lt;101.5 Prehipotens 101.5 a 106.4 Normotens 106.4 a 141.6 Prehipertens 141.6 a 146.5 Hipertens &gt; 146.5 Calculau els límits per a les dones. 2.5.2 Propietats bàsiques Ja hem explicat el significat dels paràmetres \\(\\mu\\) i \\(\\sigma\\), però el tornam a repetir: Si \\(X\\) és \\(N(\\mu,\\sigma)\\), aleshores \\(\\mu_X=\\mu\\) i \\(\\sigma_X=\\sigma\\). Una de les propietats clau de la distribució normal és la seva simetria: Si \\(X\\) és \\(N(\\mu,\\sigma)\\), la seva densitat \\(f_X\\) és simètrica respecte de \\(\\mu\\), és a dir, \\[ f_{X}(\\mu-x)=f_{X}(\\mu+x), \\] i pren el valor màxim a \\(x=\\mu\\). És a dir, \\(\\mu\\) és la moda de \\(X\\). Per tant, el valor al voltant del qual és més probable que una variable normal \\(N(\\mu,\\sigma)\\) caigui és justament el seu valor esperat \\(\\mu\\). En particular, si \\(Z\\) és \\(N(0,1)\\), llavors \\(f_Z\\) és simètrica al voltant de 0, és a dir, \\(f_{Z}(-x)=f_{Z}(x)\\), i la moda de \\(Z\\) és \\(x=0\\). Recordau que la funció de distribució d’una variable aleatòria contínua \\(X\\), \\[ F_X(x)=P(X\\leqslant x) \\] és l’àrea compresa entre la densitat \\(y=f_X(x)\\) i l’eix d’abscisses a l’esquerra de \\(x\\). Llavors, la simetria de \\(f_X\\) fa que, per a tot \\(x\\geqslant 0\\), les àrees a l’esquerra de \\(\\mu-x\\) i a la dreta de \\(\\mu+x\\) siguin iguals. És a dir, \\[ P(X\\leqslant \\mu-x)=P(X\\geqslant \\mu+x)=1-P(X\\leqslant \\mu+x) \\] En particular (prenent \\(x=0\\)) \\[ P(X\\leqslant \\mu)=1-P(X\\leqslant \\mu)\\Rightarrow P(X\\leqslant \\mu)=0.5 \\] i per tant, \\(\\mu\\) és també la mediana de \\(X\\). Si \\(X\\) és \\(N(\\mu,\\sigma)\\), \\(\\mu\\) és la mitjana, la mediana i la moda de \\(X\\). En el cas concret de la normal estàndard \\(Z\\), per a qualsevol \\(z\\geqslant 0\\) es té que les àrees a l’esquerra de \\(-z\\) i a la dreta de \\(z\\) són iguals \\[ P(Z\\leqslant -z)=P(Z\\geqslant z)=1-P(Z\\leqslant z) \\] i la mediana de \\(Z\\) és 0. Ara que sabem més coses de la normal, a l’Exemple 2.12 ens haguéssim pogut estalviar la meitat de la feina. Diguem \\(X\\) a la variable aleatòria la pressió arterial, en mm Hg, d’un home d’entre 16 i 24 anys. Ens diuen que \\(X\\) és \\(N(124,13.7)\\). Per la simetria de \\(X\\) al voltant de \\(\\mu=124\\), si escrivim el 0.05-quantil com \\(124-x\\), aleshores \\(P(X\\geqslant 124+x)=P(X\\leqslant 124-x)=0.05\\) i per tant \\(P(X\\leqslant 124+x)=1-P(X\\geqslant 124+x)=0.95\\), és a dir, \\(124+x\\) serà el 0.95-quantil de \\(X\\). El 0.05-quantil ha estat 101.5. Escrivint \\(101.5=124-x\\), obtenim \\(x=22.5\\). Per tant, el 0.95-quantil ha de ser \\(124+22.5=146.5\\). El mateix passa amb el 0.9-quantil i el 0.1-quantil, raonau-ho i comprovau-ho. L’argument que hem desenvolupat a la nota anterior mostra en general que si \\(X\\) és \\(N(\\mu,\\sigma)\\) i el seu \\(q\\)-quantil és \\(\\mu-x\\), aleshores el seu \\((1-q)\\)-quantil és \\(\\mu+x\\). Si \\(\\mu\\) creix, desplaça a la dreta l’eix vertical de simetria de la densitat, i amb ell tota la corba. Si \\(\\sigma\\) creix, la corba s’aplana: en augmentar la desviació típica, els valors són més variats i augmenta la probabilitat que prenguin valors més llunyans de \\(\\mu\\). El gràfic següent mostra l’efecte combinat: Indicarem amb \\(z_q\\) el \\(q\\)-quantil d’una variable normal estàndard \\(Z\\). És a dir, \\(z_q\\) és el valor tal que \\(P(Z\\leqslant z_q)=q\\). A banda del fet que \\(z_{0.5}=0\\) (la mediana de \\(Z\\) és 0), hi ha dos quantils més de la normal estàndard \\(Z\\) que hauríeu de recordar: \\(z_{0.95}=1.64\\); és a dir, \\(P(Z\\leqslant 1.64)=0.95\\) i per tant \\(P(Z\\leqslant -1.64)=P(Z\\geqslant 1.64)=0.05\\) (és a dir, \\(z_{0.05}=-1.64\\)) i \\[ P(-1.64\\leqslant Z\\leqslant 1.64)=0.9. \\] \\(z_{0.975}=1.96\\); és a dir, \\(P(Z\\leqslant 1.96)=0.975\\) i per tant \\(P(Z\\leqslant -1.96)=P(Z\\geqslant 1.96)=0.025\\) (és a dir, \\(z_{0.025}=-1.96\\)) i \\[ P(-1.96\\leqslant Z\\leqslant 1.96)=0.95. \\] Molt sovint el valor 1.96 de \\(z_{0.975}\\) s’aproxima per 2. Teniu permís per a fer-ho quan no disposeu de mitjans (R, aplis de mòbil) per a calcular quantils i us considereu incapaços de recordar “1.96”. Però només en aquest cas. Pel que hem comentat fa un moment, la simetria de la normal estàndard implica que \\(z_{1-q}=-z_{q}\\), perquè si \\(P(Z\\leqslant z_{q})=q\\), aleshores \\(P(Z\\geqslant -z_{q})=q\\) i per tant \\(P(Z\\leqslant -z_{q})=1-q\\). Una de les propietats de la distribució normal que ens faciliten molt la vida és que tota combinació lineal de variables aleatòries normals independents és normal. En concret, tenim els dos resultats següents: Teorema 2.5 Sigui \\(X\\) una variable \\(N(\\mu,\\sigma)\\). Per a tots \\(a,b\\in \\mathbb{R}\\), \\(aX+b\\) és normal \\(N(a\\mu+b,|a|\\cdot\\sigma)\\). En particular, la tipificada de \\(X\\) \\[ Z=\\dfrac{X-\\mu}{\\sigma} \\] és normal estàndard. Més en general: Teorema 2.6 Si \\(X_1,\\ldots,X_n\\) són variables aleatòries normals independents i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), llavors \\(a_1X_1+\\cdots +a_nX_n+b\\) és \\(N(\\mu,\\sigma)\\) amb \\[ \\mu=a_1\\mu_1+\\cdots +a_n\\mu_n+b,\\ \\sigma=\\sqrt{a_1^2\\sigma^2_1+\\cdots +a_n^2\\sigma^2_n} \\] Que tota combinació lineal de variables normals torni a ser del mateix tipus, és a dir, normal, és una propietat molt útil de les variables normals que poques famílies de distribucions comparteixen. Per exemple, si \\(X\\) és una variable binomial \\(B(n,p)\\) amb \\(p\\neq 0\\), la variable \\(2X\\) no és binomial, perquè només pren valors parells, mentre que una variable binomial \\(B(m,q)\\) ha de poder prendre tots els valors entre 0 i \\(m\\). Les probabilitats de la normal tipificada determinen les de la normal original, perquè si \\(X\\) és \\(N(\\mu,\\sigma)\\): \\[ \\begin{array}{rl} P(a\\leqslant X\\leqslant b)\\!\\!\\!\\!\\! &amp; \\displaystyle =P\\Big( \\frac{a-\\mu}{\\sigma}\\leqslant \\frac{X-\\mu}{\\sigma}\\leqslant \\frac{b-\\mu}{\\sigma}\\Big)\\\\ &amp; \\displaystyle =P\\Big(\\frac{a-\\mu}{\\sigma}\\leqslant Z\\leqslant \\frac{b-\\mu}{\\sigma}\\Big) \\end{array} \\] Això serveix per deduir fórmules o resoldre problemes com el següent, i els vostres pares ho empraven per calcular probabilitats de normals (amb taules de probabilitats de la normal estàndard), però ara és més còmode usar una apli. Exemple 2.13 Les alçades de les nordamericanes de 20 anys segueixen una distribució normal. S’ha estimat que un 10% d’elles fan menys de 1.55 m, i un 30.5% fan menys de 1.60 m. Per a quina alçada \\(h\\) es té que un 95% de les nordamericanes de 18 anys fan menys de \\(h\\) metres? Diguem \\(X\\) a la variable “Prenc una nord americana de 20 anys i mesur la seva alçada en m”. Sabem que és \\(N(\\mu,\\sigma)\\), però desconeixem \\(\\mu\\) i \\(\\sigma\\). Ens diuen que \\[ P(X&lt; 1.55)=0.1,\\ P(X&lt; 1.60)=0.305 \\] i amb això volem calcular la \\(h\\) tal que \\(P(X\\leqslant h)=0.95\\), és a dir, el 0.95-quantil de \\(X\\). El que farem serà, tipificant la \\(X\\), traduir la informació que ens han donat a quantils d’una normal estàndard \\(Z\\): \\[ \\begin{array}{l} \\displaystyle 0.1=P(X&lt; 1.55)=P\\Big(\\frac{X-\\mu}{\\sigma}&lt;\\frac{1.55-\\mu}{\\sigma}\\Big)=P\\Big(Z&lt;\\frac{1.55-\\mu}{\\sigma}\\Big)\\\\ \\displaystyle \\qquad \\Longrightarrow \\frac{1.55-\\mu}{\\sigma}=z_{0.1}\\\\ \\displaystyle 0.305=P(X&lt; 1.6)=P\\Big(\\frac{X-\\mu}{\\sigma}&lt;\\frac{1.6-\\mu}{\\sigma}\\Big)=P\\Big(Z&lt;\\frac{1.6-\\mu}{\\sigma}\\Big)\\\\ \\displaystyle \\qquad \\Longrightarrow \\frac{1.6-\\mu}{\\sigma}=z_{0.305} \\end{array} \\] Ara podem calcular aquests dos quantils \\(z_{0.1}\\) i \\(z_{0.305}\\): qnorm(0.1) ## [1] -1.281552 qnorm(0.305) ## [1] -0.5100735 Obtenim d’aquesta manera el sistema d’equacions lineals \\[ \\left. \\begin{array}{ll} 1.55-\\mu=-1.282\\sigma\\\\ 1.6-\\mu=-0.51\\sigma \\end{array}\\right\\} \\] El resolem i obtenim \\[ \\mu=1.633,\\ \\sigma=0.065 \\] I ara ja podem calcular la \\(h\\) com el 0.95-quantil d’una \\(N(1.633,0.065)\\): qnorm(0.95,1.633,0.065) ## [1] 1.739915 Concloem que un 95% de les nord americanes de 20 anys fan menys de 1.74 m. 2.5.3 Intervals de referència Un interval de referència del Q% per a una variable aleatòria \\(X\\) és un interval \\([a,b]\\) tal que \\[ P(a\\leqslant X\\leqslant b)=\\frac{Q}{100}. \\] És a dir, un interval de referència del Q% per a \\(X\\) és un interval que conté els valors de \\(X\\) del Q% dels subjectes de la població. Per exemple, hem vist en la secció anterior que [-1.64,1.64] i [-1.96,1.96] són intervals de referència del 90% i del 95%, respectivament, per a una variable normal estàndard \\(Z\\). Els més comuns són els intervals de referència del 95%, que satisfan que \\[ P(a\\leqslant X\\leqslant b)=0.95 \\] i són els, que per exemple, us donen com a valors de referència en les analítiques: Quan es parla d’un interval de referència sense donar la probabilitat, se sobreentén sempre que és l’interval de referència del 95%. Quan \\(X\\) és \\(N(\\mu,\\sigma)\\), aquests intervals de referència es prenen sempre centrats en la mitjana \\(\\mu\\), és a dir, de la forma \\[ [\\mu-\\text{alguna cosa},\\mu+\\text{aquesta mateixa cosa}]. \\] Es calculen amb el resultat següent: Teorema 2.7 Si \\(X\\) és \\(N(\\mu,\\sigma)\\), un interval de referència del Q% per a \\(X\\) és \\[ [\\mu- z_{(1+q)/2}\\cdot \\sigma, \\mu+ z_{(1+q)/2}\\cdot \\sigma] \\] on \\(q=Q/100\\) i \\(z_{(1+q)/2}\\) és el \\((1+q)/2\\)-quantil de la normal estàndard \\(Z\\). Normalment escriurem aquest interval \\[ \\mu\\pm z_{(1+q)/2}\\cdot \\sigma. \\] La demostració és un exemple d’ús de la tipificació de la normal: \\[ \\begin{array}{l} P(\\mu-x\\leqslant X\\leqslant \\mu+x)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P\\Big(\\frac{\\mu-x-\\mu}{\\sigma}\\leqslant \\frac{X-\\mu}{\\sigma}\\leqslant \\frac{\\mu+x-\\mu}{\\sigma}\\Big)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(-x/{\\sigma}\\leqslant Z\\leqslant {x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant {x}/{\\sigma})-P(Z\\leqslant -{x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant {x}/{\\sigma})-(1-P(Z\\leqslant {x}/{\\sigma}))=q\\\\ \\qquad \\text{(per la simetria de $f_Z$ al voltant de 0)}\\\\ \\qquad \\Longleftrightarrow \\displaystyle 2P(Z\\leqslant {x}/{\\sigma})=q+1\\\\ \\qquad \\Longleftrightarrow P(Z\\leqslant {x}/{\\sigma})=(1+q)/2\\\\ \\qquad \\Longleftrightarrow x/\\sigma= z_{(1+q)/2}\\\\ \\qquad \\Longleftrightarrow x=z_{(1+q)/2}\\cdot \\sigma \\end{array} \\] Si \\(q=0.95\\), llavors \\((1+q)/2=0.975\\) i \\(z_{0.975}=1.96\\). Per tant, l’interval de referència del 95% per a una variable \\(X\\) normal \\(N(\\mu,\\sigma)\\) és \\[ \\mu\\pm 1.96\\sigma. \\] I com que aquest 1.96 sovint s’aproxima per 2, l’interval de referència del 95% d’una \\(N(\\mu,\\sigma)\\) se sol simplificar a \\[ \\mu\\pm 2\\sigma. \\] Això diu, bàsicament, que Si una població segueix una distribució normal \\(N(\\mu,\\sigma)\\), un 95% dels seus individus tenen el seu valor de \\(X\\) a distància com a màxim \\(2\\sigma\\) (“a dues sigmes”) de \\(\\mu\\). Exemple 2.14 Segons l’OMS, les altures (en cm) de les dones europees de 18 anys segueixen una llei \\(N(163.1,18.53)\\). Quin és l’interval d’altures centrat en la mitjana que conté a la meitat de les europees de 18 anys? Fixau-vos que, si diem \\(X\\) a la variable aleatòria “Altura d’una dona europea de 18 anys en cm”, el que volem saber és l’interval centrat en la seva mitjana, 163.1, tal que la probabilitat que l’alçada d’una europea de 18 anys triada a l’atzar pertanyi a aquest interval sigui 0.5. És a dir, l’interval de referència del 50% per a \\(X\\). Ens diuen que \\(X\\) és \\(N(163.1,18.53)\\). Si \\(q=0.5\\), llavors \\((1+q)/2=0.75\\). El 0.75-quantil \\(z_{0.75}\\) d’una normal estàndard és qnorm(0.75) ## [1] 0.6744898 Per tant, l’interval de referència demanat és \\(163.1\\pm 0.6745\\cdot 18.53\\), és a dir, arrodonint a mm, \\([150.6, 175.6]\\). Això ens diu que la meitat de les dones europees de 18 anys fan entre 150.6 i 175.6 cm. El z-score d’un valor \\(x_0\\in \\mathbb{R}\\) respecte d’una distribució \\(N(\\mu,\\sigma)\\) és \\[ \\frac{x_0-\\mu}{\\sigma} \\] És a dir, el z-score de \\(x_0\\) és el resultat de “tipificar” \\(x_0\\) en el sentit del Teorema 2.5.2. Si la variable poblacional és normal, com més gran és el valor absolut del z-score de \\(x_0\\), més “rar” és \\(x_0\\); el signe ens diu si és més gran o més petit que el valor esperat \\(\\mu\\). Exemple 2.15 Recordau que, segons l’OMS, les altures de les dones europees de 18 anys segueixen una llei \\(N(163.1,18.53)\\). Quin seria el z-score d’una jugadora de bàsquet de 18 anys que fes 191 cm? Seria \\[ \\frac{191-163.1}{18.53}=1.5 \\] Això se sol llegir dient que l’alçada d’aquesta jugadora està 1.5 sigmes per sobre de l’alçada mitjana. 2.5.4 Variables log-normals Direm que \\(X\\) és una variable log-normal quan el seu logaritme neperià \\(\\ln(X)\\) és una variable normal. O, si ho preferiu, quan és una variable de la forma \\(e^Y\\) amb \\(Y\\) normal. Moltes concentracions d’enzims o anticossos tenen distribucions aproximadament log-normals. Si \\(a&gt;1\\), \\(\\log_a(X)=\\ln(X)/\\ln(a)\\) i per tant, pel Teorema 2.5.1, si \\(X\\) és log-normal, el seu logaritme en qualsevol base \\(a&gt;1\\) és normal. La densitat d’una variable log-normal és asimètrica, amb una cua a la dreta, com mostra la Figura 2.7. Figura 2.7: Densitat de \\(e^Z\\) amb \\(Z\\) normal estàndard. Recíprocament, molt sovint una variable la densitat de la qual mostri una pujada ràpida des del 0 a la moda i després una cua a la dreta, satisfà que el seu logaritme segueix una distribució aproximadament normal. Això ens serà útil més endavant. Amb R, la distribució log-normal és lnorm. Els paràmetres que s’empren per descriure-la són els de la variable normal definida pel seu logaritme: La mitjana en escala logarítmica de \\(X\\): \\(\\mu_{\\ln(X)}\\) La desviació típica en escala logarítmica de \\(X\\): \\(\\sigma_{\\ln(X)}\\) Exemple 2.16 La dosi letal \\(Y\\) de la digitalina en ratolins (és la dir, la variable aleatòria que dóna la quantitat de digitalina que cal administrar a un ratolí per matar-lo) té distribució log-normal. Se sap que una injecció de 1cc de digitalina mata un 10% dels ratolins (és a dir, que la probabilitat que una dosi de 1cc o menys mati un ratolí és de 0.1: \\(P(Y\\leqslant 1)=0.1\\)) i que una injecció de 2cc mata un 75% dels ratolins (\\(P(Y\\leqslant 2)=0.75\\)). Volem saber la dosi de digitalina (en cc) que és letal per al 95% dels ratolins. Aquest tipus d’experiments és la base de l’anomenat mètode probit per determinar la letalitat de substàncies. Així doncs, volem calcular el valor \\(a\\) tal que \\(P(Y\\leqslant a)=0.95\\), que no és res més que el 0.95-quantil de \\(Y\\). Com que el logaritme és injectiu, \\(P(Y\\leqslant x)=P(\\ln(Y)\\leqslant \\ln(x))\\). Per tant el pla és trobar el 0.95-quantil de \\(\\ln(Y)\\), diguem-li \\(b\\), i aleshores tendrem \\(a=e^b\\). Per simplificar, diguem \\(X\\) a \\(\\ln(Y)\\). Sabem que \\(X\\) és normal, per tant només ens cal saber la seva \\(\\mu\\) i la seva \\(\\sigma\\) i podrem calcular el seu 0.95-quantil. El que sabem és que \\[ \\begin{array}{l} 0.1=P(Y\\leqslant 1)=P(X\\leqslant \\ln(1))=P(X\\leqslant 0)\\\\ 0.75=P(Y\\leqslant 2)=P(X\\leqslant \\ln(2)) \\end{array} \\] Com podem determinar la \\(\\mu\\) i la \\(\\sigma\\) de \\(X\\) a partir d’aquests dos valors? Ja ens hem trobat en una situació semblant a l’Exemple 2.13. El que fem és traduir aquesta informació en termes de quantils de la normal estàndard. \\[ \\begin{array}{l} \\displaystyle 0.1=P(X\\leqslant 0)=P\\Big(\\frac{X-\\mu}{\\sigma}\\leqslant \\frac{-\\mu}{\\sigma}\\Big)=P\\Big(Z\\leqslant -\\frac{\\mu}{\\sigma}\\Big)\\\\ \\displaystyle\\qquad \\Longrightarrow -\\frac{\\mu}{\\sigma}=z_{0.1}=\\texttt{qnorm(0.1)}=-1.2816\\\\ \\displaystyle 0.75=P(X\\leqslant \\ln(2))=P\\Big(\\frac{X-\\mu}{\\sigma}\\leqslant \\frac{\\ln(2)-\\mu}{\\sigma}\\Big)=P\\Big(Z\\leqslant \\frac{\\ln(2)-\\mu}{\\sigma}\\Big)\\\\ \\displaystyle\\qquad \\Longrightarrow \\frac{\\ln(2)-\\mu}{\\sigma}=z_{0.75}=\\texttt{qnorm(0.75)}=0.6745 \\end{array} \\] Obtenim el sistema d’equacions \\[ \\left. \\begin{array}{l} \\mu=1.2816\\sigma\\\\ \\ln(2)-\\mu=0.6745\\sigma \\end{array} \\right\\} \\] i resolent-lo obtenim \\[ \\mu=0.4541,\\quad \\sigma=0.3544 \\] Ara podem calcular el 0.95-quantil de \\(X\\): qnorm(0.95,0.4541,0.3544) ## [1] 1.037036 Per tant \\(P(X\\leqslant 1.037)=0.95\\). D’aquí deduïm que \\(P(Y\\leqslant e^{1.037})=0.95\\). Com que \\(e^{1.037}=2.82\\), concloem que 2.82 cc de digitalina són suficients per matar el 95% dels ratolins. Ho podem comprovar (amb R, no escabetxant ratolins, malpensats!): plnorm(2.82,0.4541,0.3544) ## [1] 0.9499129 2.6 Test de la lliçó 2 (1) Sigui \\(X\\) una variable aleatòria de mitjana \\(\\mu\\) i desviació típica \\(\\sigma\\). Quina o quines de les afirmacions següents són sempre vertaderes? \\(E(X+2)=\\mu+2\\). \\(\\sigma(X+2)=\\sigma+2\\). \\(\\sigma(-X)=-\\sigma\\). \\(\\sigma(-X)=\\sigma\\). \\(\\sigma(X/2)=\\sigma/2\\). Cap de les altres afirmacions és vertadera. (2) La funció de distribució \\(F_X(x)\\) d’una variable aleatòria \\(X\\) ens dóna: La probabilitat d’obtenir el valor \\(x\\). La probabilitat d’obtenir un valor entre \\(-x\\) i \\(x\\), tots dos extrems inclosos. La probabilitat d’obtenir un valor entre \\(0\\) i \\(x\\), tots dos extrems inclosos. La probabilitat d’obtenir un valor més petit o igual que \\(x\\). La probabilitat d’obtenir un valor estrictament més petit que \\(x\\). (3) Quina o quines de les variables següents tenen distribució binomial? El pes d’una persona triada a l’atzar. Triam un nombre de llançaments a l’atzar, llançam aquest nombre de vegades una moneda, i comptam el nombre de cares. El nombre de glòbuls vermells en 1 mm3 de sang. La proporció d’hipertensos en una mostra aleatòria de 50 individus. Triam 10 estudiants diferents en una classe de 20, i comptam quantes dones han sortit. Cap d’elles. (4) Quina o quines de les variables següents tenen una distribució de Poisson? El pes d’una persona triada a l’atzar. El nombre de casos diaris de COVID-19 a Mallorca. El nombre de glòbuls vermells en 1 mm3 de sang. La proporció d’hipertensos en una mostra aleatòria de 50 individus. Triam 10 estudiants diferents en una classe de 20, i comptam quantes dones han sortit. Cap d’elles. (5) El nombre anual d’accidents laborals d’un tipus concret segueix una distribució de Poisson. Al llarg del temps s’ha observat que el 55% dels anys no es produeix cap accident d’aquests. Quin valor estimes que té el paràmetre \\(\\lambda\\) d’aquesta distribució de Poisson? 0.55 \\(e^{-0.55}\\) \\(\\ln(0.55)\\) \\(-\\ln(0.55)\\) Un valor que no és cap dels proposats en les altres respostes. (6) Sigui \\(X\\) una variable aleatòria contínua de funció de densitat: \\[ f_X(x)=\\left\\{\\begin{array}{ll} 0 &amp; \\mbox{si $x&lt;0$}\\\\ \\frac{2\\sqrt{2}}{\\sqrt{\\pi}} e^{-2x^2} &amp; \\mbox{si $x\\geqslant 0$} \\end{array} \\right. \\] És cert que \\(P(X=1)=2\\sqrt{2}e^{-2}/\\sqrt{\\pi}\\)? Sí No: en realitat \\(P(X=1)=\\int_{-\\infty}^1 \\frac{2\\sqrt{2}}{\\sqrt{\\pi}} e^{-2x^2}\\,dx\\) però no sé calcular aquesta integral, o sí que sé calcular-la, però em fa mandra fer-ho. Això no és la funció de densitat d’una variable aleatòria contínua, perquè no és una funció contínua (en el 0 bota de 0 a \\(2\\sqrt{2}/\\sqrt{\\pi}\\)) Totes les altres respostes són incorrectes (7) Sigui \\(X\\) una variable aleatòria contínua de mitjana \\(\\mu\\). Què val \\(P(X=\\mu)\\)? 0.5 \\(\\mu\\) 0 Depèn de la variable aleatòria Totes les altres respostes són falses (8) Sigui \\(X\\) una variable aleatòria contínua de moda \\(M\\). Què val \\(P(X=M)\\)? 1 0.5 0 Depèn de la variable aleatòria, però és més gran que tots els altres valors de \\(P(X=x)\\) Depèn de la variable aleatòria, però és el valor màxim de la funció de densitat de \\(X\\). Totes les altres respostes són falses (9) Sigui \\(Z\\) una variable aleatòria normal estàndard. Marca les afirmacions vertaderes. És asimètrica a l’esquerra. La seva mitjana és 1. La seva desviació típica és 0. La seva variància és 1. La seva mediana és 0. (10) Sigui \\(X\\) una variable aleatòria \\(N(\\mu,\\sigma)\\) i \\(f_X\\) la seva funció de densitat. Què val l’àrea entre la corba \\(y=f_X(x)\\) i l’eix d’abscisses? 0 \\(\\mu\\) \\(\\sigma\\) En general, no és ni \\(\\mu\\) ni \\(\\sigma\\), però sí que depèn de \\(\\mu\\) i \\(\\sigma\\) Totes les altres respostes són falses (11) Siguin \\(X\\) una variable aleatòria \\(N(\\mu,\\sigma)\\). Quina de les afirmacions següents és vertadera? \\(\\mu\\) és la mitjana de \\(X\\), però no la seva mediana \\(\\mu\\) és la mitjana i la mediana de \\(X\\), però no la seva moda \\(\\mu\\) és la mitjana, la mediana i la moda de \\(X\\), però no és veritat que \\(P(X=\\mu)&gt;P(X=a)\\) per a tot \\(a\\neq \\mu\\) \\(\\mu\\) és la mitjana, la mediana i la moda de \\(X\\) i \\(P(X=\\mu)&gt;P(X=a)\\) per a tot \\(a\\neq \\mu\\) Totes les altres respostes són falses (12) El FME (Flux Màxim d’Expiració) de les al·lotes d’11 anys segueix una distribució aproximadament normal de mitjana 300 l/min i desviació típica 20 l/min. Marca les afirmacions vertaderes: Aproximadament la meitat de les al·lotes d’11 anys tenen el FME entre 280 l/min i 320 l/min. Al voltant del 95% de les al·lotes d’11 anys tenen el FME entre 280 l/min i 320 l/min. Al voltant del 95% de les al·lotes d’11 anys tenen el FME entre 260 l/min i 340 l/min. Al voltant del 5% de les al·lotes d’11 anys tenen el FME inferior a 260 l/min. Cap al·lota d’11 anys té el FME superior a 360 l/min. (13) Se sap que una variable bioquímica té com a mitjana 90 i desviació típica 10. Si prenem una mostra d’individus sans, és raonable esperar que aproximadament el 95% d’ells tenguin un valor d’aquesta variable comprès entre 70 i 110? (marca totes les respostes correctes): Sí, sempre. No, mai. Si la variable té distribució normal, sí. Si la mostra és prou gran, sí. Si la variable té distribució normal i la mostra és prou gran, sí. (14) En una variable aleatòria contínua, la seva funció de densitat (marca una sola resposta): És sempre contínua Mesura com és de dens el seu domini. Aplicada a un nombre real, ens dóna la probabilitat d’obtenir-lo. Aplicada a un nombre real, ens dóna la probabilitat d’obtenir un valor menor o igual que ell. Totes les altres respostes són falses (15) Sigui \\(X\\) una variable aleatòria contínua de desviació típica \\(\\sigma\\). Què val la variància de la variable aleatòria \\(-X/2\\)? \\(\\sigma(-X/2)^2=-\\sigma^2/2\\). \\(\\sigma(-X/2)^2=\\sigma^2/2\\). \\(\\sigma(-X/2)^2=-\\sigma^2/4\\). \\(\\sigma(-X/2)^2=\\sigma^2/4\\). Totes les altres respostes són falses (16) El temps que tarda a produir-se una determinada reacció bioquímica es distribueix segons una variable normal de mitjana 17 segons i desviació típica 3 segons. Sense fer cap càlcul, què podem deduir d’aquesta afirmació? Marca totes les respostes correctes: Tots aquests temps se situen entre 8 i 26 segons. Gairebé tots aquests temps se situen entre 11 i 23 segons. És estrictament més probable que una reacció d’aquestes tardi entre 16 i 18 segons que tardi entre 18 i 20 segons. És estrictament més probable que una reacció d’aquestes tardi entre 18 i 20 segons que tardi entre 16 i 18 segons. És estrictament més probable que una reacció d’aquestes tardi entre 18 i 20 segons que tardi entre 14 i 16 segons. Cap de les afirmacions anteriors és correcta. (17) El temps que tarda a produir-se una determinada reacció bioquímica es distribueix segons una variable normal de mitjana 17 segons i desviació típica 3 segons. Quina és la probabilitat que tardi menys de 17 segons? 0 0.5 1 17/3 Cap de les afirmacions anteriors és correcta. (18) El temps que tarda a produir-se una determinada reacció bioquímica es distribueix segons una variable normal de mitjana 17 segons i desviació típica 3 segons. Quina o quines de les afirmacions següents són vertaderes? Si poguéssim mesurar els temps amb precisió infinita, observaríem que el temps que tarda més sovint és exactament 17 segons. Arrodonint a segons, el temps que tarda més sovint és 17 segons. En un 95% de les ocasions tarda aproximadament entre 14 i 20 segons. Tarda més de 20 segons amb la mateixa freqüència amb la qual tarda menys de 14 segons. Tarda més de 20 segons amb la mateixa freqüència amb la qual tarda menys de 20 segons. En un 95% de les ocasions tarda 23 segons o menys. (19) Quina de les tres afirmacions és vertadera per a les tres distribucions normals de la figura inferior? (\\(\\sigma_1\\), \\(\\sigma_2\\) i \\(\\sigma_3\\) indiquen les desviacions típiques de les corbes 1, 2 i 3, respectivament). \\(\\sigma_1&gt; \\sigma_2&gt; \\sigma_3\\) \\(\\sigma_1&lt; \\sigma_2&lt; \\sigma_3\\) \\(\\sigma_1= \\sigma_2= \\sigma_3\\) Del gràfic no es pot deduir la relació entre les tres desviacions típiques Cap de les altres afirmacions és veritable. (20) El pes mitjà d’una bossa de patates d’una determinada marca és de 150 grams amb una desviació típica de 5.6 grams. Quin és el z-score d’una bossa que pesa 147 grams (arrodonit a 2 xifres decimals)? -0.54 0.30 0.54 0.70 Cap de les respostes anteriors és correcta (21) Si una variable aleatòria normal té mitjana 18.1 i desviació típica 1.2, què val el seu 3er quartil (arrodonit a una xifra decimal)? (Empra R o una apli per calcular-lo) 18.1 18.9 19.3 20.5 Cap de les respostes anteriors és correcta (23) L’interval de referència (del 95%) de la concentració de creatinina en sèrum de les persones és 0.66-1.09 mg/dl. Què en podem deduir? (Marca només una resposta.) Que la probabilitat que la concentració mitjana de creatinina en sèrum d’una persona estigui entre 0.66 i 1.09 mg/dl és del 95%. Que si prenem una mostra aleatòria de persones i calculam la mitjana de les seves concentracions de creatinina, en un 95% de les ocasions aquesta mitjana estarà entre 0.66 i 1.09 mg/dl. Que un 5% de les persones tenen una concentració de creatinina en sèrum superior a 1.09 mg/dl. Que un 95% de les persones tenen una concentració de creatinina en sèrum entre 0.66 i 1.09 mg/dl. Que si prenem una mostra aleatòria de persones, en un 95% de les ocasions tots els valors estaran entre 0.66 i 1.09 mg/dl. Cap de les altres respostes és correcta. (24) Quin és l’efecte sobre la mitjana, la desviació típica i la mediana d’una variable aleatòria si sumam 1 al seu valor sobre tots els individus de la població? Cap d’aquests paràmetres varia. La mitjana i la mediana canvien, la desviació típica no. La mitjana varia, la resta no. La mitjana no varia, la resta sí. Tots tres paràmetres varien. Cap de les altres respostes és correcta. "],
["chap-estim.html", "Tema 3 Estimació puntual 3.1 Estimadors 3.2 Mitjana mostral 3.3 Proporció mostral 3.4 Variància mostral 3.5 La distribució t de Student 3.6 Biaix i precisió 3.7 Estimadors màxim versemblants 3.8 Estimació de poblacions 3.9 Test de la lliçó 3", " Tema 3 Estimació puntual L’objectiu principal de la inferència estadística és obtenir informació sobre tota una població a partir de només una mostra, com quan volem saber si un brou és fat o salat tastant-ne només una cullerada. El primer tipus d’informació que ens sol interessar és què val qualque paràmetre d’alguna variable aleatòria poblacional (una proporció, una mitjana…), per exemple per poder escriure un titular com el següent: Figura 3.1: https://www.efesalud.com/miopia-estudio-universitarios Aquest 60% no s’ha obtingut fent passar a tots els universitaris espanyols un test de miopia, ni tan sols demanant-los a tots si són miops o no, sinó que simplement s’ha pres una mostra d’universitaris, s’hi ha observat un 60% de miops i s’ha extrapolat aquesta proporció a tot el col·lectiu d’universitaris espanyols. El procés d’intentar endevinar el valor d’un paràmetre d’una població a partir d’una mostra se’n diu estimació puntual, i és el que tractarem en aquest tema. En aquest curs, sempre suposarem que empram mostres aleatòries i gairebé sempre que aquestes mostres aleatòries són a més simples. Per tant, si no diem el contrari, d’ara endavant quan parlem de mostres sempre suposarem que són mostres aleatòries simples, encara que no ho diguem explícitament per no carregar massa el text. 3.1 Estimadors Per estimar el valor d’un paràmetre d’una variable aleatòria poblacional, en prenem una mostra (aleatòria simple) i calculam qualque cosa amb els valors que la formen. Què calculam? Doncs un estimador: alguna funció adequada aplicada als valors de la mostra, i que dependrà del que volguem estimar. Per exemple: Si volem estimar l’alçada mitjana dels estudiants de la UIB, prendrem una mostra d’estudiants de la UIB, els amidarem i calcularem la mitjana aritmètica de les seves alçades. Si volem estimar la proporció d’estudiants de la UIB que han passat la COVID-19, prendrem una mostra d’estudiants de la UIB, els farem un test d’anticossos i calcularem la proporció mostral de positius en la mostra. Formalment: Tenim una variable aleatòria poblacional \\(X\\), definida sobre una població. Una mostra aleatòria simple de mida \\(n\\) de \\(X\\) és un vector \\((X_1,\\ldots,X_n)\\) format per \\(n\\) còpies independents de \\(X\\). Cada variable \\(X_i\\) és una còpia de “Prenem un subjecte de la població i hi mesuram \\(X\\)”. Una realització de la mostra aleatòria simple \\((X_1,\\ldots,X_n)\\) és un vector \\((x_1,\\ldots,x_n)\\in \\mathbb{R}^n\\) de valors presos per aquestes variables aleatòries. És a dir, amb \\((X_1,\\ldots,X_n)\\) repetim \\(n\\) vegades (independents les unes de les altres) el procés de prendre un subjecte de la població i mesurar-hi \\(X\\). Cada vegada que ho fem, obtenim un vector de números, al que diem una realització de la mostra. A la lliçó anterior a aquestes realitzacions les déiem directament “mostres aleatòries simples de valors de \\(X\\)”; no passeu ànsia, en sortir d’aquest “formalment” els ho tornarem a dir. Un estimador és una variable aleatòria \\(f(X_1,\\ldots,X_n)\\) obtinguda aplicant una funció \\(f\\) a una mostra aleatòria simple \\((X_1,\\ldots,X_n)\\). Aquest estimador s’aplica a les realitzacions de la mostra i dóna nombres reals. Un estimador és una variable aleatòria, definida sobre la població formada per les mostres aleatòries simples de la població de partida. Per tant, té funció de densitat, funció de distribució (que genèricament anomenarem distribució mostral, per indicar que refereix a la probabilitat que li passi qualque cosa al valor del estimador sobre una mostra), esperança, desviació típica, etc. Com ja us hem dit, i com que no hi ha necessitat de filar tan prim, d’ara endavant cometrem l’abús de llenguatge de dir mostra (aleatòria simple) tant al vector de variables aleatòries \\((X_1,\\ldots,X_n)\\) com a una realització \\((x_1,\\ldots,x_n)\\) i hi ometrem els parèntesis. Com ja hem comentat a la Secció 1.5, si la mida \\(N\\) de la població és MOLT més gran que la mida \\(n\\) de la mostra (per fixar idees, hem dit que si \\(N\\geqslant 1000n\\)), els resultats per a mostres aleatòries simples valen (aproximadament) per a mostres aleatòries sense reposició, perquè les variables aleatòries que formen la mostra sense reposició són gairebé idèntiques i independents i les repeticions són improbables. 3.2 Mitjana mostral Quan volem estimar el valor mitjà d’una variable sobre una població, en prenem una mostra de valors i calculam la seva mitjana aritmètica, no és ver? Doncs això és la mitjana mostral. Donada una variable aleatòria \\(X\\), la seva mitjana mostral (de mostres aleatòries simples) de mida \\(n\\) és la variable aleatòria \\(\\overline{X}\\) “Prenem una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calculam la mitjana aritmètica dels seus valors”. És a dir, formalment, la mitjana mostral de mida \\(n\\) de \\(X\\) és la variable aleatòria obtinguda prenent \\(n\\) còpies independents \\(X_1,\\ldots,X_n\\) de la variable aleatòria \\(X\\) i calculant \\[ \\overline{X}=\\frac{X_1+\\cdots+X_n}{n} \\] Fixau-vos que definim la mitjana mostral només per a mostres aleatòries simples. Naturalment, té sentit definir-la per a mostres qualssevol, però llavors la seva distribució mostral deixa de complir les propietats que donarem en aquesta secció. El mateix advertiment val per als estimadors que definim en les pròximes seccions. Com a conseqüència del comportament d’esperances i variàncies de combinacions lineals, tenim el resultat següent: Teorema 3.1 Siguin \\(X\\) una variable aleatòria d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\), i \\(\\overline{X}\\) la seva mitjana mostral (de mostres aleatòries simples) de mida \\(n\\). Aleshores El valor esperat de \\(\\overline{X}\\) és \\(E(\\overline{X})=\\mu_X\\). La desviació típica de \\(\\overline{X}\\) és \\(\\sigma(\\overline{X})={\\sigma_X}/{\\sqrt{n}}\\). En efecte, com que \\[ \\overline{X}=\\frac{1}{n}X_1+\\cdots +\\frac{1}{n}X_n \\] i les variables \\(X_1,\\ldots,X_n\\) són còpies de \\(X\\), i per tant tenen totes esperança \\(\\mu_X\\) i variància \\(\\sigma^2_X\\), tenim que \\[ \\mu_{\\overline{X}}=\\overbrace{\\frac{1}{n}\\mu_X+\\cdots +\\frac{1}{n}\\mu_X}^n=\\mu_X \\] i, si \\(X_1,\\ldots,X_n\\) són independents, \\[ \\sigma_{\\overline{X}}=\\sqrt{\\overbrace{\\frac{1}{n^2}\\sigma^2_X+\\cdots+ \\frac{1}{n^2}\\sigma^2_X}^n}=\\sqrt{\\frac{n}{n^2}\\sigma^2_X}=\\frac{\\sigma_X}{\\sqrt{n}} \\] Si us hi fixau, per demostrar que \\(E(\\overline{X})=\\mu_X\\) no hem fet servir que \\(X_1,\\ldots,X_n\\) siguin independents. De fet, la igualtat \\(E(\\overline{X})=\\mu_X\\) també és vertadera per a mitjanes mostrals de mostres aleatòries sense reposició. En canvi, la igualtat \\(\\sigma_{\\overline{X}}={\\sigma_X}/{\\sqrt{n}}\\) sí que requereix que les mostres aleatòries siguin simples. Per tant: \\(\\overline{X}\\) és un estimador puntual de \\(\\mu_X\\). \\(E(\\overline{X})=\\mu_X\\), la qual cosa significa que: La mitjana de les mitjanes mostrals de totes les mostres aleatòries de mida \\(n\\) de \\(X\\) torna a ser la mitjana \\(\\mu_X\\) de \\(X\\). Esperam que la mitjana mostral doni \\(\\mu_X\\): si repetíssim moltes vegades el procés de prendre una mostra aleatòria de mida \\(n\\) i calcular-ne la mitjana mostral, molt probablement el valor mitjà d’aquestes mitjanes s’acostaria molt a \\(\\mu_X\\). \\(\\sigma(\\overline{X})= \\sigma_X/\\sqrt{n}\\) indica que la dispersió de les mitjanes mostrals creix amb la dispersió de \\(X\\) i decreix amb la mida \\(n\\) de la mostra, tendint a 0 quan \\(n\\to\\infty\\). L’efecte de la mida de les mostres sobre la variabilitat de \\(\\overline{X}\\) és raonable. Quan prenem mostres aleatòries grans d’una variable i en calculam la mitjana, el més normal és que dins cada mostra els valors més petits se compensin amb els més grans, i que com a conseqüència les mitjanes siguin més homogènies que els valors de la variable. Vaja: si triam una persona a l’atzar, no és molt improbable que faci, jo què sé, 2.10 m. Però si prenem una mostra aleatòria de 50 persones, és molt més difícil que la mitjana de les seves alçades sigui 2.10 m. El que hi esperaríem és que les alçades dels més alts s’hi compensin amb les alçades dels més baixos i tot plegat doni una mitjana més “mitjana”. A la desviació típica de \\(\\overline{X}\\) li diem l’error estàndard, o típic, de \\(\\overline{X}\\). Per tant, l’error estàndard de la mitjana mostral de mida \\(n\\) de \\(X\\) és \\(\\sigma_X/\\sqrt{n}\\). Exemple 3.1 El fitxer tests.txt que trobareu a l’url https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt conté les notes (sobre 100) de tests dels estudiants de Matemàtiques I de fa uns cursos. El guardam en un vector anomenat tests: tests=scan(&quot;https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt&quot;) Considerarem la població dels estudiants de Matemàtiques I d’aquell curs i com a variable aleatòria d’interès \\(X\\) la seva nota de tests sobre 100. Per tant, aquest vector tests conté els valors de la variable aleatòria d’interès sobre tots els individus de la població. La seva mida és N=length(tests) N ## [1] 185 La seva mitjana, que és la mitjana poblacional \\(\\mu_X\\), és mu=mean(tests) mu ## [1] 55.43243 Si en prenem una mostra aleatòria simple, per exemple de mida \\(n=40\\), la seva mitjana mostral no té per què coincidir amb la mitjana poblacional: n=40 MAS=sample(tests,n,replace=TRUE) # Una mostra aleatòria simple x.barra=mean(MAS) # La seva mitjana mostral x.barra ## [1] 53.5 Però si prenem moltes mostres aleatòries simples, la mitjana de les seves mitjanes és molt probable que sí que s’acosti a la mitjana poblacional. Vegem si tenim sort amb cent mil mostres: mitjanes=replicate(10^5,mean(sample(tests,n,replace=TRUE))) mean(mitjanes) ## [1] 55.4187 Vegem ara que la desviació típica d’aquesta mostra de mitjanes s’acosta a l’error típic de la mitjana mostral, no a la desviació típica de la població: La desviació típica poblacional: sigma=sd(tests)*sqrt((N-1)/N) sigma ## [1] 21.38241 La desviació típica de la mostra de mitjanes: sd(mitjanes) ## [1] 3.384683 L’error típic de la mitjana mostral: sigma/sqrt(n) ## [1] 3.380856 Veiem que les mitjanes mostrals presenten una dispersió molt més petita que la variable poblacional original. Gràficament, als histogrames de les Figures 3.2 i 3.3 podeu veure com les mitjanes estan més concentrades al voltant de 55 que les notes originals. Recordau del Teorema 2.6 que una combinació lineal de variables aleatòries normals independents torna a ser normal. Com que la mitjana mostral de mostres aleatòries simples és una combinació lineal de variables aleatòries independents, obtenim el resultat següent: Teorema 3.2 Si \\(X\\) és una variable aleatòria normal \\(N(\\mu_X,\\sigma_X)\\), la seva mitjana mostral \\(\\overline{X}\\) de mostres aleatòries simples de mida \\(n\\) és normal \\[ N\\Big(\\mu_X,\\frac{\\sigma_X}{\\sqrt{n}}\\Big). \\] El teorema següent diu que la conclusió del teorema anterior és aproximadament vertadera si la mida \\(n\\) de les mostres aleatòries simples és gran: Teorema 3.3 (Teorema Central del Límit) Siguin \\(X\\) una variable aleatòria qualsevol d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\). Quan \\(n\\to \\infty\\), la funció de distribució de la seva mitjana mostral \\(\\overline{X}\\) de mostres aleatòries simples de mida \\(n\\) tendeix a la d’una variable normal \\[ N\\Big(\\mu_X,\\frac{\\sigma_X}{\\sqrt{n}}\\Big). \\] Com us podeu imaginar, quan un resultat l’anomenen Teorema Central de qualque cosa és perquè és molt important. Normalment aplicarem el Teorema Central del Límit de la manera següent: Siguin \\(X\\) una variable aleatòria qualsevol d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\). Si la mida \\(n\\) de les mostres (aleatòries simples) és gran, la mitjana mostral \\(\\overline{X}\\) és aproximadament normal \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\). Per fixar una fita, en aquest curs entendrem que \\(n\\) és prou gran com per poder aplicar aquest “resultat” quan és més gran o igual que 40, potser menys com més se sembli \\(X\\) a una normal i potser més si la \\(X\\) és molt diferent d’una normal. A partir d’ara, sovint cometrem l’abús de llenguatge d’ometre l’adverbi “aproximadament” de l’expressió anterior, i direm simplement que si \\(n\\) és gran, \\(\\overline{X}\\) és normal. Però heu de tenir present que aquest “és normal” en realitat vol dir “la seva distribució és aproximadament la d’una variable normal”. Exemple 3.2 Suposem que tenim una variable aleatòria \\(X\\) de mitjana poblacional \\(\\mu_X=3\\) i desviació típica poblacional \\(\\sigma_X=0.2\\) i que en prenem mostres aleatòries simples de mida 100. Pel Teorema Central del Límit, la distribució de la mitjana mostral \\(\\overline{X}\\) és (aproximadament) \\[ N\\Big(3,\\frac{0.2}{\\sqrt{100}}\\Big)=N(3,0.02) \\] Exemple 3.3 Tornem a la situació de l’Exemple 3.1. Teníem les notes guardades en un vector anomenat tests. Amb l’histograma següent podem veure que aquestes notes no tenen pinta de seguir una distribució normal. fact.trans=hist(tests,plot=FALSE)$counts[1]/hist(tests,plot=FALSE)$density[1] hist(tests,col=&quot;light blue&quot;,xlab=&quot;Notes dels tests&quot;, ylab=&quot;Freqüències&quot;,main=&quot;&quot;) curve(fact.trans*dnorm(x,mean(tests),sd(tests)),col=&quot;red&quot;,lwd=2,add=TRUE) Figura 3.2: Histograma de les notes de tests A l’Exemple 3.1 també hem construït un vector anomenat mitjanes format per 105 mitjanes mostrals de mostres aleatòries simples de notes de mida 40. Pel Teorema Central del Límit, aquestes mitjanes mostrals haurien de seguir aproximadament una distribució normal, malgrat que la “població original” (les notes dels tests) no sigui normal. Vegem-ho amb un histograma, on hem afegit la densitat de la normal \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\) predita pel Teorema Central del Límit. fact.trans.m=hist(mitjanes,plot=FALSE)$counts[1]/hist(mitjanes,plot=FALSE)$density[1] hist(mitjanes,col=&quot;light blue&quot;,xlab=&quot;Mitjanes&quot;, ylab=&quot;Freqüències&quot;,main=&quot;&quot;) curve(fact.trans.m*dnorm(x,mu,sigma/sqrt(n)),col=&quot;red&quot;,lwd=2,add=TRUE) Figura 3.3: Histograma de les mitjanes de mostres de notes de tests L’exemple següent és un tipus de pregunta que més endavant ens preocuparà molt. Exemple 3.4 L’alçada d’una espècie de matolls té valor mitjà 115 cm, amb una desviació típica de 25 cm. Si prenem una mostra aleatòria simple de 100 matolls d’aquesta espècie, quina és la probabilitat que la mitjana mostral de les alçades sigui més petita que 110 cm? Diguem \\(X\\) a la variable aleatòria definida per les alçades d’aquests matolls. Pel Teorema Central del Límit, la mitjana mostral \\(\\overline{X}\\) de mostres aleatòries simples de 100 alçades segueix una distribució \\(N(115,25/\\sqrt{100})=N(115,2.5)\\). Llavors, la probabilitat que ens demanen és \\[ P(\\overline{X}&lt; 110) \\] que podem calcular amb round(pnorm(110,115,2.5),4) ## [1] 0.0228 Un 2.28% de les mostra aleatòries simples de 100 matolls d’aquesta espècie tenen la mitjana de les alçades més petita que 110 cm. 3.3 Proporció mostral Quan volem estimar la proporció d’individus d’una població que tenen una determinada característica, en prenem una mostra i hi calculam la proporció de membres amb aquesta característica. Aquesta serà la proporció mostral de subjectes amb aquesta característica en la nostra mostra. Sigui \\(X\\) una variable aleatòria poblacional de Bernoulli amb probabilitat d’èxit \\(p_X\\). És a dir, \\(X\\) pren els valors 1 (èxit) o 0 (fracàs) i \\(p_X\\) és la proporció de subjectes de la població en els quals val 1. Recordau que \\(E(X)=p_X\\) i \\(\\sigma_X=\\sqrt{p_X(1-p_X)}\\). La proporció mostral (de mostres aleatòries simples) de mida \\(n\\) de \\(X\\), \\(\\widehat{p}_X\\), és la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calcular-ne la proporció d’èxits: és a dir, comptar-hi el nombre total d’èxits i dividir el resultat per \\(n\\). Formalment, sigui \\(X_1,\\ldots,X_n\\) una mostra aleatòria simple de mida \\(n\\) de \\(X\\). Sigui \\(S_n=\\sum_{i=1}^n X_i\\), que és la variable aleatòria que compta el nombre d’èxits en una mostra aleatòria simple de mida \\(n\\). Aleshores, la proporció mostral de mida \\(n\\) de \\(X\\) és \\[ \\widehat{p}_X=\\frac{S_n}{n}=\\frac{X_1+\\cdots+X_n}{n}. \\] Recordau que si prenem mostres aleatòries simples, \\(S_n\\) és una variable aleatòria binomial \\(B(n,p_X)\\). Però és un doi dir que la proporció mostral \\(\\widehat{p}_X\\) és una variable aleatòria binomial, ni que només sigui perquè les variables aleatòries binomials prenen valors nombres naturals i els valors que pot prendre \\(\\widehat{p}_X\\) són fraccions entre 0 i 1. Fixau-vos que \\(\\widehat{p}_X\\) és un cas particular de la mitjana mostral \\(\\overline{X}\\), per tant per a les proporcions mostrals val tot el que hem dit per a mitjanes mostrals: Teorema 3.4 Sigui \\(X\\) una variable aleatòria de Bernoulli amb probabilitat d’èxit \\(p_X\\). Aleshores, la proporció mostral de mostres aleatòries simples de mida \\(n\\) de \\(X\\), \\(\\widehat{p}_X\\), satisfà que: \\(E(\\widehat{p}_X)=p_X\\) \\(\\sigma(\\widehat{p}_X)=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) Pel Teorema Central del Límit, si la mida \\(n\\) de la mostra és gran, la distribució de \\(\\widehat{p}_X\\) és aproximadament la d’una variable normal \\[ N\\left({p}_X,\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}\\right) \\] i per tant \\[ \\frac{\\widehat{p}_X-p_X}{\\sqrt{{p}_X(1-{p}_X)/n}} \\] és aproximadament \\(N(0,1)\\). Els valors de l’esperança i la desviació típica de \\(\\widehat{p}_X\\) es poden deduir dels de \\(S_n\\) sense necessitat d’invocar els de la mitjana mostral. Com que \\(S_n\\) és \\(B(n,p_X)\\), sabem que \\(E(S_n)=np_X\\) i \\(\\sigma(S_n)^2=np_X(1-p_X)\\) i per tant \\[ \\begin{array}{l} \\displaystyle E(\\widehat{p}_X)=E\\Big(\\frac{S_n}{n}\\Big)=\\frac{E(S_n)}{n}=\\frac{np_X}{n}=p_X\\\\ \\displaystyle \\sigma(\\widehat{p}_X)=\\sigma\\Big(\\frac{S_n}{n}\\Big)=\\frac{\\sigma(S_n)}{n}=\\frac{\\sqrt{np_X(1-p_X)}}{n}=\\sqrt{\\frac{p_X(1-p_X)}{n}} \\end{array} \\] Alguns comentaris: \\(E(\\widehat{p}_X)=p_X\\): Esperam que la proporció mostral sigui igual a la proporció poblacional d’èxits (si hi ha, diguem, un 20% d’èxits a la població, quin percentatge d’èxits “esperau” trobar a la mostra? Un 20%, no?). És a dir, si repetíssim moltes vegades el procés de prendre una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria de Bernoulli \\(X\\) i calcular-ne la proporció mostral d’èxits, molt probablement la mitjana d’aquestes proporcions mostrals s’acostaria molt a \\(p_X\\). En particular, \\(\\widehat{p}_X\\) serveix per estimar \\(p_X\\), naturalment. \\(\\sigma(\\widehat{p}_X)= \\sqrt{{p_X(1-p_X)}/{n}}\\): la variabilitat dels resultats de \\(\\widehat{p}_X\\) decreix amb \\(n\\) i tendeix a 0 quan \\(n\\to \\infty\\). Pel que fa a la dependència de \\(\\sigma(\\widehat{p}_X)\\) respecte de \\(p_X\\) si la \\(n\\) és fixada, observau a la Figura 3.4 que \\(\\sqrt{p_X(1-p_X)}\\) creix entre 0 i 0.5 i decreix entre 0.5 i 1, assolint el valor màxim a \\(p_X=0.5\\). Figura 3.4: Gràfica de \\(\\sqrt{p(1-p)}\\) \\(\\sqrt{{p_X(1-p_X)}/{n}}\\) és l’error estándard, o típic, de \\(\\widehat{p}_X\\). L’estimam amb l’error estándard, o típic, de la mostra \\(\\sqrt{{\\widehat{p}_X(1-\\widehat{p}_X)}/{n}}\\). Sovint cometrem l’abús de llenguatge d’ometre l’adverbi “aproximadament” de l’apartat (3) del teorema anterior, i direm simplement que si \\(n\\) és gran, \\(\\widehat{p}_X\\) és normal. Però, repetim, hem de recordar que aquest “és normal” en realitat vol dir “la seva distribució és aproximadament la d’una variable normal”. Exemple 3.5 Tornem una altra vegada a la situació dels Exemples 3.1 i 3.3. Traduïm el fitxer de notes de tests en un vector binari: 0 per suspens (haver tret menys de 50) i 1 per aprovat (haver tret 50 o més): # Iniciam totes les notes a 1 aprovs=rep(1,length(tests)) # Posam 0 on la nota del test és suspesa aprovs[which(tests&lt;50)]=0 Aquest vector aprovs el podem entendre com els valors sobre la nostra població d’estudiants de la variable poblacional de Bernoulli \\(Y\\) que ens diu si un estudiant aprovà o suspengué els tests. La seva probabilitat poblacional d’èxit (aprovat) \\(p_Y\\) serà la proporció d’estudiants aprovats: p_Y=sum(aprovs)/N round(p_Y,4) ## [1] 0.5946 Ara n’extreurem 105 mostres aleatòries simples de mida \\(n=40\\), en calcularem les proporcions mostrals d’aprovats i comprovarem si es confirmen les conclusions del teorema anterior. n=40 props.mostrals=replicate(10^5,mean(sample(aprovs,n,rep=TRUE))) La mitjana d’aquest vector de proporcions hauria de ser propera a la proporció poblacional d’aprovats \\(p_Y=0.5946\\). round(mean(props.mostrals),4) ## [1] 0.5954 Vegem ara la seva desviació típica: round(sd(props.mostrals),4) ## [1] 0.0775 Pel Teorema 3.4, sabem que això hauria de ser proper a \\(\\sqrt{p_Y(1-p_Y)/n}\\) round(sqrt(p_Y*(1-p_Y)/n),4) ## [1] 0.0776 I pel Teorema Central del Límit, aquestes proporcions mostrals haurien de seguir aproximadament una distribució normal \\(N(p_Y,\\sqrt{p_Y(1-p_Y)/n})\\). Vegem-ho amb un histograma: fact.trans.p=hist(props.mostrals,plot=FALSE)$counts[1]/hist(props.mostrals,plot=FALSE)$density[1] hist(props.mostrals,col=&quot;light blue&quot;,xlab=&quot;Proporcions mostrals&quot;, ylab=&quot;Freqüències&quot;,main=&quot;Histograma de la mostra de proporcions&quot;) curve(fact.trans.p*dnorm(x,p_Y,sqrt(p_Y*(1-p_Y)/n)), col=&quot;red&quot;,lwd=2,add=TRUE) I això que la mida de les mostres, 40, no és especialment gran. Exemple 3.6 Un 59.1% dels estudiants de la UIB són dones. Hem pres una mostra més o menys aleatòria de 60 estudiants de la UIB i hi hem trobat 40 dones, dos terços. Ens demanam si 40 de 60 és una quantitat raonable de dones en una mostra aleatòria simple d’estudiants de la UIB, o si són moltes (atès que hi esperaríem al voltant d’un 59% de dones). Aquesta pregunta, que serà molt típica d’aquí a pocs temes, la traduïm en la pregunta següent: Si prenem una mostra aleatòria simple de 60 estudiants, quina és la probabilitat que la proporció mostral de dones sigui més gran o igual que 2/3? La manera més correcta de respondre aquesta qüestió és emprar que el nombre \\(S_{60}\\) de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix de manera exacta una distribució binomial \\(B(60,0.591)\\). Com que el 2/3 de la pregunta en realitat representa 40 dones, la probabilitat demanada és exactament round(1-pbinom(39,60,0.591),4) ## [1] 0.1441 Recordau que si \\(X\\) és una variable aleatòria discreta que pren valors enters, com ara la binomial, \\(P(X\\geqslant 40)=1-P(X\\leqslant 39)\\). Això ens diu que, de mitjana, 1 de cada 7 mostres aleatòries simples de 60 estudiants de la UIB conté almenys 40 dones. Naturalment, això només és exacte si la proporció poblacional “59.1%” és exacta. Una altra opció seria aprofitar el Teorema Central del Límit, segons el qual la proporció mostral \\(\\widehat{p}_X\\) de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix una distribució aproximadament normal amb \\(\\mu=0.591\\) i \\[ \\sigma=\\sqrt{\\dfrac{0.591(1-0.591)}{60}}=0.0635 \\] Per tant, la probabilitat que \\(\\widehat{p}_X\\geqslant 2/3\\) és (ara, aproximadament) round(1-pnorm(2/3,0.591,sqrt(0.591*(1-0.591)/60)),4) ## [1] 0.1166 L’aproximació seria més bona si haguéssim efectuat la correcció de continuïtat. Diguem \\(Y\\) a la normal \\(N(0.591,0.0635)\\). Com que \\(\\widehat{p}_X=S_{60}/60\\), seria millor aproximar \\[ P(S_{60}\\geqslant 40)=1-P(S_{60}\\leqslant 39) \\] per \\[ 1-P(Y\\leqslant 39.5/60) \\] round(1-pnorm(39.5/60,0.591,sqrt(0.591*(1-0.591)/60)),4) ## [1] 0.1444 En el cas de la proporció mostral, de vegades considerarem que s’han pres mostres aleatòries sense reposició. En aquest cas, la distribució del nombre d’èxits \\(S_n\\) en una mostra segueix una distribució hipergeomètrica. D’aquí deduïm, exactament igual que en el cas de mostres aleatòries simples, que seguim tenint que \\(E(\\widehat{p}_X)=p_X\\), però ara, si \\(N\\) és la mida de la població, \\[ \\sigma({\\widehat{p}_X})=\\sqrt{\\frac{p_X(1-p_X)}{n}}\\cdot \\sqrt{\\frac{\\vphantom{(p_X}N-n}{N-1}}. \\] Recordau que al factor \\[ \\sqrt{\\frac{N-n}{N-1}} \\] que transforma \\(\\sigma({\\widehat{p}_X})\\) per a mostres aleatòries simples en la desviació típica de \\({\\widehat{p}_X}\\) per a mostres aleatòries sense reposició li diem el factor de població finita, i és el que transformava la desviació típica d’una variable binomial (que compta èxits en mostres aleatòries simples) en la desviació típica d’una variable hipergeomètrica (que compta èxits en mostres aleatòries sense reposició). Però recordau que si la mida de la població \\(N\\) és molt gran comparat amb \\(n\\), podem suposar que una mostra aleatòria sense reposició és simple. Exemple 3.7 Tornem a la situació de l’Exemple 3.5. Què passa si prenem les mostres aleatòries de notes de tests sense reposició? Prenguem ara 105 mostres aleatòries sense reposició de 40 notes de tests. props.norep=replicate(10^5,mean(sample(aprovs,n))) Un altre cop, la mitjana d’aquest vector de proporcions mostrals hauria de ser propera a la proporció poblacional d’aprovats \\(p_Y=0.5946\\). round(mean(props.norep),4) ## [1] 0.5946 Calculem ara la desviació típica d’aquest vector: round(sd(props.norep),4) ## [1] 0.069 Pel que acabam d’explicar, la desviació típica d’aquest vector de proporcions mostrals de mostres sense reposició hauria de ser molt propera a \\[ \\sqrt{\\frac{p_Y(1-p_Y)}{n}}\\cdot\\sqrt{\\frac{\\vphantom{(p_Y}N-n}{N-1}} \\] on \\(N\\) és la mida de la població, és a dir, la longitud del vector aprovs, i \\(n\\) la mida de les mostres. Vegem si és veritat: round(sqrt(p_Y*(1-p_Y)/n)*sqrt((N-n)/(N-1)),4) ## [1] 0.0689 Però si prenem mostres aleatòries sense reposició i la població no és molt més gran que les mostres, ja no es pot aplicar el Teorema Central del Límit: encara que les mostres siguin grans, la proporció mostral no té per què ser aproximadament normal. 3.4 Variància mostral Donada una variable aleatòria \\(X\\), direm: La variància mostral (de mostres aleatòries simples) de mida \\(n\\), \\(\\widetilde{S}_{X}^2\\), a la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calcular la variància mostral dels seus valors. Desviació típica mostral (de mostres aleatòries simples) de mida \\(n\\), \\(\\widetilde{S}_{X}\\), a la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calcular la desviació típica mostral dels seus valors. Formalment, sigui \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria \\(X\\). Aleshores \\[ \\widetilde{S}_{X}^2=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n-1},\\quad \\widetilde{S}_{X}=+\\sqrt{\\widetilde{S}_{X}^2} \\] A més, de tant en tant també farem servir la variància i la desviació típica “a seques”: La variància (de mostres aleatòries simples) de mida \\(n\\), \\(S_{X}^2\\), és la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calcular la variància dels seus valors: \\[ S^2_{X}=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n}=\\frac{(n-1)}{n}\\widetilde{S}^2_{X} \\] La desviació típica (de mostres aleatòries simples) de mida \\(n\\), \\({S}_{X}\\), és la variable aleatòria que consisteix a prendre una mostra aleatòria simple de mida \\(n\\) de \\(X\\) i calcular la desviació típica dels seus valors: \\[ S_X=+\\sqrt{S_X^2} \\] La variància (a seques) admet la expressió senzilla següent: \\[ S^2_X=\\frac{\\sum_{i=1}^n X_{i}^2}{n}-\\overline{X}^2 \\] En efecte: \\[ \\begin{array}{l} \\displaystyle \\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n}=\\frac{1}{n}\\sum_{i=1}^n (X_{i}^2-2\\overline{X}X_i+\\overline{X}^2)\\\\ \\displaystyle\\qquad = \\frac{1}{n}\\Big(\\sum_{i=1}^n X_{i}^2-2\\overline{X}\\sum_{i=1}^n X_{i}+n\\overline{X}^2\\Big)\\\\ \\displaystyle\\qquad =\\frac{\\sum_{i=1}^n X_{i}^2}{n}-2\\overline{X}\\frac{\\sum_{i=1}^n X_{i}}{n}+\\frac{n\\overline{X}^2}{n}\\\\ \\displaystyle\\qquad =\\frac{\\sum_{i=1}^n X_{i}^2}{n}-2\\overline{X}\\cdot\\overline{X} + \\overline{X}^2=\\frac{\\sum_{i=1}^n X_{i}^2}{n}- \\overline{X}^2 \\end{array} \\] Tenim els dos resultats següents. El primer ens diu que esperam que la variància mostral d’una mostra aleatòria simple de \\(X\\) valgui la variància \\(\\sigma_{X}^2\\) de \\(X\\), en el sentit usual que si prenem mostres aleatòries simples de \\(X\\) de mida \\(n\\) gran i calculam les seves variàncies mostrals, molt probablement obtenim de mitjana un valor molt proper a \\(\\sigma_{X}^2\\). Teorema 3.5 Si \\(X\\) és una variable aleatòria de desviació típica \\(\\sigma_X\\) i \\(\\widetilde{S}_{X}\\) és la seva variància mostral de mida \\(n\\), \\[ E(\\widetilde{S}_{X}^2)=\\sigma_{X}^2 \\] per a qualsevol \\(n\\). I per tant no esperam que la variància “a seques” d’una mostra aleatòria simple valgui \\(\\sigma_{X}^2\\). Això ho podeu comprovar fàcilment, perquè \\(S_X^2\\) s’obté a partir de \\(\\widetilde{S}_{X}^2\\) canviant el denominador, \\[ S_X^2=\\frac{n-1}{n} \\widetilde{S}_{X}^2 \\] i per tant \\[ E(S_X^2)=\\frac{n-1}{n}E(\\widetilde{S}_{X}^2)=\\frac{n-1}{n}\\sigma^2_{X} \\] El segon resultat ens diu que si la variable \\(X\\) és normal, un múltiple adequat de \\(\\widetilde{S}_{X}^2\\) té distribució mostral coneguda, la qual cosa ens permetrà calcular probabilitats d’esdeveniments relatius a \\(\\widetilde{S}_{X}^2\\). Teorema 3.6 Si \\(X\\) es \\(N(\\mu_X,\\sigma_X)\\) i \\(\\widetilde{S}_{X}\\) és la seva variància mostral de mida \\(n\\), la variable aleatòria \\[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2} \\] té distribució coneguda: \\(\\chi_{n-1}^2\\) (es llegeix khi quadrat amb \\(n-1\\) graus de llibertat). La lletra \\(\\chi\\) en català es llegeix khi; en castellà, ji; i en anglès, chi, pronunciat xai. De la distribució \\(\\chi_\\nu^2\\), on \\(\\nu\\) són els graus de llibertat, heu de saber que: Per definició, és la distribució de la suma dels quadrats de \\(\\nu\\) variables aleatòries normals estàndard independents. És a dir, si \\(Z_{1},Z_{2},\\ldots, Z_{\\nu}\\) són variables \\(N(0,1)\\) independents, la variable \\[ Z_{1}^{2}+Z_{2}^{2}+\\cdots +Z_{\\nu}^{2} \\] té distribució \\(\\chi_\\nu^2\\). Per tant, és una distribució contínua El nombre de graus de llibertat \\(\\nu\\) és el paràmetre del que depèn la seva densitat Amb R és chisq Si \\(X_\\nu\\) és una variable aleatòria amb distribució \\(\\chi_\\nu^2\\), aleshores \\(\\mu_{X_\\nu}=\\nu\\) i \\(\\sigma_{X_\\nu}^2=2 \\nu\\) Per a \\(\\nu\\) petits, la distribució d’una \\(\\chi_{\\nu}^2\\) és asimètrica amb una cua a la dreta. Figura 3.5: Algunes densitats de variables \\(\\chi^2\\) A mida que \\(\\nu\\) creix, i atès que és la distribució d’una suma de \\(\\nu\\) variables aleatòries independents, pel Teorema Central del Límit es va aproximant a una distribució normal \\(N(n,\\sqrt{2n})\\). Figura 3.6: \\(\\chi^2\\) vs normal Tornem un instant a això dels graus de llibertat. Per què diem que la variància (mostral o a seques) té \\(n-1\\) graus de llibertat? Doncs perquè si volem construir un conjunt de \\(n\\) nombres \\(x_1,\\ldots,x_n\\) que tenguin variància un valor donat, posem \\(y_0\\), en principi podem escollir com volguem \\(n-1\\) d’ells, \\(x_1,\\ldots,x_{n-1}\\), i aleshores el darrer, \\(x_n\\), queda bastant fixat. En matemàtiques això se sol expressar dient que “tenim \\(n-1\\) graus de llibertat a l’hora d’escollir \\(x_1,\\ldots,x_n\\) amb variància fixada \\(y_0\\)”. En efecte, si fixam el valor \\(y_0\\geqslant 0\\) de la variància i volem trobar \\(x_1,\\ldots,x_{n}\\) tals que \\[ y_0=\\frac{\\sum_{i=1}^n (x_i-\\overline{x})^2}{n}=\\frac{\\sum_{i=1}^n x_i^2}{n}-\\overline{x}^2 \\] vegem que per a qualssevol valors de \\(x_1,\\ldots,x_{n-1}\\), el valor de \\(x_n\\) queda fixat per una equació quadràtica: \\[ \\begin{array}{l} n y_0 &amp; =\\displaystyle \\sum_{i=1}^n x_i^2-n\\overline{x}^2= \\sum_{i=1}^n x_i^2-n\\Big(\\frac{\\sum_{i=1}^n x_i}{n}\\Big)^2\\\\ &amp; =\\displaystyle \\sum_{i=1}^n x_i^2-\\frac{(\\sum_{i=1}^n x_i)^2}{n}\\\\ &amp; \\displaystyle =\\frac{1}{n}\\left(n\\sum_{i=1}^n x_i^2-\\Big(\\sum_{i=1}^{n} x_i\\Big)^2\\right)\\\\ &amp; =\\displaystyle \\frac{1}{n}\\left(n\\sum_{i=1}^{n-1} x_i^2+n\\mathbf{x_n}^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2\\right.\\\\ &amp; \\displaystyle\\qquad\\qquad \\left. -2\\Big(\\sum_{i=1}^{n-1} x_i\\Big)\\mathbf{x_n}-\\mathbf{x_n}^2\\right)\\\\ &amp; =\\displaystyle \\frac{1}{n}\\left((n-1)\\mathbf{x_n}^2-2\\Big(\\sum_{i=1}^{n-1} x_i\\Big)\\mathbf{x_n}\\right.\\\\ &amp; \\displaystyle\\qquad\\qquad \\left.+n\\sum_{i=1}^{n-1} x_i^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2 \\right) \\end{array} \\] d’on (multiplicant els dos costats de la igualtat per \\(n\\) i dividint-los per \\(n-1\\)) obtenim, finalment, l’equació de segon grau en \\(\\mathbf{x_n}\\) \\[ \\mathbf{x_n}^2-\\frac{2\\sum_{i=1}^{n-1} x_i}{n-1}\\mathbf{x_n}+\\frac{n\\sum_{i=1}^{n-1} x_i^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2-n^2y_0^2}{n-1}=0 \\] Per tant, fixat \\(y_0\\) i un cop escollits \\(x_1,\\ldots,x_{n-1}\\), el darrer valor \\(x_n\\) ha de ser per força una solució d’aquesta equació de segon grau. Fixau-vos que aquesta equació no sempre té solució real, perquè pot tenir el discriminant negatiu. Per tant exageràvem un poc dient que podíem triar \\(x_1,\\ldots,x_{n-1}\\) “com volguem”. Per exemple, si voleu que la variància sigui 0 i preneu \\(x_1,\\ldots,x_{n-1}\\) no tots iguals, podeu estar ben segurs que no trobareu cap \\(x_n\\) que satisfaci aquesta equació: per tenir variància 0, \\(x_1,\\ldots,x_n\\) han de ser tots iguals. Però el que ha de quedar clar és que un cop escollits \\(x_1,\\ldots,x_{n-1}\\), el valor de \\(x_n\\) ja no pot ser qualsevol, pot prendre com a màxim dos valors diferents. Anau alerta: Si la variable poblacional \\(X\\) no és normal, la conclusió del Teorema 3.6 no és vertadera. Encara que \\(X\\) sigui normal, \\(E(\\widetilde{S}_{X})\\neq \\sigma_{X}\\). Ja ho hem comentat abans, però ho repetim: si \\(S^2_{X}\\) és la variància “a seques” (dividint per \\(n\\) en comptes de per \\(n-1\\)), \\(E(S^2_{X})\\neq \\sigma^2_{X}\\). Exemple 3.8 Suposem que el pes en néixer dels nadons segueix una distribució normal, i s’estima que la seva desviació típica (en g) és 800. Hem anotat els pesos de tots els recent nats amb SIDA d’una ciutat durant 2 anys. El teniu al vector pesos.SIDA següent: pesos.SIDA=c(2466,3941,2807,3118,2098,3175,3515,3317,3742,3062, 3033,2353,2013,3515,3260,2892,1616,4423,3572,2750, 2807,2807,3005,3374,2722,2495,3459,3374,1984,2495, 3062,3005,2608,2353,4394,3232,2013,2551,2977,3118, 2637,1503,2438,2722,2863,2013,3232,2863) Quina és la probabilitat que una mostra (aleatòria simple) de pesos de recent nats de la mateixa mida que aquesta tengui una desviació típica mostral més petita que la d’aquesta mostra? La variable d’interès és \\(X\\): “Prenem un recent nat i pesam el seu pes en g”. Ens diuen que és normal amb \\(\\sigma=800\\). Pel que fa a la nostra mostra de pesos, la seva mida \\(n\\) és n=length(pesos.SIDA) n ## [1] 48 i la seva desviació típica mostral és s.tilda=round(sd(pesos.SIDA),1) s.tilda ## [1] 623.4 Sigui \\(\\widetilde{S}_X\\) la desviació típica mostral de mida 48 de la variable \\(X\\). Ens demanen \\(P(\\widetilde{S}_X &lt;623.4)\\). Això tal qual no ho sabem calcular, perquè no sabem la funció de distribució de \\(\\widetilde{S}_X\\). Però sí que sabem la de \\[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2}= \\frac{47\\widetilde{S}_{X}^2}{800^2} \\] Aquesta variable té distribució \\(\\chi_{47}^2\\). Per tant el que hem de fer és traduir la probabilitat que volem calcular en termes d’aquesta variable: \\[ P(\\widetilde{S}_X&lt;623.4)=P\\Big(\\frac{47\\widetilde{S}_{X}^2}{800^2}&lt;\\frac{47\\cdot 623.4^2}{800^2}\\Big)=P(\\chi_{47}^2&lt;28.54) \\] i això val round(pchisq(round((n-1)*s.tilda^2/800^2,2),n-1),4) ## [1] 0.0153 Per tant, només un 1.5% de les mostres aleatòries simples de 47 recent nats tenen una desviació típica mostral més petita que la de la nostra mostra de recent nats amb SIDA. 3.5 La distribució t de Student Recordau que si la variable poblacional \\(X\\) és \\(N(\\mu_X,\\sigma_X)\\) i prenem mostres aleatòries simples de mida \\(n\\), la variable \\[ \\frac{\\overline{X}-\\mu_X}{\\sigma_{X}/\\sqrt{n}} \\] és normal estàndard. Des del punt de vista teòric això és útil per obtenir fórmules, però normalment no ens serveix per calcular la probabilitat que a \\(\\overline{X}\\) li passi qualque cosa, perquè gairebé mai sabrem la desviació típica poblacional \\(\\sigma_{X}\\). Què passa si l’estimam per mitjà de \\(\\widetilde{S}_{X}\\) amb la mateixa mostra amb la qual calculam \\(\\overline{X}\\)? Doncs que el resultat següent ens salva el dia, perquè la variable que obtenim té distribució coneguda. Teorema 3.7 Sigui \\(X\\) una variable \\(N(\\mu_X, \\sigma_X)\\). Siguin \\(\\overline{X}\\) i \\(\\widetilde{S}_{X}\\) les seves mitjana mostral i desviació típica mostral de mostres aleatòries simples de mida \\(n\\), respectivament. Aleshores, la variable aleatòria \\[ T=\\frac{\\overline{X}-\\mu_X}{\\widetilde{S}_{X}/\\sqrt{n}} \\] segueix una distribució coneguda, anomenada t de Student amb \\(n-1\\) graus de llibertat, \\(t_{n-1}\\). Al denominador \\(\\widetilde{S}_{X}/\\sqrt{n}\\) li diem l’error estàndard, o típic, de la mostra: estima l’error estàndard \\(\\sigma_X/\\sqrt{n}\\) de \\(\\overline{X}\\). De la distribució t de Student amb \\(\\nu\\) graus de llibertat, \\(t_{\\nu}\\), heu de saber que: És contínua Amb R és t El nombre de graus de llibertat \\(\\nu\\) és el paràmetre del que depèn la seva densitat Si \\(T_{\\nu}\\) és una variable amb distribució \\(t_{\\nu}\\), aleshores \\(\\mu_{T_{\\nu}}=0\\) i \\(\\sigma_{T_{\\nu}}^2=\\nu/(\\nu-2)\\) (en realitat aquestes dues igualtats només són veritat si \\(\\nu\\geqslant 3\\), però no fa falta recordar-ho). La funció de densitat d’una variable \\(T_{\\nu}\\) és simètrica al voltant de 0 (com la d’una \\(N(0,1)\\)): \\[ P(T_{\\nu}\\leqslant -x)=P(T_{\\nu}\\geqslant x)=1-P(T_{\\nu}\\leqslant x) \\] Per tant 0 també és la seva mediana. Figura 3.7: Densitats d’algunes t de Student Si \\(\\nu\\) és gran, la distribució d’una variable \\(T_{\\nu}\\) és aproximadament la d’una \\(N(0,1)\\) però amb més variància (perquè \\(\\nu/(\\nu-2)&gt;1\\)) i per tant un poc més aplatada. Figura 3.8: t amb molts graus de llibertat vs Normal estàndard El fet que una t de Student sigui més aplatada que una normal estàndard \\(Z\\) implica que les cues de la t tenen major probabilitat que les de \\(Z\\) (fixau-vos que als gràfics anteriors els extrems de les densitats de les t estan per damunt dels de la de \\(Z\\)), la qual cosa es tradueix en el fet que és més probable obtenir valors lluny del 0 amb una t de Student que amb una \\(N(0,1)\\). Indicarem amb \\(t_{\\nu,q}\\) el \\(q\\)-quantil d’una variable aleatòria \\(T_{\\nu}\\) que segueix una distribució \\(t_\\nu\\). És a dir, \\(t_{\\nu,q}\\) és el valor tal que \\[ P(T_{\\nu}\\leqslant t_{\\nu,q})=q \\] Per la simetria de la distribució \\(t_\\nu\\), \\[ t_{\\nu,q}=-t_{\\nu,1-q}. \\] Hi ha algunes propietats dels quantils de la t de Student que heu de saber, per poder aplicar-les quan no tengueu a l’abast R o una apli per calcular quantils: \\(t_{\\nu ,q}\\approx z_{q}\\) si \\(\\nu\\) és molt gran, posem \\(\\nu \\geqslant 200\\). Per exemple qt(0.975,200) # t_{200,0.975} ## [1] 1.971896 qnorm(0.975) # z_0.975 ## [1] 1.959964 \\(t_{\\nu,0.95}\\) (per a \\(10\\leqslant \\nu\\leqslant 200\\)) està entre 1.65 i 1.8; ho podeu aproximar \\(t_{n,0.95}\\approx 1.7\\) \\(t_{n,0.975}\\) (per a \\(10\\leqslant n\\leqslant 200\\)) està entre 1.97 i 2.2; ho podeu aproximar \\(t_{n,0.975}\\approx 2\\) Comprovau amb R les afirmacions sobr els quantils de la t de Student dels darrers dos punts. Abans de tancar aquesta secció, recordau que, donada una variable aleatòria \\(X\\), no heu de confondre: Desviació típica (o estàndard) de la variable aleatòria, \\(\\sigma_X\\): El paràmetre poblacional, normalment desconegut Desviació típica (o estàndard) (sigui mostral, \\(\\widetilde{S}_X\\), o a seques, \\(S_X\\)) d’una mostra: L’estadístic que calculam sobre la mostra i que quantifica la dispersió de la mostra Error típic (o estàndard) d’un estimador: La desviació típica de la variable aleatòria que defineix l’estimador, normalment desconeguda Error típic (o estàndard) d’una mostra: Estimació de l’error típic de la mitjana mostral (o de la proporció mostral) a partir d’una mostra; servirà per calcular intervals de confiança. És \\(\\widetilde{S}_X/\\sqrt{n}\\). 3.6 Biaix i precisió En una primera aproximació, la bondat d’un estimador es descriu en termes de dues propietats: la seva exactitud i la seva precisió. L’exactitud d’un estimador refereix al fet que el seu valor esperat sigui el valor real del paràmetre que es vol estimar. La precisió d’un estimador refereix al fet que els seus valors estiguin molt concentrats. Per tant, un estimador serà exacte i precís quan els seus valors es concentrin molt al voltant del valor real del paràmetre. La combinació d’exactitud i precisió disminueix la probabilitat que una estimació caigui enfora del valor real que volem estimar. Aquests dos conceptes se solen il·lustrar amb una diana, així que nosaltres també ho farem: 3.6.1 Estimadors no esbiaixats Un estimador puntual \\(\\widehat{\\theta}\\) d’un paràmetre poblacional \\(\\theta\\) és exacte, o no esbiaixat (insesgado, en castellà), quan el seu valor esperat és precisament el valor poblacional del paràmetre, és a dir, quan \\[ E(\\widehat{\\theta})=\\theta \\] El biaix d’un estimador \\(\\widehat{\\theta}\\) d’un paràmetre \\(\\theta\\) és la diferència \\(E(\\widehat{\\theta})-\\theta\\). L’exactitud de l’estimador també es mesura amb aquesta diferència \\(E(\\widehat{\\theta})-\\theta\\), però hem de tenir en compte a l’hora d’expressar-nos que, com més petit sigui el valor absolut d’aquesta diferència, \\(|E(\\widehat{\\theta})-\\theta|\\), menys esbiaixat i més exacte és l’estimador. Per tant, “augmentar l’exactitud” és reduir el valor absolut del biaix. Exemples: Ja hem vist a les seccions anteriors que \\(E(\\overline{X})=\\mu_X\\). Per tant, \\(\\overline{X}\\) és un estimador no esbiaixat de \\(\\mu_X\\). \\(E(\\widehat{p}_X)=p_X\\). Per tant, \\(\\widehat{p}_X\\) és un estimador no esbiaixat de \\(p_X\\). \\(E(\\widetilde{S}_{X}^2)=\\sigma_X^2\\). Per tant, \\(\\widetilde{S}_{X}^2\\) és un estimador no esbiaixat de \\(\\sigma_X^2\\). Com que \\({S}_{X}^2=\\dfrac{n-1}{n}\\widetilde{S}_{X}^2\\), tenim que \\(E({S}_{X}^2)=\\dfrac{n-1}{n}\\sigma_X^2\\). Per tant, en aquest cas, \\({S}_{X}^2\\) és un estimador esbiaixat de \\(\\sigma_X^2\\), amb biaix \\[ \\mu_{{S}_{X}^2}-\\sigma_X^2=\\dfrac{n-1}{n}\\sigma_X^2-\\sigma_X^2=-\\dfrac{\\sigma_X^2}{n}\\ \\mathop{\\longrightarrow}_{\\scriptscriptstyle n\\to\\infty}\\ 0 \\] En aquest cas diem que el seu biaix tendeix a 0. \\(E(\\widetilde{S}_{X}), E({S}_{X})\\neq \\sigma_X\\) ni tan sols quan \\(X\\) és normal. Per tant, \\(\\widetilde{S}_{X}\\) i \\({S}_{X}\\) són estimadors esbiaixats de \\(\\sigma_X\\). Quan \\(X\\) és normal, el seu biaix tendeix a 0. Recordau que, en general, \\(E(X^2)\\neq E(X)^2\\). Per tant, no hauríem d’esperar que \\(E(\\widetilde{S}_{X})=\\sqrt{E(\\widetilde{S}_{X}^2)}\\). Per si qualque dia us cal saber-ho, si \\(X\\) és normal \\[ E(\\widetilde{S}_X)=\\left\\{\\begin{array}{ll} \\sigma_X\\sqrt{\\dfrac{2}{(n-1)\\pi}}\\cdot \\dfrac{2^{n-2}(\\frac{n}{2}-1)!^2}{(n-2)!} &amp; \\text{ si $n$ és parell}\\\\ \\sigma_X\\sqrt{\\dfrac{2\\pi}{n-1}}\\cdot \\dfrac{(n-2)!}{2^{n-2}(\\frac{n-1}{2}-1)!^2} &amp; \\text{ si $n$ és imparell} \\end{array}\\right. \\] Per tant, per obtenir un estimador no esbiaixat per a \\(\\sigma_X\\) només heu de dividir \\(\\widetilde{S}_X\\) pel factor que acompanyi la \\(\\sigma_X\\) a la dreta d’aquesta fórmula. 3.6.2 Estimadors precisos Donats dos estimadors \\(\\widehat{\\theta}_1\\), \\(\\widehat{\\theta}_2\\) del mateix paràmetre \\(\\theta\\), direm que \\(\\widehat{\\theta}_1\\) és més eficient, o més precís, que \\(\\widehat{\\theta}_2\\) quan la desviació típica de \\(\\widehat{\\theta}_1\\) és més petita que la de \\(\\widehat{\\theta}_2\\): \\[ \\sigma(\\widehat{\\theta}_1)&lt; \\sigma(\\widehat{\\theta}_2). \\] Quan \\(\\widehat{\\theta}_1\\) i \\(\\widehat{\\theta}_2\\) són no esbiaixats, que \\(\\widehat{\\theta}_1\\) sigui més eficient que \\(\\widehat{\\theta}_2\\) significa que els seus valors es concentren més al voltant del paràmetre \\(\\theta\\) que volem estimar. Normalment, només comparam l’eficiència de dos estimadors quan són no esbiaixats o amb el biaix que tendeixi a 0. De res ens serveix tenir un estimador molt precís però que sistemàticament dóna un valor llunyà del valor real del paràmetre. Exemples: Si \\(X\\) és normal, \\(\\overline{X}\\) és l’estimador no esbiaixat més eficient de la mitjana poblacional \\(\\mu_X\\). Si \\(X\\) és Bernoulli, \\(\\widehat{p}_X\\) és l’estimador no esbiaixat més eficient de la proporció poblacional \\(p_X\\). Si \\(X\\) és normal, \\(\\widetilde{S}_X^2\\) és l’estimador no esbiaixat més eficient de la variància poblacional \\(\\sigma_X^2\\). Exemple 3.9 Sigui \\(X\\) una variable aleatòria normal \\(N(\\mu_X,\\sigma_X)\\). Considerem la mediana \\(\\mathit{Me}=Q_{0.5}\\) d’una mostra aleatòria simple de \\(X\\) com a estimador puntual de \\(\\mu_X\\), que coincideix amb la mediana de \\(X\\) per la simetria de les variables normals. Resulta que \\(E(\\mathit{Me})=\\mu_X\\) però \\[ \\sigma^2(\\mathit{Me})\\approx \\dfrac{\\pi}{2}\\cdot \\dfrac{\\sigma_{X}^2}{n}\\approx 1.57 \\cdot \\frac{\\sigma_{X}^2}{n}=1.57\\sigma^2_{\\overline{X}} \\] Per tant, si \\(X\\) és normal, la mediana \\(\\mathit{Me}\\) també és un estimador no esbiaixat de \\(\\mu_X\\), però és menys eficient que \\(\\overline{X}\\). Per això preferim emprar la mitjana mostral per estimar \\(\\mu_X\\). Hem dit que si la població és normal, \\(\\widetilde{S}_X^2\\) és l’estimador no esbiaixat més eficient de la variància poblacional \\(\\sigma_X^2\\). La variància a seques \\[ S_X^2=\\frac{(n-1)}{n} \\widetilde{S}_X^2 \\] és més eficient, perquè \\[ \\sigma(S_X^2)=\\sqrt{\\frac{(n-1)}{n}}\\sigma(\\widetilde{S}_X^2)&lt;\\sigma(\\widetilde{S}_X^2), \\] però és un estimador esbiaixat de \\(\\sigma_X^2\\), amb biaix que tendeix a 0. Si \\(n\\) és petit, és millor fer servir la variància mostral \\(\\widetilde{S}_X^2\\) per estimar la variància, ja que el biaix pot desplaçar substancialment l’estimació, però si \\(n\\) és gran, el biaix de \\(S_X^2\\) ja és petit i es pot fer servir \\(S_X^2\\). De totes formes, si \\(n\\) és molt gran, dividir per \\(n\\) o per \\(n-1\\) no varia gaire el resultat i per tant \\(\\widetilde{S}_X^2\\) i \\(S_X^2\\) donen valors molt semblants. 3.7 Estimadors màxim versemblants Un estimador d’un paràmetre és màxim versemblant quan, aplicat a una mostra aleatòria simple, dóna el valor del paràmetre que fa màxima la probabilitat d’obtenir aquesta mostra. En realitat, l’estimació màxim versemblant d’un paràmetre el que fa màxim és el producte dels valors de la funció densitat de la variable aleatòria poblacional aplicada als elements de la mostra. Quan la variable aleatòria és discreta, això coincideix amb el que hem dit, perquè la probabilitat d’obtenir un valor concret és la funció densitat aplicada a aquest valor. Però quan la variable aleatòria poblacional és contínua, la probabilitat d’obtenir una mostra concreta és sempre 0 i no té sentit parlar de maximitzar aquest 0. Per això es pren la funció densitat. Aquí no ens complicarem la vida i entendrem que el que maximitzam és la probabilitat d’obtenir la mostra. Exemple 3.10 Suposem que tenim una variable aleatòria Bernoulli \\(X\\) de probabilitat d’èxit \\(p_X\\) desconeguda. Donada una mostra aleatòria simple \\(x_1,\\ldots,x_n\\) de \\(X\\), siguin \\(\\widehat{p}_x\\) la seva proporció mostral i \\[ P(x_1,\\ldots,x_n\\mid p_X=p) \\] la probabilitat d’obtenir la mostra quan la probabilitat poblacional \\(p_X\\) és igual \\(p\\). Un estimador per a \\(p_X\\) és màxim versemblant quan, aplicat a cada mostra aleatòria simple \\(x_1,\\ldots,x_n\\) de \\(X\\), ens dóna el valor de \\(p\\) que fa que \\[ P(x_1,\\ldots,x_n\\mid p_X=p) \\] sigui el màxim possible. Quin creieu que és l’estimador màxim versemblant de \\(p_X\\)? Un exemple concret. Suposau en 20 llançaments d’una moneda obtenim 5 cares. Quina creieu que és la probabilitat d’obtenir cara amb aquesta moneda que fa màxima la probabilitat que en 20 llançaments obtinguem 5 cares? La intuïció ens diu que hauria de ser la proporció mostral \\(\\widehat{p}_X=5/20=0.25\\), no? Confirmem-ho amb el gràfic de la probabilitat que una binomial \\(B(20,p)\\) doni 5 en funció de \\(p\\): plot((0:200)/200,dbinom(5,20,(0:200)/200),type=&quot;h&quot;,xlab=&quot;p&quot;,ylab=&quot;&quot;,xaxp=c(0,1,20)) points(0.25,dbinom(5,20,0.25),type=&quot;h&quot;,col=&quot;red&quot;) Figura 3.9: Probabilitat que una B(20,p) valgui 5 El resultat següent mostra que això sempre és així. Teorema 3.8 El valor de \\(p\\) per al qual \\(P(x_1,\\ldots,x_n\\mid p_X=p)\\) és màxim és \\(\\widehat{p}_x\\). La demostració és senzilla. Suposau que dins \\(x_1,\\ldots,x_n\\) hi ha \\(m\\) 1s i \\(n-m\\) 0s, de manera que \\(\\widehat{p}_X=m/n\\). Aleshores, la probabilitat d’obtenir \\(x_1,\\ldots,x_n\\) és \\[ P(x_1,\\ldots,x_n\\mid p_X=p)=p^m(1-p)^{n-m} \\] Per trobar el valor de \\(p\\) que fa aquest probabilitat màxima, derivau respecte de \\(p\\) i estudiau el signe de la derivada, i concloureu que el màxim es dóna efectivament a \\(p=m/n\\). La proporció \\(\\widehat{p}_x\\) és el valor que fa màxima la probabilitat d’obtenir la nostra mostra, no a l’enrevés: No és el valor més probable de \\(p_X\\) condicionat a la nostra mostra. Vaja, no confongueu \\[ P(x_1,\\ldots,x_n\\mid p_X=p)\\text{ amb }P(p_X=p\\mid x_1,\\ldots,x_n). \\] D’això darrer no en sabem trobar el màxim sense alguna hipòtesi sobre la distribució de probabilitat dels valors possibles de \\(p_X\\). Alguns altres estimadors màxim versemblants: \\(\\overline{X}\\) és l’estimador màxim versemblant del paràmetre \\(\\lambda\\) d’una variable aleatòria Poisson \\(\\overline{X}\\) és l’estimador màxim versemblant de la mitjana \\(\\mu_X\\) d’una variable aleatòria normal \\(S_X^2\\) i \\(S_X\\) (la variància i desviació típica a seques, no les mostrals!) són els estimadors màxim versemblants de la variància \\(\\sigma_X^2\\) i la desviació típica \\(\\sigma_X\\) d’una variable aleatòria normal 3.8 Estimació de poblacions 3.8.1 Estimació de poblacions numerades Exemple 3.11 Un dia vaig voler estimar quants taxis hi havia a Palma. Per fer-ho, assegut en un bar del Passeig Marítim vaig apuntar les llicències dels 40 primers taxis que passaren. Els entraré directament en un vector de R. taxis=c(1217,600,883,1026,150,715,297,137,508,134,38,961,538,1154, 314,1121,823,158,940,99,977,286,1006,1207,264,1183,1120, 498,606,566,1239,860,114,701,381,836,561,494,858,187) sort(taxis) ## [1] 38 99 114 134 137 150 158 187 264 286 297 314 381 494 498 ## [16] 508 538 561 566 600 606 701 715 823 836 858 860 883 940 961 ## [31] 977 1006 1026 1120 1121 1154 1183 1207 1217 1239 Puc estimar quants taxis hi ha a Palma a partir d’aquesta mostra? Us pot semblar una beneitura de pregunta, però aquest és un problema de rellevància històrica, com podeu consultar en aquest article. La solució d’aquest problema és donada pel resultat següent: Teorema 3.9 Sigui \\(X\\) una variable aleatòria uniforme sobre \\(\\{1,2,\\ldots,N\\}\\) (és a dir, \\(X\\) pot prendre tots els valors entre 1 i N, tots amb la mateixa probabilitat 1/N), i sigui \\(x_1,\\ldots,x_n\\) una mostra aleatòria sense reposició de \\(X\\). Sigui \\(m=\\max(x_1,\\ldots,x_n)\\). Aleshores, l’estimador no esbiaixat més eficient de \\(N\\) és \\[ \\widehat{N}=m+\\frac{m-n}{n} \\] Vegem la idea intuïtiva que hi ha al darrere d’aquesta fórmula. Suposau que teniu \\(x_1,\\ldots,x_n\\) ordenats en ordre creixent, \\(x_1&lt;\\cdots&lt;x_n\\), de manera que \\(x_n=m\\). Calculem la longitud mitjana dels “forats” a l’esquerra de cada valor \\(x_i\\). A l’esquerra de \\(x_1\\) hi “falten” els nombres \\(1,2,\\ldots,x_1-1\\), per tant hi ha un forat de \\(x_1-1\\) nombres. Entre \\(x_1\\) i \\(x_2\\) hi “falten” els nombres \\(x_1+1,\\ldots,x_2-1\\), per tant hi ha un forat de \\(x_2-x_1-1\\) nombres. En general, entre cada \\(x_{i-1}\\) i \\(x_{i}\\) hi ha un forat de \\(x_{i}-x_{i-1}-1\\) nombres (hi “falten” els nombres \\(x_{i-1}+1,\\ldots,x_i-1\\)). Per tant, la mitjana de les longituds d’aquests “forats” és \\[ \\begin{array}{l} \\displaystyle \\frac{(x_1-1)+(x_2-x_1-1)+\\cdots+(x_{n}-x_{n-1}-1)}{n}\\\\ \\displaystyle \\qquad\\quad =\\frac{x_n-n}{n}=\\frac{m-n}{n} \\end{array} \\] El que fa l’estimador \\(\\widehat{N}\\) és sumar al màxim de la mostra, \\(m\\), aquesta longitud mitjana dels forats entre membres de la mostra. És a dir, estimam que la mida de la població és tal que a la dreta del màxim de la nostra mostra hi ha un “forat” de mida la mitjana dels forats de la mostra. Exemple 3.12 Continuem amb l’Exemple 3.11. Emprant la fórmula anterior, obtenim max(taxis)+(max(taxis)-length(taxis))/length(taxis) ## [1] 1268.975 la qual cosa em permeté estimar que hi havia 1269 taxis a Palma. En realitat, consultant la web de l’Ajuntament, després vaig saber que en aquell moment n’hi havia 1246. Exemple 3.13 Fem un experiment. Generarem a l’atzar una mida N d’una població grandeta, i suposarem que els individus de la població estan numerats de l’1 al N. A continuació, prendrem 100 mostres aleaòries sense reposició de la nostra població i amb cada una d’aquestes mostres estimarem la N emprant la fórmula que hem donat. Al final, calcularem la mitjana d’aquestes estimacions i la compararem amb el valor real de N, que no descobrirem fins el final. Perquè l’experiment sigui reproduïble, fixarem la llavor d’aleatorietat, però perquè no cregueu que fem trampes amb aquesta llavor, el que farem serà generar a l’atzar la llavor d’aleatorietat amb la funció sample. Llavor=sample(1000,1) Llavor ## [1] 580 set.seed(Llavor) Ara generam la mida N de la població com un nombre a l’atzar entre 5000 i 10000. N=sample(5000:10000,1) Suposarem per tant que hi ha N individus a la nostra població, numerats de l’1 al N. Ara generarem 100 mostres aleatòries sense reposició d’aquesta població, i ens quedarem amb la mida i el valor màxim de cada una d’elles, que és l’únic que necessitam saber. Les mides les generarem a l’atzar entre, posem, 25 i 75: Mostra=function(a,b,P){ # a i b: mides màxima i mínima de la mostra; P: mida de la població n=sample(a:b,1) # Mida de la mostra X=sample(P,n) # Mostra aleatòria de mida n c(n,max(X)) # Parell (mida, màxim) } Mostres=replicate(100,Mostra(25,75,N)) Mostres ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] ## [1,] 43 53 53 40 67 44 40 73 67 67 61 26 37 30 ## [2,] 6682 6684 6684 6652 6673 6623 6607 6540 6670 6657 6657 6455 6528 6667 ## [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] ## [1,] 75 29 56 29 33 74 51 64 42 61 39 68 ## [2,] 6686 6651 6632 6617 6671 6470 6379 6565 6637 6684 6423 6522 ## [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] ## [1,] 48 28 57 28 63 46 32 31 44 69 31 31 ## [2,] 6105 6522 6293 6327 6691 6498 6464 6522 6652 6606 6298 6262 ## [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] ## [1,] 27 65 70 30 42 56 53 40 33 25 61 63 ## [2,] 6562 6676 6509 5655 6370 6641 6653 6674 6341 6612 6641 6693 ## [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62] ## [1,] 59 42 60 52 64 38 26 71 75 48 39 47 ## [2,] 6657 6596 6545 6681 6528 6583 6656 6692 6588 6603 6569 6583 ## [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74] ## [1,] 41 37 57 70 51 29 69 46 52 64 56 54 ## [2,] 6480 6535 6693 6694 6422 6665 6630 6654 6679 6414 6609 6672 ## [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] [,85] [,86] ## [1,] 59 57 56 69 39 70 58 59 48 50 37 68 ## [2,] 6675 6624 6223 6618 6480 6664 6681 6536 6525 6671 6669 6686 ## [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98] ## [1,] 70 44 39 47 56 65 43 32 60 57 42 55 ## [2,] 6697 6490 6677 6619 6492 6609 6587 6653 6564 6674 6152 6585 ## [,99] [,100] ## [1,] 75 36 ## [2,] 6398 6623 En aquesta matriu Mostres, cada columna correspon a una mostra aleatòria: la primera filera és la seva mida \\(n\\) i la segona filera el màxim \\(m\\). Ara, amb cada una d’aquestes mostres, podem estimar la mida N de la població per mitjà de la fórmula \\(m+(m-n)/n\\). Dibuixarem un histograma d’aquestes estimacions, per veure què ens ha sortit. Estimacions=Mostres[2,]+(Mostres[2,]-Mostres[1,])/Mostres[1,] round(range(Estimacions),1) # Estimacions mínima i màxima ## [1] 5842.5 6911.0 hist(Estimacions, breaks=20,col=&quot;light blue&quot;, xlab=&quot;Estimacions de N&quot;,ylab=&quot;Freqüències&quot;,main=&quot;&quot;) Com veieu, obtenim estimacions que van de 5842.5 a 6911. La mitjana d’aquestes estimacions és round(mean(Estimacions),1) ## [1] 6704.5 És hora de descobrir el valor de N, per veure si hi hem fet a prop: N ## [1] 6701 No hem fet molt enfora, com veieu. 3.8.2 Marca-recaptura Suposem que en una població hi ha \\(N\\) individus, en capturam \\(K\\) (tots diferents), els marcam i els tornam a amollar. Al cap de poc temps, en capturam \\(n\\), dels quals resulta que \\(k\\) estan marcats. A partir d’aquestes dades, volem estimar el valor de \\(N\\). Si suposam que \\(N\\) i \\(K\\) no han canviat de la primera a la segona captura (cap individu no ha abandonat la població ni se n’hi ha incorporat cap de nou), aleshores la variable aleatòria \\(X\\) definida per “Capturam un individu i miram si està marcat” és Bernoulli \\(Be(p)\\) amb \\(p=K/N\\), on coneixem la \\(K\\) i volem estimar la \\(N\\). Sigui ara \\(x_1,\\ldots,x_n\\) la mostra capturada en segon lloc. La seva proporció mostral d’individus marcats és \\(\\widehat{p}_X=k/n\\). Com que \\(\\widehat{p}_X\\) és l’estimador màxim versemblant de \\(p\\), estimam que \\[ \\dfrac{K}{N}=\\dfrac{k}{n} \\] d’on, aïllant la \\(N\\), estimam que \\[ N=\\frac{n\\cdot K}{k}. \\] En resum, l’estimador \\[ \\widehat{N}=\\frac{n\\cdot K}{k} \\] maximitza la probabilitat d’obtenir \\(k\\) individus marcats en una mostra aleatòria de \\(n\\) individus. És l’estimador màxim versemblant de \\(N\\) a partir de \\(K\\), \\(k\\) i \\(n\\); també se li diu estimador de Lincoln-Petersen. Fixau-vos que aquest estimador no fa res més que traduir la proporció “Si he trobat \\(k\\) individus marcats en un conjunt de \\(n\\) individus, què ha de valer el nombre total \\(N\\) de individus perquè hi hagi en total \\(K\\) individus marcats?” Exemple 3.14 Suposem que hem marcat 15 peixos d’un llac, i que en una captura posterior de 10 peixos, n’hi ha 4 de marcats. Quants peixos conté el llac? Ho estimarem amb l’estimador de Lincoln-Petersen: \\[ \\widehat{N}=\\frac{15\\cdot 10}{4}=37.5 \\] Per tant, estimam que hi haurà entre 37 i 38 peixos al llac. En aquest cas podem comprovar la màxima versemblança d’aquesta estimació, calculant la probabilitat d’obtenir 4 individus marcats en una mostra aleatòria de 10 individus d’una població de \\(N\\) individus on n’hi ha 15 de marcats i trobant la \\(N\\) que maximitza aquesta probabilitat. Per fer-ho, recordem que si una població està formada per \\(K\\) subjectes marcats i \\(N-K\\) subjectes no marcats, el nombre de subjectes marcats en mostres aleatòries sense reposició de mida \\(n\\) segueix una distribució hipergeomètrica \\(H(K, N-K,n)\\). Per tant, per a cada possible \\(N\\), la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats serà dhyper(4,15,N-15,10). N=15:1000 # Rang de possibles valors de N p=dhyper(4,15,N-15,10) # Probabilitats de 4 marcats en 10 Nmax=N[which(p==max(p))] # N que maximitza la probabilitat Nmax ## [1] 37 Aquest Nmax és la \\(N\\) que fa màxima la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats. Vegem-ho amb un gràfic: plot(N[1:86],p[1:86],type=&quot;h&quot;,xaxp=c(15,100,17),xlab=&quot;N&quot;,ylab=&quot;p&quot;) points(Nmax,dhyper(4,15,Nmax-15,10),type=&quot;h&quot;,col=&quot;red&quot;,lwd=1.5) I què hagués passat si no haguéssim trobat cap peix marcat a la mostra? Quan la mida de la mostra és petita, és més convenient emprar l’estimador de Chapman: \\[ \\widehat{N}=\\frac{(n+1)\\cdot (K+1)}{k+1}-1 \\] La idea és que afegim a la població un individu extra i marcat, que suposam que també capturam a la segona mostra. Llavors, aplicam l’estimador de Lincoln-Petersen i finalment restam 1, per descomptar l’individu marcat extra que realment no pertany a la població que volem estimar. D’aquesta manera ja no tenim el problema de dividir per 0 si \\(k\\) ens dóna 0. En la situació de l’Exemple 3.14, aquest estimador dóna \\[ \\widehat{N}=\\frac{16\\cdot 11}{5}-1=34.2 \\] i ens fa estimar una població total d’uns 34 peixos. Abans hem obtingut entre 37 i 38 peixos. Quina de les dues estimacions s’acosta més a la realitat? Ni idea, no ho podem saber. Amb una altra recaptura segurament haguéssim obtingut resultats diferents. L’estimador de Lincoln-Petersen \\[ \\widehat{N}=\\frac{n\\cdot K}{k} \\] és esbiaixat, amb biaix que tendeix a 0. L’estimador de Chapman és menys esbiaixat però no és màxim versemblant. Exemple 3.15 Fem un experiment similar al de l’Exemple 3.13. Generarem a l’atzar una mida N d’una població grandeta i en marcarem una certa quantitat K. A continuació, prendrem 50 mostres aleaòries sense reposició de la nostra població i amb cada una d’aquestes mostres estimarem la N emprant els dos estimadors que hem explicat en aquesta subsecció. Al final, calcularem les mitjanes d’aquestes estimacions i les compararem amb el valor real de N, que no descobrirem fins el final. Com a l’Exemple 3.13, fixarem la llavor d’aleatorietat a l’atzar. Llavor2=sample(1000,1) Llavor2 ## [1] 206 set.seed(Llavor2) Ara generam la mida N de la població com un nombre a l’atzar entre 5000 i 10000. N=sample(5000:10000,1) Ara en capturam i marcam K; per fixar idees, prendrem K=200. K=200 Per simplificar, suposarem que els N individus de la nostra població estan numerats de l’1 a l’N i que els marcats són els K primers. Ara generarem 100 mostres aleatòries sense reposició d’aquesta població, i ens quedarem amb la mida de la mostra i el nombre d’individus marcats (és a dir, el nombre de valors \\(\\leq K=200\\) en la mostra). Les mides les generarem a l’atzar entre, posem, 100 i 150: Mostra=function(a,b,P,M){ # a i b: mides màxima i mínima de la mostra; P: mida de la població; # M: nombre de marcats n=sample(a:b,1) # Mida de la mostra X=sample(P,n,rep=FALSE) # Mostra aleatòria c(n,length(which(X&lt;=M))) # Parell (mida, nombre de marcats) } Mostres=replicate(100, Mostra(100,150,N,K)) Mostres ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] ## [1,] 119 101 101 109 130 121 129 107 136 108 120 146 124 134 ## [2,] 5 2 5 1 5 4 6 3 4 3 2 5 3 4 ## [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] ## [1,] 106 131 120 149 113 143 117 125 132 101 109 108 ## [2,] 1 3 4 5 2 3 4 5 1 4 3 2 ## [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] ## [1,] 138 143 109 105 141 110 125 150 109 103 141 115 ## [2,] 4 3 8 2 3 1 5 3 2 6 8 3 ## [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] ## [1,] 107 132 135 118 131 117 110 115 135 138 127 121 ## [2,] 2 4 3 4 3 5 1 3 6 2 6 5 ## [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62] ## [1,] 124 144 134 115 129 102 111 130 102 107 111 123 ## [2,] 2 4 4 1 5 6 5 5 2 1 4 4 ## [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74] ## [1,] 119 131 115 150 145 125 119 149 129 112 146 135 ## [2,] 4 3 2 1 7 1 3 1 5 4 7 4 ## [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] [,85] [,86] ## [1,] 119 128 124 147 148 135 139 150 123 142 108 138 ## [2,] 2 5 4 4 5 6 4 6 5 8 2 2 ## [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98] ## [1,] 112 141 131 144 111 112 147 103 112 108 107 133 ## [2,] 2 7 5 4 1 6 3 4 4 1 2 5 ## [,99] [,100] ## [1,] 139 149 ## [2,] 1 5 En aquesta matriu Mostres, cada columna correspon a una mostra aleatòria: la primera filera és la seva mida \\(n\\) i la segona filera el nombre d’individus marcats a la mostra. Ara, amb cada una d’aquestes mostres, podem estimar la mida N de la població per mitjà de l’estimador de Lincoln-Petersen. EstimacionsLP=Mostres[1,]*K/Mostres[2,] round(range(EstimacionsLP),1) ## [1] 2725 30000 hist(EstimacionsLP, breaks=20,col=&quot;light blue&quot;, xlab=&quot;Estimacions de N&quot;,ylab=&quot;Freqüències&quot;, main=&quot;Estimador de Lincoln-Petersen&quot;) Com veieu, obtenim estimacions que van de 2725 a 30000. La mitjana de les estimacions és round(mean(EstimacionsLP),1) ## [1] 9246 També podem emprar l’estimador de Chapman: EstimacionsCh=(Mostres[1,]+1)*(K+1)/(Mostres[2,]+1)-1 round(range(EstimacionsCh),1) ## [1] 2455.7 15174.5 hist(EstimacionsCh, breaks=20,col=&quot;light blue&quot;,xlab=&quot;Estimacions de N&quot;,ylab=&quot;Freqüències&quot;,main=&quot;Estimador de Chapman&quot;) Com veieu, obtenim estimacions que van de 2455.7 a 15174. La mitjana d’aquestes estimacions és round(mean(EstimacionsCh),1) ## [1] 6292.7 És hora de descobrir el valor de N, per veure si hi hem fet a prop: N ## [1] 7225 Com veieu, amb l’estimador de Chapman ens hem fet més a prop del valor real de \\(N\\) que amb el màxim versemblant. Però amb cap d’ells ens hi hem fet molt a prop. 3.9 Test de la lliçó 3 (1) Tenim una variable aleatòria \\(X\\) normal de mitjana \\(\\mu\\) i desviació típica \\(\\sigma\\). Prenem mostres aleatòries simples de mida \\(n\\), i indicam amb \\(\\widetilde{S}_X\\) la seva desviació típica mostral. Quina o quines de les afirmacions següents són vertaderes? \\(E(\\widetilde{S}_X^2)=\\sigma^2\\). \\(E(\\widetilde{S}_X)=\\sigma\\). \\(\\widetilde{S}_X^2\\) segueix una distribució \\(\\chi^2\\) amb \\(n-1\\) graus de llibertat. \\((n-1)\\widetilde{S}_X^2/\\sigma^2\\) segueix una distribució \\(\\chi^2\\) amb \\(n-1\\) graus de llibertat. Totes les altres respostes són falses. (2) Quina o quines de les afirmacions següents sobre la mitjana mostral són vertaderes? Si la distribució poblacional és normal, sempre coincideix amb la mediana de la mostra. Sempre serveix per estimar la mitjana poblacional. Sempre serveix per estimar la mediana poblacional. Si la distribució poblacional és normal, serveix per estimar la mediana poblacional. Cap de les altres respostes és correcta. (3) L’error estàndard de la mitjana mostral de mida \\(n\\geq 2\\) (marca totes les continuacions correctes): Mesura la variabilitat de les observacions que formen la mostra. És l’exactitud amb què es mesura cada observació de la mostra. Mesura la variabilitat de les mitjanes mostrals de mostres aleatòries simples. Mesura la precisió amb què les mitjanes mostrals de mostres aleatòries simples estimen la mitjana poblacional. És proporcional a la mitjana mostral. És més gran que la desviació típica de la població. Sobre cada mostra val la desviació típica de la mostra. Cap de les altres respostes és correcta. (4) La proporció d’afectats per una determinada malaltia en una població és del 10%. Si estimam aquesta proporció poblacional repetidament a partir de mostres de mida 1000, aquestes estimacions segueixen una distribució que (marca totes les afirmacions correctes): És una distribució mostral. És aproximadament normal. Té mitjana 0.1. Té variància 90. És binomial. Cap de les altres respostes és correcta. (5) Què hem de fer per disminuir a la meitat l’error estàndard d’una proporció? Hem d’augmentar en un 50% la mida de la mostra Hem de doblar la mida de la mostra. Hem de quadruplicar la mida de la mostra. Hem de dividir per 2 la mida de la mostra. Hem de dividir per 4 la mida de la mostra. Cap de les altres respostes és correcta. (6) La probabilitat que els individus d’una determinada població tenguin una determinada característica \\(C\\) és \\(p\\). Prenem mostres aleatòries simples de mida \\(n\\) d’aquesta població, i indicam amb \\(\\widehat{p}_X\\) la seva proporció mostral. Quina o quines de les afirmacions següents són vertaderes? \\(\\widehat{p}_X\\) té sempre distribució binomial \\(B(n,p)\\). \\(\\widehat{p}_X\\) té sempre distribució normal. Si \\(n\\) és gran, \\(\\widehat{p}_X\\) té distribució aproximadament binomial \\(B(n,p)\\). Si \\(n\\) és gran, \\(\\widehat{p}_X\\) té distribució aproximadament normal. L’error estàndard de \\(\\widehat{p}_X\\) és \\(\\sqrt{p(1-p)/n}\\). (7) Sigui \\(X\\) una variable aleatòria que no és constant. Si en prenem mostres aleatòries simples més grans (marca totes les continuacions correctes): La mitjana mostral sempre disminueix. L’error estàndard de la mitjana sempre disminueix. L’error estàndard de la mitjana sempre augmenta. La variància mostral sempre augmenta. El nombre de graus de llibertat de l’estimador \\(\\chi^2\\) associat a la variància mostral sempre augmenta. Cap de les altres respostes és correcta. (8) La longitud d’una determinada espècie d’animalons té un valor mitjà de \\(\\mu\\) cm. Si prenem mostres aleatòries simples de 20 exemplars, calculam la seva mitjana mostral \\(\\overline{X}\\) i la seva desviació típica mostral \\(\\widetilde{S}_X\\) (marca la continuació més correcta): L’estadístic \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) segueix sempre una llei normal. L’estadístic \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) segueix sempre una llei t de Student. L’estadístic \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) segueix una llei normal si la longitud segueix una llei normal. L’estadístic \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) segueix una llei t de Student si la longitud segueix una llei normal. L’estadístic \\(\\frac{\\overline{X}-\\mu}{\\widetilde{S}_X/\\sqrt{20}}\\) no segueix mai ni una llei normal ni una llei t de Student, perquè les mostres no són prou grans. (9) En una mostra de 100 dones es va obtenir una concentració mitjana d’hemoglobina en sang de 10 amb una desviació típica de 2. Quin és l’error típic de la mostra? 0.02 0.04 0.2 0.4 1 Cap dels valors anteriors (10) Què significa que un estimador d’un paràmetre d’una variable aleatòria sigui no esbiaixat? Que la distribució mostral de l’estimador és normal. Que aplicat a una mostra aleatòria simple sempre dóna el valor poblacional del paràmetre. Que el seu valor esperat és igual al valor poblacional del paràmetre. Que aplicat a una mostra aleatòria simple sempre dóna el valor esperat del paràmetre. Que el seu error típic és petit. (11) La concentració en sang a les persones d’un determinat metabolit (en mg/ml) té una distribució \\(N(23,3)\\). Quina de les afirmacions següents és vertadera? Aproximadament un 90% de les mostres aleatòries de 100 individus tendran la seva mitjana entre 22.4 i 23.6 mg/ml. Aproximadament un 95% de les mostres aleatòries de 100 individus tendran la seva mitjana entre 22.4 i 23.6 mg/ml. Aproximadament un 99% de les mostres aleatòries de 100 individus tendran la seva mitjana entre 22.4 i 23.6 mg/ml. Més d’un 99% de les mostres aleatòries de 100 individus tendran mitjana igual a 23. Cap de les afirmacions anteriors és vertadera. (12) Sigui \\(X\\) una variable aleatòria \\(N(\\mu_X,2)\\) i sigui \\(\\overline{X}\\) la mitjana mostral de mida \\(10\\) de \\(X\\). Quina de les afirmacions següents és vertadera? La desviació típica de \\(\\overline{X}\\) és igual a 2. La desviació típica de \\(\\overline{X}\\) és menor que 2. La desviació típica de \\(\\overline{X}\\) és major que 2. Que la desviació típica de \\(\\overline{X}\\) sigui major, menor o igual que 2 depèn de \\(\\mu_X\\). Cap de les afirmacions anteriors és vertadera. "],
["chap-IC.html", "Tema 4 Intervals de confiança 4.1 Definició d’interval de confiança 4.2 Exemple: Interval de confiança del 95% per a la mitjana d’una variable aleatòria normal 4.3 Interval de confiança per a la mitjana basat en la t de Student 4.4 Intervals de confiança per a proporcions 4.5 Intervals de confiança per a la variància d’una variable normal 4.6 “Poblacions finites” 4.7 Test de la lliçó 4", " Tema 4 Intervals de confiança Amb l’estimació puntual intentam endevinar el valor d’un paràmetre d’una variable poblacional. Però hem de tenir clar que és molt difícil que amb una mostra poguem encertar exactament el valor del paràmetre. Les técniques de l’estadística inferencial ens permeten aleshores quantificar la precisió d’aquesta estimació. Això es fa complementant l’estimació puntual amb un interval al voltant d’aquesta estimació “on estam bastant segurs que cau el valor real del paràmetre”. Figura 4.1: elEconomista.es, 27/5/2019 Naturalment, és fàcil donar un interval on estiguem completament segurs que cau el valor real del paràmetre. Basta donar un interval prou ample com per contenir tots els valors raonables del paràmetre: Del que es tracta és de donar un interval el més estret possible on estiguem bastant segurs que cau el valor real del paràmetre. Aleshores, l’amplada d’aquest interval dependrà: De la variabilitat de l’estimador: com menys variabilitat tingui, més precisa serà l’estimació. Normalment, la variabilitat de l’estimador creix amb la desviació típica de la variable poblacional i decreix amb la mida de les mostres. Del nivell de confiança, o seguretat, de l’estimació: com de segurs volem estar que l’estimació és correcta 4.1 Definició d’interval de confiança Un interval de confiança del Q% (abreviadament, un IC Q%) d’un paràmetre poblacional és un interval obtingut aplicant a una mostra aleatòria simple de mida \\(n\\) una fórmula que satisfà la propietat següent: El Q% dels intervals obtinguts aplicant aquesta fórmula a mostres aleatòries simples de mida \\(n\\) contenen el valor real del paràmetre poblacional que es vol estimar. És a dir: Un Q% dels IC Q% contenen el valor real del paràmetre poblacional. Tenir una confiança del Q% significa doncs que hem calculat l’interval amb una fórmula que encerta el Q% de les vegades, en el sentit que en Q de cada 100 vegades que aplicàssim aquesta fórmula a mostres aleatòries simples, els intervals que obtendríem contendrien el valor real del paràmetre que volem estimar. Però aquesta fórmula s’equivoca el (100-Q)% de les vegades, és a dir, 100-Q de cada 100 intervals obtinguts aplicant aquesta fórmula a mostres aleatòries simples no contenen el valor real del paràmetre que volem estimar. I no sabem quin és el nostre cas. Però si una fórmula encerta, diguem, el 95% de les vegades, nosaltres confiam que hagi encertat en la nostra aplicació. Exemple 4.1 En un experiment hem mesurat el percentatge d’augment d’alcohol en sang a 40 persones després de prendre 4 canyes de cervesa. La mitjana i la desviació típica mostral d’aquests percentatges d’increment han estat \\(\\overline{x}=41.2\\) i \\(\\widetilde{s}=2.1\\). Com veurem a l’Exemple 4.3, un IC 95% per al percentatge d’augment mitjà d’alcohol en sang d’una persona després de beure 4 canyes de cervesa és [40.53, 41.87]. Això significa que estam “molt segurs” que l’augment mitjà d’alcohol en sang d’una persona després de beure 4 canyes de cervesa està entre el 40.53% i el 41.87%, perquè aquest interval l’haurem calculat amb una fórmula que el 95% de les vegades que l’aplicàssim a una mostra aleatòria simple de mida 40 donaria un interval que conté la mitjana poblacional que volem estimar. Nosaltres som optimistes i “confiam” que el nostre interval pertany a aquest 95% d’intervals que l’encerten. Sovint això ho trobareu expressat com : Hi ha un 95% de probabilitat que l’interval [40.53, 41.87] contengui el valor real de l’augment mitjà d’alcohol en sang d’una persona després de beure 4 canyes de cervesa. Però cal entendre el que diu aquesta frase: Per definició, un 95% dels intervals de confiança del 95% per a l’augment mitjà d’alcohol etc. contenen el valor real d’aquest augment mitjà. [40.53, 41.87] és un interval de confiança del 95% per a l’augment mitjà d’alcohol etc. Aleshores, [40.53, 41.87] té una probabilitat del 95% de contenir el valor real de l’augment mitjà d’alcohol etc. en el mateix sentit que si un 95% de les persones tenen una determinada característica, i prenc una persona a l’atzar, aquesta persona té un 95% de probabilitat de tenir aquesta característica. No confongueu: Interval de referència del Q% per a una variable aleatòria: Interval que conté el valor de la variable aleatòria en un individu amb probabilitat Q%. Interval de confiança del Q% per a un paràmetre: Interval que conté el valor poblacional del paràmetre de la variable aleatòria “amb probabilitat” Q%, en el sentit que l’hem calculat amb una fórmula que dóna un interval que conté el paràmetre el Q% de les vegades que l’aplicam a una mostra aleatòria simple. Interval de referència del Q% per a un estimador: Interval que conté el valor de l’estimador sobre una mostra aleatòria amb probabilitat Q%. Per exemple: Si diem que un interval de referència del 95% per a la concentració d’una proteïna en sèrum en individus sans mesurada en g/dl és [11,16], això significa que un 95% dels individus sans tenen una concentració d’aquesta proteïna en sèrum d’entre 11 i 16 g/dl, és a dir, que un individu sa escollit a l’atzar té un 95% de probabilitat que la seva concentració d’aquesta proteïna en sèrum estigui entre 11 i 16 g/dl. Si diem que un interval de confiança del 95% per a la concentració mitjana d’una proteïna en sèrum en individus sans mesurada en g/dl és [11,16], això significa que hem pres una mostra aleatòria simple de concentracions d’aquesta proteïna en sèrum en individus sans i a partir d’aquesta mostra: Hem estimat que la concentració mitjana d’aquesta proteïna en sèrum en individus sans està entre 11 i 16 g/dl I tenim un “95% de confiança” en aquest interval perquè el 95% dels intervals que s’obtenen en aplicar aquesta fórmula a mostres aleatòries simples de la mateixa mida que la nostra contenen la mitjana poblacional. Si diem que el 95% de les mostres de 100 concentracions d’una determinada proteïna en sèrum en individus sans tenen la mitjana mostral entre 11 i 16, això és un interval de referència del 95% per a la mitjana mostral de mostres de mida 100, no un interval de confiança per a la concentració mitjana poblacional ni un interval de referència per al valor de la concentració en un individu. Sovint calculareu un interval de confiança del Q% per a un cert paràmetre \\(\\theta\\) d’una població, us donarà \\([a,b]\\), i amb el poc rigor amb el qual us soleu expressar, us serà igual dir “el valor real de \\(\\theta\\) té una probabilitat del Q% de pertànyer a \\([a,b]\\)” que “\\([a,b]\\) té una probabilitat del Q% de contenir el valor real de \\(\\theta\\)” Però aquestes dues frases no diuen exactament el mateix, i de fet la primera és falsa i la segona la interpretam com a vertadera. Fixau-vos que a la primera frase parlam de la probabilitat que a \\(\\theta\\) li passi qualque cosa, i a la segona que sigui a \\([a,b]\\) a qui li passi qualque cosa. La primera frase diu que \\(\\theta\\) varia i un Q% dels seus valors pertanyen a \\([a,b]\\). Això és fals. “El valor real de \\(\\theta\\)” és un número que no varia. Per a la nostra població val una cosa concreta, desconeguda però concreta, que pertanyerà o no a l’interval \\([a,b]\\). La segona frase en canvi es pot interpretar de la manera següent. L’interval \\([a,b]\\) forma part de tota la població d’intervals de confiança del Q% per a \\(\\theta\\) calculats a partir de mostres aleatòries simples d’una mida concreta de la nostra població. Un Q% d’aquests intervals conté el valor real de \\(\\theta\\). Per tant, podem dir que el nostre interval \\([a,b]\\) té una probabilitat del Q% de contenir el valor real de \\(\\theta\\). Aquesta interpretació és correcta. Encara que el millor que podeu fer és no mesclar probabilitat amb confiança, i dir simplement que teniu un 95% de confiança, o un 95% de seguretat, en què \\([a,b]\\) conté el valor real de \\(\\theta\\). Així no us enganxau els dits. Que un IC Q% per a un paràmetre \\(\\theta\\) sigui \\([a,b]\\) serveix: Per estimar \\(\\theta\\) amb aquest marge de confiança: Estam bastant segurs que el valor poblacional de \\(\\theta\\) està entre \\(a\\) i \\(b\\) (la fórmula emprada encerta sovint) Per poder comparar el valor poblacional de \\(\\theta\\) amb un valor concret amb aquest marge de confiança: Estam bastant segurs que el valor real de \\(\\theta\\) no està ni per sota de \\(a\\) ni per sobre de \\(b\\) i per tant que és diferent de tots aquests valors Per exemple: si un IC 95% per a la prevalença \\(p\\) d’una determinada característica en una població (la fracció d’individus que tenen aquesta característica) va de 0.025 a 0.047: Estam molt (“un 95%”) segurs que \\(p\\in [0.025,0.047]\\) (perquè la fórmula emprada per calcular aquest interval encerta en un 95% de les vegades) Estam molt segurs que \\(p&gt;0.02\\) (perquè tot l’interval on estam molt segurs que cau el valor real de \\(p\\) està a la dreta de 0.02) Estam molt segurs que \\(p\\neq 0.05\\) (perquè 0.05 no pertany a l’interval on estam molt segurs que cau el valor real de \\(p\\)) Però no estam molt segurs que \\(p=0.03\\), per molt que \\(0.03\\in [0.025,0.047]\\): estam molt segurs que \\(p\\) està entre 0.025 i 0.047, però no tenim cap seguretat que valgui un valor concret entre aquests límits, només que està entre aquests límits. En aquest cas, el que direm és que no podem rebutjar que \\(p\\) sigui 0.03, perquè 0.03 pertany a l’interval on creiem que cau el valor real de \\(p\\). Hi ha dos tipus de mètodes bàsics de càlcul d’intervals de confiança a partir d’una mostra aleatòria: Paramètrics: Usant alguna fórmula basada en la distribució mostral de l’estimador. Es basen en teoremes i només serveixen si la variable aleatòria \\(X\\) i la mostra aleatòria satisfan (aproximadament) les hipòtesis del teorema. No paramètrics: Tots els altres. El nostre preferit és el bootstrap: De la mostra, es prenen a l’atzar moltes (milers) mostres aleatòries simples (és a dir, amb reposició) de la mateixa mida que la mostra. Es calcula l’estimador amb cada una d’aquestes mostres. S’usa el vector de resultats per estimar un interval de confiança. Per exemple, podríem prendre com a IC 95% l’interval entre els quantils 0.025 i 0.975 d’aquest vector. El bootstrap es pot usar sempre i funciona bé si la mostra és aleatòria, però es basa en un procés aleatori i per tant cada execució sobre una mateixa mostra pot donar un interval diferent. El bootstrap és una eina molt poderosa per calcular intervals de confiança i, en general, per estimar la distribució mostral d’un estadístic. Tant, que a la pràctica ja comença a substituir els mètodes paramètrics. Emperò no fa miracles: si la mostra és petita o molt poc representativa de la població, un IC calculat amb el bootstrap servei de tan poc com un de calculat amb un mètode paramètric. 4.2 Exemple: Interval de confiança del 95% per a la mitjana d’una variable aleatòria normal Una de les fórmules més conegudes per a intervals de confiança és la següent: Si \\(X\\sim N(\\mu,\\sigma)\\) i en tenim una mostra aleatòria simple de mida \\(n\\), mitjana mostral \\(\\overline{X}\\) i variància mostral \\(\\widetilde{S}^2_X\\), un IC 95% per a \\(\\mu\\) és \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] on \\(t_{n-1,0.975}\\) indica el 0.975-quantil de la distribució \\(t_{n-1}\\). A alguns de vosaltres us hauran explicat a Batxillerat, o trobareu a llibres que consulteu, una fórmula per a l’IC 95% per a \\(\\mu\\) similar a aquesta, però canviant-hi la \\(\\widetilde{S}_X\\) per \\(\\sigma\\) i el \\(t_{n-1,0.975}\\) per \\(z_{0.975}\\). Aquesta altra fórmula només es pot fer servir si coneixeu la desviació típica poblacional \\(\\sigma\\), que a la pràctica, mai serà el cas. Per tant, per favor, oblidau-la. Anem a explicar d’on surt aquesta fórmula, ja que és un paradigma de com s’obtenen la majoria de les fórmules paramètriques per a intervals de confiança. Suposem doncs que \\(X\\sim N(\\mu,\\sigma)\\) i que en tenim una mostra aleatòria simple de mida \\(n\\), mitjana mostral \\(\\overline{X}\\) i variància mostral \\(\\widetilde{S}^2_X\\). En aquesta situació, sabem que \\[ T=\\frac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}} \\] té distribució t de Student amb \\(n-1\\) graus de llibertat, \\(t_{n-1}\\). Si podem trobar \\(A,B\\in \\mathbb{R}\\) tals que \\[ P(A\\leq T\\leq B)=0.95, \\] llavors: \\[ \\begin{array}{rl} 0.95 &amp; =P\\Bigg(A\\leq \\dfrac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}}\\leq B\\Bigg)\\\\[2ex] &amp; =P\\Bigg(A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leq \\overline{X}-\\mu \\leq B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(-\\overline{X}+A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leq -\\mu \\leq -\\overline{X}+B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(\\overline{X}-B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leq \\mu \\leq \\overline{X}-A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg) \\end{array} \\] Com que \\(P(A\\leq T\\leq B)=0.95\\) significa que per al 95% de les mostres aleatòries simples de mida \\(n\\) el valor de \\(T\\) està entre \\(A\\) i \\(B\\), \\[ P\\Bigg(\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leq \\mu \\leq \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)=0.95 \\] significa que per al 95% de les mostres aleatòries simples de mida \\(n\\) la \\(\\mu\\) cau dins l’interval \\[ \\Bigg[\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Per tant, això serà un IC 95% per a \\(\\mu\\). Ens falta trobar els \\(A,B\\) tals que \\(P(A\\leq T\\leq B)=0.95\\). Per trobar-los, emprarem quantils de la distribució de \\(T\\). Recordem que si indicam amb \\(t_{n-1,0.975}\\) el 0.975-quantil d’una \\(t_{n-1}\\), per definició tenim que \\[ P(T\\leq t_{n-1,0.975})=0.975 \\] i per la simetria de la \\(t\\), \\[ P(T\\leq -t_{n-1,0.975})=P(T\\geq t_{n-1,0.975})=0.025 \\] Per tant: \\[ \\begin{array}{l} P(-t_{n-1,0.975}\\leq T\\leq t_{n-1,0.975})\\\\ \\quad =P(T\\leq t_{n-1,0.975})-P(T\\leq -t_{n-1,0.975})\\\\ \\quad =0.975-0.025=0.95 \\end{array} \\] Així doncs, podem prendre \\[ A=-t_{n-1,0.975},\\quad B=t_{n-1,0.975} \\] i obtenim l’IC 95% per a \\(\\mu\\) anunciat: \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] L’escriurem \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Exemple 4.2 Fem un experiment per veure que, efectivament, aquesta fórmula “encerta”, en el sentit que conté la \\(\\mu\\), al voltant del 95% de les vegades. Al bloc de codi següent: generam una Població de 107 “individus” que segueixen una llei normal estàndard i en calculam la mitjana mu; definim una funció IC que calcula l’IC 95% per a la mitjana \\(\\mu\\) amb la fórmula anterior; prenem 200 mostres aleatòries simples de mida 50 de la nostra població i les aplicam aquesta funció, obtenint una matriu M de 200 columnes formades pels dos extrems dels intervals (l’inferior a la primera filera i el superior a la segona filera); finalment, miram quantes vegades hem encertat, és a dir, a quantes columnes de M la mitjana poblacional mu està entre l’entrada de la primera filera i la de la segona. set.seed(42) Poblacio=rnorm(10^7) mu=mean(Poblacio) IC=function(x){ n=length(x) mean(x)+qt(0.975,n-1)*sd(x)/sqrt(n)*c(-1,1)} M=replicate(200,IC(sample(Poblacio,50,replace=TRUE))) Encerts=length(which(mu&gt;=M[1,] &amp; mu&lt;=M[2,])) Encerts ## [1] 189 Hem encertat 189 vegades, és a dir, un 94.5% de les vegades. És aproximadament el que esperàvem. Si ho provau amb altres llavors d’aleatorietat obtendreu altres resultats, de vegades millors, de vegades pitjors. Per veure millor els encerts, dibuixam els intervals en un gràfic, on apareixeran en gris els que encerten i en vermell els que no encerten. plot(1,type=&quot;n&quot;,xlim=c(-0.8,0.8),ylim=c(0,200), xlab=&quot;Valors&quot;,ylab=&quot;Repeticions&quot;, main=&quot;200 IC 95%&quot;) seg.int=function(i){color=&quot;grey&quot;; if((mu&lt;M[1,i]) | (mu&gt;M[2,i])){color=&quot;red&quot;} segments(M[1,i],i,M[2,i],i,col=color,lwd=2)} sapply(1:200,FUN=seg.int) abline(v=mu,lwd=2) Atenció! De mitjana, un IC Q% NO conté el valor real del paràmetre en un (100-Q)% de les ocasions. Per exemple, de mitjana, un 5% de les vegades que calculam un IC 95%, el paràmetre poblacional no pertany a l’interval obtingut. Per tant, si calculam \\(n\\) IC 95% sobre mostres aleatòries simples independents, el nombre de vegades que l’interval resultant no contendrà el paràmetre poblacional seguirà una distribució binomial \\(B(n,0.05)\\). El gràfic següent dóna el valor de \\(P(X\\geq 1)\\) per a una variable aleatòria \\(X\\) de tipus \\(B(n,0.05)\\), per a \\(n=0,...,100\\), i per tant la probabilitat que si calculam \\(n\\) IC 95% sobre mostres aleatòries simples independents, almenys un d’ells no contengui el paràmetre poblacional desitjat. plot(1-dbinom(0,0:100,0.05),pch=20,xlab=&quot;n&quot;,ylab=&quot;Probabilitat&quot;, main=&quot;Probabilitat d&#39;algun èxit en una B(n,0.05)&quot;) Tornant a l’IC 95% per a \\(\\mu\\) d’una variable normal donat per la fórmula \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] fixau-vos que: Està centrat en \\(\\overline{X}\\), per tant en cada càlcul estarà centrat en la mitjana mostral Tal i com l’hem calculat, la probabilitat que \\(\\mu\\) caigui fora d’aquest interval es reparteix per igual als dos costats: un 2.5% de les vegades la \\(\\mu\\) poblacional estarà a l’esquerra de l’extrem inferior i un 2.5% de les vegades estarà a la dreta de l’extrem superior Exemple 4.3 En un experiment hem mesurat el percentatge d’augment d’alcohol en sang a 40 persones després de prendre 4 canyes de cervesa. La mitjana i la desviació típica mostral d’aquests percentatges d’increment han estat \\[ \\overline{x}=41.2,\\quad \\widetilde{s}=2.1 \\] Per calcular un IC 95% per al percentatge mitjà d’augment, suposarem que la variable aleatòria d’interès (de la que volem estimar la mitjana) \\(X\\): “Prenem una persona i li mesuram el percentatge d’augment d’alcohol en sang després de prendre 4 canyes de cervesa” és normal i que la mostra que hem pres d’aquesta variable és aleatòria simple. Llavors, com que \\(t_{n-1,0.975}\\)=qt(0.975,39)=2.0227, un IC 95% és \\[ 41.2\\pm 2.0227\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67\\Rightarrow [40.53, 41.87] \\] Per tant, estimam amb un 95% de confiança que el percentatge mitjà d’augment d’alcohol en sang després de prendre 4 canyes de cervesa està entre el 40.53% i el 41.87%. Per calcular l’interval anterior hem suposat que la variable poblacional “Percentatge d’augment d’alcohol en sang després de prendre 4 canyes de cervesa” segueix una distribució normal. I si no fos normal? En aquest cas, com que \\(n=40\\), és gran pel Teorema 4.2 de la propera secció l’interval obtingut segueix essent (aproximadament) un interval de confiança del 95% per a \\(\\mu\\) Si \\(n\\) fos petit i \\(X\\) molt diferent d’una normal, no es pot usar aquesta fórmula i cal buscar-se la vida (per exemple, emprar el mètode de bootstrap) També hem suposat que era una mostra aleatòria simple. I si no ho és? Si és aleatòria, com que el nombre de persones que poden prendre 4 canyes de cervesa és pràcticament la població mundial, molt gran, a efectes pràctics la podem considerar simple. Però segur que no és aleatòria, sinó oportunista. No hem tret per sorteig de la llista de tota la població mundial, ni tan sols de la de Mallorca, 40 persones i les hem fetes prendre 4 cerveses, sinó que hem cercat voluntaris. En aquest cas no podem fer res per salvar la fórmula, i la seva validesa depèn de si la mostra de persones presa pot passar per aleatòria o no. 4.3 Interval de confiança per a la mitjana basat en la t de Student A partir d’ara, per tal d’evitar ambigüitats, a les fórmules hi expressarem el nivell de confiança dels intervals en tant per u, no en tant per cent; és a dir, com una proporció en comptes de com un percentatge. Per tant, parlarem d’intervals de confiança de nivell de confiança \\(q\\), amb \\(q\\) entre 0 i 1, en lloc d’intervals de confiança del \\(Q\\%\\) amb \\(Q=100q\\). Amb aquestes notacions, per exemple, els intervals de confiança del 95% seran intervals de confiança de nivell de confiança 0.95. La fórmula El mateix argument que abans, canviant 0.95 per \\(q\\) dóna: Teorema 4.1 Si \\(X\\sim N(\\mu,\\sigma)\\) i en prenem una mostra aleatòria simple de mida \\(n\\), un interval de confiança de nivell de confiança \\(q\\) (en tant per u) per a \\(\\mu\\) és \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Fixau-vos que als IC 95%, \\(q=0.95\\) i per tant \\((1+q)/2=1.95/2=0.975\\). Usant el Teorema Central del Límit i algunes aproximacions, tenim el següent resultat: Teorema 4.2 Sigui \\(X\\) una variable aleatòria qualsevol de mitjana poblacional \\(\\mu\\). Suposem que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) gran (diguem, de 40 o més elements). Llavors, un interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu\\) és aproximadament \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] L’aproximació del teorema anterior és millor com més gran sigui \\(n\\) o com més propera a una normal sigui la variable poblacional \\(X\\). En resum: Podem emprar la fórmula per a l’interval de confiança de nivell de confiança \\(q\\) per a la mitjana poblacional basada en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] quan la variable poblacional és normal o quan la mostra aleatòria simple és gran. Exemple 4.4 L’empresa RX-print ofereix una impressora de radiografies d’altíssima qualitat. En la seva publicitat afirma que els seus cartutxos imprimeixen una mitjana de 500 radiografies amb l’especificació: Dades tècniques: Mostra de mida \\(n=25\\), població suposada normal, nivell de confiança del 90% Uns radiòlegs desitgen comprovar aquestes afirmacions i prenen una mostra de cartutxos a l’atzar de mida \\(n=25\\), obtenint una mitjana de \\(\\overline{x}=518\\) radiografies i una desviació típica mostral \\(\\widetilde{s}=39.9\\). Amb aquesta mostra, la mitjana poblacional anunciada pel fabricant cau dins l’interval de confiança del 90%? La variable aleatòria d’interès és \\(X\\) és “Prenem un cartutxo d’aquesta empresa i miram el nombre de radiografies que permet imprimir”, de mitjana \\(\\mu\\) per a la qual volem calcular un IC 90%. Suposarem que la variable \\(X\\) és normal, perquè l’empresa ho suposa a les dades tècniques. Per tant podem emprar la fórmula \\[ \\overline{x}\\pm t_{n-1,(q+1)/2} \\frac{\\widetilde{s}}{\\sqrt{n}} \\] on \\(n=25\\), \\(\\overline{x}=518\\), \\(\\widetilde{s}=39.9\\), \\(q=0.9\\), \\((q+1)/2=0.95\\) i \\(t_{24,0.95}\\)=qt(0.95,24)\\(=1.71\\). Operant: \\[ 518\\pm 1.71\\times \\frac{39.9}{\\sqrt{25}}\\Rightarrow 518\\pm 13.65\\Rightarrow [504.35,531.65] \\] Tenim, doncs, un 95% de confiança que el nombre mitjà de radiografies per cartutxo està entre 504.35 i 531.65, i en particular que no és 500 (però en benefici del consumidor: estam molt segurs que és més gran que 500). Exemple 4.5 A l’exemple anterior hem suposat que la variable aleatòria era normal. Què passaria si fos molt diferent d’una normal? Com que \\(n=25\\) no és prou gran, en principi no podríem aplicar la fórmula de l’interval de confiança basada en la t de Student. Emprarem el mètode del bootstrap, per a la qual cosa necessitam tenir les dades originals, i no només els seus estadístics. Tenim aquestes dades en el vector Radios següent: Radios=c(485,511,509,509,561,529,458,532,545,546, 503,577,547,477,507,548,480,444,461,573, 513,604,542,501,488) mean(Radios) ## [1] 518 sd(Radios) ## [1] 39.89987 Prenem 5000 mostres aleatòries simples de mida 25 (la mateixa mida que el conjunt de dades original) de les dades i calculam la mitjana de cada mostra; fixam la llavor d’aleatorietat per que el càlcul sigui reproduïble: set.seed(100) Simulacions=replicate(5000,mean(sample(Radios,25,rep=TRUE))) Ara prenem com a IC 90% l’interval que tanca el 90% de valors centrals d’aquest vector de mitjanes mostrals, és a dir, l’interval que va del quantil 0.05 al quantil 0.95 d’aquest vector de mitjanes: quantile(Simulacions,c(0.05,0.95)) ## 5% 95% ## 504.96 530.92 Obtenim l’interval [504.96,530.92]: amb la fórmula basada en la t de Student, havíem obtingut l’interval [504.35,531.65]. Algunes consideracions Observau que l’estructura de l’interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu\\) donat al Teorema 4.2 és \\[\\begin{align} &amp; \\text{estimador}\\nonumber\\\\ &amp; \\qquad \\pm \\frac{1+q}{2}\\text{-quantil de la distr. mostral}\\times \\text{error típic de l&#39;estimació} \\tag{4.1} \\end{align}\\] Aquesta estructura és molt típica (tot i que, com veurem, no tots els intervals de confiança paramètrics tenen aquesta forma) i satisfà que: L’interval de confiança està centrat en el valor de l’estimador La “probabilitat d’equivocar-nos” es reparteix per igual als dos costats de l’interval: una fracció \\(q/2\\) de les vegades el paràmetre estarà a l’esquerra de l’extrem inferior i una fracció \\(q/2\\) de les vegades estarà a la dreta de l’extrem superior A més, tenim que: Per a una mateixa mostra i una mateixa fórmula (paramètrica) per calcular l’interval de confiança, si el nivell de confiança creix, l’interval s’eixampla Això és general, per a tots els intervals de confiança paramètrics. La idea intuitiva és que, per estar més segurs que un interval conté un valor, l’interval ha de ser més ample. A un interval de confiança amb l’estructura (4.1), el motiu matemàtic és que si \\(q\\) creix, el quantil d’ordre (1+\\(q\\))/2 de la distribució mostral creix. Per exemple, a l’Exemple 4.3, teníem \\(n=40\\), \\(\\overline{x}=41.2\\) i \\(\\widetilde{s}=2.1\\): L’IC 95% té \\(q=0.95\\), per tant \\(t_{n-1,(1+q)/2}=t_{39,0.975}=2.02\\), i donava \\[ 41.2\\pm 2.02\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67 \\] L’IC 99% té \\(q=0.99\\), per tant \\(t_{n-1,(1+q)/2}=t_{39,0.995}=2.71\\), i dóna \\[ 41.2\\pm 2.71\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.9 \\] més ample Però si canviam de mostra (o de fórmula, si n’hi ha més d’una) per calcular l’interval de confiança, pot passar qualsevol cosa. Amb R La funció t.test(X,conf.level=...)$conf.int calcula l’interval de confiança basat en la t de Student per a la \\(\\mu\\) de la variable aleatòria de la que el vector X n’és una mostra. El paràmetre conf.level permet especificar el nivell de confiança (en tant per u). El seu valor per defecte és 0.95, així que per calcular un IC 95% no cal especificar-lo. Per exemple, l’IC 90% per al nombre mitjà de radiografies per cartutxo de l’Exemple 4.4 es calcularia amb t.test(Radios,conf.level=0.9)$conf.int ## [1] 504.3472 531.6528 ## attr(,&quot;conf.level&quot;) ## [1] 0.9 Càlcul de la mida de la mostra per fixar l’error Recordem que l’interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu\\) basat en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] és simètric i centrat en \\(\\overline{X}\\). La seva amplada és la diferència entre els seus extrems \\[ 2t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] El marge d’error (error, precisió) \\(M\\) en l’estimació de \\(\\mu\\) per mitjà d’aquest interval de confiança és el que sumam i restam a \\(\\overline{X}\\) per obtenir l’interval, és a dir, la meitat de la seva amplada: \\[ M=t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Fixau-vos que si estimam que el valor de \\(\\mu\\) és \\(\\overline{X}\\), l’error que cometem és \\(|\\overline{X}-\\mu|\\). Aleshores, si el nostre interval de confiança per a \\(\\mu\\) és \\(\\overline{X}\\pm M\\) i l’encertam (és a dir, aquest interval conté el valor real de \\(\\mu\\)), aleshores l’error que cometem quan diem que el valor de \\(\\mu\\) és \\(\\overline{X}\\) és com a màxim \\(M\\), perquè si \\(\\mu\\in [\\overline{X}-M,\\overline{X}+M]\\), aleshores \\(|\\overline{X}-\\mu|\\leq M\\). Una pregunta típica a l’hora de planejar un experiment és quina ha de ser la mida de la mostra que hem de prendre per que el marge d’error en estimar \\(\\mu\\) amb un nivell de confiança donat sigui com a màxim un cert valor desitjat \\(M_{max}\\). És a dir, volem trobar la \\(n\\) més petita tal que \\[ t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leq M_{max}. \\] Però fixau-vos que en aquesta desigualtat la \\(n\\) hi apareix al quantil i a l’error típic, i a més la \\(\\widetilde{S}_X\\) depèn de la mostra. El que farem per respondre la pregunta serà fer algunes trampes: Aproximarem la t de Student per una normal estàndard (ja que segurament la \\(n\\) haurà de ser gran): \\[ t_{n-1,(1+q)/2}\\rightsquigarrow z_{(1+q)/2} \\] Estimarem el valor de \\(\\widetilde{S}_X\\) mitjançant la desviació típica mostral \\(\\widetilde{S}_0\\) d’una prova pilot (un experiment anterior, realitzat per nosaltres o publicat per qualcú altre a qualque lloc de confiança) D’aquesta manera, aproximam l’error \\(M\\) per mitjà de \\[ M\\approx z_{(1+q)/2}\\times \\frac{\\widetilde{S}_0}{\\sqrt{n}} \\] I ara si imposam que \\(M\\leq M_{max}\\), ja podem aïllar la \\(n\\): \\[ z_{(1+q)/2}\\times \\frac{\\widetilde{S}_0}{\\sqrt{n}}\\leq M_{max}\\Longrightarrow n\\geq \\left(\\frac{ z_{(1+q)/2}\\cdot \\widetilde{S}_0}{M_{max}} \\right)^2 \\] En resum: Teorema 4.3 Per estimar la \\(\\mu\\) amb nivell de confiança \\(q\\) amb un marge d’error com a màxim \\(M_{max}\\) mitjançant la fórmula basada en la t de Student, prendrem una mostra de mida \\[ n\\geq \\left(\\frac{ z_{(1+q)/2}\\cdot \\widetilde{S}_0}{M_{max}} \\right)^2, \\] on \\(\\widetilde{S}_0\\) és la desviació típica mostral obtinguda en una estimació anterior de \\(\\mu\\) (en una prova pilot). Naturalment, quan després prenguem una mostra de mida \\(n\\) que satisfaci aquesta condició, pot passar qualsevol cosa, ja que hem emprat els resultats d’una mostra per estimar la desviació típica d’una altra mostra i a més hem aproximat els quantils de la t de Student per els d’una normal estàndard, que són més petits. Però almenys haurem fet tot el que haurem pogut per fitar l’error dins el marge desitjat. Exemple 4.6 A l’Exemple 4.3, hem emprat una mostra de \\(n=40\\) persones, amb \\(\\overline{x}=41.2\\) i \\(\\widetilde{s}=2.1\\), i l’error ha estat \\[ t_{0.975,39}\\cdot \\frac{2.1}{\\sqrt{40}}=0.67 \\] Quin és el nombre mínim de persones que hauríem hagut d’emprar per estimar la mitjana amb un nivell de confiança del 95% i un error de (com a màxim) 0.5? És a dir, quin el nombre mínim de persones que hauríem hagut d’emprar per obtenir un IC 95% d’amplada (com a màxim) 1? Empram l’exemple com a prova pilot: \\[ n\\geq \\left(\\frac{ z_{(1+q)/2}\\cdot \\widetilde{s}}{M_{max}} \\right)^2= \\left(\\frac{1.96\\cdot 2.1}{0.5} \\right)^2=67.77 \\] El valor de \\(n\\) més petit que satisfà aquesta condició és 68, per tant aquest és el nombre mínim de persones que hauríem hagut d’emprar per esperar obtenir un IC 95% d’amplada (com a màxim) 1. 4.4 Intervals de confiança per a proporcions Suposem que tenim una variable Bernoulli \\(X\\) amb probabilitat d’èxit \\(p_X\\) desconeguda. Volem calcular un interval de confiança per a \\(p_X\\). Per fer-ho, prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\), amb nombre d’èxits \\(S\\) i per tant proporció mostral d’èxits \\(\\widehat{p}_{X}=S/n\\) Explicarem tres mètodes per calcular aquest interval de confiança: El mètode exacte de Clopper-Pearson, que es pot aplicar sempre però sol donar intervals de confiança més amples del necessari. El mètode aproximat de Wilson, que es pot emprar quan la mostra és gran, posem de mida 40 o més, i es basa en el fet que, pel Teorema Central del Límit, la proporció mostral de mostres aleatòries simples segueix una distribució aproximadament normal. El mètode aproximat de Laplace, que és una simplificació del mètode de Wilson, però només es pot emprar quan la mostra és bastant més gran, posem de mida 100 o més, i la proporció mostral \\(\\widehat{p}_{X}\\) no és molt propera a 0 o a 1. És el mètode més clàssic i conegut. Mètode “exacte” de Clopper-Pearson Aquest mètode es basa en el fet que el nombre d’èxits \\(S\\) en mostres aleatòries simples de mida \\(n\\) de \\(X\\) segueix una distribució binomial \\(B(n,p_X)\\). Raonant de manera similar a com obteníem l’interval per a \\(\\mu\\) basat en la t de Student (us estalviarem els detalls) arribam a la fórmula següent: Teorema 4.4 Un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) és \\([p_0,p_1]\\), on (recordau que \\(n\\) indica la mida de la mostra i \\(S\\) el nombre d’èxits) \\(p_0\\) és la solució de l’equació \\[ \\sum_{k=S}^n\\binom{n}{k}p_0^k(1-p_0)^{n-k}= \\frac{1-q}{2} \\] \\(p_1\\) és la solució de l’equació \\[ \\sum_{k=0}^S\\binom{n}{k}p_1^k(1-p_1)^{n-k}= \\frac{1-q}{2} \\] Calcular a mà aquest interval és intractable, i en general dóna més ample del necessari (degut a la natura discreta de la distribució binomial, que només pren valors nombres naturals), però es pot emprar amb mostres aleatòries simples de qualsevol mida ja que empra que el nombre d’èxits \\(S\\) en mostres aleatòries simples de mida \\(n\\) de \\(X\\) segueix una distribució binomial i això sempre és veritat. Per calcular-lo amb R, podeu emprar la funció del paquet epitools binom.exact(S,n,conf.level=...) on Sés el nombre d’èxits, n la mida de la mostra, i conf.level el nivell de confiança en tant per u, que per defecte val 0.95. Exemple 4.7 De 10 pacients tractats amb un medicament, 2 s’han curat. Quin seria un IC 95% per a la proporció p de pacients que aquest medicament cura? Emprarem el mètode de Clopper-Pearson: library(epitools) round(binom.exact(2,10),3) ## x n proportion lower upper conf.level ## 1 2 10 0.2 0.025 0.556 0.95 Dóna l’interval [0.025,0.556]. Estimam per tant amb una confiança del 95% que aquest medicament cura entre el 2.5% i el 55.6% dels pacients. Sí, aquest interval és molt ample. La culpa no és del mètode de Clopper-Pearson, és de la mida petita de la mostra. L’interval de Clopper-Pearson té l’inconvenient que, en general, no està centrat en \\(\\widehat{p}_{X}\\). Per exemple, el centre de l’interval anterior és \\((0.025+0.556)/2= 0.29\\), diferent de \\(\\widehat{p}_X=0.2\\) Mètode de Wilson Suposem ara que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) gran (posem, de 40 o més subjectes) i proporció mostral d’èxits \\(\\widehat{p}_{X}\\). En aquestes condicions, pel Teorema Central del Límit, \\[ Z=\\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\approx N(0,1) \\] Per tant \\[ P\\Big(-z_{(1+q)/2}\\leq \\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\leq z_{(1+q)/2}\\Big)=q \\] Aïllant \\(p_X\\) obtenim: Teorema 4.5 Si la mida \\(n\\) de la mostra és gran, un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) és (aproximadament): \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/{2}}^2}{2n}\\pm z_{(1+q)/{2}}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(1+q)/{2}}^2}{4n^2}}}{1+\\frac{z_{(1+q)/{2}}^2}{n}} \\] Amb R es calcula amb la funció binom.wilson(x,n,conf.level=...) del paquet epitools, amb la mateixa sintaxi que binom.exact. Aquest interval també té l’inconvenient que, si us hi fixau, no està centrat en \\(\\widehat{p}_{X}\\): el seu centre és \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/{2}}^2}{2n}}{1+\\frac{z_{(1+q)/{2}}^2}{n}} \\] Mètode de Laplace Suposem finalment que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) encara més gran i \\(\\widehat{p}_{X}\\) enfora de 0 i 1. Per fixar idees, suposem que \\[ n\\geq 100,\\ n\\widehat{p}_{X}\\geq 10,\\ n(1-\\widehat{p}_{X})\\geq 10 \\] En aquest cas, a la fórmula de l’interval de Wilson podem suposar que els termes \\(z_{(1+q)/{2}}^2/n\\) són (aproximadament) 0 i obtenim la fórmula següent: Teorema 4.6 En les condicions explicades, un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) és (aproximadament): \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Amb R es calcula amb la funció binom.approx(x,n,conf.level=...) del paquet epitools, amb la mateixa sintaxi que binom.exact. Aquesta fórmula és la més popular, amb més de 200 anys de rodatge. Us heu de saber la fórmula de Laplace, no cal saber les fórmules dels altres dos intervals. Més exemples Exemple 4.8 En una mostra aleatòria de 500 famílies amb nins en edat escolar es va trobar que 340 introduïen fruita diàriament en la dieta dels seus fills. A partir d’aquestes dades, volem calcular un interval de confiança del 95% per a la proporció real de famílies d’aquesta ciutat amb nins en edat escolar que incorporen fruita fresca cada dia en la dieta dels seus fills. Diguem \\(X\\) a la variable aleatòria “Prenem una família amb nins en edat escolar i miram si inclou diàriament fruita a la dieta dels fills”. És Bernoulli, diguem \\(p_X\\) a la seva probabilitat d’èxit: la probabilitat que una família amb nins en edat escolar inclogui diàriament fruita a la dieta dels fills. Cercam un interval de confiança del 95% per a \\(p_X\\). Com que \\(n=500\\geq 100\\), \\(n\\widehat{p}_X=340\\geq 10\\) i \\(n(1-\\widehat{p}_X)=160\\geq 10\\), podem emprar la fórmula de Laplace \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] amb \\(n=500\\), \\(\\widehat{p}_{X}=340/500=0.68\\) i \\(z_{(q+1)/2}=z_{0.975}=1.96\\). Dóna \\[ 0.68\\pm 1.96\\sqrt{\\frac{0.68(1-0.68)}{500}}\\Rightarrow [0.639,0.721] \\] Amb R: round(binom.approx(340,500), 3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.639 0.721 0.95 Amb els altres mètodes, que també podríem aplicar en aquest cas, obtenim els intervals: round(binom.exact(340,500),3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.637 0.721 0.95 round(binom.wilson(340,500),3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.638 0.719 0.95 En resum, estimam que entre aproximadament un 64% i un 72% de les famílies d’aquesta ciutat amb nins en edat escolar inclouen diàriament fruita fresca en la dieta dels seus fills. Quan podem calcular més d’un interval per a \\(p_X\\), quin calculam? D’entrada cal dir que si podem calcular més d’un interval, segurament donaran molt parescuts, com heu pogut comprovar a l’exemple anterior. A més, recordau que les tres fórmules només ens donen “un nivell de confiança q” si s’apliquen a mostres aleatòries simples, i les nostres mostres gairebé sempre seran oportunistes, cas en el qual, si ens posam perepunyetes, no en podem aplicar cap. Però en tot cas, si no filam molt prim i podem triar, hem de tenir en compte que: L’interval de Clopper-Pearson és exacte, no empra cap aproximació, però: Tendeix a donar un interval més ample del necessari No està centrat en la proporció mostral Només és un interval “exacte” si la mostra és aleatòria simple, cosa que gairebé sempre serà fals (com a molt, serà “aproximadament” aleatòria simple) Com que no es pot calcular “a mà”, no és molt popular L’interval de Wilson és aproximat, fa servir l’aproximació a la normal donada pel Teorema Central del Límit. Això no és un gran emperò, pequè tanmateix segurament la mostra serà com a molt “aproximadament” aleatòria simple. Ara bé, tampoc no està centrat en la proporció mostral, i ens agrada poder donar els intervals en la forma “tal més menys qual” perquè d’aquesta manera donam l’estimació puntual i el marge d’error. L’interval de Laplace és molt aproximat, però: Forma part de la cultura general del científic, tothom el coneix És l’únic centrat en la proporció mostral Exemple 4.9 En un assaig d’un nou tractament de quimioteràpia, en una mostra de \\(n\\) malalts tractats, cap desenvolupà càncer testicular com a efecte secundari. Quin seria un interval de confiança al 95% per a la proporció de malalts tractats amb aquesta quimio que desenvolupen càncer testicular? Per calcular-lo podem emprar el mètode de Clopper-Pearson i, si \\(n\\) és gran, el de Wilson. No podem emprar la fórmula de Laplace, perquè \\(\\widehat{p}_X=0\\). Pel que fa a Clopper-Pearson, aquest és un dels pocs casos que admeten solució analítica senzilla: dóna l’interval \\[ \\Big[0,1-\\Big(\\frac{1-q}{2}\\Big)^{1/n}\\Big] \\] que, si \\(q=0.95\\), queda \\[ [0,1-0.025^{1/n}]. \\] Per exemple, si \\(n=40\\) binom.exact(0,40) ## x n proportion lower upper conf.level ## 1 0 40 0 0 0.0880973 0.95 1-0.025^(1/40) ## [1] 0.0880973 Si podem emprar el mètode de Wilson, la fórmula \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(q+1)/2}^2}{2n}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(q+1)/2}^2}{4n^2}}}{1+\\frac{z_{(q+1)/2}^2}{n}} \\] amb \\(\\widehat{p}_{X}=0\\) i \\(z_{(1+q)/2}=1.96\\) dóna \\[ \\frac{\\frac{1.96^2}{2n}\\pm 1.96\\sqrt{\\frac{1.96^2}{4n^2}}}{1+\\frac{1.96^2}{n}}\\Longrightarrow \\Big[0,\\frac{1.96^2}{n+1.96^2}\\Big] \\] Per exemple, un altre cop amb \\(n=40\\) binom.wilson(0,40) ## x n proportion lower upper conf.level ## 1 0 40 0 6.330897e-18 0.0876216 0.95 qnorm(0.975)^2/(40+qnorm(0.975)^2) ## [1] 0.0876216 Quan s’ha de calcular “a ull” un interval de confiança del 95% per a una probabilitat \\(p_X\\) a partir d’una mostra aleatòria simple on no hi ha hagut cap èxit, sovint es fa servir la regla següent: Regla del 3: Quan en una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria de Bernoulli de paràmetre \\(p_X\\) no hi trobam cap èxit, un IC 95% per a \\(p_X\\) va, aproximadament, de 0 a \\(3/n\\). Amb aquesta regla, en el nostre exemple amb \\(n=40\\) obtendríem l’interval [0,3/40]=[0,0.075], no molt enfora del [0,0.088] que hem obtingut amb els altres dos mètodes. Per veure com la regla del 3 aproxima l’interval de Clopper-Pearson, el gràfic següent mostra els valors \\(3/n\\) i l’extrem superior de l’IC 95% de Clopper-Pearson a partir d’una mostra de mida \\(n\\) amb 0 èxits: f=function(n){binom.exact(0,n)$upper} plot(1:100,sapply(1:100,f),pch=20,cex=0.7,xlab=&quot;n&quot;,ylab=&quot;Extrem superior&quot;, main=&quot;Extrem superior d&#39;un IC 95% en cas de 0 èxits&quot;) curve(3/x,col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,lty=c(NA,1),pch=c(20,NA), legend=c(&quot;Clopper-Pearson&quot;,&quot;Regla del 3&quot;),col=c(&quot;black&quot;,&quot;red&quot;),cex=0.7) El gràfic següent mostra els valors \\(3/n\\) i els extrems superiors dels IC 95% de Clopper-Pearson i de Wilson a partir d’una mostra de mida \\(n\\) (\\(n\\geq 40\\) per als intervals de confiança de Wilson) amb 0 èxits: f=function(n){binom.exact(0,n)$upper} plot(1:100,sapply(1:100,f),pch=20,cex=0.5,xlab=&quot;n&quot;,ylab=&quot;Extrem superior&quot;, main=&quot;Extrem superior d&#39;un IC 95% en cas de 0 èxits&quot;) curve(3/x,col=&quot;red&quot;,lwd=1.5,add=TRUE) points(40:100,3.84/(40:100+3.84),pch=20,cex=0.5,col=&quot;blue&quot;) legend(&quot;topright&quot;,lty=c(NA,NA,1),pch=c(20,20,NA), legend=c(&quot;Clopper-Pearson&quot;,&quot;Wilson&quot;,&quot;Regla del 3&quot;),col=c(&quot;black&quot;,&quot;blue&quot;,&quot;red&quot;),cex=0.7) Els extrems superiors dels intervals de Clopper-Pearson i Wilson se superposen en aquest darrer gràfic. Exemple 4.10 En un assaig d’un tractament de quimioteràpia, en una mostra de 100 pacients tractats, 25 desenvoluparen càncer testicular secundari. Volem calcular un IC 95% per a la proporció de pacients tractats amb aquesta quimioteràpia que desenvolupen càncer testicular. En aquest cas podem emprar els tres mètodes: round(binom.exact(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1688 0.3466 0.95 round(binom.wilson(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1755 0.343 0.95 round(binom.approx(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1651 0.3349 0.95 Concloem, amb un nivell de confiança del 95%, que entre aproximadament un 17% i un 34% dels pacients tractats amb aquesta quimioteràpia desenvolupen càncer testicular. Càlcul de la mida de la mostra per a fixar l’error L’error de l’interval de confiança de Laplace és \\[ M= z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] perquè l’interval de confiança de Laplace és \\(\\widehat{p}_X\\pm M\\) i per tant, si conté el valor real de \\(p_X\\), l’error \\(|\\widehat{p}_X-p_X|\\) que cometem quan diem que el valor de \\(p_X\\) és \\(\\widehat{p}_X\\) és com a màxim \\(M\\). No podem determinar la mida de la mostra a fi que l’interval de confiança tingui un error màxim sense conèixer \\(\\widehat{p}_{X}\\), que no coneixem sense una mostra. Però en el cas de l’interval de Laplace per a una proporció, podem donar un \\(n\\) que garanteixi una amplada màxima donada valgui el que valgui \\(\\widehat{p}_{X}\\in [0,1]\\). Fixau-vos que la funció \\(y=p (1-p)\\), amb \\(p\\in [0,1]\\), és una paràbola còncava amb vèrtex al punt \\(p=0.5\\) curve(x*(1-x),xlim=c(0,1),xlab=&quot;p&quot;,ylab=&quot;&quot;) abline(v=0.5,lty=&quot;dashed&quot;) Per tant, el seu màxim s’assoleix a \\(p=0.5\\). Així, doncs \\[ \\widehat{p}_{X} (1-\\widehat{p}_{X})\\leq 0.5(1-0.5)=0.5^2\\text{ per a tot $\\widehat{p}_X\\in[0,1]$} \\] i per tant \\[ \\begin{array}{l} \\displaystyle M=z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\\\ \\qquad\\displaystyle \\leq z_{(q+1)/2}\\sqrt{\\frac{0.5^2}{n}}=\\frac{0.5z_{(q+1)/2}}{\\sqrt{n}}=\\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\end{array} \\] D’aquesta manera, si prenem \\(n\\) tal que \\[ \\frac{z_{(q+1)/2}}{2\\sqrt{n}}\\leq M_{max} \\] aleshores segur que \\(M\\leq M_{max}\\), valgui el que valgui \\(\\widehat{p}_{X}\\). Per tant, el que farem serà calcular la \\(n\\) per obtenir un error com a màxim \\(M_{max}\\) en el cas més desfavorable: quan l’interval és el més ample possible, és a dir, suposant que \\(\\widehat{p}_{X}=0.5\\): \\[ M_{max}\\geq \\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\Rightarrow n\\geq \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2 \\] En resum: Teorema 4.7 Si \\[ n\\geq \\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2, \\] l’error de l’interval de Laplace calculat amb una mostra de mida \\(n\\) sempre serà com a molt \\(M_{max}\\). Exemple 4.11 Quina és la mida més petita d’una mostra que ens garanteix un error de com a màxim 0.05 en estimar una proporció \\(p_X\\) emprant un interval de confiança de Laplace del 95%? Pel teorema anterior, per garantir un error de 0.05 en calcular un IC 95% per una proporció \\(p_X\\) emprant la fórmula de Laplace, hem d’emprar una mostra de mida \\(n\\) tal que \\[ n\\geq \\Bigg(\\frac{z_{(1+q)/2}}{2M_{max}}\\Bigg)^2=\\Bigg(\\frac{1.96}{0.1}\\Bigg)^2=384.16 \\] La mida més petita que satisfà aquesta condició és \\(n=385\\). La resposta correcta no és 384, per molt que 384.16 s’arrodoneixi a 384. Fixau-vos que 384 no és més gran que 384.16. Observau tres coses: El valor de \\(n\\) només depèn de la precisió i del nivell de confiança, no de la natura de l’estudi ni de proves pilot Tal i com hem trobat la \\(n\\), estam segurs que si prenem una mostra com a mínim d’aquesta mida, el marge d’error de l’interval de confiança de Laplace serà com a màxim \\(M_{max}\\) (la seva amplada serà com a màxim \\(2M_{max}\\)), sigui quina sigui la mostra. És de les poques vegades que podem estar segurs de qualque cosa en estadística. El teorema anterior és per l’amplada de l’interval de Laplace, però la \\(n\\) segurament us sortirà molt gran i en aquest cas l’interval de Laplace aproxima molt bé els altres dos intervals. 4.5 Intervals de confiança per a la variància d’una variable normal Suposem que tenim una variable normal \\(X\\sim N(\\mu,\\sigma)\\). Volem trobar un IC 95% per a la seva variància \\(\\sigma^2\\) (o la seva desviació típica \\(\\sigma\\)). Per calcular-lo, prenem una mostra aleatòria simple de mida \\(n\\), de variància mostral \\(\\widetilde{S}^2_X\\). Recordau que, en aquestes condicions, \\[ \\frac{(n-1) \\widetilde{S}_{X}^2}{\\sigma^2} \\] té distribució \\(\\chi^2_{n-1}\\) Podem aprofitar aquest fet per obtenir intervals de confiança per a \\(\\sigma^2\\): Teorema 4.8 Si la variable \\(X\\) és normal, un interval de confiança de nivell de confiança \\(q\\) per a \\(\\sigma^2\\) és \\[ \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}, \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right], \\] on \\(\\chi_{n-1,r}^2\\) és el \\(r\\)-quantil de la distribució \\(\\chi_{n-1}^2\\) La justificació d’aquesta fórmula és la usual: com que \\[ \\begin{array}{l} \\displaystyle P(\\chi_{n-1}^2\\leq \\chi_{n-1,(1-q)/2}^2)=\\frac{1-q}{2}\\\\ \\displaystyle P(\\chi_{n-1}^2\\geq \\chi_{n-1,(1+q)/2}^2)=1-\\frac{1+q}{2}=\\frac{1-q}{2}, \\end{array} \\] tenim que \\[ \\begin{array}{l} q=P\\left(\\chi_{n-1,(1-q)/2}^2\\leq \\chi_{n-1}^2\\leq \\chi_{n-1,(1+q)/2}^2\\right)\\\\[2ex] \\quad\\displaystyle =P\\left(\\chi_{n-1,(1-q)/2}^2\\leq \\frac{(n-1) \\widetilde{S}_{X}^2}{\\sigma^2}\\leq \\chi_{n-1,(1+q)/2}^2 \\right)\\\\[2ex] \\quad\\displaystyle = P\\left(\\frac{(n-1) \\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}\\leq\\sigma^2\\leq\\frac{ (n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right) \\end{array} \\] Fixau-vos que aquest interval de confiança per \\(\\sigma^2\\) no està centrat en \\(\\widetilde{S}_{X}^2\\) ni en \\({S}_{X}^2\\). A més, com que \\(\\chi_{n-1}^2\\) no és simètrica, s’han de calcular els dos quantils \\(\\chi_{n-1,(1-q)/2}^2\\) i \\(\\chi_{n-1,(1+q)/2}^2\\), perquè no hi ha cap relació entre ells que doni el valor d’un d’ells a partir del de l’altre. Exemple 4.12 Un índex de qualitat d’un reactiu químic és la variabilitat en el temps que triga a actuar: es demana que aquest temps sigui aproximadament constant, és a dir, que tengui una desviació típica petita. Hem realitzat 30 proves en les quals hem mesurat el temps d’actuació d’un determinat reactiu, i a partir dels resultats volem calcular un IC 95% per a la desviació típica del seu temps d’actuació. Tenim els resultats guardats en el vector següent: Temps=c(12,13,13,14,14,14,15,15,16,17,17,18,18,19,19, 25,25,26,27,30,33,34,35,40,40,51,51,58,59,83) Per ara suposarem que la distribució del temps d’actuació d’aquest reactiu és (aproximadament) normal. Més endavant estudiarem tècniques per determinar (amb un cert nivell de confiança) si podem acceptar que una mostra prové d’una variable normal. Continuem. Com que la variable que ens dóna el temps és (aproximadament) normal, podem emprar la fórmula per a l’IC 95% per a \\(\\sigma^2\\) anterior: \\[ \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}, \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right] \\] on: \\(n=\\)length(Temps)\\(=30\\) \\(\\widetilde{S}_X^2=\\)var(Temps)\\(=301.55\\) \\(q=0.95\\), per tant \\(\\chi_{n-1,(1+q)/2}^2=\\)qchisq(0.975,29)\\(=45.72\\) i \\(\\chi_{n-1,(1-q)/2}^2=\\)qchisq(0.025,29)\\(=16.05\\) Obtenim l’interval: \\[ \\left[ \\frac{29\\cdot 301.55}{45.72}, \\frac{29\\cdot 301.55}{16.05}\\right]= [191.26, 544.96] \\] Aquest interval és per a la variància! Per obtenir un interval de confiança per a la desviació típica, prenem arrels quadrades dels extrems: \\[ [\\sqrt{191.26}, \\sqrt{544.96}]=[13.83,23.34] \\] Per tant la variabilitat dels temps d’actuació d’aquest reactiu és molt gran. Comparau aquest interval amb l’IC 95% per al seu temps mitjà d’actuació: round(t.test(Temps)$conf.int,2) ## [1] 21.88 34.85 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 L’extrem superior de l’IC 95% per a la desviació típica és més gran que l’extrem inferior d’aquest IC 95% per a la mitjana. Amb R, aquest interval de confiança amb nivell de confiança \\(q\\) per a la variància es pot calcular amb la funció varTest(X,conf.level=...)$conf.int del paquete EnvStats, on X és el vector que conté la mostra i conf.level indica el nivell de confiança en tant per u, que per defecte és igual a 0.95. Així, l’interval de confiança que ens demanàvem a l’exemple anterior es calcularia amb library(EnvStats) varTest(Temps)$conf.int ## LCL UCL ## 191.2627 544.9572 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 Que no, que aquest és el de la variància! L’IC 95% per a la desviació típica és: sqrt(varTest(Temps)$conf.int) ## LCL UCL ## 13.82977 23.34432 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 L’interval per a la variància basat en la distribució \\(\\chi^2\\) només és vàlid si la variable poblacional és (aproximadament) normal. En cas que no poguem acceptar que ho és, el millor és emprar un mètode no paramètric, com per exemple el bootstrap. Exemple 4.13 Anem a calcular un IC 95% per a la desviació típica del temps de reacció de l’Exemple anterior amb el mètode del bootstrap. Prenem 5000 mostres aleatòries simples de mida 30 del vector Temps i calculam la desviació típica mostral de cada mostra: Simulacions.sd=replicate(5000,sd(sample(Temps,30,rep=TRUE))) Ara prenem com a IC 95% l’interval que va del quantil 0.025 al quantil 0.975 d’aquest vector de desviacions típiques: quantile(Simulacions.sd,c(0.025,0.975)) ## 2.5% 97.5% ## 11.00926 22.69609 No ha sortit molt diferent de l’obtingut amb la fórmula basada en la distribució \\(\\chi^2\\). 4.6 “Poblacions finites” Fins ara hem emprat mostres aleatòries simples. Què passa si prenem mostres aleatòries sense reposició? Si la mida \\(N\\) de la població és molt més gran que la mida \\(n\\) de la mostra (posem \\(N\\geq 1000n\\)), les fórmules donades fins ara funcionen (aproximadament) bé. Quan la mida \\(N\\) de la població no és molt més gran que la mida \\(n\\) de la mostra, el que es fa és, a les fórmules que hem donat per als intervals de confiança per a \\(\\mu\\) o \\(p_X\\), multiplicar-hi l’error estàndard pel factor de població finita \\[ \\sqrt{\\frac{N-n}{N-1}} \\] Així: Si \\(X\\) és una població de mida \\(N\\) amb mitjana poblacional \\(\\mu\\) i prenem una mostra aleatòria sense reposició de \\(X\\), amb mitjana \\(\\overline{X}\\) i desviació típica mostral \\(\\widetilde{S}_X\\), i si \\(X\\) normal o si \\(n\\) és gran, es recomana prendre com a interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu\\) \\[ \\overline{X}\\pm t_{n,(q+1)/2}\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] Si \\(X\\) una població de mida \\(N\\) que segueix una distribució Bernoulli amb probabilitat d’èxit \\(p_X\\) i prenem una mostra aleatòria sense reposició de \\(X\\), amb \\(n\\) molt gran i nombres d’èxits i fracassos com a mínim 10, es recomana prendre com a interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] En les condicions del punt anterior, per obtenir un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) amb un marge d’error \\(M_{max}\\) en el cas més desfavorable (\\(\\widehat{p}_X=0.5\\)) caldrà prendre una mostra de mida \\[ n\\geq \\frac{Nz_{(q+1)/2}^2}{4M_{max}^2(N-1)+z_{(q+1)/2}^2} \\] Exemple 4.14 En una mostra aleatòria de 727 estudiants (diferents) de la UIB (\\(N=12000\\)), 557 afirmàrem haver comès plagi en algun treball durant els seus estudis. Quin seria un interval de confiança del 95% per a la proporció \\(p_X\\) d’estudiants de la UIB que han comès plagi en algun treball? Una mostra de 727 estudiants diferents és molt gran respecte del total d’estudiants de la UIB, per la qual cosa convé emprar la fórmula de Laplace amb el factor de població finita \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] on \\(\\widehat{p}_{X}=557/727=0.766\\), \\(z_{(q+1)/2}=1.96\\), \\(n=727\\) i \\(N=12000\\): dóna \\[ 0.766\\pm \\sqrt{\\frac{0.766(1-0.766)}{727}}\\sqrt{\\frac{\\vphantom{(}12000-727}{12000-1}}\\Rightarrow [0.751,0.781] \\] Estimam amb un nivell de confiança del 95% que entre un 75.1 i un 78.1 dels estudiants de la UIB han comès plagi en algun treball. Exemple 4.15 De quina mida hem de prendre una mostra aleatòria sense reposició d’estudiants de la UIB per estimar una proporció amb nivell de confiança del 95% i un marge d’error màxim de 0.05? Per la fórmula anterior (prenent \\(N=12000\\) i \\(z_{(1+q)/2}=1.96\\)), per garantir un marge d’error màxim de 0.05 cal prendre una mostra de mida \\[ n\\geq \\frac{12000\\cdot 1.96^2}{4\\cdot 0.05^2(12000-1)+1.96^2}=372.3 \\] Per tant, ens calen 373 estudiants. 4.7 Test de la lliçó 4 () En un estudi transversal sobre una mostra de 500 subjectes representatius d’una comunitat, s’ha observat una prevalença d’una certa malaltia del 20% (IC 95%: 16.5%-23.5%). Quina de les afirmacions següents és correcta? Si prenem una altra mostra de 500 subjectes de la mateixa comunitat, tenim un 95% de confiança que l’interval 16.5%-23.5% contendrà el percentatge de subjectes de la mostra que té aquesta malaltia. Un 95% dels individus de la comunitat tenen entre el 16.5% i el 23.5% de probabilitat de tenir aquesta malaltia. La fórmula amb la qual hem obtingut l’interval 16.5%-23.5% produeix intervals que contenen la proporció poblacional de malalts en un 95% de les ocasions. La fórmula amb la qual hem obtingut l’interval 16.5%-23.5% produeix intervals que contenen la proporció de malalts en la mostra en un 95% de les ocasions. Hi ha un 95% de probabilitats que la prevalença de la malaltia a la comunitat sigui del 20%. Totes les altres respostes són falses. () Prenem una mostra aleatòria simple de mida 50 d’una variable aleatòria. Calculam un interval de confiança del 90% per a la mitjana de la variable aleatòria a partir d’aquesta mostra, dóna [11.8,12.8]. Què significa això? Que l’hem obtingut amb una fórmula que el 90% de les vegades dóna un interval que conté el valor real de la variable. Que l’hem obtingut amb una fórmula que el 90% de les vegades dóna un interval que conté el valor de la mitjana de la mostra emprada per calcular-lo. Que l’hem obtingut amb una fórmula que el 90% de les vegades dóna un interval que conté el valor de la mitjana mostral de qualsevol mostra. Que l’hem obtingut amb una fórmula que el 90% de les vegades dóna un interval que conté el valor real de la mitjana de la variable aleatòria. Cap de les respostes anteriors és correcta. () En un estudi transversal sobre una mostra de subjectes representatius d’una comunitat, s’ha observat una prevalença d’hipertensió arterial (HTA) del 20% (interval de confiança del 95%: 15%-25%). Quina de les afirmacions següents és vertadera? Es té un 95% de seguretat que entre un 15% i un 25% dels subjectes de la mostra són hipertensos. Es té un 95% de seguretat que entre un 15% i un 25% dels subjectes de la comunitat són hipertensos. Es té un 95% de seguretat que la prevalença de la HTA en la comunitat és del 20%. La prevalença real de HTA en la comunitat se situa entre el 15% i el 25%. Cap de les respostes anteriors és correcta. () Un interval de confiança del 99% per a la concentració d’un determinat metabolit a la sang dels individus d’una determinada espècie és [10,12]. D’acord amb això, esperam trobar fora d’aquest interval: Un 1% de les concentracions mitjanes de totes les mostres de qualsevol mida d’individus d’aquesta espècie. Un 1% de les concentracions mitjanes de les mostres grans (\\(\\geq 40\\)) d’individus d’aquesta espècie. Un 99% de les concentracions mitjanes de les mostres de qualsevol mida d’individus d’aquesta espècie. Un 1% de les concentracions dels individus d’aquesta espècie. Un 99% de les concentracions dels individus d’aquesta espècie. Cap de les anteriors respostes és correcta () Quina de les situacions següents ens permet una estimació més precisa d’una mitjana poblacional \\(\\mu\\) amb la fórmula basada en la t de Student? \\(\\overline{x}=10\\), \\(\\widetilde{s}=0.2\\), \\(n=30\\). \\(\\overline{x}=20\\), \\(\\widetilde{s}=0.2\\), \\(n=30\\). \\(\\overline{x}=10\\), \\(\\widetilde{s}=0.2\\), \\(n=50\\). \\(\\overline{x}=40\\), \\(\\widetilde{s}=0.1\\), \\(n=50\\). () Prenem una mostra aleatòria simple de mida 100 d’una variable aleatòria i calculam un interval de confiança del 95% per a \\(\\mu\\) amb la fórmula basada en la t de Student. Obtenim [11.8,12.8]. Què ha valgut, aproximadament, la desviació típica mostral de la mostra? 12.3 2.5 3 6.5 No ho podem saber a partir de les dades donades () Per calcular un interval de confiança al 95% per al valor mitjà \\(\\mu\\) d’una certa variable, hem pres una mostra aleatòria simple de mida 100. Si ara prenguéssim una altra mostra aleatòria simple de mida 100 i amb aquesta calculàssim un interval de confiança del 99% per a \\(\\mu\\), com seria aquest interval? Més ample que l’anterior Més estret que l’anterior Exactament igual d’ample que l’anterior Pot passar qualsevol cosa () Per estimar una certa mitjana poblacional amb un nivell de confiança 0.95, hem emprat la fórmula basada en la t de Student sobre una mostra de 100 individus i hem obtingut un IC 95% amb un marge d’error de 0.02. Si empram la mateixa fórmula per a calcular aquest IC sobre una mostra de 200 individus, estam segurs que (marcau totes les afirmacions correctes): L’IC 95% obtingut tindrà un marge d’error &lt;0.02 L’IC 95% obtingut tindrà un marge d’error &gt;0.02 Si calculam un IC 99%, el seu marge d’error serà &gt;0.02 Si calculam un IC 90%, el seu marge d’error serà &gt;0.02 Cap de les altres afirmacions és correcta () En una mostra de 88 estudiants, es trobà que un 8% consumien begudes energètiques (IC 95%: 2% a 14%, mètode de Laplace). Quines de les afirmacions següents són certes? Una altra mostra de la mateixa mida sempre mostraria una taxa d’estudiants consumidors de begudes energètiques entre el 2% i el 14%. El 95% del estudiants té una probabilitat d’entre el 2% i el 14% de consumir begudes energètiques. Estam molt segurs que entre el 2% i el 14% dels estudiants consumeixin begudes energètiques. Si la mostra hagués estat de 880 estudiants i també hagués tingut un 8% de consumidors de begudes energètiques, l’interval de confiança del 95% hagués estat més estret. Seria impossible obtenir aquest IC 95% si la taxa de consum de begudes energètiques entre els estudiants fos del 20%. () Prenem una mostra aleatòria de 200 residents de Santa Margalida (població, 12000 habitants) per calcular un interval de confiança de la proporció dels margalidans que presenten una determinada condició. Quines de les afirmacions següents són vertaderes? Marcau totes les respostes vertaderes: Si la mostra és simple, no cal tenir en compte el factor de població finita. Encara que la mostra sigui simple, cal tenir en compte el factor de població finita. Si la mostra no és simple, cal tenir en compte el factor de població finita. Una mostra aleatòria sense repeticions de mida 200 d’una població de mida 12000 sempre podem entendre que és simple, a efectes de calcular intervals de confiança de proporcions. Totes les altres respostes són falses. () Estam calculant intervals de confiança per a la probabilitat d’èxit d’una variable Bernoulli a partir de mostres aleatòries simples de mida 100 emprant la fórmula de Laplace. Sobre una mostra hem obtingut una proporció mostral d’èxits \\(\\widehat{p}_X=0.5\\) i sobre una altra mostra una proporció mostral d’èxits \\(\\widehat{p}_X=0.7\\). Quin dels dos intervals de confiança és més ample? Marcau la resposta correcta. El calculat amb la mostra amb \\(\\widehat{p}_X=0.5\\) El calculat amb la mostra amb \\(\\widehat{p}_X=0.7\\) Com que les dues mostres són de la mateixa mida, els dos intervals tenen la mateixa amplitud Com que les dues mostres són diferents, no ho podem saber Cap de les respostes anteriors és correcta () Quina o quines de les afirmacions següents sobre l’interval de confiança per a la variància poblacional basat en la distribució \\(\\chi^2\\) són vertaderes? Marcau totes les respostes vertaderes: Sempre està centrat en la variància mostral de la mostra emprada Sempre està centrat en la variància “a seques” de la mostra emprada Si es tracta d’un interval de confiança del 95%, la fórmula donada satisfà que el 95% de les vegades que l’aplicam a una mostra aleatòria simple dóna un interval que conté la variància mostral de la mostra. Si canviam de mostra, però mantenim la mida de la mostra i el nivell de confiança, l’interval és més ample com més gran sigui la variància mostral de la mostra Si no canviam de mostra i augmentam el nivell de confiança, disminueix la seva amplada. Si dues mostres són de la mateixa mida i tenen la mateixa variància mostral, donen lloc al mateix interval de confiança del 95% per a la variància poblacional Si dues mostres tenen la mateixa variància mostral, donen lloc al mateix interval de confiança del 95% per a la variància poblacional encara que siguin de mides diferents () Volem estimar el nivell mitjà de potassi en sang en un poble de Mallorca, mesurant-lo sobre una mostra aleatòria d’habitants del poble. L’exactitud de l’estimació pot dependre de (marcau totes les respostes correctes): El valor real del nivell mitjà de potassi en sang en el poble objecte d’estudi. El nombre d’habitants del poble. La mida de la mostra. La variància del nivell de potassi en sang en aquest poble. Cap de les altres respostes és correcta. () Prenem una mostra aleatòria simple de mida 50 d’una variable aleatòria. Calculam un interval de confiança del 90% per a la \\(\\mu\\) de la variable aleatòria a partir d’aquesta mostra, i dóna [11.8,12.8]. Què podem deduir d’aquest fet? Que el 90% dels valors de la variable poblacional estan dins l’interval [11.8,12.8]. Que el 90% de les mostra aleatòria simple de mida 50 tindran la seva mitjana mostral dins l’interval [11.8,12.8]. Que el 90% de les mostra aleatòria simple de qualsevol mida tindran la seva mitjana mostral dins l’interval [11.8,12.8]. Que l’interval [11.8,12.8] conté el vertader valor de \\(\\mu\\). Que el vertader valor de \\(\\mu\\) serà, amb probabilitat 0.9, o bé 11.8 o bé 12.8. Cap de les respostes anteriors és correcta. () En una mostra aleatòria d’individus d’una comunitat s’ha obtingut una valor mitjà de la tensió arterial diastólica (TAD) de 85 mmHg, amb un error estàndard de 2.5 mmHg. Quines de les afirmacions següents són vertaderes? El 95% dels subjectes de la mostra tenien valors de TAD entre 80 i 90 mmHg. El 90% dels subjectes de la mostra tenien valors de TAD entre 82.5 i 87.5 mmHg. Es té un 95% de confiança que l’interval 80-90 mmHg inclourà el valor mitjà vertader de la TAD de la comunitat. Es té un 90% de confiança que l’interval 82.5-87.5 mmHg inclogui el valor mitjà vertader de la TAD de la comunitat. Com que la mostra és aleatòria, el valor mitjà vertader de la TAD en la comunitat és de 85 mmHg. () Per calcular un interval de confiança al 95% per al valor mitjà \\(\\mu\\) d’una certa variable, hem pres una mostra aleatòria simple de mida 100. Si, amb la mateixa mostra, calculàssim un interval de confiança del 99% per a \\(\\mu\\), com seria aquest interval? Més ample que l’anterior Més estret que l’anterior Pot passar qualsevol cosa () Per calcular un interval de confiança al 95% per el valor mitjà d’una certa variable, havíem decidit prendre una mostra aleatòria simple de mida 200, però resulta massa costós, i hem decidit reduir la mida a 100. Té aquesta decisió qualque efecte sobre l’amplada de l’interval de confiança? Amb 100 l’interval de confiança serà més ample que amb 200 Amb 100 l’interval de confiança serà més estret que amb 200 Com que el nivell de confiança és el mateix, els intervals de confiança tendran la mateixa amplada Pot passar qualsevol cosa () Calculam un interval de confiança al 95% per a la mitjana poblacional d’una variable aleatòria, a partir d’una mostra aleatòria simple de 100 individus. Si calculam el mateix interval de confiança amb una altra mostra aleatòria simple de 100 individus que té una variància més gran, quina de les tres coses següents passarà? El segon interval serà més ample El segon interval serà més estret Els dos intervals tendran la mateixa amplada Pot passar qualsevol cosa () Amb la finalitat de disminuir el marge d’error en l’estimació de la mitjana d’una certa v.a. per mitjà de la mitjana aritmètica d’una mostra, el millor que podem fer és (marcau una única resposta): Disminuir la variància de la variable aleatòria. Augmentar el nivell de confiança. Disminuir el nivell de confiança. Augmentar la mida de la mostra. Eliminar els valors dubtosos de la mostra. () Un article d’una revista científica informa que l’interval de confiança al 95% del nivell mitjà de colesterol en sang en els adults d’una certa població és 192-208. Es va acceptar que la variable tenia una distribució normal, per la qual cosa s’emprà la fórmula basada en la t de Student, i la mostra que s’usà per calcular aquest interval de confiança va ser de 100 individus. Quines de les següents afirmacions són vertaderes? És molt probable que el nivell mitjà poblacional estigui comprès entre 192 i 208. Si se repetís l’estudi molts pics, en un 95% de les vegades s’obtindria una mitjana mostral compresa entre 192 i 208. El 95% dels adults de la població té un nivell de colesterol comprès entre 192 i 208. La mitjana mostral trobada en l’estudi és de 200. La desviació típica mostral trobada en l’estudi ha estat aproximadament 40 o 41. () Estam planejant fer un assaig clínic per estudiar l’eficàcia d’un nou tipus de medicament per al tractament de la hipercolesterolèmia (colesterol alt). Volem estimar la reducció mitjana del nivell de colesterol en plasma als 15 dies de començar a prendre el medicament. Quines de les dades següents NO són útils per calcular la mida de la mostra de pacients als quals administrarem el nou medicament per estimar-la? Marcau totes la respostes correctes. La reducció mitjana del nivell de colesterol en plasma als 15 dies obtinguda en una petita prova pilot prèvia, que va ser de 8 mg/dl. La desviació típica en la reducció del nivell de colesterol en plasma als 15 dies obtinguda en una petita prova pilot prèvia, que va ser d’1.2 mg/dl. El nivell de confiança, que fixarem en un 5%. La proporció esperada de pacients que no completaran l’estudi, que en altres estudis similars de la literatura ha estat d’un 10%. L’error màxim que ens volem permetre en l’estimació de la reducció mitjana del nivell de colesterol en plasma, que fixarem en 1 mg/dl. () Prenem una mostra aleatòria de 200 residents de Santa Margalida (població, 12000 habitants) per calcular un interval de confiança de la proporció dels margalidans que presenten una determinada condició. Quines de les afirmacions següents són vertaderes? Marcau totes les respostes vertaderes: Si la mostra és simple, no cal tenir en compte el factor de població finita. Encara que la mostra sigui simple, cal tenir en compte el factor de població finita. Si la mostra no és simple, cal tenir en compte el factor de població finita. Una mostra aleatòria sense repeticions de mida 200 d’una població de mida 12000 sempre podem entendre que és simple, a efectes de calcular intervals de confiança de proporcions. Totes les altres respostes són falses. () Estam planejant fer un assaig clínic per estudiar l’eficàcia d’un nou tipus de medicament per al tractament de la hipercolesterolèmia (colesterol alt). Volem estimar la reducció mitjana del nivell de colesterol en plasma als 15 dies de començar a prendre el medicament. Quines de les dades següents NO són útils per calcular la mida de la mostra de pacients als quals administrarem el nou medicament per estimar-la? Marcau totes la respostes correctes. La reducció mitjana del nivell de colesterol en plasma als 15 dies obtinguda en una petita prova pilot prèvia, que va ser de 8 mg/dl. La desviació típica en la reducció del nivell de colesterol en plasma als 15 dies obtinguda en una petita prova pilot prèvia, que va ser d’1.2 mg/dl. El nivell de confiança, que fixarem en un 5%. La proporció esperada de pacients que no completaran l’estudi, que en altres estudis similars de la literatura ha estat d’un 10%. L’error màxim que ens volem permetre en l’estimació de la reducció mitjana del nivell de colesterol en plasma, que fixarem en 1 mg/dl. () Un investigador vol determinar la proporció d’estudiants de secundària d’una determinada comunitat que consumeixen begudes energètiques passant una enquesta a una mostra d’estudiants. Per calcular la mida mostral que necessita per al seu estudi ja disposa de les dades següents: mida de la població objectiu; percentatge esperat d’estudiants que no contestaran l’enquesta; la precisió amb la qual desitja donar l’estimació de la proporció (5 punts percentuals); el nivell de confiança (95%). Vol calcular aquesta mida nostral en el pitjor dels casos (proporció mostral 0.5). Quines altres dades li falten? (marcau totes les respostes correctes): Saber l’error estàndard de la proporció mostral d’estudiants consumidors de begudes energètiques. Estimar la desviació típica de la proporció de consumidors de begudes energètiques. Conèixer la proporció de consumidors de begudes energètiques en el total de la població de la zona d’interès. Estimar la proporció d’estudiants consumidors de begudes energètiques amb una petita prova pilot. Com que vol calcular l’interval de confiança en el pitjor dels casos, ja no li fa falta cap altra dada. "]
]
