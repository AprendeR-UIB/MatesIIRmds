[
["index.html", "Matemàtiques II Presentació", " Matemàtiques II 2020-05-04 Presentació Això és una edició en línea dels apunts de Matemàtiques II dels graus de Biologia i Bioquímica de la UIB. Aquests apunts no són autocontinguts pel que fa al R: suposam que l’estudiant va llegint les lliçons de R corresponents a cada tema a la 2a part del manual AprendeR. Aquests apunts estan en construcció. A la llista següent hi anirem anunciant les actualitzacions. 24-03-2020: Pujats temes 7 i 8 19-03-2020: Pujat tema 6 07-03-2020: Pujat tema 5 i corregits alguns errors irrellevants al tema 4 02-03-2020: Afegits dos exemples a la Secció 2.7 24-02-2020: Pujat tema 4 i corregits alguns errors irrellevants als temes anteriors 17-02-2020: Pujats temes 1, 2 i 3 Significats d’algunes capses: Material molt important. Alerta! Exercici. Detalls matemàtics que us poden interessar, però que no cal saber. Comentari que volem emfatitzar. Comentari que volem que recordeu. Qüestió en què volem que caigueu. Acabam de matar un moixet. El llibre està escrit en R Markdown, emprant RStudio com a editor de textos i el paquet bookdown per convertir els fitxers markdown en un llibre Aquest treball se publica sota llicència Atribució-No Comercial-SenseDerivats 4.0 "],
["repàs-de-la-distribució-normal.html", "Tema 1 Repàs de la distribució normal 1.1 Propietats de la distribució normal 1.2 Amb R 1.3 Combinacions lineals 1.4 Intervals de referència 1.5 El z-score", " Tema 1 Repàs de la distribució normal 1.1 Propietats de la distribució normal Una variable aleatòria contínua \\(X\\) és normal de paràmetres \\(\\mu\\) i \\(\\sigma\\), i ho indicarem escrivint \\(X\\sim N(\\mu,\\sigma)\\), quan la seva funció de densitat és Naturalment, no cal saber aquesta fórmula. El que cal saber és que: Una variable aleatòria normal \\(X\\) és contínua, i per tant \\(P(X=x)=0\\), \\(P(X\\leqslant x)=P(X&lt;x)\\) etc. Si \\(X\\sim N(\\mu,\\sigma)\\), aleshores el seu valor esperat és \\(E(X)=\\mu\\) i la seva desviació típica és \\(\\sigma_X=\\sigma\\) Una variable aleatòria normal és típica (o estàndard) quan \\(\\mu=0\\) i \\(\\sigma=1\\); la indicarem usualment amb \\(Z\\). Per tant, si \\(Z\\sim N(0,1)\\), \\(E(Z)=0\\) i \\(\\sigma_Z=1\\). La gràfica de la densitat d’una variable aleatòria normal és la famosa campana de Gauss: La gràfica de la densitat d’una variable aleatòria normal és també la menys famosa gràfica del capell del gendarme: La distribució normal és una distribució teòrica, no la trobareu exacta en la pràctica. I malgrat el seu nom, no és més “normal” que les altres distribucions que estudiarem. La distribució normal és important perquè aproxima bé moltes distribucions reals, perquè: Moltes variables aleatòries que consisteixen a prendre \\(n\\) observacions independents d’una o diverses variables aleatòries i sumar-les, tenen distribució aproximadament normal quan \\(n\\) és gran, encara que les variables aleatòries de partida no ho siguin. Per exemple: Si \\(X\\) és una variable aleatòria binomial B(n,p), amb \\(n\\) gran, alehores \\(X\\) és aproximadament \\(N(np,\\sqrt{np(1-p)})\\), en el sentit que les dues funcions de densitat (salvant la diferència pel fet que la binomial és discreta i la normal contínua) són semblants: Si \\(X\\) és una variable aleatòria de Poisson \\(Po(\\lambda)\\) i \\(\\lambda\\) és gran, aleshores \\(X\\) és aproximadament \\(N(\\lambda,\\sqrt{\\lambda})\\) Quan s’aproxima una variable binomial o Poisson \\(X\\) per mitjà d’una variable normal \\(Y\\), és convenient aplicar l’anomenada correcció de continuïtat: per a cada \\(n\\in \\mathbb{N}\\), interpretar \\(P(X\\leqslant n)\\) com \\(P(X&lt; n+1/2)\\) i aleshores aproximar: \\(P(X\\leqslant n)\\) per mitjà de \\(P(Y&lt; n+1/2)\\) \\(P(X=n)\\) per mitjà de \\(P(n-1/2&lt; Y&lt; n+1/2)\\) Vegeu l’Exemple 1.1 a la propera secció. Una de les propietats clau de la distribució normal és la seva simetria: Si \\(X\\sim N(\\mu,\\sigma)\\), la seva densitat \\(f_X\\) és simètrica respecte de \\(x=\\mu\\), és a dir, \\[ f_{X}(\\mu-x)=f_{X}(\\mu+x), \\] i té el màxim en \\(x=\\mu\\). Diem aleshores que \\(\\mu\\) és la moda de \\(X\\). Recordem que no té sentit definir la moda d’una variable contínua \\(X\\) com el valor \\(x_0\\) tal que \\(P(X=x_0)\\) sigui màxim, perquè \\(P(X=x)=0\\) per a tot \\(x\\in \\mathbb{R}\\). Es defineix llavors la moda d’una variable contínua \\(X\\) com el valor (o els valors) \\(x_0\\) tal(s) que \\(f_X(x_0)\\) és màxim. En particular, si \\(Z\\sim N(0,1)\\), llavors \\(f_{Z}\\) és simètrica al voltant de \\(x=0\\), és a dir, \\(f_{Z}(-x)=f_{Z}(x)\\), i la moda de \\(Z\\) és 0. Si la \\(\\mu\\) creix, el màxim es desplaça a la dreta, i amb ell tota la corba de manera rígida. Si la \\(\\sigma\\) creix, la corba s’aplata: en augmentar la desviació típica, els valors s’allunyen més del valor mitjà. Vegem l’efecte combinat: Recordem que la funció de distribució d’una variable aleatòria contínua \\(X\\) \\[ F_X(x)=P(X\\leqslant x) \\] és l’àrea compresa entre la corba definida per la densitat \\(y=f_X(x)\\) i l’eix d’abscisses a l’esquerra de \\(x\\). La simetria de \\(f_X\\) fa que les àrees a l’esquerra de \\(\\mu-x\\) i a la dreta de \\(\\mu+x\\) siguin iguals. És a dir, \\[ P(X\\leqslant\\mu-x) = P(X\\geqslant\\mu+x)=1-P(X\\leqslant\\mu+x) \\] En particular (prenent \\(x=0\\)) \\[ P(X\\leqslant\\mu)=1-P(X\\leqslant\\mu)\\Rightarrow P(X\\leqslant\\mu)=0.5, \\] i per tant \\(\\mu\\) és també la mediana de \\(X\\). Si \\(X\\sim N(\\mu,\\sigma)\\), \\(\\mu\\) és la moda, la mitjana, o esperança, i la mediana de \\(X\\). En particular, si \\(Z\\sim N(0,1)\\), les àrees a l’esquerra de \\(-z\\) i a la dreta de \\(z\\) són iguals, \\[ P(Z\\leqslant-z)=P(Z\\geqslant z)=1-P(Z\\leqslant z), \\] i la mediana de \\(Z\\) és 0. Indicarem amb \\(z_q\\) el \\(q\\)-quantil d’una variable normal estàndard \\(Z\\). És a dir, \\(z_q\\) és el valor tal que \\(P(Z\\leqslant z_q)=q\\). A banda del fet que \\(z_{0.5}=0\\) (la mediana de \\(Z\\) és 0), hi ha dos quantils més de la normal estándard que heu de saber “de memòria”: \\(z_{0.95}=1.64\\); és a dir, \\(P(Z\\leqslant 1.64)=0.95\\) i per tant \\(P(Z\\leqslant-1.64)=P(Z\\geqslant 1.64)=0.05\\). \\(z_{0.975}=1.96\\); és a dir, \\(P(Z\\leqslant 1.96)=0.975\\) i per tant \\(P(Z\\leqslant-1.96)=P(Z\\leqslant 1.96)=0.025\\) Molt sovint el valor 1.96 de \\(z_{0.975}\\) s’aproxima per 2. Teniu permís per fer-ho quan no disposeu de mitjans (R, aplis de mòbil) per calcular quantils. 1.2 Amb R Per calcular probabilitats d’una variable normal emprant R, heu de recordar que la normal és norm. Per tant, si \\(X\\sim N(\\mu,\\sigma)\\): dnorm(x,mu,sigma) dóna el valor de la densitat \\(f_X(x)\\) pnorm(x,mu,sigma) dóna el valor de la distribució \\(F_X(x)=P(X\\leqslant x)\\); afegint-hi el paràmetre lower.tail=FALSE dóna el valor de \\(P(X&gt;x)\\) qnorm(q,mu,sigma) dóna el \\(q\\)-quantil de \\(X\\) rnorm(N,mu,sigma) dóna un vector de \\(n\\) nombres aleatoris generats amb aquesta distribució A la normal estàndard no és necessari entrar-hi \\(\\mu=0\\) i \\(\\sigma=1\\), són els valors per defecte d’aquests paràmetres. Vegem-ne alguns exemples: Si \\(X\\sim N(3,0.5)\\), què val \\(P(X\\leqslant 2)\\)? pnorm(2,3,0.5) ## [1] 0.02275013 Si \\(X\\sim N(-2,0.3)\\), què val \\(P(X\\geqslant-1.8)\\)? 1-pnorm(-1.8,-2,0.3) ## [1] 0.2524925 pnorm(-1.8,-2,0.3,lower.tail=FALSE) ## [1] 0.2524925 Si \\(X\\sim N(0,1)\\), què val \\(P(-1\\leqslant X\\leqslant 1)\\)? Com que \\(P(-1\\leqslant X\\leqslant 1)=P(X\\leqslant 1)-P(X\\leqslant-1)\\), pnorm(1)-pnorm(-1) ## [1] 0.6826895 Què val el primer quartil d’una variable \\(N(3,0.5)\\)? qnorm(0.25,3,0.5) ## [1] 2.662755 Comprovau els valors de \\(z_{0.95}\\) i \\(z_{0.975}\\) donats al final de la secció anterior. Exemple 1.1 A la secció anterior, us hem dit que una variable binomial \\(B(n,p)\\) amb \\(n\\) gran s’aproxima per mitjà d’una variable normal \\(N(np,\\sqrt{np(1-p)})\\). Així, per exemple, una variable \\(X\\sim B(400,0.2)\\) s’aproxima per mitjà d’una variable \\(Y\\sim N(400\\cdot 0.2,\\sqrt{400\\cdot 0.2\\cdot 0.8})=N(80,8)\\). Vegem amb alguns exemples que aquesta aproximació és millor aplicant-hi la correcció de continuïtat: \\(P(X\\leqslant 70)\\): pbinom(70,400,0.2) ## [1] 0.1163917 \\(P(Y&lt; 70+1/2)\\): pnorm(70.5,80,8) ## [1] 0.1175152 \\(P(Y\\leqslant 70)\\): pnorm(70,80,8) ## [1] 0.1056498 \\(P(X=70)\\): dbinom(70,400,0.2) ## [1] 0.02338443 \\(P(70-1/2&lt; Y&lt; 70+1/2)\\): pnorm(70.5,80,8)-pnorm(69.5,80,8) ## [1] 0.02283949 \\(P(Y=70)\\): dnorm(70,80,8) ## [1] 0.02283114 NO! dnorm(70,80,8) és la funció de densitat de \\(Y\\) (la fórmula que hem censurat al començament d’aquest tema) aplicada a 70, i no és igual a la probabilitat que \\(Y\\) valgui 70. Recordau que \\(P(Y=70)=0\\) perquè \\(Y\\) és contínua. 1.3 Combinacions lineals El resultat següent descriu el comportament de la mitjana i la variància d’una combinació lineal de variables aleatòries: Teorema 1.1 Siguin \\(Y_1,\\ldots,Y_n\\) variables aleatòries, cada \\(Y_i\\) de mitjana \\(\\mu_i\\) i variància \\(\\sigma_i^2\\), i siguin \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\). Sigui \\(Y\\) la variable aleatòria \\[ Y=a_1Y_1+\\cdots+a_nY_n+b. \\] Aleshores La mitjana de \\(Y\\) és \\[ \\mu_Y=a_1\\mu_1+\\cdots+a_n\\mu_n+b. \\] Si \\(Y_1,\\ldots,Y_n\\) són independents, aleshores la variància de \\(Y\\) és \\[ \\sigma_Y^2=a_1^2\\sigma_1^2+\\cdots+a_n^2\\sigma_n^2 \\] i per tant la seva desviació típica és \\[ \\sigma_Y=\\sqrt{a_1^2\\sigma_1^2+\\cdots+a_n^2\\sigma_n^2}. \\] Una altra propietat destacada de la distribució normal és que tota combinació lineal de variables aleatòries normals independents torna a ser normal: Teorema 1.2 Si \\(Y_1,\\ldots,Y_n\\) son variables aleatòries normals independents, cada \\(Y_i\\sim N(\\mu_i,\\sigma_i)\\), i \\(a_1,\\ldots,a_n,b\\in \\mathbb{R}\\), aleshores \\[ Y=a_1Y_1+\\cdots+a_nY_n+b \\] és una variable aleatòria \\(N(\\mu,\\sigma)\\) amb \\(\\mu\\) i \\(\\sigma\\) els que toquin pel teorema anterior: \\(\\mu=a_1\\mu_1+\\cdots+a_n\\mu_n+b\\) \\(\\sigma=\\sqrt{a_1^2\\sigma_1^2+\\cdots+a_n^2\\sigma_n^2}\\) Com a cas particular, obtenim que una transformació afí d’una variable aleatòria normal torna a ser normal: Teorema 1.3 Si \\(X\\sim N(\\mu,\\sigma)\\) i \\(a,b\\in \\mathbb{R}\\), llavors \\(aX+b\\) també és normal, i en concret és \\(N(a\\mu+b,|a|\\cdot\\sigma)\\). En particular, si \\(X\\sim N(\\mu,\\sigma)\\), llavors la seva tipificada \\[ Z=\\dfrac{X-\\mu}{\\sigma} \\] és \\(N(0,1)\\). Les probabilitats de la normal tipificada determinen les de la normal original, perquè si \\(X\\sim N(\\mu,\\sigma)\\), \\[ \\begin{array}{rl} P(a\\leqslant X\\leqslant b) &amp; \\displaystyle =P\\Big( \\frac{a-\\mu}{\\sigma}\\leqslant\\frac{X-\\mu}{\\sigma}\\leqslant\\frac{b-\\mu}{\\sigma}\\Big)\\\\ &amp; \\displaystyle =P\\Big(\\frac{a-\\mu}{\\sigma}\\leqslant Z\\leqslant\\frac{b-\\mu}{\\sigma}\\Big) \\end{array} \\] Que tota combinació lineal de variables normals torni a ser del mateix tipus, és a dir, normal, és una propietat molt útil de les variables normals que pocs altres tipus de variables aleatòries tenen. Per exemple, si \\(X\\) és una variable binomial \\(B(n,p)\\) amb \\(p\\neq 0\\), \\(2X\\) no és cap variable binomial, perquè només pren valors parells i una variable binomial \\(B(m,q)\\) pot prendre tots els valors entre 0 i \\(m\\). 1.4 Intervals de referència Un interval de referència del \\(100q\\%\\) per a una variable aleatòria \\(X\\) és un interval \\([a,b]\\) tal que \\[ P(a\\leqslant X\\leqslant b)=q. \\] És a dir, un interval de referència del \\(100q\\%\\) per a \\(X\\) és un interval que conté els valors de \\(X\\) del \\(100q\\%\\) de subjectes de la població on està definida. Els més comuns són els intervals de referència del 95% (\\(q=0.95\\)), que satisfan que \\[ P(a\\leqslant X\\leqslant b)=0.95 \\] i són els, que per exemple, us donen com a valors de referència a les analítiques: Quan es parla d’un interval de referència sense donar-ne la probabilitat, se sobreentén sempre que és l’interval de referència del 95%. Quan \\(X\\sim N(\\mu,\\sigma)\\), aquests intervals de referència es prenen sempre centrats en la mitjana \\(\\mu\\), és a dir, de la forma \\([\\mu-x,\\mu+x]\\). Per calcular-los fàcilment, podem emprar el resultat següent: Teorema 1.4 Si \\(X\\sim N(\\mu,\\sigma)\\), un interval de referència del \\(100q\\%\\) és \\[ [\\mu- z_{(1+q)/2}\\cdot \\sigma, \\mu+ z_{(1+q)/2}\\cdot \\sigma] \\] on \\(z_{(1+q)/2}\\) indica el \\((1+q)/2\\)-quantil de \\(Z\\sim N(0,1)\\). L’escriurem \\[ \\mu\\pm z_{(1+q)/2}\\cdot \\sigma. \\] En efecte: \\[ \\begin{array}{l} P(\\mu-x\\leqslant X\\leqslant\\mu+x)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P\\Big(\\frac{\\mu-x-\\mu}{\\sigma}\\leqslant\\frac{X-\\mu}{\\sigma}\\leqslant\\frac{\\mu+x-\\mu}{\\sigma}\\Big)=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(-x/{\\sigma}\\leqslant Z\\leqslant{x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant{x}/{\\sigma})-P(Z\\leqslant-{x}/{\\sigma})=q\\\\ \\qquad \\Longleftrightarrow \\displaystyle P(Z\\leqslant{x}/{\\sigma})-(1-P(Z\\leqslant{x}/{\\sigma}))=q\\\\ \\qquad \\mbox{(per la simetria de $f_Z$ al voltant de 0)}\\\\ \\qquad \\Longleftrightarrow \\displaystyle 2P(Z\\leqslant{x}/{\\sigma})=q+1\\\\ \\qquad \\Longleftrightarrow P(Z\\leqslant{x}/{\\sigma})=(1+q)/2\\\\ \\qquad \\Longleftrightarrow x/\\sigma= z_{(1+q)/2}\\\\ \\qquad \\Longleftrightarrow x=z_{(1+q)/2}\\cdot \\sigma \\end{array} \\] En particular, com que si \\(q=0.95\\), aleshores \\((1+q)/2=0.975\\) i llavors \\(z_{0.975}=1.96\\), i això sovint s’aproxima per 2, l’interval de referència del 95% per a \\(X\\sim N(\\mu,\\sigma)\\) és \\[ \\mu\\pm 1.96\\sigma \\] o simplement, per simplificar, \\[ \\mu\\pm 2\\sigma. \\] Això diu, bàsicament, que si una població segueix una distribució normal \\(N(\\mu,\\sigma)\\), un 95% dels seus individus tenen el seu valor de \\(X\\) a distància como a màxim \\(2\\sigma\\) (“a dues sigmes”) de \\(\\mu\\). Exemple 1.2 Segons l’OMS, les alçades de les dones europees de 18 anys segueixen una llei \\(N(163.1,18.53)\\). Vull trobar un interval d’alçades centrat en la mitjana que contengui les de la meitat de les europees de 18 anys. És, a dir, vull trobar l’interval de referència del 50% per a la variable aleatòria \\(X\\) definida per les alçades de les dones europees de 18 anys. Com que \\(X\\sim N(163.1,18.53)\\) i si \\(q=0.5\\), aleshores \\((1+q)/2=0.75\\), aquest interval és 163.1+qnorm(0.75)*18.53*c(-1,1) ## [1] 150.6017 175.5983 Arrodonint a cm, és l’interval [151, 176]. Per tant, la meitat de les dones europees de 18 anys fan entre 1.51 m i 1.76 m d’alçada. Exemple 1.3 Quin és l’interval de referència per a les alçades de les dones europees de 18 anys? Com que sobreentenem que es tracta de l’interval de referència del 95%, és \\[ 163.1\\pm 1.96\\times 18.53\\Longrightarrow [127, 199] \\] 1.5 El z-score El z-score (o valor z, puntuació z) d’un valor \\(x_0\\) respecte d’una distribució \\(N(\\mu,\\sigma)\\) és \\[ \\frac{x_0-\\mu}{\\sigma}. \\] És a dir, el z-score de \\(x_0\\) és el resultat de “tipificar” \\(x_0\\) en el sentit del Teorema 1.3. Si la variable poblacional és normal, com més gran és el valor absolut del z-score de \\(x_0\\), més “rar” és \\(x_0\\); el signe ens diu si és més gran o més petit que el valor esperat \\(\\mu\\). Exemple 1.4 Recordau que, segons l’OMS, les altures de les dones europees de 18 anys segueixen una llei \\(N(163.1,18.53)\\). Quin és el z-score d’una jugadora de bàsket de 18 anys que faci 191 cm? Serà: \\[ \\frac{191-163.1}{18.53}=1.5 \\] Això normalment es llegeix dient que aquesta alçada “està a 1.5 sigmes de l’alçada mitjana.” "],
["estimació-puntual.html", "Tema 2 Estimació puntual 2.1 Definicions bàsiques 2.2 Mitjana mostral 2.3 Proporció mostral 2.4 Variància mostral 2.5 La t de Student 2.6 “Bons” estimadors 2.7 Estimació de poblacions", " Tema 2 Estimació puntual L’objectiu principal de la inferència estadística és intentar obtenir informació sobre tota una població a partir de només una mostra, com quan volem saber si un brou és fat o salat tastant-ne només una culleradeta. El primer tipus d’informació que ens sol interessar és el valor concret d’alguna característica numèrica (una proporció, una mitjana…) d’una població, per exemple per poder escriure un titular com el següent: Figura 2.1: https://www.efesalud.com/miopia-estudio-universitarios Aquest 60% no s’ha obtingut fent passar a tots els universitaris espanyols un test de miopia, ni tan sols demanant-los a tots si són miops o no, sinó que simplement s’ha pres una mostra d’universitaris, s’hi ha observat un 60% de miops i s’ha extrapolat aquesta proporció a tot el col·lectiu d’universitaris espanyols. El procés d’intentar endevinar el valor d’un paràmetre d’una població a partir d’una mostra se’n diu estimació puntual, i és el que tractarem en aquest tema. Al tema següent ens centrarem en intentar endevinar el valor d’un paràmetre amb un cert marge d’error i de seguretat. 2.1 Definicions bàsiques Una població és un conjunt d’individus o objectes sobre el que volem obtenir informació. Una mostra de mida \\(n\\) d’una població és simplement un conjunt de \\(n\\) individus (possiblement repetits) de la població. Una població inclou tots els membres d’un grup específic d’individus sobre els que volem saber qualque cosa, mentre que una mostra està formada per alguns membres de la població, els que mesuram al nostre estudi. Una mostra aleatòria simple de mida \\(n\\) d’una població s’obté repetint \\(n\\) vegades, cada una de manera independent de les altres, el procés d’escollir equiprobablement un individu de la població; els individus triats es poden repetir. D’aquesta manera, totes les mostres possibles de \\(n\\) individus (possiblement repetits: en diem multiconjunts) tenen la mateixa probabilitat d’obtenir-se. Un estimador (puntual) o estadístic és una funció que aplicada a una mostra d’una població dóna un valor que ens permet estimar alguna cosa que vulguem saber de tota la població. Figura 2.2: Població versus mostra Exemple 2.1 Si escollim 30 estudiants de la UIB a l’atzar (mitjançant una sorteig a partir d’un llistat de tots els estudiants de la UIB), un rere l’altre i permetent que es repeteixin, i mesuram les seves alçades, obtenim una mostra aleatòria simple de mida 30 d’alçades de la població formada pels estudiants de la UIB. Si llavors calculam la mitjana aritmètica d’aquestes alçades amb l’objectiu d’estimar la mitjana de les alçades de tots els estudiants de la UIB, aquesta mitjana és el valor sobre aquesta mostra de l’estimador que anomenarem “mitjana mostral”. Per què prenem una mostra, en lloc d’estudiar directament la població? Doncs perquè sovint és impossible accedir a tota la població: La població pot ser massa gran: per exemple, si volem calcular l’alçada mitjana dels europeus que avui tenen 18 anys, és pràcticament impossible midar-los tots. La població pot ser virtual en el sentit que pot contenir membres que en aquest moment ni existeixin: per exemple, si volem saber qualque cosa sobre els diabètics, això hauria d’incloure els passats, que ja són morts, els presents, que n’hi haurà molts que ni saben que ho són, i els futurs, que encara no ho són o per ventura no hagin ni nascut. Simplement, pot ser difícil accedir a tota la població: per exemple, els estudiants de la UIB són relativament pocs, uns 12000, però seria molt difícil aconseguir midar-los tots. I tanmateix, per provar si el brou ha quedat fat, en provau una cullerada (una mostra), no us bebeu tota l’olla (la població), no? Si basta una mostra per als nostres propòsits, no cal esforçar-se en accedir a tota la població. Formalment: Una població és un conjunt on està definida una variable aleatòria (poblacional) \\(X\\). Una mostra aleatòria simple de mida \\(n\\) de la variable aleatòria \\(X\\) és un vector \\((X_1,\\ldots,X_n)\\) format per \\(n\\) còpies independents de \\(X\\). Una realització de la mostra aleatòria simple \\((X_1,\\ldots,X_n)\\) és un vector \\((x_1,\\ldots,x_n)\\) de valors presos per aquestes variables aleatòries. Un estimador és una variable aleatòria \\(f(X_1,\\ldots,X_n)\\) obtinguda aplicant una funció \\(f\\) a una mostra aleatòria simple \\(X_1,\\ldots,X_n\\). Aquest estimador s’aplica a les realitzacions de la mostra i dóna nombres reals. Com que és una variable aleatòria, té distribució (en diem la distribució mostral de l’estimador), esperança, desviació típica (en diem l’error estàndard, o típic, de l’estimador), etc. Exemple 2.2 Podem formalitzar l’Exemple 2.1 de la manera següent: Població: El conjunt dels estudiants de la UIB Variable aleatòria poblacional \\(X\\): Prenem un estudiant de la UIB i midam la seva alçada Mostra aleatòria simple de mida 30: Un vector \\((X_1,\\ldots,X_{30})\\) format per 30 còpies independents de \\(X\\) Una realització d’aquesta mostra aleatòria simple: Un vector \\((x_1,\\ldots,x_{30})\\) obtingut repetint 30 vegades, de manera independent cada una de les altres, el procés d’escollir un estudiant de la UIB i midar-li l’alçada Estimador: La mitjana aritmètica que farem servir sobre aquesta mostra és \\[ \\overline{X}=\\frac{X_1+\\cdots+X_{30}}{30} \\] Això és una variable aleatòria. Sobre la realització concreta obtinguda pren el valor \\[ \\overline{x}=\\frac{x_1+\\cdots+x_{30}}{30} \\] A partir d’ara, quan no hi hagi necessitat de filar prim, cometrem l’abús de llenguatge de dir mostra aleatòria simple tant al vector de variables aleatòries \\((X_1,\\ldots,X_n)\\) com a una realització \\((x_1,\\ldots,x_n)\\in \\mathbb{R}^n\\); i hi ometrem els parèntesis. A la vida real, les mostres aleatòries se solen prendre prohibint les repeticions (sense reposició). No són mostres aleatòries simples, però la situació encara pot tenir salvació. Si la mida \\(N\\) de la població és MOLT més gran que la mida \\(n\\) de la mostra, els resultats per a mostres aleatòries simples valen (aproximadament) per a mostres aleatòries sense reposició, perquè les variables aleatòries que formen la mostra sense reposició són gairebé idèntiques i independents i les repeticions són improbables. Exemple 2.3 Imaginau que teniu una població de 106 individus i en voleu extreure una mostra aleatòria de 10. Si la treieu escollint els individus un a un a l’atzar sense repeticions, la probabilitat a cada moment d’escollir un individu concret dels que quedin és gairebé la mateixa que si permetéssiu repeticions. Per exemple, quan ja portau 9 individus escollits, la probabilitat de triar un individu concret dels que queden és 1/999991=10-6+9·10-12, mentre que si permeteu que surti qualcun dels ja escollits és 1/106=10-6. Observau també que si prenem una mostra aleatòria de 10 individus sense reposició de la nostra població de 106 individus, gairebé és com si hagués estat presa permetent repeticions, perquè per molt que les permetéssim, seria molt improbable que s’hi donàs alguna repetició. Recordau que si una població té \\(N\\) individus, la probabilitat que una mostra aleatòria simple de mida \\(n\\) tingui tots els seus membres diferents és \\[ \\frac{N(N-1)\\cdots (N-n+1)}{N^n}. \\] Per tant, la probabilitat que una mostra aleatòria simple de mida 10 d’una població de mida 106 tengui algun membre repetit és \\[ 1-\\frac{10^6(10^6-1)\\cdots (10^6-9)}{(10^6)^{10}}=0.000045. \\] Molt petita. Per tant, si ens trobam al davant d’una mostra aleatòria de 10 individus d’aquesta població escollida sense permetre repeticions, ens podem creure perfectament que l’hem obtinguda permetent repeticions i que simplement no n’hi ha hagut cap per pur atzar. Ara bé, quan \\(n\\) és relativament gran per comparació amb \\(N\\), ja és mal de creure que una mostra sense repeticions hagi estat escollida permetent-les. Per exemple, si prenem una mostra aleatòria simple (permetent repeticions) de 10 individus d’una població de 100 individus, la probabilitat que escollim qualque individu més d’una vegada és \\[ 1-\\frac{100\\cdot 99\\cdots 91}{100^{10}}=0.37. \\] Més d’una de cada 3 mostres aleatòries simples de 10 individus d’una població de 100 individus contenen qualque repetició, per tant no podem acceptar amb els ulls clucs que si no tenim cap repetició, les hàgim permeses. Exemple 2.4 La UIB té uns 12000 estudiants. El gràfic següent mostra la probabilitat que si prenem una mostra aleatòria simple de \\(n\\) estudiants d’una població de 12000 individus, com ara la UIB, siguin tots diferents, en funció de \\(n\\): f=function(N,i){prod((N:(N-i+1))/N)} prob=sapply(1:200,f,N=1200) plot(1:200, prob, type=&quot;l&quot;, lwd=2, xlab=&quot;n&quot;, ylab=&quot;probabilitat&quot;, xaxp=c(0,200,20),yaxp=c(0,1,10)) El gràfic següent mostra la mida màxima \\(n\\) d’una mostra aleatòria simple extreta d’una població de mida \\(N\\) per que la probabilitat de repeticions sigui menor que 0.05, en funció de \\(N\\): h=function(n){max(which(sapply(1:(n/50),f,N=n)&gt;0.95))} fites=sapply(500+100*(0:150),h) plot(500+100*(0:150), fites, pch=20, xlab=&quot;N&quot;, ylab=&quot;n&quot;, xaxp=c(500,15500,30)) En resum: Si prenem una mostra sense reposició de mida \\(n\\) d’una població de mida \\(N\\) MOLT més gran que n, la tractarem com si fos una mostra aleatòria simple (i direm sense manies que és una mostra aleatòria simple). Per fixar una fita, en aquest curs entendrem que \\(N\\) és prou MOLT més gran que \\(n\\) com per poder aplicar aquesta regla quan \\(N\\) és com a mínim unes 1000 vegades més gran que \\(n\\). A la pràctica, en realitat gairebé mai no disposarem d’una mostra aleatòria. Fixau-vos, per exemple, que per poder obtenir una mostra aleatòria, necessitam una llista de tota la població, per poder sortejar qui cau i qui no cau dins la mostra, i aquesta llista normalment no existeix. Una llista de tots els conills de Mallorca, o de tots els arbres afectats per la Xyllella fastidiosa? Complicat. Així que ens haurem de conformar amb una mostra oportunista (o de conveniència: la que poguem obtenir). Heu de tenir clar que, en principi, els resultats que donarem NO són vàlids per a mostres no aleatòries, però si no tenim res millor… El que es fa aleshores és explicar amb detall com s’ha obtingut la mostra i descriure amb detall les seves característiques, a fi que altres investigadors puguin decidir si els individus “són típics” i podrien passar per una mostra aleatòria, i si poden extrapolar les estimacions al seu context. Per exemple, si per saber l’opinió dels estudiants de Biologia espanyols sobre un tema, ho deman als meus estudiants, serà una mostra clarament oportunista i caldrà llavors esbrinar si podria passar per una mostra aleatòria simple a efectes de l’estudi que vull portar a terme. Els estimadors tenen sempre sentit per a mostres en general, però gairebé tots els teoremes que estableixen les seves propietats són vertaders només sota determinades restriccions (mostra aleatòria simple, condicions extra sobre \\(X\\), …), per la qual cosa les seves conseqüències tan sols són segures sota aquestes restriccions. A la Secció 2.1 de la 2a part dels apunts de R hi explicam alguns altres tipus de mostreig aleatori: estratificat, per conglomerats, sistemàtic… Donau-li una ullada. 2.2 Mitjana mostral La mitjana mostral \\(\\overline{X}\\) d’una mostra aleatòria de mida \\(n\\) d’una variable aleatòria \\(X\\) és simplement la seva mitjana artimètica. Formalment, la mitjana mostral és una variable aleatòria obtinguda prenent \\(n\\) còpies \\(X_1,\\ldots,X_n\\) de la variable aleatòria \\(X\\) i calculant \\[ \\overline{X}=\\frac{X_1+\\cdots+X_n}{n} \\] Com a conseqüència del Teorema 1.1, tenim el següent: Teorema 2.1 Siguin \\(X\\) una variable aleatòria d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\), \\(X_1,\\ldots,X_n\\) una mostra aleatòria de \\(X\\) i \\(\\overline{X}\\) la seva mitjana mostral. Aleshores El valor esperat de \\(\\overline{X}\\) és \\(\\mu_{\\overline{X}}=\\mu_X\\). Si la mostra aleatòria és simple, l’error estàndard o típic de \\(\\overline{X}\\) (la desviació típica de \\(\\overline{X}\\)) és \\(\\sigma_{\\overline{X}}={\\sigma_X}/{\\sqrt{n}}\\). En efecte, com que \\[ \\overline{X}=\\frac{1}{n}X_1+\\cdots +\\frac{1}{n}X_n \\] i les variables \\(X_1,\\ldots,X_n\\) són còpies de \\(X\\), i per tant tenen totes esperança \\(\\mu_X\\) i variància \\(\\sigma^2_X\\), aplicant el Teorema 1.1 tenim que \\[ \\mu_{\\overline{X}}=\\overbrace{\\frac{1}{n}\\mu_X+\\cdots +\\frac{1}{n}\\mu_X}^n=\\mu_X \\] i, si \\(X_1,\\ldots,X_n\\) són independents, \\[ \\sigma_{\\overline{X}}=\\sqrt{\\overbrace{\\frac{1}{n^2}\\sigma^2_X+\\cdots+ \\frac{1}{n^2}\\sigma^2_X}^n}=\\sqrt{\\frac{n}{n^2}\\sigma^2_X}=\\frac{\\sigma_X}{\\sqrt{n}} \\] Per tant: \\(\\overline{X}\\) és un estimador puntual de \\(\\mu_X\\). \\(\\mu_{\\overline{X}}=\\mu_X\\) (esperam que la mitjana mostral doni \\(\\mu_X\\)) significa que si repetíssim moltes vegades el procés de prendre una mostra aleatòria simple de mida \\(n\\) i calcular-ne la mitjana mostral, molt probablement el valor mitjà d’aquestes mitjanes s’acostaria molt a \\(\\mu_X\\). \\(\\sigma_{\\overline{X}}= \\sigma_X/\\sqrt{n}\\) indica que la dispersió dels resultats de \\(\\overline{X}\\) creix amb la variabilitat de \\(X\\) i decreix amb la mida \\(n\\) de la mostra, tendint a 0 quan \\(n\\to\\infty\\). Exemple 2.5 El fitxer tests.txt que trobareu a l’url https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt conté les notes (sobre 100) de tests dels estudiants de Matemàtiques I de fa uns cursos. El guardam en un vector anomenat tests: tests=scan(&quot;https://raw.githubusercontent.com/AprendeR-UIB/MatesII/master/Dades/tests.txt&quot;) head(tests) ## [1] 70 44 90 64 76 68 la mida de la població és N=length(tests) N ## [1] 185 La seva mitjana, que és la mitjana poblacional, és mu=mean(tests) mu ## [1] 55.43243 Si en prenem una mostra aleatòria simple, per exemple de mida \\(n=40\\), la seva mitjana mostral no té per què coincidir amb la mitjana poblacional: n=40 MAS=sample(tests,n,replace=TRUE) # Una mostra aelatòria simple x.barra=mean(MAS) # La mitjana mostral x.barra ## [1] 53.5 Però si prenem moltes mostres aleatòries simples, la mitjana de les seves mitjanes és molt probable que sí que s’acosti a la mitjana poblacional. Vegem si tenim sort: mitjanes=replicate(10^5,mean(sample(tests,n,replace=TRUE))) mean(mitjanes) ## [1] 55.4187 Vegem ara que la desviació típica d’aquesta mostra de mitjanes s’acosta a l’error típic de la mitjana mostral, no a la desviació típica de la població: La desviació típica poblacional: sigma=sd(tests) sigma ## [1] 21.44044 La desviació típica de la mostra de mitjanes: sd(mitjanes) ## [1] 3.384683 L’error típic de la mitjana mostral: sigma/sqrt(n) ## [1] 3.390031 Recordau del Teorema 1.2 que una combinació lineal de variables aleatòries normals independents torna a ser normal. Com que la mitjana mostral d’una mostra aleatòria simple és una combinació lineal de variables aleatòries independents, obtenim el resultat següent: Teorema 2.2 Siguin \\(X\\) una variable aleatòria normal \\(N(\\mu_X,\\sigma_X)\\) i \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de \\(X\\). Aleshores, la seva mitjana mostral \\(\\overline{X}\\) és normal, i en concret \\[ \\overline{X}\\sim N\\Big(\\mu_X,\\frac{\\sigma_X}{\\sqrt{n}}\\Big). \\] El teorema següent diu que la conclusió del teorema anterior és aproximadament vertadera si la mida \\(n\\) de les mostres aleatòries simples és gran: Teorema 2.3 (Teorema Central del Límit) Siguin \\(X\\) una variable aleatòria qualsevol d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\) i \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de \\(X\\). Quan \\(n\\to \\infty\\), la distribució de probabilitats de la seva mitjana mostral \\(\\overline{X}\\) tendeix a la d’una varianle normal \\[ N\\Big(\\mu_X,\\frac{\\sigma_X}{\\sqrt{n}}\\Big). \\] Com us podeu imaginar, quan un resultat l’anomenen Teorema Central de qualque cosa és perquè és molt important. Normalment aplicarem el Teorema Central del Límit de la manera següent: Siguin \\(X\\) una variable aleatòria qualsevol d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\) i \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de \\(X\\). Si la mida \\(n\\) de la mostra és gran, la seva mitjana mostral \\(\\overline{X}\\) és aproximadament normal \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\). En aquest curs, entendrem que \\(n\\) és prou gran com per poder aplicar aquest “resultat” si és més gran o igual que 30, potser menys com més se sembli \\(X\\) a una normal i potser més si la \\(X\\) és molt diferent d’una normal. A partir d’ara, sovint cometrem l’abús de llenguatge d’ometre l’adverbi “aproximadament” de l’expressió anterior, i direm simplement que si \\(n\\) és gran, \\(\\overline{X}\\) és normal. Però hem de recordar que aquest “és normal” en realitat vol dir “la seva distribució és aproximadament la d’una variable normal”. Exemple 2.6 Suposem que tenim una variable aleatòria \\(X\\) de mitjana poblacional \\(\\mu_X=3\\) i desviació típica poblacional \\(\\sigma_X=0.2\\) i que en prenem mostres aleatòries simples de mida 100. Pel Teorema Central del Límit, la distribució de la mitjana mostral \\(\\overline{X}\\) és \\[ N\\Big(3,\\frac{0.2}{\\sqrt{100}}\\Big)=N(3,0.02) \\] Exemple 2.7 Tornem a la situació de l’Exemple 2.5. Teníem les notes guardades en un vector anomenat tests. Amb l’histograma següent podem veure que aquestes notes no tenen pinta de seguir una distribució normal. fact.trans=hist(tests,plot=FALSE)$counts[1]/hist(tests,plot=FALSE)$density[1] hist(tests,col=&quot;light blue&quot;,xlab=&quot;Notes dels tests&quot;, ylab=&quot;Freqüències&quot;,main=&quot;Histograma de notes de tests&quot;) curve(fact.trans*dnorm(x,mean(tests),sd(tests)),col=&quot;red&quot;,lwd=2,add=TRUE) A l’Exemple 2.5 també hem construit un vector anomenat mitjanes format per 105 mitjanes mostrals de mostres aleatòries simples de notes de mida 40. Pel Teorema Central del Límit, aquestes mitjanes mostrals haurien de seguir aproximadament una distribució normal, malgrat que la “població original” (les notes dels tests) no sigui normal. Vegem-ho amb un histograma, on hem afegit la densitat de la normal \\(N(\\mu_X,\\sigma_X/\\sqrt{n})\\) predita pel Teorema Central del Límit. fact.trans.m=hist(mitjanes,plot=FALSE)$counts[1]/hist(mitjanes,plot=FALSE)$density[1] hist(mitjanes,col=&quot;light blue&quot;,xlab=&quot;Mitjanes&quot;, ylab=&quot;Freqüències&quot;,main=&quot;Histograma de la mostra de mitjanes&quot;) curve(fact.trans.m*dnorm(x,mu,sigma/sqrt(n)),col=&quot;red&quot;,lwd=2,add=TRUE) L’exemple següent és un tipus de pregunta que més endavant ens preocuparà molt. Exemple 2.8 L’alçada d’una espècie de matolls té valor mitjà 115 cm, amb una desviació típica de 25 cm. Si prenem una mostra aleatòria simple de 100 matolls d’aquesta espècie, quina és la probabilitat que la mitjana mostral de les alçades sigui més petita que 110 cm? Diguem \\(X\\) a la variable aleatòria definida per les alçades d’aquests matolls. Pel Teorema Central del Límit, la mitjana mostral \\(\\overline{X}\\) de mostres aleatòries simples de 100 alçades segueix una distribució \\(N(115,25/\\sqrt{100})=N(115,2.5)\\). Llavors, la probabilitat que ens demanen és \\[ P(\\overline{X}&lt; 110) \\] que podem calcular amb round(pnorm(110,115,2.5),4) ## [1] 0.0228 Un 2.28% de les mostra aleatòries simples de 100 matolls d’aquesta espècie tenen la mitjana de les alçades més petita que 110 cm. Sigui ara \\(X_1,\\ldots, X_n\\) una mostra aleatòria sense reposició de mida \\(n\\) d’una variable aleatòria \\(X\\) d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\). Si \\(n\\) és molt petit en relació a la mida \\(N\\) de la població, ja hem explicat que podem suposar que aquesta mostra aleatòria és simple i per tant tot funciona com fins ara; en particular, en aquest cas entendrem que els tres teoremes anteriors són vertaders. Si \\(n\\) és gran en relació a \\(N\\), aleshores el resultat per l’esperança segueix essent vertader (al Teorema 2.1.a no suposàvem que la mostra fos simple), i per tant encara tenim que \\[ \\mu_{\\overline{X}}=\\mu_X. \\] Però en aquest cas cal modificar la fórmula del Teorema 2.1.b per a la desviació típica, que ara és: \\[ \\sigma_{\\overline{X}}=\\frac{\\sigma_X}{\\sqrt{n}}\\cdot\\sqrt{\\frac{N-n}{N-1}} \\] A més, en aquest cas les conclusions dels Teoremes 2.2 i 2.3 no són certes, ni tan sols amb aquesta correcció de l’error típic. Al terme \\[ \\sqrt{\\frac{N-n}{N-1}} \\] que apareix a la fórmula anterior li diuen el factor de població finita. Si us en recordau, aquest factor de població finita és el factor que passava de la desviació típica d’una distribució binomial a la d’una hipergeomètrica. En efecte: Si \\(X_B\\sim B(n,p)\\), \\(\\sigma^2_{X_B}=np(1-p)\\) i per tant \\(\\sigma_{X_B}=\\sqrt{np(1-p)}\\) Si \\(X_H\\sim H(A,B,n)\\), amb \\(A+B=N\\) i \\(p=A/N\\), \\[ \\begin{array}{rl} \\sigma^2_{X_H} &amp; \\displaystyle =\\dfrac{nAB}{(A+B)^2}\\cdot\\dfrac{A+B-n}{A+B-1}\\\\ &amp; \\displaystyle =n\\cdot\\frac{A}{N}\\cdot\\frac{N-A}{N}\\cdot\\dfrac{N-n}{N-1}\\\\ &amp; \\displaystyle = np(1-p)\\cdot \\dfrac{N-n}{N-1} \\end{array} \\] i per tant \\[ \\sigma_{X_H}=\\sqrt{np(1-p)}\\cdot \\sqrt{\\dfrac{N-n}{N-1}}=\\sigma_{X_B}\\cdot \\sqrt{\\dfrac{N-n}{N-1}}. \\] Exemple 2.9 Tornem a la situació dels Exemples 2.5 i 2.7. Què passa si prenem les mostres aleatòries de notes de tests sense reposició? Prenguem ara 105 mostres aleatòries sense reposició de 40 notes de tests. mitjanes.norep=replicate(10^5,mean(sample(tests,40))) Un altre cop, la mitjana d’aquest vector de mitjanes hauria de ser propera a la mitjana de la població original, que era 55.43: round(mean(mitjanes.norep),2) ## [1] 55.42 Calculem ara la desviació típica d’aquest vector de mitjanes: round(sd(mitjanes.norep),2) ## [1] 3 Aquesta desviació típica no s’apropa a la desviació típica de la població partida per l’arrel quadrada de la mida de les mostres, que hem calculat abans i era 3.39. Pel que acabam d’explicar, la desviació típica d’aquest vector de mitjanes de mostres sense reposició hauria de ser molt propera a la desviació típica de la població partida per l’arrel quadrada de la mida de les mostres i tot multiplicat pel factor de població finita \\(\\sqrt{(N-n)/(N-1)}\\), on \\(N\\) és la mida de la població, és a dir, la longitud del vector tests, i \\(n\\) la mida de les mostres. Vegem si és veritat: round((sd(tests)/sqrt(n))*sqrt((N-n)/(N-1)),2) ## [1] 3.01 Això ja s’acosta més a la desviació típica del vector de mitjanes de mostres sense reposició, que ha valgut 3. 2.3 Proporció mostral Suposem que ara tenim una variable aleatòria poblacional \\(X\\) que és Bernoulli amb probabilitat d’èxit (o proporció d’èxits) \\(p_X\\). Entendrem que \\(X\\) pren els valors 1 (èxit) o 0 (fracàs). Recordau que \\(E(X)=p_X\\) i \\(\\sigma_X=\\sqrt{p_X(1-p_X)}\\). Sigui \\(X_1,\\ldots,X_n\\) una mostra aleatòria de mida \\(n\\) de \\(X\\) i sigui \\(S_n=\\sum_{i=1}^n X_i\\) el nombre d’èxits observats en aquesta mostra aleatòria. La proporció mostral d’èxits de la nostra mostra és \\[ \\widehat{p}_X=\\frac{S_n}{n}=\\frac{\\sum_{i=1}^n X_i}{n}. \\] Recordau que si prenem mostres aleatòries simples, \\(S_n\\) és una variable aleatòria binomial \\(B(n,p_X)\\). Però és un doi dir que la proporció mostral \\(\\widehat{p}_X\\) és una variable aleatòria binomial, ni que només sigui perquè les variables aleatòries binomials prenen valors nombres naturals i els valors que pot prendre \\(\\widehat{p}_X\\) són fraccions entre 0 i 1. Fixau-vos que \\(\\widehat{p}_X\\) és un cas particular de la mitjana mostral \\(\\overline{X}\\), per tant per a les proporcion mostrals val tot el que hem dit fins ara per a mitjanes mostrals: Teorema 2.4 Si \\(X\\) és una variable aleatòria Bernoulli amb probabilitat d’èxit \\(p_X\\) i \\(X_1,\\ldots,X_n\\) és una mostra aleatòria de mida \\(n\\) de \\(X\\), de proporció mostral \\(\\widehat{p}_X\\), aleshores \\(\\mu_{\\widehat{p}_X}=p_X\\) Si la mostra aleatòria és simple, \\(\\sigma_{\\widehat{p}_X}=\\sqrt{\\dfrac{p_X(1-p_X)}{n}}\\) Si la mostra aleatòria és sense reposició i \\(n\\) és relativament gran per comparació amb la mida de la població \\(N\\), \\[ \\sigma_{\\widehat{p}_X}=\\sqrt{\\frac{p_X(1-p_X)}{n}}\\cdot \\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] Pel Teorema Central del Límit, si la mostra és aleatòria simple i la seva mida \\(n\\) és gran, la distribució de \\(\\widehat{p}_X\\) és aproximadament la d’una variable normal \\[ N\\left({p}_X,\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}\\right) \\] i per tant \\[ \\frac{\\widehat{p}_X-p_X}{\\sqrt{\\frac{{p}_X(1-{p}_X)}{n}}} \\] és aproximadament \\(N(0,1)\\). Alguns comentaris: \\(\\mu_{\\widehat{p}_X}=p_X\\): Si repetíssim moltes vegades el procés de prendre una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria de Bernoulli \\(X\\) i calcular-ne la proporció mostral d’èxits, molt probablement la mitjana d’aquestes proporcions mostrals s’acostaria molt a \\(p_X\\) En particular, \\(\\widehat{p}_X\\) serveix per estimar \\(p_X\\) \\(\\sigma_{\\widehat{p}_X}= \\sqrt{{p_X(1-p_X)}/{n}}\\): la variabilitat dels resultats de \\(\\widehat{p}_X\\) decreix amb \\(n\\) i tendeix a 0 quan \\(n\\to \\infty\\). Pel que fa a la dependència de \\(\\sigma_{\\widehat{p}_X}\\) respecte de \\(p_X\\) si la \\(n\\) és fixada, observau al gràfic següent que \\(\\sqrt{p_X(1-p_X)}\\) creix entre 0 i 0.5 i decreix entre 0.5 i 1, assolint el valor màxim a \\(p_X=0.5\\). curve(sqrt(x*(1-x)),xlab=&quot;p&quot;,ylab=&quot;sqrt(p*(1-p))&quot;,lwd=2) \\(\\sqrt{{p_X(1-p_X)}/{n}}\\) és l’error típic de \\(\\widehat{p}_X\\). L’estimam amb l’error típic de l’estimació \\(\\sqrt{{\\widehat{p}_X(1-\\widehat{p}_X)}/{n}}\\). A partir d’ara, sovint cometrem l’abús de llenguatge d’ometre l’adverbi “aproximadament” de l’apartat (4) del teorema anterior, i direm simplement que si \\(n\\) és gran, \\(\\widehat{p}_X\\) és normal. Però, repetim, hem de recordar que aquest “és normal” en realitat vol dir “la seva distribució és aproximadament la d’una variable normal”. Exemple 2.10 Tornem una altra vegada a la situació dels Exemples 2.5 i 2.7. Vaig a traduir el fitxer de notes de tests en un vector binari: 0 per suspens (haver tret menys de 50) i 1 per aprovat (haver tret 50 o més): # Iniciam totes les notes a 1 aprovs=rep(1,length(tests)) # Posam 0 on la nota del test és suspesa aprovs[which(tests&lt;50)]=0 Aquest vector aprovs el podem entendre com una població de Bernoulli de probabilitat poblacional d’èxit (aprovat) \\(p_X\\). Les proporcions de suspesos i aprovats són: round(prop.table(table(aprovs)),4) ## aprovs ## 0 1 ## 0.4054 0.5946 Per tant, \\(p_X\\) és: p_X=as.numeric(prop.table(table(aprovs))[2]) round(p_X,4) ## [1] 0.5946 Ara n’extreurem 105 mostres aleatòries simples de mida 40, en calcularem les proporcions mostrals d’aprovats i comprovarem si es confirmen les conclusions del teorema anterior. set.seed(100) props.mostrals=replicate(10^5,mean(sample(aprovs,40,rep=TRUE))) La mitjana d’aquest vector de proporcions hauria de ser propera a la proporció poblacional d’aprovats \\(p_X=0.5946\\). round(mean(props.mostrals),4) ## [1] 0.5942 Vegem ara la seva desviació típica: round(sd(props.mostrals),4) ## [1] 0.0774 Pel Teorema 2.4, sabem que això hauria de ser proper a \\(\\sqrt{p_X(1-p_X)/n}\\) round(sqrt(p_X*(1-p_X)/40),4) ## [1] 0.0776 I pel Teorema Central del Límit, aquestes proporcions mostrals haurien de seguir aproximadament una distribució normal $N(p_X,). Vegem-ho amb un histograma: fact.trans.p=hist(props.mostrals,plot=FALSE)$counts[1]/hist(props.mostrals,plot=FALSE)$density[1] hist(props.mostrals,col=&quot;light blue&quot;,xlab=&quot;Proporcions mostrals&quot;, ylab=&quot;Freqüències&quot;,main=&quot;Histograma de la mostra de proporcions&quot;) curve(fact.trans.p*dnorm(x,p_X,sqrt(p_X*(1-p_X)/40)), col=&quot;red&quot;,lwd=2,add=TRUE) I això que la mida de les mostres, 40, no és especialment gran. Exemple 2.11 Un 59.1% dels estudiants de la UIB són dones. Hem pres una mostra més o menys aleatòria de 60 estudiants de la UIB i hi hem trobat 40 dones, un 66.67%. Ens demanam si 40 de 60 és una quantitat raonable de dones en una mostra aleatòria simple d’estudiants de la UIB, o si són moltes (atès que hi esperaríem al voltant d’un 59% de dones). Aquesta pregunta, que serà molt típica d’aquí a pocs temes, la traduïm en la següent pregunta: Si prenem una mostra aleatòria simple de 60 estudiants, quina és la probabilitat que la proporció mostral de dones sigui superior al 66.67%? Una manera senzilla de respondre aquesta pregunta és aprofitar el Teorema Central del Límit, segons el qual la proporció mostral \\(\\widehat{p}_X\\) de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix una distribució aproximadament normal amb \\(\\mu=0.591\\) i \\[ \\sigma=\\sqrt{\\dfrac{0.591(1-0.591)}{60}}=0.0635 \\] Per tant, la probabilitat que \\(\\widehat{p}_X\\geqslant 0.6667\\) és (recordau, aproximadament) round(1-pnorm(0.6667,0.591,0.0635),4) ## [1] 0.1166 Això ens diu que, de mitjana, aproximadament 1 de cada 9 mostres aleatòries simples de 60 estudiants de la UIB conté almenys 40 dones. Naturalment, si tenim R o qualsevol altra manera de calcular probabilitats, també podem fer servir la distribució binomial per calcular aquesta probabilitat, i de fet és més correcte, ja que la probabilitat anterior ha emprat una aproximació de la distribució de \\(\\widehat{p}_X\\) i en canvi sabem que el nombre \\(S_{60}\\) de dones en mostres aleatòries simples de 60 estudiants de la UIB segueix de manera exacta una distribució binomial \\(B(60,0.591)\\). Com que el 66.67% de la pregunta en realitat representa 40 dones, la probabilitat exacta demanada és round(1-pbinom(39,60,0.591),4) ## [1] 0.1441 Recordau que si \\(X\\) és una variable aleatòria discreta que pren valors enters, com ara la binomial, \\(P(X\\geqslant 40)=1-P(X\\leqslant 39)\\). Aquesta probabilitat exacta (exacta, si el 59.1% és el percentatge exacte de dones a la UIB) ens diu que, de mitjana, 1 de cada 7 mostres aleatòries simples de 60 estudiants de la UIB conté almenys 40 dones. 2.4 Variància mostral Sigui \\(X_1,\\ldots, X_n\\) una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria \\(X\\) d’esperança \\(\\mu_X\\) i desviació típica \\(\\sigma_X\\). La variància mostral d’aquesta mostra aleatòria simple és \\[ \\widetilde{S}_{X}^2=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n-1} \\] La seva desviació típica mostral és \\[ \\widetilde{S}_{X}=+\\sqrt{\\widetilde{S}_{X}^2} \\] A més, de tant en tant també farem servir la variància i la desviació típica “a seques”: \\[ \\begin{array}{l} \\displaystyle S^2_{X}=\\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n}=\\frac{(n-1)}{n}\\widetilde{S}^2_{X}\\\\ \\displaystyle S_X=+\\sqrt{S_X^2} \\end{array} \\] La variància (a seques) admet la següent expressió senzilla: \\[ S^2_X=\\frac{\\sum_{i=1}^n X_{i}^2}{n}-\\overline{X}^2 \\] En efecte: \\[ \\begin{array}{l} \\displaystyle \\frac{\\sum_{i=1}^n (X_{i}-\\overline{X})^2}{n}=\\frac{1}{n}\\sum_{i=1}^n (X_{i}^2-2\\overline{X}X_i+\\overline{X}^2)\\\\ \\displaystyle\\qquad = \\frac{1}{n}\\Big(\\sum_{i=1}^n X_{i}^2-2\\overline{X}\\sum_{i=1}^n X_{i}+n\\overline{X}^2\\Big)\\\\ \\displaystyle\\qquad =\\frac{\\sum_{i=1}^n X_{i}^2}{n}-2\\overline{X}\\frac{\\sum_{i=1}^n X_{i}}{n}+\\frac{n\\overline{X}^2}{n}\\\\ \\displaystyle\\qquad =\\frac{\\sum_{i=1}^n X_{i}^2}{n}-2\\overline{X}\\cdot\\overline{X} + \\overline{X}^2=\\frac{\\sum_{i=1}^n X_{i}^2}{n}- \\overline{X}^2 \\end{array} \\] Teorema 2.5 Si \\(X\\) és una variable aleatòria normal de desviació típica \\(\\sigma_X\\) i \\(X_1,\\ldots,X_n\\) és una mostra aleatòria simple de mida \\(n\\) de \\(X\\), amb variància mostral \\(\\widetilde{S}_{X}^2\\), aleshores \\(\\mu_{\\widetilde{S}_{X}^2}=\\sigma_{X}^2\\) i la variable aleatòria \\[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\sigma_{X}^2} \\] té distribució coneguda: \\(\\chi_{n-1}^2\\) (es llegeix khi quadrat amb \\(n-1\\) graus de llibertat). La lletra \\(\\chi\\) en català es diu khi; en castellà, ji; i en anglès, chi, pronunciat xai. De la distribució \\(\\chi_n^2\\), on \\(n\\) són els graus de llibertat, heu de saber que: Per definició, és la distribució de la suma dels quadrats de \\(n\\) variables aleatòries normals estàndard independents. És a dir, si \\(Z_{1},Z_{2},\\ldots, Z_{n}\\sim N(0,1)\\) són independents, la variable \\[ Z_{1}^{2}+Z_{2}^{2}+\\cdots +Z_{n}^{2} \\] té distribució \\(\\chi_n^2\\). La \\(n\\) és un paràmetre del que depèn la seva distribució Amb R és chisq Si \\(X\\) és una variable aleatòria amb distribució \\(\\chi_n^2\\), aleshores \\(\\mu_X=n\\) i \\(\\sigma_X^2=2 n\\) Per a \\(n\\) petits, la distribució d’una \\(\\chi_{n}^2\\) presenta una cua a la dreta, i a mida que \\(n\\) creix, pel Teorema Central del Límit, es va aproximant a una distribució normal \\(N(n,\\sqrt{2n})\\), com podeu veure als gràfics següents curve(dchisq(x,1),col=1,lwd=2,xlim=c(0,20),xlab=&quot;&quot;,ylab=&quot;&quot;,ylim=c(0,0.3),main=&quot;Algunes khi quadrat&quot;) curve(dchisq(x,2),col=2,lwd=2,add=TRUE) curve(dchisq(x,3),col=3,lwd=2,add=TRUE) curve(dchisq(x,4),col=4,lwd=2,add=TRUE) curve(dchisq(x,5),col=5,lwd=2,add=TRUE) curve(dchisq(x,10),col=6,lwd=2,add=TRUE) legend(&quot;topright&quot;,col=1:6,lty=c(1,1), lwd=c(2,2),legend=paste(&quot;n=&quot;,c(1:5,10),sep=&quot;&quot;),cex=0.8) curve(dchisq(x,300),xlim=c(150,450),lwd=2,xlab=&quot;&quot;,ylab=&quot;&quot;,main=&quot;Khi quadrat vs Normal&quot;) curve(dnorm(x,300,sqrt(600)),lwd=2,col=&quot;red&quot;,add=TRUE) legend(&quot;topleft&quot;,col=c(&quot;black&quot;,&quot;red&quot;),lty=c(1,1), lwd=c(2,2),legend=c(&quot;Khi quadrat amb n=300&quot;,&quot;Normal&quot;),cex=0.7) Tornem un instant a això dels graus de llibertat. Per què diem que la variància (mostral o a seques) té \\(n-1\\) graus de llibertat? Doncs perquè si volem construir un conjunt de \\(n\\) nombres \\(x_1,\\ldots,x_n\\) que tenguin variància un valor donat, posem \\(y_0\\), aleshores en principi podem escollir \\(n-1\\) d’ells, \\(x_1,\\ldots,x_{n-1}\\), com volguem i aleshores el darrer, \\(x_n\\), queda bastant fixat. En matemàtiques això se sol expressar dient que “tenim \\(n-1\\) graus de llibertat a l’hora d’escollir \\(x_1,\\ldots,x_n\\) amb variància fixada \\(y_0\\)”. En efecte, si fixam el valor \\(y_0\\geqslant 0\\) de la variància i volem trobar \\(x_1,\\ldots,x_{n}\\) tals que \\[ y_0=\\frac{\\sum_{i=1}^n (x_i-\\overline{x})^2}{n}=\\frac{\\sum_{i=1}^n x_i^2}{n}-\\overline{x}^2 \\] vegem que per a qualssevol valors de \\(x_1,\\ldots,x_{n-1}\\), el valor de \\(x_n\\) queda fixat per una equació quadràtica: \\[ \\begin{array}{l} ny_0 &amp; =\\displaystyle \\sum_{i=1}^n x_i^2-n\\overline{x}^2= \\sum_{i=1}^n x_i^2-n\\Big(\\frac{\\sum_{i=1}^n x_i}{n}\\Big)^2\\\\ &amp; =\\displaystyle \\sum_{i=1}^n x_i^2-\\frac{(\\sum_{i=1}^n x_i)^2}{n}\\\\ &amp; \\displaystyle =\\frac{1}{n}\\left(n\\sum_{i=1}^n x_i^2-\\Big(\\sum_{i=1}^{n} x_i\\Big)^2\\right)\\\\ &amp; =\\displaystyle \\frac{1}{n}\\left(n\\sum_{i=1}^{n-1} x_i^2+n\\mathbf{x_n}^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2\\right.\\\\ &amp; \\displaystyle\\qquad\\qquad \\left. -2\\Big(\\sum_{i=1}^{n-1} x_i\\Big)\\mathbf{x_n}-\\mathbf{x_n}^2\\right)\\\\ &amp; =\\displaystyle \\frac{1}{n}\\left((n-1)\\mathbf{x_n}^2-2\\Big(\\sum_{i=1}^{n-1} x_i\\Big)\\mathbf{x_n}\\right.\\\\ &amp; \\displaystyle\\qquad\\qquad \\left.+n\\sum_{i=1}^{n-1} x_i^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2 \\right) \\end{array} \\] d’on (multiplicant els dos costats de la igualtat per \\(n\\) i dividint-los per \\(n-1\\)) obtenim, finalment, l’equació de segon grau en \\(\\mathbf{x_n}\\) \\[ \\mathbf{x_n}^2-\\frac{2\\sum_{i=1}^{n-1} x_i}{n-1}\\mathbf{x_n}+\\frac{n\\sum_{i=1}^{n-1} x_i^2-\\Big(\\sum_{i=1}^{n-1} x_i\\Big)^2-n^2y_0^2}{n-1}=0 \\] Per tant, fixat \\(y_0\\) i un cop escollits \\(x_1,\\ldots,x_{n-1}\\), el darrer valor \\(x_n\\) ha de ser per força una solució d’aquesta equació de segon grau. Fixau-vos que aquesta equació no sempre té solució real, perquè pot tenir el discriminant negatiu. Per tant exageràvem un poc dient que podíem triar \\(x_1,\\ldots,x_{n-1}\\) “com volguem”. Per exemple, si voleu que la variància sigui 0 i preneu \\(x_1,\\ldots,x_{n-1}\\) no tots iguals, podeu estar ben segurs que no trobareu cap \\(x_n\\) que satisfaci aquesta equació: per tenir variància 0, \\(x_1,\\ldots,x_n\\) han de ser tots iguals. Però el que ha de quedar clar és que un cop escollits \\(x_1,\\ldots,x_{n-1}\\), el valor de \\(x_n\\) ja no pot ser qualsevol, pot prendre com a màxim dos valors diferents. 2.5 La t de Student Tornem a les mitjanes mostrals de variables normals. Teorema 2.6 Sigui \\(X\\) una variable \\(N(\\mu_X,\\sigma_X)\\) i sigui \\(X_1,\\ldots,X_n\\) una mostra aleatòria simple de \\(X\\), amb mitjana \\(\\overline{X}\\) i desviació típica mostral \\(\\widetilde{S}_{X}\\). Aleshores, la variable aleatòria \\[ T=\\frac{\\overline{X}-\\mu_X}{\\widetilde{S}_{X}/\\sqrt{n}} \\] segueix una distribució coneguda, anomenada t de Student amb \\(n-1\\) graus de llibertat, \\(t_{n-1}\\). A \\(\\widetilde{S}_{X}/\\sqrt{n}\\) li diem l’error típic, o estàndard, de la mostra: estima l’error típic \\(\\sigma_X/\\sqrt{n}\\) de \\(\\overline{X}\\). De la distribució t de Student amb \\(n\\) graus de llibertat, \\(t_{n}\\), heu de saber que: Amb R és t La \\(n\\) és un paràmetre del que depèn la seva distribució Si \\(T_{n}\\) és una variable amb distribució \\(t_{n}\\), aleshores \\(\\mu_{T_{n}}=0\\) si \\(n\\geqslant 2\\) i \\(\\sigma_{T_{n}}^2=n/(n-2)\\) si \\(n\\geqslant 3\\) La funció de densitat d’una variable \\(T_{n}\\) amb distribució \\(t_{n}\\) és simètrica al voltant de 0 (com la d’una \\(N(0,1)\\)): \\[ P(T_{n}\\leqslant-x)=P(T_{n}\\geqslant x)=1-P(T_{n}\\leqslant x) \\] Si \\(n\\) és gran, la distribució d’una variable \\(T_{n}\\) amb distribució \\(t_{n}\\) és aproximadament la d’una \\(N(0,1)\\) (però amb més variància: un poc més aplatada), com podeu veure als gràfics següents: curve(dnorm(x),col=1,lwd=2,xlim=c(-4,4),xlab=&quot;&quot;,ylab=&quot;&quot;,ylim=c(0,0.4), main=&quot;Algunes t de Student&quot;) curve(dt(x,2),col=2,lwd=2,add=TRUE) curve(dt(x,3),col=3,lwd=2,add=TRUE) curve(dt(x,4),col=4,lwd=2,add=TRUE) curve(dt(x,5),col=5,lwd=2,add=TRUE) curve(dt(x,10),col=6,lwd=2,add=TRUE) legend(&quot;topleft&quot;,col=1:6,lty=rep(1,6), lwd=rep(2,6), legend=c(&quot;Normal estàndard&quot;, paste(&quot;Student amb g.l.=&quot;,c(2:5,10),sep=&quot;&quot;)),cex=0.7) curve(dnorm(x),col=1,lwd=2,xlim=c(-4,4),xlab=&quot;&quot;,ylab=&quot;&quot;,ylim=c(0,0.4), main=&quot;t vs Normal estàndard&quot;) curve(dt(x,50),col=2,lwd=2,add=TRUE) legend(&quot;topleft&quot;,col=1:2,lty=rep(1,2), lwd=rep(2,2), legend=c(&quot;Normal estàndard&quot;, &quot;Student amb g.l.=50&quot;),cex=0.7) El fet que una t de Student sigui més aplatada que una normal estàndard \\(Z\\) implica que les cues de la t tenen major probabilitat que les de \\(Z\\) (fixau-vos que als gràfics anteriors els extrems de les densitats de les t estan per damunt dels de la de \\(Z\\)), la qual cosa es tradueix en el fet que és més probable obtenir valors lluny del 0 amb una t de Student que amb una \\(N(0,1)\\). Indicarem amb \\(t_{n,q}\\) el \\(q\\)-quantil d’una variable aleatòria \\(T_{n}\\) que segueix una distribució \\(t_n\\). És a dir, \\(t_{n,q}\\) és el valor tal que \\[ P(T_{n}\\leqslant t_{n,q})=q \\] Per la simetria de la distribució \\(t_n\\), \\[ t_{n,q}=-t_{n,1-q}. \\] Hi ha algunes propietats dels quantils de la t de Student que heu de saber, per poder aplicar-les quan no tingueu a l’abast R o una apli per calcular quantils: \\(t_{n ,q}\\approx z_{q}\\) si \\(n\\) és molt gran, posem \\(n \\geqslant 200\\). Per exemple qt(0.975,300) # t_{300,0.975} ## [1] 1.967903 qnorm(0.975) # z_0.975 ## [1] 1.959964 \\(t_{n,0.95}\\) (per a \\(10\\leqslant n\\leqslant 200\\)) està entre 1.65 i 1.8; ho podeu aproximar \\(t_{n,0.95}\\approx 1.7\\) \\(t_{n,0.975}\\) (per a \\(10\\leqslant n\\leqslant 200\\)) està entre 1.97 i 2.2; ho podeu aproximar \\(t_{n,0.975}\\approx 2\\) Comprovau amb R les afirmacions sobr els quantils de la t de Student dels darrers dos punts. Abans de tancar aquesta secció, recordau que, donada una variable aleatòria \\(X\\), no heu de confondre: Desviació típica (o estàndard) de la variable aleatòria, \\(\\sigma_X\\): El paràmetre poblacional, normalment desconegut Desviació típica (o estàndard) (sigui mostral, \\(\\widetilde{S}_X\\), o a seques, \\(S_X\\)) d’una mostra: L’estadístic que calculam sobre la mostra i que quantifica la dispersió de la mostra Error típic (o estàndard) d’un estimador: La desviació típica de la variable aleatòria que defineix l’estimador, normalment desconeguda Error típic (o estàndard) d’una mostra: Estimació de l’error típic de la mitjana mostral (o de la proporció mostral) a partir d’una mostra; servirà per calcular intervals de confiança. És \\(\\widetilde{S}_X/\\sqrt{n}\\). 2.6 “Bons” estimadors 2.6.1 Estimadors no esbiaixats Un estimador puntual \\(\\widehat{\\theta}\\) d’un paràmetre poblacional \\(\\theta\\) és no esbiaixat (insesgado, en castellà) quan el seu valor esperat és precisament el valor poblacional del paràmetre, és a dir, quan \\[ \\mu_\\widehat{\\theta}=\\theta \\] Es diu aleshores que l’estimació puntual és no esbiaixada. El biaix d’un estimador \\(\\widehat{\\theta}\\) d’un paràmetre \\(\\theta\\) és la diferència \\(\\mu_\\widehat{\\theta}-\\theta\\) Exemples: Ja hem vist a les seccions anteriors que \\(\\mu_{\\overline{X}}=\\mu_X\\). Per tant, \\(\\overline{X}\\) és sempre un estimador no esbiaixat de \\(\\mu_X\\) \\(\\mu_{\\widehat{p}_X}=p_X\\). Per tant, \\(\\widehat{p}_X\\) és sempre un estimador no esbiaixat de \\(p_X\\) \\(\\mu_{\\widetilde{S}_{X}^2}=\\sigma_X^2\\) si \\(X\\) és normal. Per tant, \\(\\widetilde{S}_{X}^2\\) és un estimador no esbiaixat de \\(\\sigma_X^2\\) quan \\(X\\) és normal Com que \\({S}_{X}^2=\\dfrac{n-1}{n}\\widetilde{S}_{X}^2\\), tenim que \\(\\mu_{{S}_{X}^2}=\\dfrac{n-1}{n}\\sigma_X^2\\) si \\(X\\) és normal. Per tant, en aquest cas, \\({S}_{X}^2\\) és un estimador esbiaixat de \\(\\sigma_X^2\\), amb biaix \\[ \\mu_{{S}_{X}^2}-\\sigma_X^2=\\dfrac{n-1}{n}\\sigma_X^2-\\sigma_X^2=-\\dfrac{\\sigma_X^2}{n}\\ \\mathop{\\longrightarrow}_{\\scriptscriptstyle n\\to\\infty}\\ 0 \\] Diem en aquest cas que el biaix tendeix a 0. \\(\\mu_{\\widetilde{S}_{X}}, \\mu_{{S}_{X}}\\neq \\sigma_X\\) ni tan sols quan \\(X\\) és normal. Per tant, \\(\\widetilde{S}_{X}\\) i \\({S}_{X}\\) són estimadors esbiaixats de \\(\\sigma_X\\) 2.6.2 Estimadors eficients Donats dos estimadors \\(\\widehat{\\theta}_1\\), \\(\\widehat{\\theta}_2\\) del mateix paràmetre \\(\\theta\\), direm que \\(\\widehat{\\theta}_1\\) és més eficient, o més precís, que \\(\\widehat{\\theta}_2\\) quan l’error típic de \\(\\widehat{\\theta}_1\\) és més petit que el de \\(\\widehat{\\theta}_2\\): \\[ \\sigma(\\widehat{\\theta}_1)&lt; \\sigma(\\widehat{\\theta}_2). \\] Normalment, només comparam l’eficiència de dos estimadors quan són no esbiaixats (o, com a molt, quan el seu biaix tendeix a 0). En aquest cas, que \\(\\widehat{\\theta}_1\\) sigui més eficient que \\(\\widehat{\\theta}_2\\) significa que la seva variabilitat és menor i que per tant les estimacions amb \\(\\widehat{\\theta}_1\\) es concentren més al voltant del seu valor esperat, que és el paràmetre \\(\\theta\\) que volem estimar, que les estimacions amb \\(\\widehat{\\theta}_2\\). Exemples: Si \\(X\\) és normal, \\(\\overline{X}\\) és l’estimador no esbiaixat més eficient de la mitjana poblacional \\(\\mu_X\\). Si \\(X\\) és Bernoulli, \\(\\widehat{p}_X\\) és l’estimador no esbiaixat més eficient de la proporció poblacional \\(p_X\\). Si \\(X\\) és normal, \\(\\widetilde{S}_X^2\\) és l’estimador no esbiaixat més eficient de la variància poblacional \\(\\sigma_X^2\\). Exemple 2.12 Sigui \\(X\\) una variable aleatòria normal \\(N(\\mu_X,\\sigma_X)\\). Considerem la mediana \\(\\mathit{Me}=Q_{0.5}\\) d’una mostra aleatòria simple de \\(X\\) com a estimador puntual de \\(\\mu_X\\), que coincideix amb la mediana de \\(X\\) per la simetria de les variables normals. Resulta que \\(\\mu_{\\mathit{Me}}=\\mu_X\\) però \\[ \\sigma^2(\\mathit{Me})\\approx \\dfrac{\\pi}{2}\\cdot \\dfrac{\\sigma_{X}^2}{n}\\approx 1.57 \\cdot \\frac{\\sigma_{X}^2}{n}=1.57\\sigma^2_{\\overline{X}} \\] Per tant, si \\(X\\) és normal, la mediana \\(\\mathit{Me}\\) és un estimador no esbiaixat de \\(\\mu_X\\), però menys eficient que \\(\\overline{X}\\). Per això preferim emprar la mitjana mostral per estimar \\(\\mu_X\\). Hem dit que si la població és normal, \\(\\widetilde{S}_X^2\\) és l’estimador no esbiaixat més eficient de la variància poblacional \\(\\sigma_X^2\\). La variància a seques \\[ S_X^2=\\frac{(n-1)}{n} \\widetilde{S}_X^2 \\] és més eficient, perquè \\[ \\sigma(S_X^2)=\\sqrt{\\frac{(n-1)}{n}}\\sigma(\\widetilde{S}_X^2)&lt;\\sigma(\\widetilde{S}_X^2), \\] però és un estimador esbiaixat de \\(\\sigma_X^2\\), amb biaix que tendeix a 0. Si \\(n\\) és petit (per davall de 30), és millor fer servir la variància mostral \\(\\widetilde{S}_X^2\\) per estimar la variància, ja que el biaix pot desplaçar l’estimació, però si \\(n\\) és gran, el biaix de \\(S_X^2\\) ja és petit i es pot fer servir \\(S_X^2\\): de fet, si \\(n\\) és molt gran, dividir per \\(n\\) o per \\(n-1\\) no varia gaire el resultat i per tant \\(\\widetilde{S}_X^2\\) i \\(S_X^2\\) donen valors molt semblants. 2.6.3 Estimadors màxim versemblants Un estimador d’un paràmetre és màxim versemblant quan, aplicat a una mostra aleatòria simple d’una mida \\(n\\) fixada, dóna el valor del paràmetre que fa màxima la probabilitat d’obtenir aquesta mostra. En realitat, el que fa màxim l’estimació màxim versemblant d’un paràmetre és el producte dels valors de la funció densitat de la variable aleatòria poblacional aplicada als elements de la mostra. Quan la variable aleatòria és discreta, això coincideix amb el que hem dit, perquè la probabilitat d’obtenir un valor concret és la funció densitat aplicada a aquest valor. Però quan la variable aleatòria poblacional és contínua, la probabilitat d’obtenir una mostra concreta és sempre 0 i no té sentit parlar de maximitzar aquest 0. Per això es pren la funció densitat. En aquest curs no ens complicarem la vida i entendrem que el que maximitzam és la probabilitat d’obtenir la mostra. Exemple 2.13 Suposem que tenim una variable aleatòria Bernoulli \\(X\\) de probabilitat d’èxit \\(p_X\\) desconeguda. Donada una mostra aleatòria simple \\(x_1,\\ldots,x_n\\) de \\(X\\), siguin \\(\\widehat{p}_x\\) la seva proporció mostral i \\[ P(x_1,\\ldots,x_n\\mid p_X=p) \\] la probabilitat d’obtenir la mostra quan la probabilitat poblacional \\(p_X\\) és igual \\(p\\). Un estimador per a \\(p_X\\) és màxim versemblant quan, aplicat a cada mostra aleatòria simple \\(x_1,\\ldots,x_n\\) de \\(X\\), ens dóna el valor de \\(p\\) que fa que \\[ P(x_1,\\ldots,x_n\\mid p_X=p) \\] sigui el màxim possible. Quin creieu que és l’estimador màxim versemblant de \\(p_X\\)? Doncs sí, la proporció mostral \\(\\widehat{p}_X\\). Teorema 2.7 El valor de \\(p\\) per al qual \\(P(x_1,\\ldots,x_n\\mid p)\\) és màxim és \\(\\widehat{p}_x\\). La demostració és senzilla. Suposau que dins \\(x_1,\\ldots,x_n\\) hi ha \\(m\\) 1s i \\(n-m\\) 0s, de manera que \\(\\widehat{p}_X=m/n\\). Aleshores, la probabilitat d’obtenir \\(x_1,\\ldots,x_n\\) és \\[ P(x_1,\\ldots,x_n\\mid p)=p^m(1-p)^{n-m} \\] Per trobar el valor de \\(p\\) que fa aquest probabilitat màxima, derivau respecte de \\(p\\) i estudiau el signe de la derivada, i concloureu que el màxim es dóna efectivament a \\(p=m/n\\). La proporció \\(\\widehat{p}_x\\) és el valor que fa màxima la probabilitat d’obtenir la nostra mostra, no a l’enrevés: No és el valor més probable de \\(p_X\\) condicionat a la nostra mostra. Vaja, no confongueu \\[ P(x_1,\\ldots,x_n\\mid p_X=p)\\text{ amb }P(p_X=p\\mid x_1,\\ldots,x_n). \\] D’això darrer no en sabem trobar el màxim sense alguna hipòtesi sobre la distribució de probabilitat dels valors possibles de \\(p_X\\). Alguns altres estimadors màxim versemblants: \\(\\overline{X}\\) és l’estimador màxim versemblant del paràmetre \\(\\lambda\\) d’una variable aleatòria Poisson \\(\\overline{X}\\) és l’estimador màxim versemblant de la mitjana \\(\\mu\\) d’una variable aleatòria normal 2.7 Estimació de poblacions 2.7.1 Estimació de poblacions numerades Exemple 2.14 Un dia vaig voler estimar quants taxis hi havia a Palma. Per fer-ho, assegut en un bar del Passeig Marítim vaig apuntar les llicències dels 40 primers taxis que passaren. Els entraré directament en un vector de R. taxis=c(1217,600,883,1026,150,715,297,137,508,134,38,961,538,1154,314,1121,823,158,940,99, 977,286,1006,1207,264,1183,1120,498,606,566,1239,860,114,701,381,836,561,494,858,187) sort(taxis) ## [1] 38 99 114 134 137 150 158 187 264 286 297 314 381 494 498 ## [16] 508 538 561 566 600 606 701 715 823 836 858 860 883 940 961 ## [31] 977 1006 1026 1120 1121 1154 1183 1207 1217 1239 Puc estimar quants taxis hi ha a Palma a partir d’aquesta mostra? Us pot semblar una beneitura de pregunta, però aquest és un problema de rellevància històrica, com podeu consultar en aquest article. La solució d’aquest problema és donada pel resultat següent: Teorema 2.8 Sigui \\(X\\) una variable aleatòria uniforme sobre \\(\\{1,2,\\ldots,N\\}\\), i sigui \\(x_1,\\ldots,x_n\\) una mostra aleatòria de \\(X\\). Sigui \\(m=\\max(x_1,\\ldots,x_n)\\). Aleshores, l’estimador no esbiaixat més eficient de \\(N\\) és \\[ \\widehat{N}=m+\\frac{m-n}{n} \\] La idea que hi ha sota aquesta fórmula és que si suposau que teniu \\(x_1,\\ldots,x_n\\) ordenats en ordre creixent, de manera que \\(x_n=m\\), i calculau la mitjana de la longitud dels “forats” a l’esquerra de cada valor \\(x_i\\), tenim que a l’esquerra de \\(x_1\\) hi ha \\(x_1-1\\) nombres i entre cada \\(x_{i-1}\\) i \\(x_{i}\\) hi ha \\(x_{i}-x_{i-1}-1\\) nombres, i per tant aquesta mitjana és \\[ \\begin{array}{l} \\displaystyle \\frac{(x_1-1)+(x_2-x_1-1)+\\cdots+(x_{n}-x_{n-1}-1)}{n}\\\\ \\displaystyle \\qquad\\quad =\\frac{x_n-n}{n}=\\frac{m-n}{n} \\end{array} \\] i el que fa l’estimador \\(\\widehat{N}\\) és sumar al màxim de la mostra, \\(m\\), la mitjana dels forats entre membres de la mostra. És a dir, estimam que la mida de la població és tal que a la dreta del màxim de la nostra mostra hi ha un “forat” de mida la mitjana dels forats de la mostra. Exemple 2.15 Continuem amb l’Exemple 2.14. Emprant la fórmula anterior, obtenim max(taxis)+(max(taxis)-length(taxis))/length(taxis) ## [1] 1268.975 la qual cosa ens permet estimar que hi havia 1269 taxis a Palma. En realitat, consultant la web de l’Ajuntament, després vaig saber que en aquell moment n’hi havia 1246. Exemple 2.16 Fem un experiment. Generarem a l’atzar una mida N d’una població grandeta, i suposarem que els individus de la població estan numerats de l’1 a l’N. A continuació, prendrem 100 mostres aleaòries sense reposició de la nostra població i amb cada una d’aquestes mostres estimarem la N emprant la fórmula que hem donat. Al final, calcularem la mitjana d’aquestes estimacions i la compararem amb el valor real de N, que no descobrirem fins el final. Perquè l’experiment sigui reproductible, fixarem la llavor d’aleatorietat, però perquè no cregueu que fem trampes amb aquesta llavor, el que farem serà generar a l’atzar la llavor d’aleatorietat amb la funció sample. Llavor=sample(10000,1) Llavor ## [1] 6283 set.seed(Llavor) Ara generam la mida N de la població com un nombre a l’atzar entre 5000 i 10000. N=sample(5000:10000,1) Suposarem per tant que hi ha N individus a la nostra població, numerats de l’1 a l’N. Ara generarem 100 mostres aleatòries sense reposició d’aquesta població, i ens quedarem amb la mida i el valor màxim de cada una d’elles, que és l’únic que necessitam saber. Les mides les generarem a l’atzar entre, posem, 25 i 75: Mostra=function(a,b,P){ #a i b: mides màxima i mínima de la mostra; P: mida de la població n=sample(a:b,1) #Mida de la mostra X=sample(P,n,rep=FALSE) # Mostra aleatòria c(n,max(X)) #Parell (mida, màxim) } Mostres=replicate(100,Mostra(25,75,N)) Mostres ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] ## [1,] 67 42 75 67 39 69 26 30 30 46 34 50 59 65 ## [2,] 6442 6320 6346 6403 5805 6410 6326 6398 6365 6354 6337 6371 5932 6439 ## [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] ## [1,] 55 58 74 41 28 40 39 50 52 46 74 52 ## [2,] 6274 6433 6426 5795 6213 6367 6066 5903 6219 6187 6393 6333 ## [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] ## [1,] 43 31 45 55 63 46 73 74 45 45 53 63 ## [2,] 6243 6295 6406 6409 6308 6421 6327 6354 6319 6282 6255 6430 ## [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] ## [1,] 54 28 36 61 52 53 37 29 65 75 37 43 ## [2,] 6335 6002 6310 6331 6381 6338 6235 6304 6292 6394 6309 6362 ## [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62] ## [1,] 73 30 70 55 45 31 62 54 36 50 28 67 ## [2,] 6302 6426 6278 6265 6191 6442 6389 6242 6260 6406 5937 6235 ## [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74] ## [1,] 25 71 40 49 65 65 55 67 55 33 39 74 ## [2,] 5673 6285 6269 6200 6381 6414 6183 6304 6433 6426 6442 6372 ## [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] [,85] [,86] ## [1,] 29 63 39 57 51 55 61 33 33 58 71 44 ## [2,] 5602 6371 6412 6369 6374 6412 6307 5945 6259 6095 6397 6361 ## [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98] ## [1,] 62 68 34 68 37 39 63 65 66 68 64 36 ## [2,] 6379 6435 5956 6373 6335 6285 6426 6437 6438 6403 6406 5954 ## [,99] [,100] ## [1,] 55 32 ## [2,] 6271 5993 En aquesta matriu Mostres, cada columna correspon a una mostra aleatòria: la primera filera és la seva mida \\(n\\) i la segona filera el màxim \\(m\\). Ara, amb cada una d’aquestes mostres, podem estimar la mida N de la població per mitjà de la fórmula \\(m+(m-n)/n\\). Donarem aquestes estimacions ordenades de menor a major. Estimacions=Mostres[2,]+(Mostres[2,]-Mostres[1,])/Mostres[1,] round(sort(Estimacions),1) ## [1] 5794.2 5898.9 5935.3 5952.8 6020.1 6031.5 6118.4 6124.2 6130.2 6148.0 ## [11] 6179.3 6199.1 6215.4 6220.5 6294.4 6320.5 6325.5 6327.1 6327.6 6337.6 ## [21] 6356.6 6366.7 6372.0 6372.5 6377.9 6384.0 6387.1 6387.2 6387.3 6387.8 ## [31] 6397.1 6402.5 6407.1 6409.4 6412.7 6420.6 6424.7 6429.6 6432.9 6433.8 ## [41] 6433.9 6438.9 6445.2 6447.7 6451.3 6453.8 6456.6 6457.1 6458.4 6465.7 ## [51] 6469.5 6471.1 6478.2 6478.3 6478.4 6478.5 6479.7 6480.9 6484.3 6486.1 ## [61] 6491.0 6491.1 6496.2 6497.1 6497.4 6497.6 6498.0 6501.9 6502.7 6504.6 ## [71] 6505.1 6505.2 6509.0 6511.7 6511.8 6520.4 6522.4 6524.5 6525.2 6527.0 ## [81] 6527.6 6528.6 6531.1 6533.1 6534.5 6535.0 6537.1 6537.1 6542.9 6547.4 ## [91] 6549.0 6559.6 6568.3 6575.4 6576.2 6606.2 6610.3 6619.7 6639.2 6648.8 hist(Estimacions, breaks=20,col=&quot;light blue&quot;,xlab=&quot;Estimacions de N&quot;,ylab=&quot;Freqüències&quot;,main=&quot;&quot;) Com veieu, obtenim estimacions que van de 5794.2 a 6648.8. La mitjana d’aquestes estimacions és round(mean(Estimacions),1) ## [1] 6415.9 És hora de descobrir el valor de N, per veure si ens hi hem fet a prop: N ## [1] 6442 No hem fet molt enfora, com veieu. 2.7.2 Marca-recaptura Suposem que en una població hi ha \\(N\\) individus, en capturam \\(K\\) (tots diferents), els marcam i els tornam a amollar. Al cap de poc temps, en capturam \\(n\\), dels quals \\(k\\) estan marcats. A partir d’aquestes dades, volem estimar \\(N\\). Si suposam que \\(N\\) i \\(K\\) no han canviat de la primera a la segona captura (cap individu no ha abandonat la població ni s’hi ha incorporat), aleshores la variable aleatòria \\(X\\) definida per “Capturam un individu i miram si està marcat” és Bernoulli \\(Be(p)\\) amb \\(p=K/N\\), on coneixem la \\(K\\) i volem estimar la \\(N\\). Sigui ara \\(x_1,\\ldots,x_n\\) la mostra capturada en segon lloc. La seva proporció mostral d’individus marcats és \\(\\widehat{p}_X=k/n\\). Com que \\(\\widehat{p}_X\\) és l’estimador màxim versemblant de \\(p\\), estimam que \\[ \\dfrac{K}{N}=\\dfrac{k}{n} \\] d’on, aïllant la \\(N\\), estimam que \\[ N=\\frac{n\\cdot K}{k}. \\] En resum, l’estimador \\[ \\widehat{N}=\\frac{n\\cdot K}{k} \\] maximitza la probabilitat d’obtenir \\(k\\) individus marcats en una mostra aleatòria de \\(n\\) individus. És l’estimador màxim versemblant de \\(N\\) a partir de \\(K\\), \\(k\\) i \\(n\\); també se li diu estimador de Lincoln-Petersen. Fixau-vos que aquest estimador no fa res més que traduir la proporció “Si he trobat \\(k\\) individus marcats en un conjunt de \\(n\\) individus, què ha de valer el nombre total \\(N\\) de individus perquè hi hagi en total \\(K\\) individus marcats?” Exemple 2.17 Suposem que hem marcat 15 peixos d’un llac, i que en una captura posterior de 10 peixos, n’hi ha 4 de marcats. Quants peixos conté el llac? Ho estimarem amb l’estimador de Lincoln-Petersen: \\[ \\widehat{N}=\\frac{15\\cdot 10}{4}=37.5 \\] Per tant, estimam que hi haurà entre 37 i 38 peixos al llac. En aquest cas podem comprovar la màxima versemblança d’aquesta estimació, calculant la probabilitat d’obtenir 4 individus marcats en una mostra aleatòria de 10 individus d’una població de \\(N\\) individus on n’hi ha 15 de marcats i trobant la \\(N\\) que maximitza aquesta probabilitat. Per fer-ho, recordem que si una població està formada per \\(K\\) subjectes marcats i \\(N-K\\) subjectes no marcats, el nombre de subjectes marcats en mostres aleatòries sense reposició de mida \\(n\\) segueix una distribució hipergeomètrica \\(H(K, N-K,n)\\). Per tant, per a cada possible \\(N\\), la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats serà dhyper(4,15,N-15,10). N=15:1000 #Rang de possibles valors de N p=dhyper(4,15,N-15,10) #Probabilitats de 4 marcats en 10 Nmax=N[which(p==max(p))] # N que maximitza la probabilitat Nmax ## [1] 37 Aquest Nmax és la \\(N\\) que fa màxima la probabilitat que en una mostra de 10 peixos del nostre llac n’hi hagi 4 de marcats. Vegem-ho amb un gràfic: plot(N[1:86],p[1:86],type=&quot;h&quot;,xaxp=c(15,100,17),xlab=&quot;N&quot;,ylab=&quot;p&quot;) points(Nmax,dhyper(4,15,Nmax-15,10),type=&quot;h&quot;,col=&quot;red&quot;,lwd=1.5) Un altre estimador per a \\(N\\) a partir de \\(K\\), \\(n\\) i \\(k\\) és l’estimador de Chapman: \\[ \\widehat{N}=\\frac{(n+1)\\cdot (K+1)}{k+1}-1 \\] La idea és que afegim a la població un individu extra i marcat, que suposam que també capturam a la segona mostra. Llavors, aplicam l’estimador anterior i finalment restam 1, per descomptar l’individu marcat extra que realment no pertany a la població que volem estimar. En la situació de l’Exemple 2.17, aquest estimador dóna \\[ \\widehat{N}=\\frac{16\\cdot 11}{5}-1=34.2 \\] i ens fa estimar una població total d’uns 34 peixos. Abans hem obtingut entre 37 i 38 peixos. Quina de les dues estimacions s’acosta més a la realitat? Ni idea, no ho podem saber. Amb una altra recaptura segurament haguéssim obtingut resultats diferents. L’estimador de Lincoln-Petersen \\[ \\widehat{N}=\\frac{n\\cdot K}{k} \\] és esbiaixat, amb biaix que tendeix a 0. L’estimador de Chapman és menys esbiaixat però no és màxim versemblant. Exemple 2.18 Fem un experiment similar al de l’Exemple 2.16. Generarem a l’atzar una mida N d’una població grandeta i en marcarem una certa quantitat K. A continuació, prendrem 50 mostres aleaòries sense reposició de la nostra població i amb cada una d’aquestes mostres estimarem la N emprant els dos estimadors que hem explicat en aquesta subsecció. Al final, calcularem les mitjanes d’aquestes estimacions i les compararem amb el valor real de N, que no descobrirem fins el final. Com a l’Exemple 2.16, fixarem la llavor d’aleatorietat a l’atzar. Llavor2=sample(10000,1) Llavor2 ## [1] 6244 set.seed(Llavor2) Ara generam la mida N de la població com un nombre a l’atzar entre 5000 i 10000. N=sample(5000:10000,1) Ara en capturam i marcam K; per fixar idees, prendrem K=200. K=200 Per simplificar, suposarem que els N individus de la nostra població estan numerats de l’1 a l’N i que els marcats són els K primers. Ara generarem 100 mostres aleatòries sense reposició d’aquesta població, i ens quedarem amb la mida i el nombre d’individus marcats (és a dir, el nombre de valors menor o iguals a K=100 en la mostra). Les mides les generarem a l’atzar entre, posem, 50 i 150: Mostra=function(a,b,P,M){ #a i b: mides màxima i mínima de la mostra; P: mida de la població; #M: nombre de marcats n=sample(a:b,1) #Mida de la mostra X=sample(P,n,rep=FALSE) # Mostra aleatòria c(n,length(which(X&lt;=M))) #Parell (mida, nombre de marcats) } Mostres=replicate(100,Mostra(50,150,N,K)) Mostres ## [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12] [,13] [,14] ## [1,] 79 94 110 116 128 127 68 59 144 135 147 86 89 51 ## [2,] 2 2 1 2 1 3 2 1 4 2 10 8 4 0 ## [,15] [,16] [,17] [,18] [,19] [,20] [,21] [,22] [,23] [,24] [,25] [,26] ## [1,] 121 95 50 54 71 67 113 141 65 129 111 97 ## [2,] 4 4 0 2 3 0 0 4 3 3 5 2 ## [,27] [,28] [,29] [,30] [,31] [,32] [,33] [,34] [,35] [,36] [,37] [,38] ## [1,] 74 102 88 82 112 92 120 138 82 65 103 114 ## [2,] 1 2 3 9 1 6 1 2 1 3 6 5 ## [,39] [,40] [,41] [,42] [,43] [,44] [,45] [,46] [,47] [,48] [,49] [,50] ## [1,] 106 72 57 54 123 68 51 52 81 75 121 90 ## [2,] 1 0 0 2 3 1 2 2 2 2 3 3 ## [,51] [,52] [,53] [,54] [,55] [,56] [,57] [,58] [,59] [,60] [,61] [,62] ## [1,] 87 123 128 73 139 115 130 50 102 80 90 92 ## [2,] 1 1 3 2 5 2 1 2 2 3 2 1 ## [,63] [,64] [,65] [,66] [,67] [,68] [,69] [,70] [,71] [,72] [,73] [,74] ## [1,] 143 125 141 132 54 102 79 100 107 137 113 118 ## [2,] 3 5 6 1 1 4 3 2 4 4 2 4 ## [,75] [,76] [,77] [,78] [,79] [,80] [,81] [,82] [,83] [,84] [,85] [,86] ## [1,] 106 101 78 56 99 82 118 131 102 108 63 136 ## [2,] 4 3 6 3 3 2 4 6 0 4 1 5 ## [,87] [,88] [,89] [,90] [,91] [,92] [,93] [,94] [,95] [,96] [,97] [,98] ## [1,] 60 73 81 107 130 70 70 54 103 77 115 133 ## [2,] 4 0 1 3 4 1 1 2 3 3 1 5 ## [,99] [,100] ## [1,] 75 100 ## [2,] 1 3 En aquesta matriu Mostres, cada columna correspon a una mostra aleatòria: la primera filera és la seva mida \\(n\\) i la segona filera el nombre d’individus marcats a la mostra. Ara, amb cada una d’aquestes mostres, podem estimar la mida N de la població per mitjà de l’estimador de Lincoln-Petersen. EstimacionsLP=Mostres[1,]*K/Mostres[2,] round(sort(EstimacionsLP),1) ## [1] 1822.2 2150.0 2600.0 2940.0 3000.0 3066.7 3433.3 3733.3 4333.3 ## [10] 4333.3 4366.7 4440.0 4450.0 4560.0 4700.0 4733.3 4750.0 5000.0 ## [19] 5000.0 5100.0 5100.0 5133.3 5200.0 5266.7 5300.0 5320.0 5333.3 ## [28] 5350.0 5400.0 5400.0 5400.0 5400.0 5440.0 5560.0 5866.7 5900.0 ## [37] 5900.0 6000.0 6050.0 6500.0 6600.0 6666.7 6733.3 6800.0 6850.0 ## [46] 6866.7 7050.0 7133.3 7200.0 7300.0 7500.0 7900.0 8066.7 8100.0 ## [55] 8200.0 8200.0 8466.7 8533.3 8600.0 9000.0 9400.0 9533.3 9700.0 ## [64] 10000.0 10200.0 10200.0 10800.0 11300.0 11500.0 11600.0 11800.0 12600.0 ## [73] 13500.0 13600.0 13800.0 14000.0 14000.0 14800.0 15000.0 16200.0 16400.0 ## [82] 17400.0 18400.0 21200.0 22000.0 22400.0 23000.0 24000.0 24600.0 25600.0 ## [91] 26000.0 26400.0 Inf Inf Inf Inf Inf Inf Inf ## [100] Inf hist(EstimacionsLP, breaks=20,col=&quot;light blue&quot;,xlab=&quot;Estimacions de N&quot;,ylab=&quot;Freqüències&quot;,main=&quot;Estimador de Lincoln-Petersen&quot;) Com veieu, obtenim estimacions que van de 1822.2 a \\(\\infty\\), que corresponen a mostres on no ens ha sortit cap individu marcat. La mitjana de les estimacions finites és round(mean(EstimacionsLP[is.finite(EstimacionsLP)]),1) ## [1] 9261.2 També podem emprar l’estimador de Chapman: EstimacionsCh=(Mostres[1,]+1)*(K+1)/(Mostres[2,]+1)-1 round(sort(EstimacionsCh),1) ## [1] 1667.3 1942.0 2267.4 2451.2 2669.4 2703.4 2863.2 2985.3 3315.5 ## [10] 3315.5 3416.0 3483.0 3550.0 3617.0 3617.0 3684.0 3684.0 3684.0 ## [19] 3751.0 3789.3 3851.5 3858.2 3918.5 4019.0 4069.2 4076.4 4139.6 ## [28] 4220.0 4300.4 4340.6 4380.8 4471.2 4488.0 4571.8 4588.5 4622.0 ## [37] 4689.0 4782.8 4782.8 4903.4 4957.0 5024.0 5074.2 5091.0 5124.5 ## [46] 5225.0 5265.2 5359.0 5426.0 5493.0 5526.5 5546.6 5560.0 5707.4 ## [55] 5828.0 6029.0 6096.0 6129.5 6230.0 6364.0 6431.0 6431.0 6481.2 ## [64] 6531.5 6565.0 6766.0 6900.0 6900.0 6933.5 7134.5 7134.5 7235.0 ## [73] 7536.5 7637.0 7637.0 7771.0 7838.0 8240.0 8340.5 8843.0 9111.0 ## [82] 9312.0 9345.5 10250.0 10451.0 10752.5 11154.5 11355.5 11657.0 11657.0 ## [91] 12159.5 12461.0 12963.5 13164.5 13365.5 13667.0 14672.0 14873.0 20702.0 ## [100] 22913.0 hist(EstimacionsCh, breaks=20,col=&quot;light blue&quot;,xlab=&quot;Estimacions de N&quot;,ylab=&quot;Freqüències&quot;,main=&quot;Estimador de Chapman&quot;) Com veieu, obtenim estimacions que van de 1667.3 a 22913; per construcció, no hi ha estimacions infinites. La mitjana d’aquestes estimacions és round(mean(EstimacionsCh),1) ## [1] 6618.6 És hora de descobrir el valor de N, per veure si ens hi hem fet a prop: N ## [1] 7134 "],
["intervals-de-confiança.html", "Tema 3 Intervals de confiança 3.1 Definicions bàsiques 3.2 Exemple: Interval de confiança del 95% per a la mitjana d’una variable aleatòria normal 3.3 Interval de confiança per a la mitjana basat en la t de Student 3.4 Intervals de confiança per a proporcions 3.5 Intervals de confiança per a la variància d’una variable normal 3.6 “Poblacions finites”", " Tema 3 Intervals de confiança L’estimació puntual ens dóna el valor d’una característica d’una població, però no ens indica l’error que es comet amb aquesta estimació. A la pràctica, el que se sol fer és complementar una estimació puntual amb un interval que mesuri la precisió de l’estimació. Aquesta precisió depèn: De la variabilitat de la variable aleatòria d’interès: \\(\\sigma_X\\) De la mida de la mostra: \\(n\\) De la variabilitat de l’estimador (que segurament depèn de les dues anteriors): \\(\\sigma_{\\overline{X}}\\), \\(\\sigma_{\\widehat{p}_X}\\)… Del nivell de confiança, o seguretat, de l’estimació: com de segurs volem estar que l’estimació és correcta 3.1 Definicions bàsiques Un interval de confiança del Q% (abreviadament, un IC Q%) d’un paràmetre poblacional és un interval obtingut aplicant a una mostra aleatòria simple de mida \\(n\\) una fórmula que satisfà la propietat següent: L’interval obtingut conté el valor del paràmetre poblacional el Q% de les vegades que l’aplicam sobre mostres aleatòries simples de mida \\(n\\) preses a l’atzar Tenir una confiança del Q% significa doncs que empram una fórmula que encerta el Q% de les vegades; o, per ser precisos, el Q% de les vegades que l’aplicam bé. Però assumim que un (100-Q)% de les vegades que l’aplicam ens equivocam, i no sabem quin és el nostre cas. Exemple 3.1 En un experiment hem mesurat el percentatge d’augment d’alcohol en sang a 40 persones després de prendre 4 canyes de cervesa. La mitjana i la desviació típica mostral d’aquests percentatges d’increment han estat \\(\\overline{x}=41.2\\) i \\(\\widetilde{s}=2.1\\). Com veurem a l’Exemple 3.3, un IC 95% per al percentatge d’augment mitjà d’alcohol en sang d’una persona després de beure 4 canyes de cervesa és [40.53, 41.87]. Això significa que estam segurs al 95% que l’augment mitjà d’alcohol en sang d’una persona després de beure 4 canyes de cervesa està entre el 40.53% i el 41.87%, perquè aquest interval l’haurem calculat amb una fórmula que el 95% de les vegades que l’aplicam (bé) sobre mostres aleatòries de 40 persones dóna un interval que conté la mitjana poblacional que volem estimar. Nosaltres som optimistes i “confiam” estar dins aquest 95% d’encerts. No confongueu: Interval de referència del Q% per a una variable aleatòria: Interval que conté el valor de la variable aleatòria en un individu amb probabilitat Q%. Interval de confiança del Q% per a un paràmetre: Interval que conté el valor poblacional del paràmetre de la variable aleatòria “amb probabilitat” Q%, en el sentit que l’hem calculat amb una fórmula que dóna un interval que conté el paràmetre el Q% de les vegades que l’aplicam a una mostra aleatòria. Interval de referència del Q% per a un estimador: Interval que conté el valor de l’estimador sobre una mostra aleatòria amb probabilitat Q%. Per exemple: Si diem que un interval de referència del 95% per a la concentració d’una proteïna en sèrum en individus sans mesurada en g/dl és [11,16], això significa significa que un 95% dels individus sans tenen una concentració d’aquesta proteïna en sèrum entre 11 i 16 g/dl, o, equivalentment, que un individu sa escollit a l’atzar té, amb un 95% de probabilitat, una concentració d’aquesta proteïna en sèrum entre 11 i 16 g/dl Si diem que un interval de confiança del 95% per a la concentració mitjana d’una proteïna en sèrum en individus sans mesurada en g/dl és [11,16], això significa que hem pres una mostra aleatòria de concentracions d’aquesta proteïna en sèrum en individus sans i a partir d’aquesta mostra hem estimat que, amb un 95% de confiança, la concentració mitjana d’aquesta proteïna en sèrum en individus sans està entre 11 i 16 g/dl (i tenim un 95% de confiança en aquest interval perquè l’hem calculat amb una fórmula que dóna un interval que conté la mitjana poblacional un 95% de les vegades que l’empram sobre mostres aleatòries de la mateixa mida que la nostra). Si diem que el 95% de les mostres de 100 concentracions d’una determinada proteïna en sèrum en individus sans tenen la mitjana mostral entre 11 i 16, això és un interval de referència del 95% per a la mitjana mostral de mostres de mida 100, no un interval de confiança per a la concentració mitjana poblacional ni un interval de referència per al valor de la concentració en un individu. Que un IC Q% per a un paràmetre \\(\\theta\\) sigui \\([a,b]\\) serveix: Per estimar \\(\\theta\\) amb aquest marge de confiança: Estam bastant segurs que el valor poblacional de \\(\\theta\\) està entre \\(a\\) i \\(b\\) (la fórmula emprada encerta sovint) Per poder comparar el valor poblacional de \\(\\theta\\) amb un valor concret amb aquest marge de confiança: Estam bastant segurs que el valor real de \\(\\theta\\) no està ni per sota de \\(a\\) ni per sobre de \\(b\\) i per tant que és diferent de tots aquests valors Per exemple: si un IC 95% per a la prevalència \\(p\\) d’una determinada característica en una població (la fracció d’individus que tenen aquesta característica) va de 0.025 a 0.047: Estam molt (“un 95%”) segurs que \\(p\\in [0.025,0.047]\\) (perquè la fórmula emprada per calcular aquest interval encerta en un 95% de les vegades) Estam molt segurs que \\(p&gt;0.02\\) (perquè tot l’interval on estam molt segurs que cau el valor real de \\(p\\) està a la dreta de 0.02) Estam molt segurs que \\(p\\neq 0.05\\) (perquè 0.05 no pertany a l’interval on estam molt segurs que cau el valor real de \\(p\\)) Però no estam molt segurs que \\(p=0.03\\), per molt que \\(0.03\\in [0.025,0.047]\\): estam molt segurs que \\(p\\) està entre 0.025 i 0.047, però no tenim cap seguretat que valgui un valor concret entre aquests límits, només que està entre aquests límits. Hi ha dos tipus de mètodes bàsics de càlcul d’intervals de confiança a partir d’una mostra aleatòria: Paramètrics: Usant alguna fórmula basada en la distribució mostral de l’estimador Es basen en teoremes Només serveixen si la variable aleatòria \\(X\\) i la mostra aleatòria satisfan (aproximadament) les hipòtesis del teorema No paramètrics: El més emprat és el bootstrap: De la mostra, es prenen a l’atzar moltes (milers) mostres aleatòries simples de la mateixa mida que la mostra, es calcula l’estimador amb cada una d’aquestes mostres i s’usa el vector de resultats per estimar un interval de confiança (per exemple, podríem prendre com a IC 95% l’interval entre els quantils 0.025 i 0.975 d’aquest vector) Es pot usar sempre (si la mostra és aleatòria) Empra un procés aleatori: en cada execució sobre les mateixes dades pot donar un interval diferent El bootstrap és una eina molt poderosa per calcular intervals de confiança i, en general, per estimar la distribució mostral d’un estadístic. Tant, que a la pràctica ja comença a substituir els mètodes paramètrics. Emperò no fa miracles: si la mostra és petita o molt poc representativa de la població, un IC calculat amb el bootstrap servei de tan poc com un de calculat amb un mètode paramètric. 3.2 Exemple: Interval de confiança del 95% per a la mitjana d’una variable aleatòria normal Una de les fórmules més conegudes per a intervals de confiança és la següent: Si \\(X\\sim N(\\mu,\\sigma)\\) i en tenim una mostra aleatòria simple de mida \\(n\\), mitjana mostral \\(\\overline{X}\\) i variància mostral \\(\\widetilde{S}^2_X\\), un IC 95% per a \\(\\mu\\) és \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] on \\(t_{n-1,0.975}\\) indica el 0.975-quantil de la distribució \\(t_{n-1}\\). A alguns de vosaltres us hauran explicat a Batxillerat, o trobareu a llibres que consulteu, una fórmula per a l’IC 95% per a \\(\\mu\\) similar a aquesta, però canviant-hi la \\(\\widetilde{S}_X\\) per \\(\\sigma\\) i el \\(t_{n-1,0.975}\\) per \\(z_{0.975}\\). Aquesta altra fórmula només es pot fer servir si coneixeu la desviació típica poblacional \\(\\sigma\\), que a la pràctica, mai serà el cas. Per tant, per favor, oblidau-la. Anem a explicar d’on surt aquesta fórmula, ja que és un paradigma de com s’obtenen la majoria de les fórmules paramètriques per a intervals de confiança. Suposem doncs que \\(X\\sim N(\\mu,\\sigma)\\) i que en tenim una mostra aleatòria simple de mida \\(n\\), mitjana mostral \\(\\overline{X}\\) i variància mostral \\(\\widetilde{S}^2_X\\). En aquesta situació, sabem que \\[ T=\\frac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}} \\] té distribució t de Student amb \\(n-1\\) graus de llibertat, \\(t_{n-1}\\). Si podem trobar \\(A,B\\in \\mathbb{R}\\) tals que \\[ P(A\\leqslant T\\leqslant B)=0.95, \\] llavors: \\[ \\begin{array}{rl} 0.95 &amp; =P\\Bigg(A\\leqslant\\dfrac{\\overline{X}-\\mu}{\\widetilde{S}_{X}/\\sqrt{n}}\\leqslant B\\Bigg)\\\\[2ex] &amp; =P\\Bigg(A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\overline{X}-\\mu \\leqslant B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(-\\overline{X}+A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant-\\mu \\leqslant-\\overline{X}+B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)\\\\[2ex] &amp; =P\\Bigg(\\overline{X}-B\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu \\leqslant\\overline{X}-A\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg) \\end{array} \\] Com que \\(P(A\\leqslant T\\leqslant B)=0.95\\) significa que per al 95% de les mostres aleatòries simples de mida \\(n\\) el valor de \\(T\\) està entre \\(A\\) i \\(B\\), \\[ P\\Bigg(\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu \\leqslant\\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg)=0.95 \\] significa que per al 95% de les mostres aleatòries simples de mida \\(n\\) la \\(\\mu\\) cau dins l’interval \\[ \\Bigg[\\overline{X}-B\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}-A\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Per tant, això serà un IC 95% per a \\(\\mu\\). Ens falta trobar els \\(A,B\\) tals que \\(P(A\\leqslant T\\leqslant B)=0.95\\). Per trobar-los, emprarem quantils de la distribució de \\(T\\). Recordem que si indicam amb \\(t_{n-1,0.975}\\) el 0.975-quantil d’una \\(t_{n-1}\\), per definició tenim que \\[ P(T\\leqslant t_{n-1,0.975})=0.975 \\] i per la simetria de la \\(t\\), \\[ P(T\\leqslant-t_{n-1,0.975})=P(T\\geqslant t_{n-1,0.975})=0.025 \\] Per tant: \\[ \\begin{array}{l} P(-t_{n-1,0.975}\\leqslant T\\leqslant t_{n-1,0.975})\\\\ \\quad =P(T\\leqslant t_{n-1,0.975})-P(T\\leqslant-t_{n-1,0.975})\\\\ \\quad =0.975-0.025=0.95 \\end{array} \\] Així doncs, podem prendre \\[ A=-t_{n-1,0.975},\\quad B=t_{n-1,0.975} \\] i obtenim l’IC 95% per a \\(\\mu\\) anunciat: \\[ \\Bigg[\\overline{X}-t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}},\\ \\overline{X}+t_{n-1,0.975}\\cdot\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] L’escriurem \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Exemple 3.2 Fem un experiment per veure que, efectivament, aquesta fórmula “encerta”, en el sentit que conté la \\(\\mu\\), al voltant del 95% de les vegades. Al bloc de codi següent: generam una Població de 107 “individus” que segueixen una llei normal estàndard i en calculam la mitjana mu; definim una funció IC que calcula l’IC 95% per a la mitjana \\(\\mu\\) amb la fórmula anterior; prenem 200 mostres aleatòries simples de mida 50 de la nostra població i les aplicam aquesta funció, obtenint una matriu M de 200 columnes formades pels dos extrems dels intervals (l’inferior a la primera filera i el superior a la segona filera); finalment, miram quantes vegades hem encertat, és a dir, a quantes columnes de M la mitjana poblacional mu està entre l’entrada de la primera filera i la de la segona. set.seed(42) Poblacio=rnorm(10^7) mu=mean(Poblacio) IC=function(x){ n=length(x) mean(x)+qt(0.975,n-1)*sd(x)/sqrt(n)*c(-1,1)} M=replicate(200,IC(sample(Poblacio,50,replace=TRUE))) Encerts=length(which(mu&gt;=M[1,] &amp; mu&lt;=M[2,])) Encerts ## [1] 189 Hem encertat 189 vegades, és a dir, un 94.5% de les vegades. És aproximadament el que esperàvem. Si ho provau amb altres llavors d’aleatorietat obtendreu altres resultats, de vegades millors, de vegades pitjors. Per veure millor els encerts, dibuixam els intervals en un gràfic, on apareixeran en gris els que encerten i en vermell els que no encerten. plot(1,type=&quot;n&quot;,xlim=c(-0.8,0.8),ylim=c(0,200), xlab=&quot;Valors&quot;,ylab=&quot;Repeticions&quot;, main=&quot;200 IC 95%&quot;) seg.int=function(i){color=&quot;grey&quot;; if((mu&lt;M[1,i]) | (mu&gt;M[2,i])){color=&quot;red&quot;} segments(M[1,i],i,M[2,i],i,col=color,lwd=2)} sapply(1:200,FUN=seg.int) abline(v=mu,lwd=2) Atenció! De mitjana, un IC Q% NO conté el valor real del paràmetre en un (100-Q)% de les ocasions. Per exemple, de mitjana, un 5% de les vegades que calculam un IC 95%, el paràmetre poblacional no pertany a l’interval obtingut. Per tant, si calculam \\(n\\) IC 95% sobre mostres aleatòries simples independents, el nombre de vegades que l’interval resultant no contendrà el paràmetre poblacional seguirà una distribució binomial \\(B(n,0.05)\\). El gràfic següent dóna el valor de \\(P(X\\geqslant 1)\\) per a una variable aleatòria \\(X\\) de tipus \\(B(n,0.05)\\), per a \\(n=0,...,100\\), i per tant la probabilitat que si calculam \\(n\\) IC 95% sobre mostres aleatòries simples independents, almenys un d’ells no contengui el paràmetre poblacional desitjat. plot(1-dbinom(0,0:100,0.05),pch=20,xlab=&quot;n&quot;,ylab=&quot;Probabilitat&quot;, main=&quot;Probabilitat d&#39;algun èxit en una B(n,0.05)&quot;) Tornant a l’IC 95% per a \\(\\mu\\) d’una variable normal donat per la fórmula \\[ \\overline{X}\\pm t_{n-1,0.975}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] fixau-vos que: Està centrat en \\(\\overline{X}\\), per tant en cada càlcul estarà centrat en la mitjana mostral Tal i com l’hem calculat, la probabilitat que \\(\\mu\\) caigui fora d’aquest interval es reparteix per igual als dos costats: un 2.5% de les vegades la \\(\\mu\\) poblacional estarà a l’esquerra de l’extrem inferior i un 2.5% de les vegades estarà a la dreta de l’extrem superior Exemple 3.3 En un experiment hem mesurat el percentatge d’augment d’alcohol en sang a 40 persones després de prendre 4 canyes de cervesa. La mitjana i la desviació típica mostral d’aquests percentatges d’increment han estat \\[ \\overline{x}=41.2,\\quad \\widetilde{s}=2.1 \\] Per calcular un IC 95% per al percentatge mitjà d’augment, suposarem que la variable aleatòria d’interès (de la que volem estimar la mitjana) \\(X\\): “Prenem una persona i li mesuram el percentatge d’augment d’alcohol en sang després de prendre 4 canyes de cervesa” és normal i que la mostra que hem pres d’aquesta variable és aleatòria simple. Llavors, com que \\(t_{n-1,0.975}\\)=qt(0.975,39)=2.0227, un IC 95% és \\[ 41.2\\pm 2.0227\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67\\Rightarrow [40.53, 41.87] \\] Per tant, estimam amb un 95% de confiança que el percentatge mitjà d’augment d’alcohol en sang després de prendre 4 canyes de cervesa està entre el 40.53% i el 41.87%. Per calcular l’interval anterior hem suposat que la variable poblacional “Percentatge d’augment d’alcohol en sang després de prendre 4 canyes de cervesa” segueix una distribució normal. I si no fos normal? En aquest cas, com que \\(n=40\\), és gran pel Teorema 3.2 de la propera secció l’interval obtingut segueix essent (aproximadament) un interval de confiança del 95% per a \\(\\mu\\) Si \\(n\\) fos petit i \\(X\\) molt diferent d’una normal, no es pot usar aquesta fórmula i cal buscar-se la vida (per exemple, emprar el mètode de bootstrap) També hem suposat que era una mostra aleatòria simple. I si no ho és? Si és aleatòria, com que el nombre de persones que poden prendre 4 canyes de cervesa és pràcticament la població mundial, molt gran, a efectes pràctics la podem considerar simple. Però segur que no és aleatòria, sinó oportunista. No hem tret per sorteig de la llista de tota la població mundial, ni tan sols de la de Mallorca, 40 persones i les hem fetes prendre 4 cerveses, sinó que hem cercat voluntaris. En aquest cas no podem fer res per salvar la fórmula, i la seva validesa depèn de si la mostra de persones presa pot passar per aleatòria o no. 3.3 Interval de confiança per a la mitjana basat en la t de Student A partir d’ara, per tal d’evitar ambigüitats, a les fórmules hi expressarem el nivell de confiança dels intervals en tant per u, no en tant per cent; és a dir, com una proporció en comptes de com un percentatge. Per tant, parlarem d’intervals de confiança de nivell de confiança \\(q\\), amb \\(q\\) entre 0 i 1, en lloc d’intervals de confiança del \\(Q\\%\\) amb \\(Q=100q\\). Amb aquestes notacions, per exemple, els intervals de confiança del 95% seran intervals de confiança de nivell de confiança 0.95. La fórmula El mateix argument que abans, canviant 0.95 per \\(q\\) dóna: Teorema 3.1 Si \\(X\\sim N(\\mu,\\sigma)\\) i en prenem una mostra aleatòria simple de mida \\(n\\), un interval de confiança de nivell de confiança \\(q\\) (en tant per u) per a \\(\\mu\\) és \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Fixau-vos que als IC 95%, \\(q=0.95\\) i per tant \\((1+q)/2=1.95/2=0.975\\). Usant el Teorema Central del Límit i algunes aproximacions, tenim el següent resultat: Teorema 3.2 Sigui \\(X\\) una variable aleatòria qualsevol de mitjana poblacional \\(\\mu\\). Suposem que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) gran (diguem, de 40 o més elements). Llavors, un interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu\\) és aproximadament \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] L’aproximació del teorema anterior és millor com més gran sigui \\(n\\) o com més propera a una normal sigui la variable poblacional \\(X\\). En resum: Podem emprar la fórmula per a l’interval de confiança de nivell de confiança \\(q\\) per a la mitjana poblacional basada en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] quan la variable poblacional és normal o quan la mostra aleatòria simple és gran. Exemple 3.4 L’empresa RX-print ofereix una impressora de radiografies d’altíssima qualitat. En la seva publicitat afirma que els seus cartutxos imprimeixen una mitjana de 500 radiografies amb l’especificació: Dades tècniques: Mostra de mida \\(n=25\\), població suposada normal, nivell de confiança del 90% Uns radiòlegs desitgen comprovar aquestes afirmacions i prenen una mostra de cartutxos a l’atzar de mida \\(n=25\\), obtenint una mitjana de \\(\\overline{x}=518\\) radiografies i una desviació típica mostral \\(\\widetilde{s}=39.9\\). Amb aquesta mostra, la mitjana poblacional anunciada pel fabricant cau dins l’interval de confiança del 90%? La variable aleatòria d’interès és \\(X\\) és “Prenem un cartutxo d’aquesta empresa i miram el nombre de radiografies que permet imprimir”, de mitjana \\(\\mu\\) per a la qual volem calcular un IC 90%. Suposarem que la variable \\(X\\) és normal, perquè l’empresa ho suposa a les dades tècniques. Per tant podem emprar la fórmula \\[ \\overline{x}\\pm t_{n-1,(q+1)/2} \\frac{\\widetilde{s}}{\\sqrt{n}} \\] on \\(n=25\\), \\(\\overline{x}=518\\), \\(\\widetilde{s}=39.9\\), \\(q=0.9\\), \\((q+1)/2=0.95\\) i \\(t_{24,0.95}\\)=qt(0.95,24)\\(=1.71\\). Operant: \\[ 518\\pm 1.71\\times \\frac{39.9}{\\sqrt{25}}\\Rightarrow 518\\pm 13.65\\Rightarrow [504.35,531.65] \\] Tenim, doncs, un 95% de confiança que el nombre mitjà de radiografies per cartutxo està entre 504.35 i 531.65, i en particular que no és 500 (però en benefici del consumidor: estam molt segurs que és més gran que 500). Exemple 3.5 A l’exemple anterior hem suposat que la variable aleatòria era normal. Què passaria si fos molt diferent d’una normal? Com que \\(n=25\\) no és prou gran, en principi no podríem aplicar la fórmula de l’interval de confiança basada en la t de Student. Emprarem el mètode del bootstrap, per a la qual cosa necessitam tenir les dades originals, i no només els seus estadístics. Tenim aquestes dades en el vector Radios següent: Radios=c(485,511,509,509,561,529,458,532,545,546, 503,577,547,477,507,548,480,444,461,573, 513,604,542,501,488) mean(Radios) ## [1] 518 sd(Radios) ## [1] 39.89987 Prenem 5000 mostres aleatòries simples de mida 25 (la mateixa mida que el conjunt de dades original) de les dades i calculam la mitjana de cada mostra; fixam la llavor d’aleatorietat per que el càlcul sigui reproduïble: set.seed(100) Simulacions=replicate(5000,mean(sample(Radios,25,rep=TRUE))) Ara prenem com a IC 90% l’interval que tanca el 90% de valors centrals d’aquest vector de mitjanes mostrals, és a dir, l’interval que va del quantil 0.05 al quantil 0.95 d’aquest vector de mitjanes: quantile(Simulacions,c(0.05,0.95)) ## 5% 95% ## 504.96 530.92 Obtenim l’interval [504.96,530.92]: amb la fórmula basada en la t de Student, havíem obtingut l’interval [504.35,531.65]. Algunes consideracions Observau que l’estructura de l’interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu\\) donat al Teorema 3.2 és \\[\\begin{align} &amp; \\text{estimador}\\nonumber\\\\ &amp; \\qquad \\pm \\frac{1+q}{2}\\text{-quantil de la distr. mostral}\\times \\text{error típic de l&#39;estimació} \\tag{3.1} \\end{align}\\] Aquesta estructura és molt típica (tot i que, com veurem, no tots els intervals de confiança paramètrics tenen aquesta forma) i satisfà que: L’interval de confiança està centrat en el valor de l’estimador La “probabilitat d’equivocar-nos” es reparteix per igual als dos costats de l’interval: una fracció \\(q/2\\) de les vegades el paràmetre estarà a l’esquerra de l’extrem inferior i una fracció \\(q/2\\) de les vegades estarà a la dreta de l’extrem superior A més, tenim que: Per a una mateixa mostra i una mateixa fórmula (paramètrica) per calcular l’interval de confiança, si el nivell de confiança creix, l’interval s’eixampla Això és general, per a tots els intervals de confiança paramètrics. La idea intuitiva és que, per estar més segurs que un interval conté un valor, l’interval ha de ser més ample. A un interval de confiança amb l’estructura (3.1), el motiu matemàtic és que si \\(q\\) creix, el quantil d’ordre (1+\\(q\\))/2 de la distribució mostral creix. Per exemple, a l’Exemple 3.3, teníem \\(n=40\\), \\(\\overline{x}=41.2\\) i \\(\\widetilde{s}=2.1\\): L’IC 95% té \\(q=0.95\\), per tant \\(t_{n-1,(1+q)/2}=t_{39,0.975}=2.02\\), i donava \\[ 41.2\\pm 2.02\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.67 \\] L’IC 99% té \\(q=0.99\\), per tant \\(t_{n-1,(1+q)/2}=t_{39,0.995}=2.71\\), i dóna \\[ 41.2\\pm 2.71\\cdot \\frac{2.1}{\\sqrt{40}}\\Rightarrow 41.2\\pm 0.9 \\] més ample Però si canviam de mostra (o de fórmula, si n’hi ha més d’una) per calcular l’interval de confiança, pot passar qualsevol cosa. Amb R La funció t.test(X,conf.level=...)$conf.int calcula l’interval de confiança basat en la t de Student per a la \\(\\mu\\) de la variable aleatòria de la que el vector X n’és una mostra. El paràmetre conf.level permet especificar el nivell de confiança (en tant per u). El seu valor per defecte és 0.95, així que per calcular un IC 95% no cal especificar-lo. Per exemple, l’IC 90% per al nombre mitjà de radiografies per cartutxo de l’Exemple 3.4 es calcularia amb t.test(Radios,conf.level=0.9)$conf.int ## [1] 504.3472 531.6528 ## attr(,&quot;conf.level&quot;) ## [1] 0.9 Càlcul de la mida de la mostra per fixar l’error Recordem que l’interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu\\) basat en la t de Student \\[ \\overline{X}\\pm t_{n-1,(1+q)/2}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] és simètric i centrat en \\(\\overline{X}\\). La seva amplada és la diferència entre els seus extrems \\[ 2t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] El marge d’error (error, precisió) \\(M\\) en l’estimació de \\(\\mu\\) per mitjà d’aquest interval de confiança és el que sumam i restam a \\(\\overline{X}\\) per obtenir l’interval, és a dir, la meitat de la seva amplada: \\[ M=t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}} \\] Fixau-vos que si estimam que el valor de \\(\\mu\\) és \\(\\overline{X}\\), l’error que cometem és \\(|\\overline{X}-\\mu|\\). Aleshores, si el nostre interval de confiança per a \\(\\mu\\) és \\(\\overline{X}\\pm M\\) i l’encertam (és a dir, aquest interval conté el valor real de \\(\\mu\\)), aleshores l’error que cometem quan diem que el valor de \\(\\mu\\) és \\(\\overline{X}\\) és com a màxim \\(M\\), perquè si \\(\\mu\\in [\\overline{X}-M,\\overline{X}+M]\\), aleshores \\(|\\overline{X}-\\mu|\\leqslant M\\). Una pregunta típica a l’hora de planejar un experiment és quina ha de ser la mida de la mostra que hem de prendre per que el marge d’error en estimar \\(\\mu\\) amb un nivell de confiança donat sigui com a màxim un cert valor desitjat \\(M_{max}\\). És a dir, volem trobar la \\(n\\) més petita tal que \\[ t_{n-1,(1+q)/2}\\times \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant M_{max}. \\] Però fixau-vos que en aquesta desigualtat la \\(n\\) hi apareix al quantil i a l’error típic, i a més la \\(\\widetilde{S}_X\\) depèn de la mostra. El que farem per respondre la pregunta serà fer algunes trampes: Aproximarem la t de Student per una normal estàndard (ja que segurament la \\(n\\) haurà de ser gran): \\[ t_{n-1,(1+q)/2}\\rightsquigarrow z_{(1+q)/2} \\] Estimarem el valor de \\(\\widetilde{S}_X\\) mitjançant la desviació típica mostral \\(\\widetilde{S}_0\\) d’una prova pilot (un experiment anterior, realitzat per nosaltres o publicat per qualcú altre a qualque lloc de confiança) D’aquesta manera, aproximam l’error \\(M\\) per mitjà de \\[ M\\approx z_{(1+q)/2}\\times \\frac{\\widetilde{S}_0}{\\sqrt{n}} \\] I ara si imposam que \\(M\\leqslant M_{max}\\), ja podem aïllar la \\(n\\): \\[ z_{(1+q)/2}\\times \\frac{\\widetilde{S}_0}{\\sqrt{n}}\\leqslant M_{max}\\Longrightarrow n\\geqslant\\left(\\frac{ z_{(1+q)/2}\\cdot \\widetilde{S}_0}{M_{max}} \\right)^2 \\] En resum: Teorema 3.3 Per estimar la \\(\\mu\\) amb nivell de confiança \\(q\\) amb un marge d’error com a màxim \\(M_{max}\\) mitjançant la fórmula basada en la t de Student, prendrem una mostra de mida \\[ n\\geqslant\\left(\\frac{ z_{(1+q)/2}\\cdot \\widetilde{S}_0}{M_{max}} \\right)^2, \\] on \\(\\widetilde{S}_0\\) és la desviació típica mostral obtinguda en una estimació anterior de \\(\\mu\\) (en una prova pilot). Naturalment, quan després prenguem una mostra de mida \\(n\\) que satisfaci aquesta condició, pot passar qualsevol cosa, ja que hem emprat els resultats d’una mostra per estimar la desviació típica d’una altra mostra i a més hem aproximat els quantils de la t de Student per els d’una normal estàndard, que són més petits. Però almenys haurem fet tot el que haurem pogut per fitar l’error dins el marge desitjat. Exemple 3.6 A l’Exemple 3.3, hem emprat una mostra de \\(n=40\\) persones, amb \\(\\overline{x}=41.2\\) i \\(\\widetilde{s}=2.1\\), i l’error ha estat \\[ t_{0.975,39}\\cdot \\frac{2.1}{\\sqrt{40}}=0.67 \\] Quin és el nombre mínim de persones que hauríem hagut d’emprar per estimar la mitjana amb un nivell de confiança del 95% i un error de (com a màxim) 0.5? És a dir, quin el nombre mínim de persones que hauríem hagut d’emprar per obtenir un IC 95% d’amplada (com a màxim) 1? Empram l’exemple com a prova pilot: \\[ n\\geqslant\\left(\\frac{ z_{(1+q)/2}\\cdot \\widetilde{s}}{M_{max}} \\right)^2= \\left(\\frac{1.96\\cdot 2.1}{0.5} \\right)^2=67.77 \\] El valor de \\(n\\) més petit que satisfà aquesta condició és 68, per tant aquest és el nombre mínim de persones que hauríem hagut d’emprar per esperar obtenir un IC 95% d’amplada (com a màxim) 1. 3.4 Intervals de confiança per a proporcions Suposem que tenim una variable Bernoulli \\(X\\) amb probabilitat d’èxit \\(p_X\\) desconeguda. Volem calcular un interval de confiança per a \\(p_X\\). Per fer-ho, prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\), amb nombre d’èxits \\(S\\) i per tant proporció mostral d’èxits \\(\\widehat{p}_{X}=S/n\\) Explicarem tres mètodes per calcular aquest interval de confiança: El mètode exacte de Clopper-Pearson, que es pot aplicar sempre però sol donar intervals de confiança més amples del necessari. El mètode aproximat de Wilson, que es pot emprar quan la mostra és gran, posem de mida 40 o més, i es basa en el fet que, pel Teorema Central del Límit, la proporció mostral de mostres aleatòries simples segueix una distribució aproximadament normal. El mètode aproximat de Laplace, que és una simplificació del mètode de Wilson, però només es pot emprar quan la mostra és bastant més gran, posem de mida 100 o més, i la proporció mostral \\(\\widehat{p}_{X}\\) no és molt propera a 0 o a 1. És el mètode més clàssic i conegut. Mètode “exacte” de Clopper-Pearson Aquest mètode es basa en el fet que el nombre d’èxits \\(S\\) en mostres aleatòries simples de mida \\(n\\) de \\(X\\) segueix una distribució binomial \\(B(n,p_X)\\). Raonant de manera similar a com obteníem l’interval per a \\(\\mu\\) basat en la t de Student (us estalviarem els detalls) arribam a la fórmula següent: Teorema 3.4 Un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) és \\([p_0,p_1]\\), on (recordau que \\(n\\) indica la mida de la mostra i \\(S\\) el nombre d’èxits) \\(p_0\\) és la solució de l’equació \\[ \\sum_{k=S}^n\\binom{n}{k}p_0^k(1-p_0)^{n-k}= \\frac{1-q}{2} \\] \\(p_1\\) és la solució de l’equació \\[ \\sum_{k=0}^S\\binom{n}{k}p_1^k(1-p_1)^{n-k}= \\frac{1-q}{2} \\] Calcular a mà aquest interval és intractable, i en general dóna més ample del necessari (degut a la natura discreta de la distribució binomial, que només pren valors nombres naturals), però es pot emprar amb mostres aleatòries simples de qualsevol mida ja que empra que el nombre d’èxits \\(S\\) en mostres aleatòries simples de mida \\(n\\) de \\(X\\) segueix una distribució binomial i això sempre és veritat. Per calcular-lo amb R, podeu emprar la funció del paquet epitools binom.exact(S,n,conf.level=...) on Sés el nombre d’èxits, n la mida de la mostra, i conf.level el nivell de confiança en tant per u, que per defecte val 0.95. Exemple 3.7 De 10 pacients tractats amb un medicament, 2 s’han curat. Quin seria un IC 95% per a la proporció p de pacients que aquest medicament cura? Emprarem el mètode de Clopper-Pearson: library(epitools) round(binom.exact(2,10),3) ## x n proportion lower upper conf.level ## 1 2 10 0.2 0.025 0.556 0.95 Dóna l’interval [0.025,0.556]. Estimam per tant amb una confiança del 95% que aquest medicament cura entre el 2.5% i el 55.6% dels pacients. Sí, aquest interval és molt ample. La culpa no és del mètode de Clopper-Pearson, és de la mida petita de la mostra. L’interval de Clopper-Pearson té l’inconvenient que, en general, no està centrat en \\(\\widehat{p}_{X}\\). Per exemple, el centre de l’interval anterior és \\((0.025+0.556)/2= 0.29\\), diferent de \\(\\widehat{p}_X=0.2\\) Mètode de Wilson Suposem ara que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) gran (posem, de 40 o més subjectes) i proporció mostral d’èxits \\(\\widehat{p}_{X}\\). En aquestes condicions, pel Teorema Central del Límit, \\[ Z=\\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\approx N(0,1) \\] Per tant \\[ P\\Big(-z_{(1+q)/2}\\leqslant\\dfrac{\\widehat{p}_{X}-p_X} {\\sqrt{\\frac{p_X(1-p_X)}{n}}}\\leqslant z_{(1+q)/2}\\Big)=q \\] Aïllant \\(p_X\\) obtenim: Teorema 3.5 Si la mida \\(n\\) de la mostra és gran, un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) és (aproximadament): \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/{2}}^2}{2n}\\pm z_{(1+q)/{2}}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(1+q)/{2}}^2}{4n^2}}}{1+\\frac{z_{(1+q)/{2}}^2}{n}} \\] Amb R es calcula amb la funció binom.wilson(x,n,conf.level=...) del paquet epitools, amb la mateixa sintaxi que binom.exact. Aquest interval també té l’inconvenient que, si us hi fixau, no està centrat en \\(\\widehat{p}_{X}\\): el seu centre és \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(1+q)/{2}}^2}{2n}}{1+\\frac{z_{(1+q)/{2}}^2}{n}} \\] Mètode de Laplace Suposem finalment que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) encara més gran i \\(\\widehat{p}_{X}\\) enfora de 0 i 1. Per fixar idees, suposem que \\[ n\\geqslant 100,\\ n\\widehat{p}_{X}\\geqslant 10,\\ n(1-\\widehat{p}_{X})\\geqslant 10 \\] En aquest cas, a la fórmula de l’interval de Wilson podem suposar que els termes \\(z_{(1+q)/{2}}^2/n\\) són (aproximadament) 0 i obtenim la fórmula següent: Teorema 3.6 En les condicions explicades, un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) és (aproximadament): \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] Amb R es calcula amb la funció binom.approx(x,n,conf.level=...) del paquet epitools, amb la mateixa sintaxi que binom.exact. Aquesta fórmula és la més popular, amb més de 200 anys de rodatge. Us heu de saber la fórmula de Laplace, no cal saber les fórmules dels altres dos intervals. Més exemples Exemple 3.8 En una mostra aleatòria de 500 famílies amb nins en edat escolar es va trobar que 340 introduïen fruita diàriament en la dieta dels seus fills. A partir d’aquestes dades, volem calcular un interval de confiança del 95% per a la proporció real de famílies d’aquesta ciutat amb nins en edat escolar que incorporen fruita fresca cada dia en la dieta dels seus fills. Diguem \\(X\\) a la variable aleatòria “Prenem una família amb nins en edat escolar i miram si inclou diàriament fruita a la dieta dels fills”. És Bernoulli, diguem \\(p_X\\) a la seva probabilitat d’èxit: la probabilitat que una família amb nins en edat escolar inclogui diàriament fruita a la dieta dels fills. Cercam un interval de confiança del 95% per a \\(p_X\\). Com que \\(n=500\\geqslant 100\\), \\(n\\widehat{p}_X=340\\geqslant 10\\) i \\(n(1-\\widehat{p}_X)=160\\geqslant 10\\), podem emprar la fórmula de Laplace \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] amb \\(n=500\\), \\(\\widehat{p}_{X}=340/500=0.68\\) i \\(z_{(q+1)/2}=z_{0.975}=1.96\\). Dóna \\[ 0.68\\pm 1.96\\sqrt{\\frac{0.68(1-0.68)}{500}}\\Rightarrow [0.639,0.721] \\] Amb R: round(binom.approx(340,500), 3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.639 0.721 0.95 Amb els altres mètodes, que també podríem aplicar en aquest cas, obtenim els intervals: round(binom.exact(340,500),3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.637 0.721 0.95 round(binom.wilson(340,500),3) ## x n proportion lower upper conf.level ## 1 340 500 0.68 0.638 0.719 0.95 En resum, estimam que entre aproximadament un 64% i un 72% de les famílies d’aquesta ciutat amb nins en edat escolar inclouen diàriament fruita fresca en la dieta dels seus fills. Quan podem calcular més d’un interval per a \\(p_X\\), quin calculam? D’entrada cal dir que si podem calcular més d’un interval, segurament donaran molt parescuts, com heu pogut comprovar a l’exemple anterior. A més, recordau que les tres fórmules només ens donen “un nivell de confiança q” si s’apliquen a mostres aleatòries simples, i les nostres mostres gairebé sempre seran oportunistes, cas en el qual, si ens posam perepunyetes, no en podem aplicar cap. Però en tot cas, si no filam molt prim i podem triar, hem de tenir en compte que: L’interval de Clopper-Pearson és exacte, no empra cap aproximació, però: Tendeix a donar un interval més ample del necessari No està centrat en la proporció mostral Només és un interval “exacte” si la mostra és aleatòria simple, cosa que gairebé sempre serà fals (com a molt, serà “aproximadament” aleatòria simple) Com que no es pot calcular “a mà”, no és molt popular L’interval de Wilson és aproximat, fa servir l’aproximació a la normal donada pel Teorema Central del Límit. Això no és un gran emperò, pequè tanmateix segurament la mostra serà com a molt “aproximadament” aleatòria simple. Ara bé, tampoc no està centrat en la proporció mostral, i ens agrada poder donar els intervals en la forma “tal més menys qual” perquè d’aquesta manera donam l’estimació puntual i el marge d’error. L’interval de Laplace és molt aproximat, però: Forma part de la cultura general del científic, tothom el coneix És l’únic centrat en la proporció mostral Exemple 3.9 En un assaig d’un nou tractament de quimioteràpia, en una mostra de \\(n\\) malalts tractats, cap desenvolupà càncer testicular com a efecte secundari. Quin seria un interval de confiança al 95% per a la proporció de malalts tractats amb aquesta quimio que desenvolupen càncer testicular? Per calcular-lo podem emprar el mètode de Clopper-Pearson i, si \\(n\\) és gran, el de Wilson. No podem emprar la fórmula de Laplace, perquè \\(\\widehat{p}_X=0\\). Pel que fa a Clopper-Pearson, aquest és un dels pocs casos que admeten solució analítica senzilla: dóna l’interval \\[ \\Big[0,1-\\Big(\\frac{1-q}{2}\\Big)^{1/n}\\Big] \\] que, si \\(q=0.95\\), queda \\[ [0,1-0.025^{1/n}]. \\] Per exemple, si \\(n=40\\) binom.exact(0,40) ## x n proportion lower upper conf.level ## 1 0 40 0 0 0.0880973 0.95 1-0.025^(1/40) ## [1] 0.0880973 Si podem emprar el mètode de Wilson, la fórmula \\[ \\frac{\\widehat{p}_{X}+\\frac{z_{(q+1)/2}^2}{2n}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X}(1-\\widehat{p}_{X})}{n}+\\frac{z_{(q+1)/2}^2}{4n^2}}}{1+\\frac{z_{(q+1)/2}^2}{n}} \\] amb \\(\\widehat{p}_{X}=0\\) i \\(z_{(1+q)/2}=1.96\\) dóna \\[ \\frac{\\frac{1.96^2}{2n}\\pm 1.96\\sqrt{\\frac{1.96^2}{4n^2}}}{1+\\frac{1.96^2}{n}}\\Longrightarrow \\Big[0,\\frac{1.96^2}{n+1.96^2}\\Big] \\] Per exemple, un altre cop amb \\(n=40\\) binom.wilson(0,40) ## x n proportion lower upper conf.level ## 1 0 40 0 6.330897e-18 0.0876216 0.95 qnorm(0.975)^2/(40+qnorm(0.975)^2) ## [1] 0.0876216 Quan s’ha de calcular “a ull” un interval de confiança del 95% per a una probabilitat \\(p_X\\) a partir d’una mostra aleatòria simple on no hi ha hagut cap èxit, sovint es fa servir la regla següent: Regla del 3: Quan en una mostra aleatòria simple de mida \\(n\\) d’una variable aleatòria de Bernoulli de paràmetre \\(p_X\\) no hi trobam cap èxit, un IC 95% per a \\(p_X\\) va, aproximadament, de 0 a \\(3/n\\). Amb aquesta regla, en el nostre exemple amb \\(n=40\\) obtendríem l’interval [0,3/40]=[0,0.075], no molt enfora del [0,0.088] que hem obtingut amb els altres dos mètodes. Per veure com la regla del 3 aproxima l’interval de Clopper-Pearson, el gràfic següent mostra els valors \\(3/n\\) i l’extrem superior de l’IC 95% de Clopper-Pearson a partir d’una mostra de mida \\(n\\) amb 0 èxits: f=function(n){binom.exact(0,n)$upper} plot(1:100,sapply(1:100,f),pch=20,cex=0.7,xlab=&quot;n&quot;,ylab=&quot;Extrem superior&quot;, main=&quot;Extrem superior d&#39;un IC 95% en cas de 0 èxits&quot;) curve(3/x,col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,lty=c(NA,1),pch=c(20,NA), legend=c(&quot;Clopper-Pearson&quot;,&quot;Regla del 3&quot;),col=c(&quot;black&quot;,&quot;red&quot;),cex=0.7) El gràfic següent mostra els valors \\(3/n\\) i els extrems superiors dels IC 95% de Clopper-Pearson i de Wilson a partir d’una mostra de mida \\(n\\) (\\(n\\geqslant 40\\) per als intervals de confiança de Wilson) amb 0 èxits: f=function(n){binom.exact(0,n)$upper} plot(1:100,sapply(1:100,f),pch=20,cex=0.5,xlab=&quot;n&quot;,ylab=&quot;Extrem superior&quot;, main=&quot;Extrem superior d&#39;un IC 95% en cas de 0 èxits&quot;) curve(3/x,col=&quot;red&quot;,lwd=1.5,add=TRUE) points(40:100,3.84/(40:100+3.84),pch=20,cex=0.5,col=&quot;blue&quot;) legend(&quot;topright&quot;,lty=c(NA,NA,1),pch=c(20,20,NA), legend=c(&quot;Clopper-Pearson&quot;,&quot;Wilson&quot;,&quot;Regla del 3&quot;),col=c(&quot;black&quot;,&quot;blue&quot;,&quot;red&quot;),cex=0.7) Els extrems superiors dels intervals de Clopper-Pearson i Wilson se superposen en aquest darrer gràfic. Exemple 3.10 En un assaig d’un tractament de quimioteràpia, en una mostra de 100 pacients tractats, 25 desenvoluparen càncer testicular secundari. Volem calcular un IC 95% per a la proporció de pacients tractats amb aquesta quimioteràpia que desenvolupen càncer testicular. En aquest cas podem emprar els tres mètodes: round(binom.exact(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1688 0.3466 0.95 round(binom.wilson(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1755 0.343 0.95 round(binom.approx(25,100),4) ## x n proportion lower upper conf.level ## 1 25 100 0.25 0.1651 0.3349 0.95 Concloem, amb un nivell de confiança del 95%, que entre aproximadament un 17% i un 34% dels pacients tractats amb aquesta quimioteràpia desenvolupen càncer testicular. Càlcul de la mida de la mostra per a fixar l’error L’error de l’interval de confiança de Laplace és \\[ M= z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}} \\] perquè l’interval de confiança de Laplace és \\(\\widehat{p}_X\\pm M\\) i per tant, si conté el valor real de \\(p_X\\), l’error \\(|\\widehat{p}_X-p_X|\\) que cometem quan diem que el valor de \\(p_X\\) és \\(\\widehat{p}_X\\) és com a màxim \\(M\\). No podem determinar la mida de la mostra a fi que l’interval de confiança tingui un error màxim sense conèixer \\(\\widehat{p}_{X}\\), que no coneixem sense una mostra. Però en el cas de l’interval de Laplace per a una proporció, podem donar un \\(n\\) que garanteixi una amplada màxima donada valgui el que valgui \\(\\widehat{p}_{X}\\in [0,1]\\). Fixau-vos que la funció \\(y=p (1-p)\\), amb \\(p\\in [0,1]\\), és una paràbola còncava amb vèrtex al punt \\(p=0.5\\) curve(x*(1-x),xlim=c(0,1),xlab=&quot;p&quot;,ylab=&quot;&quot;) abline(v=0.5,lty=&quot;dashed&quot;) Per tant, el seu màxim s’assoleix a \\(p=0.5\\). Així, doncs \\[ \\widehat{p}_{X} (1-\\widehat{p}_{X})\\leqslant 0.5(1-0.5)=0.5^2\\text{ per a tot $\\widehat{p}_X\\in[0,1]$} \\] i per tant \\[ \\begin{array}{l} \\displaystyle M=z_{(q+1)/2} \\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\\\ \\qquad\\displaystyle \\leqslant z_{(q+1)/2}\\sqrt{\\frac{0.5^2}{n}}=\\frac{0.5z_{(q+1)/2}}{\\sqrt{n}}=\\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\end{array} \\] D’aquesta manera, si prenem \\(n\\) tal que \\[ \\frac{z_{(q+1)/2}}{2\\sqrt{n}}\\leqslant M_{max} \\] aleshores segur que \\(M\\leqslant M_{max}\\), valgui el que valgui \\(\\widehat{p}_{X}\\). Per tant, el que farem serà calcular la \\(n\\) per obtenir un error com a màxim \\(M_{max}\\) en el cas més desfavorable: quan l’interval és el més ample possible, és a dir, suposant que \\(\\widehat{p}_{X}=0.5\\): \\[ M_{max}\\geqslant\\frac{z_{(q+1)/2}}{2\\sqrt{n}} \\Rightarrow n\\geqslant\\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2 \\] En resum: Teorema 3.7 Si \\[ n\\geqslant\\left(\\frac{z_{(q+1)/2}}{2\\cdot M_{max}}\\right)^2, \\] l’error de l’interval de Laplace calculat amb una mostra de mida \\(n\\) sempre serà com a molt \\(M_{max}\\). Exemple 3.11 Quina és la mida més petita d’una mostra que ens garanteix un error de com a màxim 0.05 en estimar una proporció \\(p_X\\) emprant un interval de confiança de Laplace del 95%? Pel teorema anterior, per garantir un error de 0.05 en calcular un IC 95% per una proporció \\(p_X\\) emprant la fórmula de Laplace, hem d’emprar una mostra de mida \\(n\\) tal que \\[ n\\geqslant\\Bigg(\\frac{z_{(1+q)/2}}{2M_{max}}\\Bigg)^2=\\Bigg(\\frac{1.96}{0.1}\\Bigg)^2=384.16 \\] La mida més petita que satisfà aquesta condició és \\(n=385\\). La resposta correcta no és 384, per molt que 384.16 s’arrodoneixi a 384. Fixau-vos que 384 no és més gran que 384.16. Observau tres coses: El valor de \\(n\\) només depèn de la precisió i del nivell de confiança, no de la natura de l’estudi ni de proves pilot Tal i com hem trobat la \\(n\\), estam segurs que si prenem una mostra com a mínim d’aquesta mida, el marge d’error de l’interval de confiança de Laplace serà com a màxim \\(M_{max}\\) (la seva amplada serà com a màxim \\(2M_{max}\\)), sigui quina sigui la mostra. És de les poques vegades que podem estar segurs de qualque cosa en estadística. El teorema anterior és per l’amplada de l’interval de Laplace, però la \\(n\\) segurament us sortirà molt gran i en aquest cas l’interval de Laplace aproxima molt bé els altres dos intervals. 3.5 Intervals de confiança per a la variància d’una variable normal Suposem que tenim una variable normal \\(X\\sim N(\\mu,\\sigma)\\). Volem trobar un IC 95% per a la seva variància \\(\\sigma^2\\) (o la seva desviació típica \\(\\sigma\\)). Per calcular-lo, prenem una mostra aleatòria simple de mida \\(n\\), de variància mostral \\(\\widetilde{S}^2_X\\). Recordau que, en aquestes condicions, \\[ \\frac{(n-1) \\widetilde{S}_{X}^2}{\\sigma^2} \\] té distribució \\(\\chi^2_{n-1}\\) Podem aprofitar aquest fet per obtenir intervals de confiança per a \\(\\sigma^2\\): Teorema 3.8 Si la variable \\(X\\) és normal, un interval de confiança de nivell de confiança \\(q\\) per a \\(\\sigma^2\\) és \\[ \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}, \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right], \\] on \\(\\chi_{n-1,r}^2\\) és el \\(r\\)-quantil de la distribució \\(\\chi_{n-1}^2\\) La justificació d’aquesta fórmula és la usual: com que \\[ \\begin{array}{l} \\displaystyle P(\\chi_{n-1}^2\\leqslant\\chi_{n-1,(1-q)/2}^2)=\\frac{1-q}{2}\\\\ \\displaystyle P(\\chi_{n-1}^2\\geqslant\\chi_{n-1,(1+q)/2}^2)=1-\\frac{1+q}{2}=\\frac{1-q}{2}, \\end{array} \\] tenim que \\[ \\begin{array}{l} q=P\\left(\\chi_{n-1,(1-q)/2}^2\\leqslant\\chi_{n-1}^2\\leqslant \\chi_{n-1,(1+q)/2}^2\\right)\\\\[2ex] \\quad\\displaystyle =P\\left(\\chi_{n-1,(1-q)/2}^2\\leqslant\\frac{(n-1) \\widetilde{S}_{X}^2}{\\sigma^2}\\leqslant \\chi_{n-1,(1+q)/2}^2 \\right)\\\\[2ex] \\quad\\displaystyle = P\\left(\\frac{(n-1) \\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}\\leqslant\\sigma^2\\leqslant\\frac{ (n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right) \\end{array} \\] Fixau-vos que aquest interval de confiança per \\(\\sigma^2\\) no està centrat en \\(\\widetilde{S}_{X}^2\\) ni en \\({S}_{X}^2\\). A més, com que \\(\\chi_{n-1}^2\\) no és simètrica, s’han de calcular els dos quantils \\(\\chi_{n-1,(1-q)/2}^2\\) i \\(\\chi_{n-1,(1+q)/2}^2\\), perquè no hi ha cap relació entre ells que doni el valor d’un d’ells a partir del de l’altre. Exemple 3.12 Un índex de qualitat d’un reactiu químic és la variabilitat en el temps que triga a actuar: es demana que aquest temps sigui aproximadament constant, és a dir, que tengui una desviació típica petita. Hem realitzat 30 proves en les quals hem mesurat el temps d’actuació d’un determinat reactiu, i a partir dels resultats volem calcular un IC 95% per a la desviació típica del seu temps d’actuació. Tenim els resultats guardats en el vector següent: Temps=c(12,13,13,14,14,14,15,15,16,17,17,18,18,19,19, 25,25,26,27,30,33,34,35,40,40,51,51,58,59,83) Per ara suposarem que la distribució del temps d’actuació d’aquest reactiu és (aproximadament) normal. Més endavant estudiarem tècniques per determinar (amb un cert nivell de confiança) si podem acceptar que una mostra prové d’una variable normal. Continuem. Com que la variable que ens dóna el temps és (aproximadament) normal, podem emprar la fórmula per a l’IC 95% per a \\(\\sigma^2\\) anterior: \\[ \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1+q)/2}^2}, \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,(1-q)/2}^2} \\right] \\] on: \\(n=\\)length(Temps)\\(=30\\) \\(\\widetilde{S}_X^2=\\)var(Temps)\\(=301.55\\) \\(q=0.95\\), per tant \\(\\chi_{n-1,(1+q)/2}^2=\\)qchisq(0.975,29)\\(=45.72\\) i \\(\\chi_{n-1,(1-q)/2}^2=\\)qchisq(0.025,29)\\(=16.05\\) Obtenim l’interval: \\[ \\left[ \\frac{29\\cdot 301.55}{45.72}, \\frac{29\\cdot 301.55}{16.05}\\right]= [191.26, 544.96] \\] Aquest interval és per a la variància! Per obtenir un interval de confiança per a la desviació típica, prenem arrels quadrades dels extrems: \\[ [\\sqrt{191.26}, \\sqrt{544.96}]=[13.83,23.34] \\] Per tant la variabilitat dels temps d’actuació d’aquest reactiu és molt gran. Comparau aquest interval amb l’IC 95% per al seu temps mitjà d’actuació: round(t.test(Temps)$conf.int,2) ## [1] 21.88 34.85 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 L’extrem superior de l’IC 95% per a la desviació típica és més gran que l’extrem inferior d’aquest IC 95% per a la mitjana. Amb R, aquest interval de confiança amb nivell de confiança \\(q\\) per a la variància es pot calcular amb la funció varTest(X,conf.level=...)$conf.int del paquete EnvStats, on X és el vector que conté la mostra i conf.level indica el nivell de confiança en tant per u, que per defecte és igual a 0.95. Així, l’interval de confiança que ens demanàvem a l’exemple anterior es calcularia amb library(EnvStats) varTest(Temps)$conf.int ## LCL UCL ## 191.2627 544.9572 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 Que no, que aquest és el de la variància! L’IC 95% per a la desviació típica és: sqrt(varTest(Temps)$conf.int) ## LCL UCL ## 13.82977 23.34432 ## attr(,&quot;conf.level&quot;) ## [1] 0.95 L’interval per a la variància basat en la distribució \\(\\chi^2\\) només és vàlid si la variable poblacional és (aproximadament) normal. En cas que no poguem acceptar que ho és, el millor és emprar un mètode no paramètric, com per exemple el bootstrap. Exemple 3.13 Anem a calcular un IC 95% per a la desviació típica del temps de reacció de l’Exemple anterior amb el mètode del bootstrap. Prenem 5000 mostres aleatòries simples de mida 30 del vector Temps i calculam la desviació típica mostral de cada mostra: Simulacions.sd=replicate(5000,sd(sample(Temps,30,rep=TRUE))) Ara prenem com a IC 95% l’interval que va del quantil 0.025 al quantil 0.975 d’aquest vector de desviacions típiques: quantile(Simulacions.sd,c(0.025,0.975)) ## 2.5% 97.5% ## 11.00926 22.69609 No ha sortit molt diferent de l’obtingut amb la fórmula basada en la distribució \\(\\chi^2\\). 3.6 “Poblacions finites” Fins ara hem emprat mostres aleatòries simples. Què passa si prenem mostres aleatòries sense reposició? Si la mida \\(N\\) de la població és molt més gran que la mida \\(n\\) de la mostra (posem \\(N\\geqslant 1000n\\)), les fórmules donades fins ara funcionen (aproximadament) bé. Quan la mida \\(N\\) de la població no és molt més gran que la mida \\(n\\) de la mostra, el que es fa és, a les fórmules que hem donat per als intervals de confiança per a \\(\\mu\\) o \\(p_X\\), multiplicar-hi l’error estàndard pel factor de població finita \\[ \\sqrt{\\frac{N-n}{N-1}} \\] Així: Si \\(X\\) és una població de mida \\(N\\) amb mitjana poblacional \\(\\mu\\) i prenem una mostra aleatòria sense reposició de \\(X\\), amb mitjana \\(\\overline{X}\\) i desviació típica mostral \\(\\widetilde{S}_X\\), i si \\(X\\) normal o si \\(n\\) és gran, es recomana prendre com a interval de confiança de nivell de confiança \\(q\\) per a \\(\\mu\\) \\[ \\overline{X}\\pm t_{n,(q+1)/2}\\frac{\\widetilde{S}_X}{\\sqrt{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] Si \\(X\\) una població de mida \\(N\\) que segueix una distribució Bernoulli amb probabilitat d’èxit \\(p_X\\) i prenem una mostra aleatòria sense reposició de \\(X\\), amb \\(n\\) molt gran i nombres d’èxits i fracassos com a mínim 10, es recomana prendre com a interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] En les condicions del punt anterior, per obtenir un interval de confiança de nivell de confiança \\(q\\) per a \\(p_X\\) amb un marge d’error \\(M_{max}\\) en el cas més desfavorable (\\(\\widehat{p}_X=0.5\\)) caldrà prendre una mostra de mida \\[ n\\geqslant\\frac{Nz_{(q+1)/2}^2}{4M_{max}^2(N-1)+z_{(q+1)/2}^2} \\] Exemple 3.14 En una mostra aleatòria de 727 estudiants (diferents) de la UIB (\\(N=12000\\)), 557 afirmàrem haver comès plagi en algun treball durant els seus estudis. Quin seria un interval de confiança del 95% per a la proporció \\(p_X\\) d’estudiants de la UIB que han comès plagi en algun treball? Una mostra de 727 estudiants diferents és molt gran respecte del total d’estudiants de la UIB, per la qual cosa convé emprar la fórmula de Laplace amb el factor de població finita \\[ \\widehat{p}_{X}\\pm z_{(q+1)/2}\\sqrt{\\frac{\\widehat{p}_{X} (1-\\widehat{p}_{X})}{n}}\\sqrt{\\frac{\\vphantom{(}N-n}{N-1}} \\] on \\(\\widehat{p}_{X}=557/727=0.766\\), \\(z_{(q+1)/2}=1.96\\), \\(n=727\\) i \\(N=12000\\): dóna \\[ 0.766\\pm \\sqrt{\\frac{0.766(1-0.766)}{727}}\\sqrt{\\frac{\\vphantom{(}12000-727}{12000-1}}\\Rightarrow [0.751,0.781] \\] Estimam amb un nivell de confiança del 95% que entre un 75.1 i un 78.1 dels estudiants de la UIB han comès plagi en algun treball. Exemple 3.15 De quina mida hem de prendre una mostra aleatòria sense reposició d’estudiants de la UIB per estimar una proporció amb nivell de confiança del 95% i un marge d’error màxim de 0.05? Per la fórmula anterior (prenent \\(N=12000\\) i \\(z_{(1+q)/2}=1.96\\)), per garantir un marge d’error màxim de 0.05 cal prendre una mostra de mida \\[ n\\geqslant\\frac{12000\\cdot 1.96^2}{4\\cdot 0.05^2(12000-1)+1.96^2}=372.3 \\] Per tant, ens calen 373 estudiants. "],
["contrastos-dhipòtesis-generalitats.html", "Tema 4 Contrastos d’hipòtesis: Generalitats 4.1 Hipòtesis nul·la i alternativa 4.2 Un exemple 4.3 El p-valor 4.4 Tipus d’errors 4.5 Exemple: El test t 4.6 Recapitulació", " Tema 4 Contrastos d’hipòtesis: Generalitats En moltes situacions, s’ha de prendre a partir d’una mostra una decisió sobre si es pot acceptar o rebutjar una hipòtesi relativa al valor d’un paràmetre d’una població o diverses poblacions. Per exemple: Volem saber si una moneda està trucada a favor de cara. Per decidir-ho, la llençam en l’aire una sèrie de vegades, i comptam quantes cares surten. Volem decidir si un tractament nou A és més efectiu que el tractament vell B en la curació d’una malaltia X. Per decidir-ho, portam a terme un assaig clínic, tractant amb A un grup de malalts i amb B un altre grup de malalts, i comparam la taxa de curació dels tractaments sobre aquests dos grups. El mètode estadístic que s’empra per acceptar o rebutjar una hipòtesi rep el nom de contrast d’hipòtesis. 4.1 Hipòtesis nul·la i alternativa En un contrast d’hipòtesis, es comparen sempre dues hipòtesis alternatives: la hipòtesi nul·la \\(H_{0}\\) i la hipòtesi alternativa \\(H_{1}\\). Se sol plantejar formalment \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{hipòtesi nul·la}\\\\ H_{1}:\\text{hipòtesi alternativa} \\end{array} \\right. \\] En un contrast d’hipòtesis: Típicament, la hipòtesi nul·la \\(H_{0}\\) és “no hi ha diferència”, “no passa res”, “no hi ha res d’estrany” o l’equivalent en el context del contrast: La moneda és honrada (50% de probabilitat de cara) Els tractaments A i B són igual d’efectius en la curació de la malaltia X La hipòtesi alternativa \\(H_{1}\\) planteja la diferència de la qual cercam evidència: La moneda està trucada a favor de cara (més del 50% de probabilitat de cara) A és més efectiu que B en la curació de la malaltia X Per defecte, estam disposats a acceptar \\(H_0\\): que no hi ha diferència, no passa res. Per defecte, estam disposats a acceptar que la moneda és honrada (la majoria ho són, no?) Per defecte, estam disposats a acceptar que els dos tractaments són igual d’efectius Si obtenim evidència suficient que \\(H_0\\) és falsa, rebutjarem \\(H_0\\) en favor de \\(H_1\\) i conclourem que \\(H_1\\) és vertadera. Què vol dir “obtenir evidència suficient que \\(H_0\\) és falsa”? Doncs que les proves obtingudes fan que \\(H_0\\) sigui inversemblant (mala de creure) per comparació amb \\(H_1\\): Tendrem evidència que la moneda està trucada a favor de cara si a la nostra sèrie de llençaments la proporció de cares és tan i tan gran que fa molt difícil creure que la probabilitat de cara sigui del 50% Tendrem evidència que el tractament A és més efectiu que B en la curació de la malaltia X si en el nostre assaig la taxa de curació de la malaltia X amb el tractament A és tan i tan més gran que la de B que fa molt difícil creure que els dos tractaments siguin iguals d’efectius Si no obtenim evidència suficient que \\(H_0\\) és falsa, és a dir, si les nostres dades són compatibles amb \\(H_0\\), no podrem rebutjar-la: acceptarem la hipòtesi nul·la. Acceptarem que la moneda no està trucada a favor de cara si a la nostra sèrie de llençaments la proporció de cares no és prou gran com per fer molt difícil creure que sigui honrada Acceptarem que el tractament A és igual d’efectiu que B en la curació de la malaltia X si en el nostre assaig la taxa de curació de la malaltia X amb el tractament A no és prou més gran que la de B com per fer molt difícil creure que els dos tractaments siguin iguals d’efectius Si rebutjam \\(H_0\\) en favor de \\(H_1\\) no serà perquè hàgim demostrat que \\(H_0\\) sigui impossible, ni tan sols que sigui improbable: tan sols haurem observat que és mala de creure vists els resultats del nostre experiment Per exemple, si en una seqüència de 30 llençaments d’una moneda obtenim totes les vegades cara, segurament ho considerarem evidència que la moneda està trucada, però no demostra que la moneda estigui trucada. Sí, fa mal de creure que sigui honrada, però no és impossible: la moneda podria ser honrada i per pur atzar nosaltres haver tengut aquesta ratxa de cares. I tampoc podem dir que sigui improbable que sigui honrada, ja que nosaltres sabem calcular \\[ P(\\text{30 cares en 30 llençaments}|\\text{La moneda és honrada})=0.5^{30} \\] però no sabem calcular \\[ P(\\text{La moneda és honrada}|\\text{30 cares en 30 llençaments}). \\] Si acceptam la hipòtesi nul·la és perquè no trobam motius per dubtar d’ella, però no haurem trobat evidència que sigui vertadera ni haurem demostrat que sigui probable (i possible en principi ho és sempre). Per exemple, si en una seqüència de 4 llençaments d’una moneda obtenim 2 cares, haurem d’acceptar que la moneda és honrada. Però podria ser que estigués lleugerament escorada cap a cara i no haver-se notat en una seqüència tan curta de llençaments. Exemple 4.1 En un judici (on l’acusat és innocent si no es demostra el contrari, i per tant estam disposats a acceptar per defecte que és innocent), se cerca evidència que l’acusat és culpable, per tant aquesta és la hipòtesi alternativa: El contrast és \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;acusat és innocent}\\\\ H_{1}:\\text{L&#39;acusat és culpable} \\end{array} \\right. \\] S’aporten proves Si el jurat troba prou incriminatòries les proves, “més enllà de tot dubte raonable”, declara culpable l’acusat (rebutja \\(H_0\\) en favor de \\(H_1\\)) Si el jurat no les troba prou incriminatòries, el considera no culpable (no rebutja \\(H_{0}\\)) Observau que considerar no culpable no és el mateix que demostrar que és innocent: simplement, es considera que l’acusat no és culpable si no s’ha trobat prou evidència que sigui culpable. Exemple 4.2 Un examen és un contrast d’hipòtesis. En aquest cas, “no passa res” significa que l’estudiant és com si no hagués anat al curs, no ha après res, i per tant aquesta és la hipòtesi nul·la; amb l’examen cercam evidència que l’estudiant ha après la matèria, per tant aquesta serà la hipòtesi alternativa: Contrast: \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;estudiant no sap la matèria}\\\\ H_{1}:\\text{L&#39;estudiant sap la matèria} \\end{array} \\right. \\] Prenem una mostra del coneixement de l’estudiant (l’estudiant fa l’examen) Si hi ha prou evidència en favor de \\(H_1\\) (si l’examen li surt prou bé), rebutjam \\(H_0\\): decidim que l’estudiant sap la matèria, aprova l’assignatura Si no hi ha prou evidència en favor de \\(H_1\\) (si l’examen no li surt prou bé), ens quedam amb \\(H_0\\): concloem que l’estudiant no ha après la matèria, suspèn l’assignatura Exemple 4.3 Ens trobam amb la notícia següent al diari, i ens demanam si les dones practiquen realment menys esport que els homes. Aquesta pregunta la podem plantejar de moltes maneres: Totes les dones fan cada dia menys hores d’esport que tots els homes? Si prenc una dona i un home a l’atzar, hi ha més d’un 50% de probabilitat que ella practiqui menys esport que ell? La majoria de les dones fan cada dia menys hores d’esport que la majoria dels homes? La proporció de practicants d’esport entre les dones és més petita que entre els homes? La mitjana setmanal de vegades que les dones practiquen esport és més petita que la dels homes? La mitjana setmanal d’hores que les dones practiquen esport és més petita que la dels homes? … Cada una d’aquestes preguntes es traduiria en un contrast d’hipòtesis diferent i possiblement mostres de tipus de dades diferents per realitzar-los. Com que aquí estam tractant contrastos sobre paràmetres poblacionals (mitjanes, proporcions, etc.), podríem plantejar algun dels tres darrers. Anem a centrar-nos en la darrera qüestió, sobre mitjanes setmanals d’hores d’esport. Aquí, les variables poblacionals d’interés són: \\(X_d\\): “Prenc una dona i calcul el seu nombre mitjà d’hores setmanals d’esport”, amb mitjana \\(\\mu_d\\): la mitjana d’hores setmanals d’esport de les dones (la mitjana de les mitjanes d’hores setmanals d’esport de totes les dones és la mitjana d’hores setmanals d’esport de les dones). \\(X_h\\): “Prenc un home i calcul el seu nombre mitjà d’hores setmanals d’esport”, amb mitjana \\(\\mu_h\\): la mitjana d’hores setmanals d’esport dels homes El contrast que volem realitzar és Hipòtesi nul·la: no hi ha diferència entre les mitjanes d’hores setmanals d’esport d’homes i dones Hipòtesi alternativa: la mitjana d’hores setmanals d’esport de les dones és més petita que la dels homes És a dir \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&lt;\\mu_h \\end{array} \\right. \\] El procediment per realitzar-lo serà: Prenem mostres aleatòries de dones i d’homes i els demanam pels seus hàbits de pràctica d’esport Calculam la mitjana mostral \\(\\overline{X}_d\\) d’hores setmanals d’esport de les dones de la mostra Calculam la mitjana mostral \\(\\overline{X}_h\\) d’hores setmanals d’esport dels homes de la mostra Si \\(\\overline{X}_d\\) és molt més petita que \\(\\overline{X}_h\\), ho prendrem com a evidència que \\(\\mu_d&lt;\\mu_h\\) Si \\(\\overline{X}_d\\) no és molt més petita que \\(\\overline{X}_h\\), no podrem rebutjar que \\(\\mu_d=\\mu_h\\) Què significa “\\(\\overline{X}_d\\) molt més petita que \\(\\overline{X}_h\\)”? Una opció, que podríem importar del tema anterior, seria calcular un interval de confiança del 95% per a \\(\\mu_d-\\mu_h\\) a partir de la mostra: Si està totalment a l’esquerra del 0, amb un 95% de confiança podem concloure que \\(\\mu_d&lt;\\mu_h\\) En cas contrari (si conté el 0 o si està totalment a la dreta del 0), amb un 95% de confiança no podem concloure que \\(\\mu_d&lt;\\mu_h\\) Com que aquí voldrem filar més prim que això del “nivell de confiança”, el procediment serà una mica més complicat (bàsicament, emprarem diferents fórmules per calcular els intervals de confiança segons la forma que tengui la hipòtesi alternativa). Abans de tancar aquesta secció, volem emfatitzar algunes advertències. Les hipòtesis dels contrastos són sobre paràmetres de les poblacions, NO sobre estadístics de les mostres. Aquí les hipòtesis del contrast comparaven les mitjanes poblacionals d’hores setmanals d’esport de les dones i els homes, no les mitjanes mostrals d’hores setmanals d’esport de les dones i els homes de la nostra mostra. Per comparar les mitjanes mostrals no ens fa falta un contrast d’hipòtesis: les calculam i punt. En canvi, com que no podem calcular les mitjanes d’hores setmanals d’esport de totes les dones i de tots els homes, ens veiem obligats a fer un contrast d’hipòtesis. La falta d’evidència a favor de \\(H_1\\) no és evidència a favor de \\(H_0\\) Si no podem assegurar que les dones practiquin menys esport que els homes (perquè no hàgim trobat evidència a favor d’aquesta hipòtesi), això no significarà que hàgim trobat evidència que els homes i les dones practiquin la mateixa quantitat d’esport o que les dones en practiquin més. Simplement, significarà que l’evidència a favor de \\(H_1\\) no ha estat prou forta com per poder afirmar que és vertadera i per tant acceptam que tothom practica la mateixa quantitat d’esport. En general, mai no podrem trobar evidència de la hipòtesi nul·la. Si per exemple al nostre estudi haguéssim trobat que \\(\\overline{X}_d=\\overline{X}_h\\), això seria compatible amb la hipòtesi nul·la \\(\\mu_d=\\mu_h\\), i per això no la podríem rebutjar, però no aporta evidència que \\(\\mu_d=\\mu_h\\), ja que segurament també seria compatible, per exemple, amb \\(\\mu_d=\\mu_h+0.0007\\) (les dones fan, de mitjana, un minut més d’esport a la setmana que els homes). La pregunta (el contrast) us la plantejau a priori a partir d’hipòtesis o suposicions prèvies. No val canviar de contrast a la vista de les dades. La pregunta la plantejam abans d’obtenir la mostra. Si estam interessats en el contrast \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&lt;\\mu_h \\end{array} \\right. \\] i obtenim que \\(\\overline{X}_d\\) és molt més gran que \\(\\overline{X}_h\\) en la nostra mostra, concloem que no tenim evidència que \\(\\mu_d&lt;\\mu_h\\) i punt. És fer trampes dir: “No hem trobat evidència que les dones practiquin menys esport que els homes, però si amb aquestes mateixes dades realitzam el contrast \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&gt;\\mu_h \\end{array} \\right. \\] sí que obtenim evidència que elles practiquen més esport que ells.” D’això s’en diu “anar a pescar” o també “torturar les dades”: obtenir unes dades i cercar de què donen evidència. És mala praxis científica. Qualsevol conjunt de dades, si el torturam prou, acaba donant evidència de qualque cosa. Triau la hipòtesi alternativa en funció d’allò que cercau evidència. No confongueu \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&lt;\\mu_h \\end{array} \\right. \\] amb \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d\\neq \\mu_h \\end{array} \\right. \\] que tradueix la pregunta &quot;Els homes i les dones, de mitjana, practiquen esport un nombre diferent d’hores a la setmana?’’ Regles per triar \\(H_0\\) i \\(H_1\\) en aquest curs: \\(H_0\\) sempre ha de significar “no hi ha diferència” i s’ha de definir formalment mitjançant una igualtat \\(H_1\\) és la hipòtesi de la que cercam evidència, i s’ha de definir formalment mitjançant alguna cosa “estricta”: Hipòtesi unilateral (one-sided; també d’una cua, one-tailed): definida amb &lt; o amb &gt; Hipòtesi bilateral (two-sided; també de dues cues, two-tailed): definida amb \\(\\neq\\) Els contrastos prenen el nom del tipus d’hipòtesi alternativa: contrast unilateral, de dues cues, etc. 4.2 Un exemple Tenc una moneda, i crec que està trucada a favor de cara. Vull contrastar-ho. Aquí la variable aleatòria \\(X\\) que ens interessa és “Llenç la moneda en l’aire i mir si surt cara”, que és Bernoulli amb probabilitat d’èxit (és a dir, probabilitat de treure cara amb la meva moneda) \\(p_{\\mathit{Cara}}\\). La hipòtesi nul·la serà que la moneda no està trucada (no li passa res a la meva moneda), i l’alternativa (de la que cerc evidència) que la moneda està trucada a favor de cara. En termes de \\(p_{\\mathit{Cara}}\\), el contrast és \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Exemple 4.4 Suposem que llenç la moneda en l’aire 3 vegades i obtenc 3 cares. És evidència suficient que està trucada? Diguem \\(S_3\\) a la variable aleatòria “Nombre de cares en 3 llençaments d’aquesta moneda.” Si la moneda no està trucada, \\(S_3\\) és binomial, \\(S_3\\sim B(3,0.5)\\), i per tant \\[ P(S_3=3)=0.5^{3}=0.125 \\] El resultat obtingut no és molt improbable amb una moneda honrada: passaria en 1 de cada 8 seqüències de 3 llençaments. Per tant, no és evidència suficient que estigui trucada. D’aquest tipus de procediment, emprant la distribució binomial del nombre d’èxits en una mostra aleatòria simple per contrastar un valor de la probabilitat poblacional d’èxit, en direm un test binomial. Exemple 4.5 Suposem que ara llenç la moneda en l’aire 10 vegades i obtenc 10 cares. És evidència suficient que està trucada? Diguem ara \\(S_{10}\\) a la variable aleatòria “Nombre de cares en 10 llençaments.” Si la moneda no està trucada, \\(S_{10}\\sim B(10,0.5)\\) i per tant \\[ P(S_{10}=10)=0.5^{10}=0.001 \\] El resultat obtingut és molt improbable si la moneda no està trucada: si la moneda fos honrada, només en 1 de cada 1000 seqüències de 10 llençaments obtendríem 10 cares. És a dir: El resultat del nostre experiment seria molt estrany si la moneda fos honrada, per tant és inversemblant que sigui honrada. Ho consideram evidència que està trucada. Fixau-vos en el procediment: Hem plantejat el contrast: \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Hem recollit una mostra aleatòria: la seqüència de llençaments Hem triat un estadístic de contrast amb distribució mostral coneguda quan \\(H_0\\) és vertadera: al nostre cas, el nombre de cares Hem calculat el valor d’aquest estadístic sobre la nostra mostra Hem calculat la probabilitat que l’estadístic prengui el valor observat si \\(H_0\\) és vertadera Si aquesta probabilitat és molt petita, ho consideram evidència que \\(H_1\\) és vertadera Si no és prou petita, no tenim evidència que \\(H_0\\) sigui falsa Bé, això és el que hem fet, però no és del tot correcte. Als punts (5) i (6) diem que: “Calculam la probabilitat que l’estadístic prengui el valor observat si \\(H_0\\) és vertadera i si és molt petita, ho consideram evidència que \\(H_1\\) és vertadera.” Segur?? Suposem que, al contrast anterior, llençam la moneda en l’aire 10 vegades i ara obtenim 10 creus. És evidència suficient que està trucada a favor de cara? Òbviament no ho pot ser, però la probabilitat és la mateixa que abans: \\[ P(S_{10}=0)=0.5^{10}=0.001 \\] En molts casos, la probabilitat d’obtenir exactament el que hem obtingut pot ser molt petita, independentment del que hàgim obtingut. Per exemple, suposem que llençam la moneda en l’aire 10000 vegades i obtenim 5000 cares. Si la moneda és honrada, el nombre de cares seguirà una distribució binomial \\(B(10000,0.5)\\) i la probabilitat d’obtenir 5000 cares serà dbinom(5000,10000,0.5)=0.008, ben petita, però clarament si la meitat de llençaments donen cara, no podem tenir mai evidència que la moneda estigui trucada. O, encara més exagerat, si l’estadístic de contrast té distribució contínua, recordau que la probabilitat que una variable aleatòria contínua prengui un valor concret és 0. Més petit impossible, però no sempre rebutjarem la hipòtesi nu·la. En realitat, a (5) es calcula la probabilitat que, si \\(H_0\\) és vertadera, l’estadístic prengui un valor tan extrem o més (en el sentit de \\(H_1\\)) que l’obtingut. A aquesta probabiitat li diem el p-valor. Al nostre exemple de la moneda, com que la hipòtesi nul·la és \\(p_{\\mathit{Cara}}= 0.5\\) i la hipòtesi alternativa és \\(p_{\\mathit{Cara}}&gt; 0.5\\), el p-valor és la probabilitat que, si \\(p_{\\mathit{Cara}}= 0.5\\), el nombre de cares sigui tan o més gran que l’obtingut a la nostra mostra. En els dos exemples anteriors concrets, on obteníem 3 cares en 3 llençaments i 10 cares en 10 llençaments, és el mateix demanar que el nombre de cares sigui igual a l’obtingut i demanar que el nombre de cares sigui més gran o igual que l’obtingut, perquè en els dos experiments hem obtingut el nombre màxim possible de cares; per exemple, treure 3 o més cares en 3 llençaments és exactament el mateix que treure 3 cares en 3 llençaments. Però en general no serà el cas. Exemple 4.6 Tornem al nostre contrast \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Suposem que llenç la moneda en l’aire 10 vegades i obtenc 7 cares. És evidència suficient que està trucada? Seguim dient \\(S_{10}\\) a la variable aleatòria “Nombre de cares en 10 llençaments”. Si la moneda no està trucada, \\(S_{10}\\sim B(10,0.5)\\). Com que la hipòtesi alternativa és \\(p_{\\mathit{Cara}}&gt; 0.5\\), “obtenir un nombre de cares tan extrem o més que el que hem obtingut en el sentit de la hipòtesi alternativa” és treure tantes cares com les que hem obtingut o més, és a dir treure 7 o més cares. Per tant \\[ \\text{p-valor}=P(S_{10}\\geqslant 7)=\\texttt{1-pbinom(6,10,0.5)}=0.172 \\] Un resultat tan extrem o més que l’obtingut no és molt improbable si la moneda no està trucada: passaria 1 de cada 6 vegades. Per tant, com que és bastant compatible amb el fet que la moneda sigui honrada, no ho podem considerar evidència que estigui trucada a favor de cara. Exemple 4.7 Tenc una moneda, i ara crec que està trucada a favor de creu. Vull contrastar-ho. Plantejat en termes de \\(p_{\\mathit{Cara}}\\), el contrast que vull realitzar és \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}: p_{\\mathit{Cara}}&lt; 0.5 \\end{array} \\right. \\] Suposem que llenç la moneda en l’aire 10 vegades i obtenc 1 cara. És evidència suficient que \\(p_{\\mathit{Cara}}&lt; 0.5\\)? Seguim dient \\(S_{10}\\) a la variable aleatòria “Nombre de cares en 10 llençaments d’aquesta moneda.” Si la moneda no està trucada, \\(S_{10}\\sim B(10,0.5)\\). Ara, com que \\(H_{1}\\) és \\(p_{\\mathit{Cara}}&lt; 0.5\\), “obtenir un nombre de cares tan extrem o més que el que hem obtingut en el sentit de la hipòtesi alternativa” és treure tantes cares com les que hem obtingut o menys, és a dir treure 1 cara o cap. Per tant \\[ \\text{p-valor}=P(S_{10}\\leqslant 1)=\\texttt{pbinom(1,10,0.5)}=0.01 \\] Un resultat tan extrem o més que l’obtingut és molt improbable si \\(p_{\\mathit{Cara}}= 0.5\\): passaria en 1 de cada 100 seqüències de 10 llençaments. Ho podem considerar evidència que la moneda està trucada a favor de creu. 4.3 El p-valor El p-valor d’un contrast és la probabilitat que, si la hipòtesi nul·la és vertadera, l’estadístic de contrast prengui en una mostra aleatòria simple de la mateixa mida que la nostra un valor tan o més extrem, en el sentit de la hipòtesi alternativa, que l’obtingut amb la mostra emprada per realitzar el contrast. Ho tornarem a repetir, posant èmfasi en els components fonamentals de la definició. El p-valor és: La probabilitat que, si la hipòtesi nul·la és vertadera, l’estadístic de contrast prengui en una mostra aleatòria simple de la mateixa mida que la nostra un valor tan o més extrem, en el sentit de la hipòtesi alternativa, que l’obtingut amb la nostra mostra. Exemple 4.8 Suposem que al contrast de les mitjanes d’hores setmanals d’esport d’homes i dones de l’Exemple 4.3 empram com a estadístic de contrast la diferència entre les mitjanes mostrals \\(\\overline{X}_d-\\overline{X}_h\\) (que no serà el cas: només és un exemple!) i que hem pres mostres de 50 dones i de 50 homes. Aleshores, el p-valor del contrast és La probabilitat que, si la hipòtesi nul·la és vertadera, si \\(\\mu_d=\\mu_h\\), és a dir, si els homes i les dones practiquen de mitjana el mateix nombre d’hores d’esport a la setmana, l’estadístic de contrast prengui en una mostra aleatòria simple de la mateixa mida que la nostra el valor de \\(\\overline{X}_d-\\overline{X}_h\\), és a dir, de la mitjana mostral d’hores setmanals d’esport en les dones menys la mitjana mostral d’hores setmanals d’esport en els homes, d’una mostra aleatòria formada per 50 dones i 50 homes un valor tan o més extrem, en el sentit de la hipòtesi alternativa, sigui més petit o igual (perquè la hipòtesi alternativa és \\(\\mu_d&lt;\\mu_h\\), és a dir \\(\\mu_d-\\mu_h&lt;0\\)) que l’obtingut amb la nostra mostra. que el de la nostra mostra En resum, el p-valor seria en aquest cas La probabilitat, suposant que \\(\\mu_d=\\mu_h\\), que, si prenem una mostra aleatòria de 50 dones i 50 homes, el valor de \\(\\overline{X}_d-\\overline{X}_h\\) que obtinguem sigui més petit o igual que el de la nostra mostra. Si aquesta probabilitat és molt petita, la mostra obtinguda és poc consistent amb la hipòtesi nul·la i per tant conclourem que la hipòtesi alternativa és vertadera. Si, en canvi, aquesta probabilitat no és molt petita, la mostra obtinguda és consistent amb la hipòtesi nul·la i per tant no podrem rebutjar que \\(H_0\\) sigui vertadera. El p-valor no és: La probabilitat que \\(H_0\\) sigui vertadera condicionada al nostre resultat La probabilitat que \\(H_1\\) sigui falsa condicionada al nostre resultat És a l’inrevés: El p-valor és la probabilitat del nostre resultat (o quelcom més extrem) condicionada al fet que \\(H_0\\) sigui vertadera. Per tant, el p-valor és una evidencia indirecta inversa de \\(H_1\\): Com més petit sigui el p-valor, més rar seria el que hem obtingut si \\(H_0\\) fos vertadera i \\(H_1\\) falsa, i per tant més evidència tenim que \\(H_0\\) no pot ser vertadera i que la vertadera és \\(H_1\\). Per exemple, que el p-valor d’un contrast doni 0.03 Significa que, si \\(H_0\\) és vertadera, la probabilitat que l’estadístic de contrast prengui sobre una mostra un valor tan extrem o més que el que hem obtingut és 0.03 El trobau petit? Ho preneu com a evidència que \\(H_0\\) és falsa i \\(H_1\\) vertadera No el trobau petit? No teniu evidència per rebutjar que \\(H_0\\) és vertadera No significa que: La probabilitat que \\(H_0\\) sigui vertadera és 0.03 \\(H_0\\) és vertadera un 3% de les vegades En un contrast d’hipòtesis no obtenim cap informació directa sobre la probabilitat de \\(H_0\\) o de \\(H_1\\). Exemple 4.9 Tenc una moneda i crec que està trucada; a favor de cara o a favor de creu, no ho sé, només sospit que està trucada. Vull contrastar-ho. Plantejat en termes de la probabilitat de treure cara \\(p_{\\mathit{Cara}}\\), el contrast que vull realitzar ara és \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}\\neq 0.5 \\end{array} \\right. \\] Suposem que la llenç en l’aire 10 vegades i obtenc 8 cares. És evidència suficient que està trucada? Com a la secció anterior, diguem \\(S_{10}\\) a la variable “Nombre de cares en 10 llençaments”. Si \\(p_{\\mathit{Cara}}= 0.5\\), \\(S_{10}\\sim B(10,0.5)\\). Si la hipòtesi nul·la fos vertadera, esperaríem treure 5 cares i 5 creus. Com que la hipòtesi alternativa és \\(H_{1}:p_{\\mathit{Cara}}\\neq 0.5\\), ara “obtenir un resultat tan o més extrem, en el sentit de la hipòtesi alternativa, que l’obtingut” és treure un resultat tant o més diferent de 5 cares i 5 creus que l’obtingut: és a dir, treure almenys 8 cares o almenys 8 creus, o el que és el mateix, treure o bé 8 o més cares, o bé 2 o menys cares. Per tant, el p-valor és \\[ \\begin{array}{l} P(S_{10}\\geqslant 8\\text{ o }S_{10}\\leqslant 2) =P(S_{10}\\geqslant 8) + P(S_{10}\\leqslant 2)\\\\ \\qquad =1-P(S_{10}\\leqslant 7) + P(S_{10}\\leqslant 2)\\\\ \\qquad =\\texttt{1-pbinom(7,10,0.5)+pbinom(2,10,0.5)}\\\\ \\qquad =0.11 \\end{array} \\] Per tant, si la moneda no està trucada, un resultat com l’obtingut o més llunyà de “meitat cares, meitat creus” és improbable, però no gaire (1 de cada 9 vegades passaria). És evidència suficient que estigui trucada? 4.4 Tipus d’errors Al darrer exemple ens ha sorgit la qüestió de quin p-valor marca el llindar entre obtenir evidència o no. És 0.11 prou petit? La resposta és que depèn de quant estiguem disposats a equivocar-nos. La comparació entre la realitat i la decisió resultant d’un contrast dóna lloc a quatre situacions possibles, resumides en la taula següent: \\(H_0\\) és la vertadera a la realitat i nosaltres decidim que \\(H_1\\) és vertadera. La conclusió del contrast és errònia. En diem error de tipus I o positiu fals. Indicarem amb \\(\\alpha\\) la probabilitat de cometre un error de tipus I, és a dir, de rebutjar \\(H_0\\) si és vertadera, i en direm el nivell de significació: \\[ \\alpha=P(\\text{Rebutjar } H_0| H_0\\text{ vertadera}). \\] \\(H_1\\) és vertadera a la realitat i nosaltres acceptam \\(H_0\\). La conclusió del contrast és errònia. En diem error de tipus II o negatiu fals. Indicarem amb \\(\\beta\\) la probabilitat de cometre un error de tipus II, és a dir, d’acceptar \\(H_0\\) si \\(H_1\\) és vertadera,: \\[ \\beta=P(\\text{Acceptar } H_0| H_1\\text{ vertadera}). \\] \\(H_1\\) és vertadera a la realitat i nosaltres decidim que \\(H_1\\) és vertadera. La conclusió del contrast és correcta. En diem un positiu vertader. La probabilitat d’encertar amb un positiu vertader és \\(1-\\beta\\) i en direm la potència: \\[ 1-\\beta=P(\\text{Rebutjar } H_0| H_1\\text{ vertadera}). \\] \\(H_0\\) és la vertadera a la realitat i nosaltres l’acceptam. La conclusió del contrast és correcta. En diem un negatiu vertader. La probabilitat d’encertar amb un negatiu vertader és \\(1-\\alpha\\) i en direm el nivell de confiança: \\[ 1-\\alpha=P(\\text{Acceptar } H_0| H_0\\text{ vertadera}). \\] En el context d’un contrast d’hipòtesis, un resultat positiu és rebutjar la hipòtesi nul·la i decidir que l’alternativa és la vertadera (hem trobat qualque cosa) un resultat negatiu és acceptar la hipòtesi nul·la (no hem trobat res i ens hem de conformar amb la hipòtesi nul·la) Ho tornam a repetir: el nivell de significació d’un contrast és la probabilitat que, si la hipótesi nul·la és vertadera, nosaltres ens equivoquem i la rebutjem en favor de l’alternativa: \\[ \\alpha=P(\\text{Rebutjar } H_0| H_0\\text{ vertadera}). \\] la potència d’un contrast és la probabilitat que, si la hipótesi alternativa és vertadera, nosaltres ho detectem i rebutjem la hipòtesi nul·la en favor de l’alternativa: \\[ 1-\\beta=P(\\text{Rebutjar } H_0| H_1\\text{ vertadera}). \\] Exemple 4.10 En un test d’embaraç, el contrast que es realitza és: \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{No estàs embaraçada}\\\\ H_{1}:\\text{Estàs embaraçada} \\end{array} \\right. \\] Exemple 4.11 En un judici, on s’ha de declarar un acusat innocent o culpable, el contrast era \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;acusat és innocent}\\\\ H_{1}:\\text{L&#39;acusat és culpable} \\end{array} \\right. \\] Es poden cometre dos errors: Error de tipus I: Declarar culpable un innocent Error de tipus II: Declarar no culpable un culpable És pitjor l’error de tipus I, convé minimitzar-lo. Per això només es declara qualcú culpable quan les proves ho demostren més enllà de qualsevol dubte raonable Exemple 4.12 En un examen, el contrast era \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;estudiant no sap la matèria}\\\\ H_{1}:\\text{L&#39;estudiant sap la matèria} \\end{array} \\right. \\] Es poden donar dos errors: Que l’estudiant aprovi sense saber la matèria Que l’estudiant suspengui sabent la matèria Quin és el de tipus I i quin el de tipus II? Quin creieu que és pitjor? Normalment, es considera pitjor cometre un error de tipus I que cometre un error de tipus II. Per tant, l’objectiu primari en un contrast és trobar una regla de rebuig de \\(H_{0}\\) que tengui poca probabilitat \\(\\alpha\\) d’error de tipus I. Però també voldríem minimitzar la probabilitat \\(\\beta\\) d’error de tipus II. El problema és que quan fem disminuir \\(\\alpha\\), sol augmentar \\(\\beta\\). Què se sol fer? Donar una regla de decisió per a un \\(\\alpha\\) màxim fixat Després, augmentar la mida \\(n\\) de la mostra per arribar a la \\(\\beta\\) desitjada Abans d’acabar amb els errors, fixau-vos que si efectuam \\(M\\) contrastos (independents) emprant una regla de decisió que garanteixi un nivell de significació \\(\\alpha\\) fixat, i a tots aquests contrastos la \\(H_0\\) és vertadera, el nombre de contrastos d’aquests on ens equivocarem i rebutjarem \\(H_0\\) té distribució binomial \\(B(M,\\alpha)\\). En particular, esperam equivocar-nos en \\(\\alpha M\\) d’aquests \\(M\\) contrastos on l’hipòtesi nul·la sigui vertadera. Si efectuam molts contrastos, augmenta la probabilitat de “trobar qualque cosa” encara que no hi hagi res que trobar, i acabar dient que les gominoles verdes curen l’acné: Figura 4.1: “Significant” (https://xkcd.com/882/ (CC-BY-NC 2.5)) 4.5 Exemple: El test t Ens demanam si els homes joves amb diabetis tenen una concentració de calci en plasma superior a la dels homes joves sans. Ho traduirem en un contrast d’hipòtesis sobre la concentració mitjana de calci en plasma en els homes joves amb diabetis, diguem-li \\(\\mu\\): La hipòtesi nul·la serà que no hi ha diferència entre \\(\\mu\\) i la concentració mitjana de calci en plasma en els homes joves sans, és a dir, que són iguals La hipòtesi alternativa és d’allò que cercam evidència: que \\(\\mu\\) és més gran que la concentració mitjana de calci en plasma en els homes joves sans. Se sap que la concentració de calci en plasma en homes sans segueix una llei aproximadament normal. El seu valor mitjà en homes sans de 22 a 44 anys s’estima en 2.5 mmol/l. Per tant, el contrast que volem realitzar és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=2.5\\\\ H_{1}:\\mu &gt;2.5 \\end{array} \\right. \\] En una mostra de 20 diabètics d’aquesta franja d’edat, es va obtenir una concentració mitjana de calci \\(\\overline{x}=3.2\\) mmol/l amb una desviació típica mostral \\(\\widetilde{s}=1.5\\). Suposem que aquesta mostra de diabètics joves és representativa i raonablement aleatòria. Volem decidir el contrast a partir d’aquesta mostra. Diguem \\(X\\) a la variable aleatòria “Prenem un home diabètic de 22 a 44 anys i li mesuram la concentració de calci en plasma en mmol/l”. Aquesta variable \\(X\\) també segueix una llei normal, però ara no sabem la seva mitjana \\(\\mu\\) i volem contrastar si és més gran que 2.5 o no. La nostra situació, doncs, és un cas particular del cas general següent. Tenim una variable aleatòria poblacional \\(X\\sim N(\\mu,\\sigma)\\) i plantejam el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt;\\mu_0 \\end{array} \\right. \\] per a un valor concret \\(\\mu_0\\). Volem prendre una decisió a partir d’una mostra aleatòria simple. En aquesta situació, si \\(H_0\\) és vertadera, és a dir, si la mitjana de \\(X\\) és \\(\\mu_0\\), sabem que \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\sim t_{n-1} \\] La idea que guiarà el procediment per prendre una decisió en aquest contrast serà: Rebutjarem \\(H_0\\) en favor de \\(H_1\\) si aquest estadístic de contrast \\(T\\) pren un valor “molt gran” sobre la mostra, és a dir, si \\(\\overline{X}\\) és “molts errors típics” més gran que \\(\\mu_0\\). La definició precisa de “molt gran” dependrà del valor d’\\(\\alpha\\) que volguem prendre, és a dir, de la probabilitat de cometre un error de tipus I que estiguem disposats a assumir. En Biologia i Bioquímica usualment es pren \\(\\alpha=0.05\\): una mica menys que la probabilitat de treure 4 cares seguides amb una moneda honrada. Aquí ara prendrem aquest mateix nivell de significació \\(\\alpha=0.05\\). És a dir, acceptarem que la probabilitat d’equivocar-nos rebutjant \\(H_0\\) en favor de \\(H_1\\) és 0.05, o el que és el mateix, ens permetrem cometre un error de tipus I una vegada de cada 20 que la hipòtesi nul·la sigui vertadera. Sigui \\(T_0\\) el valor que pren l’estadístic de contrast \\(T\\) en la nostra mostra. Rebutjarem \\(H_{0}\\) si \\(T_0\\) és més gran que un cert llindar \\(L_0\\), que determinam a partir de \\(\\alpha\\): \\[ \\begin{array}{l} \\alpha = P(\\text{Rebutjar } H_{0}| H_{0} \\text{ certa})=P(T&gt; L_0)\\\\ \\qquad\\quad \\Longrightarrow 1-\\alpha= P(T\\leqslant L_0)\\Longrightarrow L_0= t_{n-1,1-\\alpha} \\end{array} \\] Per tant, a fi que el nivell de significació del contrast sigui \\(\\alpha\\), Rebutjarem \\(H_0\\) si \\(T_0&gt;t_{n-1,1-\\alpha}\\) En direm una regla de rebuig per aquest tipus de contrast. Tornem al nostre exemple dels diabètics \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=2.5\\\\ H_{1}:\\mu &gt; 2.5 \\end{array} \\right. \\] Si \\(\\alpha=0.05\\) i \\(n=20\\), el llindar a partir del qual rebutjam \\(H_0\\) és \\(t_{n-1,1-\\alpha}=t_{19,0.95}=\\texttt{qt(0.95,19)}=1.73\\). A la nostra mostra hi tenim que \\(\\overline{x}=3.2\\), \\(\\widetilde{s}=1.5\\) i \\(n=20\\), per tant l’estadístic de contrast val \\[ T_0=\\frac{3.2-2.5}{1.5/\\sqrt{20}}=2.09 \\] Com que \\(2.09&gt;1.73\\), concloem amb un nivell de significació de 0.05 que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els joves sans. Anem a veure com entra en joc el p-valor. Recordem que rebutjarem \\(H_0\\) quan \\(T_0&gt;t_{n-1,1-\\alpha}\\): \\[ \\begin{array}{l} \\text{Rebutjarem $H_0$} \\Longleftrightarrow T_0&gt; t_{n-1,1-\\alpha}\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt; P(T\\geqslant t_{n-1,1-\\alpha})\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt; 1-P(T\\leqslant t_{n-1,1-\\alpha})=1-(1-\\alpha)=\\alpha\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt;\\alpha \\end{array} \\] I ara observau que \\(P(T\\geqslant T_0)\\) és la probabilitat que, si \\(H_0\\) és vertadera, l’estadístic de contrast \\(T\\) prengui un valor tan extrem o més, en el sentit de \\(H_1: \\mu&gt;2.5\\), que l’obtingut en la nostra mostra, \\(T_0\\): és el p-valor del contrast. Per tant, tenim una altra regla de rebuig (equivalent a l’anterior): Rebutjarem \\(H_0\\) quan el p-valor sigui més petit que \\(\\alpha\\) En el nostre exemple, ja hem calculat \\(T_0=2.09\\). Llavors, \\[ \\text{p-valor} =P(T\\geqslant 2.09)=\\texttt{1-pt(2.09,19)} =0.025 \\] Com que el p-valor és més petit que 0.05, concloem amb un nivell de significació de 0.05 que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els sans. D’aquest tipus de procediment, emprant la distribució t de Student de \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\sim t_{n-1} \\] per comparar la \\(\\mu\\) d’una variable amb el valor \\(\\mu_0\\) en direm un test t. Fixau-vos que la nostra conclusió ha estat que “concloem amb un nivell de significació de 0.05 que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els joves sans.” Per tant, reconeixem una probabilitat d’equivocar-nos del 5%: Si en realitat el nivell mitjà de calci en sang en els joves diabètics és el mateix que en els sans, la probabilitat que teníem d’equivocar-nos i concloure que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els sans és del 5%. Anem a estudiar aquesta taxa d’encerts per mitjà d’una simulació. Primer suposarem que el nivell mitjà real és 2.5, i simularem la probabilitat d’error de tipus I. Com que estam fent el contrast amb nivell de significació 0.05, esperam al voltant d’un 5% d’errors de tipus I. Per fixar idees, modelarem la població de joves diabètics per mitjà d’una variable aleatòria \\(N(2.5,0.5)\\). La \\(\\sigma=0.5\\) ens l’hem inventada. Aprofitam per fixar la llavor d’aleatorietat. set.seed(42) mu0=2.5 sigma0=0.5 El llindar \\(L_0\\) per \\(n=20\\) i \\(\\alpha=0.05\\) és L0=qt(0.95,19) La funció estadístic següent pren una mostra aleatòria de mida \\(n\\) d’una variable \\(N(\\mu, \\sigma)\\) i en calcula l’estadístic de contrast \\(T\\): estadístic=function(n,mu,sigma){ mostra=rnorm(n,mu,sigma) (mean(mostra)-mu0)/(sd(mostra)/sqrt(n)) } Ara, repetim 200 vegades el procés de prendre una mostra aleatòria de mida 20 de la nostra població i calcular la \\(T\\) corresponent. Després miram la proporció de vegades que això ha donat més gran que el llindar, és a dir, la proporció de vegades que rebutjam la hipòtesi nul·la \\(\\mu=2.5\\) i que per tant cometem un error de tipus I. Tes=replicate(200,estadístic(20,mu0,sigma0)) p.error.Tipus.I=length(which((Tes&gt;L0)==TRUE))/200 p.error.Tipus.I ## [1] 0.05 Hem comès exactament un 5% d’errors de tipus I! Ara suposarem que el nivell mitjà real és estrictament més gran que 2.5, i anam a simular els errors de tipus II, per veure amb quina freqüència els cometem. Per començar, generam de manera uniforme un vector de 100 \\(\\mu\\)’s entre 2.6 i 3. mus=runif(100,2.6,3) I ara el que farem serà el següent. Per a cada \\(\\mu_i\\) d’aquest vector, prendrem com a “població de diabètics” una variable \\(N(\\mu_i,0.5)\\). A continuació, per a cada una d’aquestes poblacions, repetim 200 vegades el procés de prendre una mostra aleatòria simple de mida 20 d’aquesta població i calcular la \\(T\\) corresponent. Després, per a cada població, miram la proporció de vegades que això ha donat més petit o igual que el llindar, és a dir, la proporció de vegades que acceptam la hipòtesi nul·la \\(\\mu=2.5\\) i que per tant cometem un error de tipus II. Organitzam totes aquestes proporcions en un vector p.error.Tipus.II. p.error.Tipus.II=rep(1,100) for (j in 1:100){ Tes=replicate(200,estadístic(20,mus[j],sigma0)) p.error.Tipus.II[j]=round(length(which((Tes&lt;=L0)==TRUE))/200,2) } p.error.Tipus.II ## [1] 0.24 0.36 0.52 0.53 0.31 0.04 0.08 0.09 0.78 0.68 0.62 0.00 0.10 0.12 0.65 ## [16] 0.01 0.04 0.62 0.57 0.10 0.58 0.25 0.30 0.00 0.29 0.48 0.26 0.00 0.09 0.66 ## [31] 0.07 0.08 0.79 0.03 0.03 0.00 0.00 0.56 0.52 0.23 0.72 0.04 0.70 0.77 0.74 ## [46] 0.70 0.06 0.15 0.06 0.48 0.00 0.04 0.10 0.01 0.01 0.00 0.35 0.60 0.58 0.64 ## [61] 0.08 0.38 0.09 0.40 0.78 0.02 0.03 0.66 0.47 0.27 0.18 0.05 0.59 0.01 0.04 ## [76] 0.44 0.33 0.34 0.66 0.01 0.10 0.68 0.73 0.74 0.21 0.07 0.18 0.69 0.01 0.32 ## [91] 0.06 0.64 0.66 0.27 0.08 0.49 0.20 0.01 0.10 0.42 La proporció mitjana d’errors de tipus II ha estat: mean(p.error.Tipus.II) ## [1] 0.3092 Si prenem mostres més grans, la probabilitat d’error de tipus II disminueix. Comprovem-ho repetint aquest segon experiment amb mostres de mida 200. p.error.Tipus.II.200=rep(1,100) for (j in 1:100){ Tes=replicate(200,estadístic(200,mus[j],sigma0)) p.error.Tipus.II.200[j]=round(length(which((Tes&lt;=L0)==TRUE))/200,2) } mean(p.error.Tipus.II.200) ## [1] 0.0078 Multiplicant per 10 la mida de les mostres, hem baixat d’una taxa d’errors de tipus II del 30.92% al 0.78%. Recordau que la potència d’un contrast és la probabilitat de no cometre un error de tipus II. Hem vist que prenent mostres més grans, la proporció d’errors de tipus II ha disminuït. Això és general: Si fixam el nivell de significació, com més grans són les mostres, més gran és la potència del contrast. Tornem a la situació general en la que tenim una variable aleatòria \\(X\\sim N(\\mu,\\sigma)\\) i volem contrastar \\(\\mu\\) amb un cert valor \\(\\mu_0\\) i suposem que ara cercam evidència que \\(\\mu&lt;\\mu_0\\), de manera que el contrast és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &lt; \\mu_0 \\end{array} \\right. \\] En aquest cas, el p-valor és \\(P(T\\leqslant T_0)\\) i, raonant exactament igual com abans, obtenim les dues regles de rebuig equivalents següents: Rebutjarem \\(H_0\\) si \\(T_0&lt; t_{n-1,\\alpha}\\) Rebutjarem \\(H_0\\) si el p-valor és més petit que \\(\\alpha\\) I què passa si ara cercam evidència que \\(\\mu\\) és diferent de \\(\\mu_0\\), és a dir, si tenim el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu\\ \\neq \\mu_0 \\end{array} \\right. \\] Aleshores rebutjarem \\(H_{0}\\) quan \\(\\overline{X}\\) és prou diferent de \\(\\mu_0\\), per damunt o per davall de \\(\\mu_0\\), i això ho traduïm en que rebutjarem \\(H_{0}\\) quan \\(|T_0|\\) (el valor absolut de \\(T_0\\)) sigui més gran que un cert llindar \\(L_0\\), que determinam a partir de \\(\\alpha\\) com abans: \\[ \\begin{array}{l} \\alpha = P(\\text{Rebutjar } H_{0}| H_{0} \\text{ certa})=P(|T|&gt; L_0)\\\\ \\hphantom{\\alpha} = P(T&lt; -L_0\\text{ o } T&gt;L_0)= P(T&lt; -L_0)+P(T&gt;L_0)\\\\ \\hphantom{\\alpha} =2P(T&gt;L_0) \\text{ (per la simetria de $t_{n-1}$)}\\\\ \\Longrightarrow \\alpha/2=P(T&gt;L_0)= 1-P(T\\leqslant L_0) \\\\ \\Longrightarrow P(T\\leqslant L_0)=1-\\alpha/2\\Longrightarrow L_0= t_{n-1,1-\\alpha/2} \\end{array} \\] Per tant, en un contrast bilateral amb nivell de significació \\(\\alpha\\), tenim la regla de rebuig següent: Rebutjarem \\(H_0\\) si \\(|T_0|&gt;t_{n-1,1-\\alpha/2}\\) En aquest cas, el p-valor serà la probabilitat que \\(T\\) prengui un valor tant o més extrem que \\(T_0\\), en el sentit de la hipòtesi alternativa, és a dir, més enfora de 0 que \\(T_0\\): més gran que \\(|T_0|\\) o més petit que \\(-|T_0|\\): \\[ \\text{p-valor} =P(T\\leqslant-|T_0|)+P(T\\geqslant|T_0|)=2 P(T\\geqslant|T_0|). \\] Fixau-vos que empram que, per la simetria de les variables t de Student, \\(P(T\\leqslant-|T_0|)=P(T\\geqslant|T_0|)\\). Per tant, \\[ \\begin{array}{l} \\text{Rebutjam $H_0$} \\Longleftrightarrow |T_0|&gt;t_{n-1,1-\\alpha/2}\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant|T_0|)&lt;{\\alpha}/{2}\\\\ \\qquad\\Longleftrightarrow 2 P(T\\geqslant|T_0|)&lt;\\alpha\\\\ \\qquad \\Longleftrightarrow \\text{p-valor} &lt; \\alpha \\end{array} \\] Per tant, en un contrast bilateral amb nivell de significació \\(\\alpha\\) també tenim la regla de rebuig: Rebutjarem \\(H_0\\) si el p-valor és més petit que \\(\\alpha\\) En resum, en un contrast d’una mitjana \\(\\mu\\) emprant un test t i nivell de significació \\(\\alpha\\): Si \\(H_1:\\mu&gt; \\mu_0\\): Rebutjam \\(H_0\\) si \\(T_0&gt;t_{n-1,1-\\alpha}\\) El p-valor és \\(P(T\\geqslant T_0)\\) i rebutjam \\(H_0\\) si el p-valor és més petit que \\(\\alpha\\) Si \\(H_1:\\mu&lt; \\mu_0\\): Rebutjam \\(H_0\\) si \\(T_0&lt; t_{n-1,\\alpha}\\) El p-valor és \\(P(T\\leqslant T_0)\\) i rebutjam \\(H_0\\) si el p-valor és més petit que \\(\\alpha\\) Si \\(H_1:\\mu\\neq \\mu_0\\): Rebutjam \\(H_0\\) si \\(|T_0|&gt;t_{n-1,1-\\alpha/2}\\) El p-valor és \\(2P(T\\geqslant|T_0|)\\) i rebutjam \\(H_0\\) si el p-valor és més petit que \\(\\alpha\\) Exemple 4.13 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&gt;20 \\end{array} \\right. \\] amb un nivell de significació de 0.05. Prenem una m.a.s. de \\(n=25\\) observacions i obtenim \\(\\overline{x}=20.7\\) i \\(\\widetilde{s}=1.8\\). Què decidim? Estadístic de contrast: \\(T=\\dfrac{\\overline{X}-\\mu_0}{\\widetilde{S}_X/\\sqrt{n}}\\) Pren el valor \\[ T_0=\\dfrac{20.7-20}{{1.8}/{\\sqrt{25}}}=1.944 \\] p-valor \\[ P(T\\geqslant 1.944)=\\texttt{1-pt(1.944,24)}=0.032 \\] Decisió: Com que el p-valor és més petit que 0.05, rebutjam \\(H_0\\) i concloem (amb \\(\\alpha=0.05\\)) que \\(\\mu&gt;20\\). Exemple 4.14 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&gt;20 \\end{array} \\right. \\] amb un nivell de significació de 0.01. Amb la mateixa m.a.s. de l’exemple anterior, què decidim? El p-valor és el mateix que abans, 0.032, perquè el contrast i la mostra són els mateixos. Com que aquest p-valor ara és més gran que 0.01, no podem rebutjar \\(H_0\\) amb \\(\\alpha=0.01\\) i hem d’acceptar que \\(\\mu=20\\). Fixau-vos que per reduir la probabilitat d’equivocar-nos rebutjant \\(H_0\\) si és vertadera, fem més fàcil acceptar-la “per si de cas”. Exemple 4.15 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&lt; 20 \\end{array} \\right. \\] amb un nivell de significació de 0.05. Amb la mateixa m.a.s. dels exemples anteriors (\\(n=25\\), \\(\\overline{x}=20.7\\),\\(\\widetilde{s}=1.8\\)), què decidim? L’estadístic de contrast i el seu valor \\(T_0\\) són el mateixos que abans. p-valor \\[ P(T\\leqslant 1.944)=\\texttt{pt(1.944,24)}=0.968 \\] Decisió: Com que el p-valor és més gran que 0.05, no podem rebutjar \\(H_0\\) i hem d’acceptar que \\(\\mu=20\\). Vegem, com volíeu que concloguéssim que \\(\\mu&lt;20\\) si ens ha sortit una mitjana mostral 20.7, més gran que 20? No feia falta fer cap càlcul (i exposar-nos a equivocar-nos), bastava raonar una mica. Exemple 4.16 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu\\neq 20 \\end{array} \\right. \\] amb un nivell de significació de 0.05. Amb la mateixa m.a.s. dels exemples anteriors, què decidim? Recordem que \\(n=25\\), \\(\\overline{x}=20.7\\) i \\(\\widetilde{s}=1.8\\). L’estadístic de contrast prenia el valor \\(T_0=1.944\\). Ara el p-valor és \\[ 2\\cdot P(T\\geqslant 1.944)=\\texttt{2*(1-pt(1.944,24))}=0.064 \\] Com que el p-valor és més gran que \\(\\alpha\\), no podem rebutjar \\(H_0\\): no podem afirmar amb \\(\\alpha=0.05\\) que \\(\\mu\\neq 20\\). Com pot ser que amb la mateixa mostra i mateix nivell de significació poguem concloure que \\(\\mu&gt; 20\\) però no poguem concloure que \\(\\mu\\neq 20\\)? O és que \\(\\mu&gt; 20\\) no implica que \\(\\mu\\neq 20\\)? Vegem, si haguéssim demostrat que segur que \\(\\mu&gt; 20\\), està clar que això implicaria que \\(\\mu\\neq 20\\). Però hem arribat a la conclusió \\(\\mu&gt; 20\\) assumint un cert marge d’error, una probabilitat d’error de tipus I de 0.05, i ens demanam si \\(\\mu\\neq 20\\) assumint el mateix marge d’error. En aquesta situació les regles de la lògica aristotèlica ja no funcionen. Fixau-vos que, en realitat, el que passa és que trobarem evidència que \\(\\mu\\neq 20\\) si \\(T\\) és molt gran o molt petit, i per tant al contrast bilateral hi tenim dues fonts d’error de tipus I: que per pur atzar \\(T\\) ens surti molt gran o que ens surti molt petit. En canvi, només trobarem evidència que \\(\\mu&gt; 20\\) si \\(T\\) és molt gran, i per tant hi tenim una sola font d’error de tipus I. Aleshores, per garantir una mateixa probabilitat d’error de tipus I, hem de ser molt més exigents al contrast bilateral, on ens podem equivocar de dues maneres diferents, que a l’unilateral. Exemple 4.17 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu\\neq 20 \\end{array} \\right. \\] amb un nivell de significació de 0.05. Prenem una m.a.s. de \\(n=25\\) observacions i obtenim \\(\\overline{x}=19\\) i \\(\\widetilde{s}=1.8\\). Què decidim? Estadístic de contrast: \\(T=\\dfrac{\\overline{X}-\\mu_0}{\\widetilde{S}_X/\\sqrt{n}}\\) Pren el valor \\[ T_0=\\dfrac{19-20}{{1.8}/{\\sqrt{25}}}=-2.778 \\] p-valor \\[ 2P(T\\geqslant-2.778)=\\texttt{2*(1-pt(-2.778,24))}=1.99 \\] Decisió: com que el p-valor és més gran que \\(\\alpha\\), no podem rebutjar \\(H_0\\). El p-valor és una probabiitat. Com voleu que doni 1.99? NO! El p-valor no és \\(2\\cdot P(T\\geqslant T_0)\\), sinó \\(2\\cdot P(T\\geqslant|T_0|)\\). Per tant, el p-valor és \\[ 2\\cdot P(T\\geqslant 2.778)=\\texttt{2*(1-pt(2.778,24))}=0.01 \\] i com que p-valor és més petit que \\(\\alpha\\), podem rebutjar \\(H_0\\) i concloure, amb nivell de significació 0.05, que \\(\\mu\\neq 20\\). 4.6 Recapitulació Repassem els conceptes introduïts fins ara, i posem nom a alguns altres: Nivell de significació, \\(\\alpha\\): probabilitat de rebutjar \\(H_0\\) si aquesta és vertadera (probabilitat d’error de tipus I, de positiu fals) Nivell de confiança, \\(1-\\alpha\\): probabilitat d’acceptar \\(H_0\\) si aquesta és vertadera (probabilitat de negatiu vertader) Potència, \\(1-\\beta\\): probabilitat de rebutjar \\(H_0\\) si \\(H_1\\) és vertadera (probabilitat de positiu vertader) Estadístic de contrast: el que calculam sobre una mostra aleatòria simple i ens permet definir una regla de rebuig de \\(H_{0}\\) Regió crítica o de rebuig: el rang de valors de l’estadístic de contrast per als quals rebutjam \\(H_{0}\\) amb un nivell de significació \\(\\alpha\\) donat Regió d’acceptació: el complementari de la regió de rebuig, és a dir, el rang de valors de l’estadístic de contrast per als quals acceptam \\(H_{0}\\) amb un nivell de significació \\(\\alpha\\) donat p-valor: la probabilitat que, si \\(H_0\\) és vertadera, l’estadístic de contrast prengui sobre una mostra aleatòria simple de la mateixa mida que la nostra un valor tan o més extrem (en el sentit de \\(H_1\\)) que l’obtingut sobre la nostra mostra Exemple 4.18 Si realitzam un test t per efectuar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt; \\mu_0 \\end{array} \\right. \\] rebutjam \\(H_0\\) amb nivell de significació \\(\\alpha\\) (o amb nivell de confiança \\(1-\\alpha\\)) quan \\[ T=\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}&gt;t_{n-1,1-\\alpha} \\] Per tant: Estadístic de contrast: aquest \\(T\\) Regió crítica per aquest \\(\\alpha\\): l’interval \\((t_{n-1,1-\\alpha},\\infty)\\) Regió d’acceptació per aquest \\(\\alpha\\): l’interval \\((-\\infty,t_{n-1,1-\\alpha}]\\) p-valor: \\(P(T\\geqslant T_0)\\), on \\(T_0\\) indica el valor de \\(T\\) sobre la nostra mostra Si en canvi el contrast que volem efectuar és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &lt; \\mu_0 \\end{array} \\right. \\] rebutjam \\(H_0\\) amb nivell de significació \\(\\alpha\\) (o amb nivell de confiança \\(1-\\alpha\\)) quan \\[ T=\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}&lt;t_{n-1,\\alpha} \\] Per tant: Estadístic de contrast: el mateix \\(T\\) que abans Regió crítica per aquest \\(\\alpha\\): l’interval \\((-\\infty,t_{n-1,\\alpha})\\) Regió d’acceptació per aquest \\(\\alpha\\): l’interval \\([t_{n-1,\\alpha},\\infty)\\) p-valor: \\(P(T\\leqslant T_0)\\) Finalment, si el contrast que volem realitzar és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq \\mu_0 \\end{array} \\right. \\] rebutjam \\(H_0\\) amb nivell de significació \\(\\alpha\\) (o amb nivell de confiança \\(1-\\alpha\\)) quan \\[ |T|=\\left|\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\right|&gt;t_{n-1,1-\\alpha/2} \\] Per tant: Estadístic de contrast: el mateix \\(T\\) que abans Regió crítica per aquest \\(\\alpha\\): la unió d’intervals \\((-\\infty,-t_{n-1,1-\\alpha/2})\\cup (t_{n-1,1-\\alpha/2},\\infty)\\) Regió d’acceptació per aquest \\(\\alpha\\): l’interval \\([-t_{n-1,1-\\alpha/2},t_{n-1,1-\\alpha/2}]\\) p-valor: \\(2P(T\\geqslant|T_0|)\\) Interval de confiança d’un contrast L’interval de confiança de nivell de confiança \\(1-\\alpha\\) d’un contrast és un interval on el paràmetre poblacional que contrastam té probabilitat \\(1-\\alpha\\) de pertànyer-hi en el sentit dels intervals de confiança del tema anterior: calculat amb una fórmula que un \\((1-\\alpha)\\cdot 100\\%\\) de les vegades que l’aplicam de manera correcta a una mostra aleatòria simple, dóna un interval que conté el paràmetre d’interès. Aquest interval de confiança s’obté imposant que l’estadístic de contrast pertanyi a la regió d’acceptació per al nivell de significació \\(\\alpha\\) i aïllant el paràmetre poblacional. Quan \\(H_1\\) és bilateral, coincideix amb l’interval de confiança donat en el tema anterior Quan \\(H_1\\) és unilateral, dóna un interval infinit al costat definit per la hipòtesi alternativa. Per exemple, considerem el cas de un test t per efectuar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt; \\mu_0 \\end{array} \\right. \\] Acceptam \\(H_0\\) amb nivell de significació \\(\\alpha\\) quan \\[ \\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\leqslant t_{n-1,1-\\alpha} \\] Aïllant \\(\\mu_0\\), obtenim \\[ \\overline{X}- t_{n-1,1-\\alpha}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu_0 \\] Per tant, l’interval de confiança de nivell de confiança \\(1-\\alpha\\) per a aquest contrast és \\[ \\Bigg[\\overline{X}- t_{n-1,1-\\alpha}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}},\\infty\\Bigg) \\] Si la \\(\\mu_0\\) que contrastam pertany a aquest interval, no podem concloure que la \\(\\mu\\) poblacional sigui més gran, i per tant no podem rebutjar que \\(\\mu=\\mu_0\\). En l’exemple dels diabètics de la Secció 4.5, dóna l’interval \\[ \\Bigg[3.2- 1.73\\cdot \\dfrac{1.5}{\\sqrt{20}},\\infty\\Bigg)=[2.62,\\infty) \\] Obtenim que, amb un nivell de confiança del 95%, la concentració mitjana de calci en sang en els joves diabètics és com a mínim 2.62, i que per tant, amb aquest nivell de confiança, no pot ser 2.5, encara que per poc. Si efectuam un contrast bilateral amb un test t \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu\\neq \\mu_0 \\end{array} \\right. \\] acceptam \\(H_0\\) amb nivell de significació \\(\\alpha\\) quan \\[ -t_{n-1,1-\\alpha/2}\\leqslant\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\leqslant t_{n-1,1-\\alpha/2} \\] Aïllant \\(\\mu_0\\), obtenim: \\[ \\overline{X}- t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu_0 \\leqslant\\overline{X}+ t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}} \\] Per tant, l’interval de confiança de nivell de confiança \\(1-\\alpha\\) per a aquest contrast és \\[ \\Bigg[\\overline{X}- t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}},\\overline{X}+ t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Us sona? Fent \\(q=1-\\alpha\\), és el del tema anterior. Donat un contrast d’hipòtesis, podem decidir si rebutjam \\(H_0\\) en favor de \\(H_1\\) amb nivell de significació \\(\\alpha\\) emprant: La regió crítica: Si l’estadístic de contrast cau dins la regió crítica per al nivell de significació \\(\\alpha\\), rebutjam \\(H_0\\) El p-valor: Si el p-valor és més petit que el nivell de significació \\(\\alpha\\), rebutjam \\(H_0\\) L’interval de confiança: Si el valor que contrastam del paràmetre poblacional no pertany a l’interval de confiança de nivell de confiança \\(1-\\alpha\\), rebutjam \\(H_0\\) Els tres mètodes són equivalents. El més adequat és donar el p-valor i l’interval de confiança: el p-valor perquè el lector el pugui comparar amb el nivell de significació que consideri oportú i l’interval de confiança perquè mostra el marge amb el qual hem acceptat o rebutjat la hipòtesi nul·la amb el nostre nivell de significació. Si no establim un nivell de significació \\(\\alpha\\), el que és habitual en Biologia i Bioquímica és: Acceptar \\(H_0\\) si el p-valor és més gran que 0.1: es diu que el p-valor no és estadísticament significatiu Rebutjar \\(H_0\\) si el p-valor és més petit que 0.05: es diu que el p-valor és estadísticament significatiu Si el p-valor està entre 0.05 i 0.1 i no s’ha fixat nivell de significació, el millor que podeu fer és no concloure res Quan el p-valor és més petit que 0.05, se solen distingir tres franges: Significatiu si està entre 0.01 i 0.05 Fortament significatiu si està entre 0.001 i 0.01 Molt significatiu si és més petit que 0.001 R marca aquestes franges amb un codi d’asteriscs Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Figura 4.2: Emoticones per representar els nivells de significació estadística (BMJ 2018; 363, doi: https://doi.org/10.1136/bmj.k5033) Atès que rebutjam \\(H_0\\) si, i només si, el p-valor és més petit que \\(\\alpha\\), el p-valor d’un contrast és el nivell de significació més petit per al qual rebutjaríem la hipòtesi nul·la. És a dir: El p-valor obtingut en un contrast és la probabilitat mínima que tenim d’equivocar-nos rebutjant la hipòtesi nul·la si és vertadera. Per tant, per favor, acostumau-vos a donar el p-valor, i no la franja de significació on cau. La potència Recordau que la potència \\(1-\\beta\\) és la probabilitat de rebutjar \\(H_0\\) quan \\(H_1\\) és vertadera. Per exemple, en l’exemple del calci en diabètics de la Secció 4.5, la regla de rebuig era \\[ T=\\frac{\\overline{X}-2.5}{\\widetilde{S}_X/\\sqrt{n}}&gt;1.73, \\] per tant la potència era \\[ 1-\\beta=P(\\text{Rebutjar } H_0| H_1\\text{ vertadera})=P(T&gt;1.73| \\mu&gt;2.5). \\] Aquesta probabilitat és impossible de calcular, però hi ha paquets de R que la saben estimar. Per a cada tipus de contrast es té una relació numèrica entre: La potència \\(1-\\beta\\) La mida de la mostra \\(n\\): la potència creix amb \\(n\\) El nivell de significació \\(\\alpha\\): la potència decreix amb \\(\\alpha\\) La mida de l’efecte, un valor que quantifica la diferència entre el paràmetre mostral i el valor contrastat. La potència creix amb el valor absolut de la mida de l’efecte (ja que, com més gran és la diferència entre el paràmetre mostral i el valor contrastat, més probable és que sigui estadísticament significativa i per tant rebutgem la hipòtesi nul·la). Aquesta relació permet calcular qualsevol dels quatre valors a partir dels altres tres; amb R, el paquet pwr permet fer-ho amb els contrastos més usuals. A l’hora de planejar un experiment per realitzar un contrast, el que s’ha de fer és: Fixar el nivell de significació desitjat Fixar la potència desitjada Estimar la mida de l’efecte esperat (a partir de la nostra teoria, de la nostra experiència, dels resultats d’altres estudis…) o que volguem detectar (per rebutjar la hipòtesi nul·la ens bastarà una mida de l’efecte petita o la requerirem grossa?) i emprar la relació anterior per calcular la mida de la mostra necessària per assolir la potència desitjada. Desconfiau dels treballs on això no es faci. Podria ser que la potència fos molt baixa i hi hagués un biaix de infrapotència (underpower): es necessitava un efecte molt gran per poder rebutjar la hipòtesi nul·la i publicar l’article. El risc de positiu fals (Opcional) El paquet statcheck de R permet revisar de manera automàtica tots els càlculs d’un article escrit en un format concret en psicologia i comprovar-ne els p-valors. Els autors van analitzar 30,000 articles i varen concloure que (Behavior research methods 48 (2016), 1205-1226): “Hem trobat que la meitat dels articles contenen almenys un p-valor erroni. I un de cada vuit articles conté un p-valor erroni que a més afecta la conclusió estadística.” Per tant, Qualsevol article pot donar un p-valor petit que estigui equivocat No us en refieu. A més, teniu present que: Qualsevol estudi mal dissenyat o mal realitzat pot donar un p-valor petit… que no signifiqui absolutament res Qualsevol estudi perfectament dissenyat i realitzat pot donar per pur atzar un p-valor petit… que impliqui un positiu fals En resum, a qualsevol estudi us podeu trobar amb un fals positiu. Sigau escèptics. El risc de positiu fals, FPR, en un contrast és \\[ P(H_0\\text{ vertadera}|H_0\\text{ rebutjada}). \\] Pel teorema de Bayes (notau que interpretam \\(H_1= \\text{no }H_0\\)) \\[ \\begin{array}{rl} FPR&amp;=\\dfrac{P(H_0)\\cdot P(H_0\\text{ reb.}|H_0)}{P(H_0)\\cdot P(H_0\\text{ reb.}|H_0)+P(H_1)\\cdot P(H_0\\text{ reb.}|H_1)}\\\\ &amp; =\\dfrac{P(H_0)\\cdot \\alpha}{P(H_0)\\cdot \\alpha+(1-P(H_0))\\cdot (1-\\beta)}\\\\ &amp; =\\dfrac{(1-P(H_1))\\cdot \\alpha}{(1-P(H_1))\\cdot \\alpha+ P(H_1)\\cdot (1-\\beta)} \\end{array} \\] Per calcular-lo, hem de saber el nivell de significació i la potència i hem de decidir a priori quina probabilitat assignam al fet que \\(H_1\\) sigui vertadera. Exemple 4.19 En un estudi (publicat a Psychological Science 22 (2011), pp. 1011-1018) es repartiren 66 participants en dos grups de 33, als que direm grup Bandera i grup Control, i els mostraren les mateixes 4 fotos d’edificis. En les del grup Bandera, dues mostraven una bandera dels EUA, i en les del grup Control, aquestes banderes havien estat eliminades digitalment. Per emmascarar l’estudi, se’ls demanà que endevinassin l’hora del dia en què varen ser preses les fotos. Després de mirar les fotos, els participants emplenaren un qüestionari sobre idees polítiques, a partir del qual es pot calcular un cert “índex de republicanisme” (en el sentit nordamericà del terme) \\(M\\) del que l’ha contestat. Resulta que \\(M\\) va ser significativament més gran en el grup Bandera que en el grup Control, i amb un nivell de significació \\(\\alpha=0.05\\) els autors de l’estudi conclogueren que mirar fotos amb banderes estatals et “dretitza” (almenys a curt termini) les idees polítiques. Vaig a estimar el risc que aquest positiu sigui fals. Com que a priori, trob molt improbable que la conclusió sigui certa, li assignaré \\(P(H_1)=0.1\\) i gràcies. Emprarem el seu \\(\\alpha=0.05\\), i si es calcula la potència del contrast publicat, dóna 0.5. Llavors \\[ FPR =\\dfrac{0.9\\cdot 0.05}{0.9\\cdot 0.05+0.1\\cdot 0.5}=0.47 \\] Per tant, a posteriori, crec que hi ha un 47% de probabilitats que \\(H_1\\) sigui falsa i un 53% de probabilitats que \\(H_1\\) sigui vertadera. "],
["contrastos-dhipòtesis-dun-i-dos-paràmetres.html", "Tema 5 Contrastos d’hipòtesis d’un i dos paràmetres 5.1 Contrastos de mitjanes 5.2 Contrastos de variàncies 5.3 Contrastos per a proporcions", " Tema 5 Contrastos d’hipòtesis d’un i dos paràmetres Per adquirir un poc de disciplina en la realització de contrastos d’hipòtesis, procurau, almenys per ara, dividir-los en els apartats següents: Variables aleatòries d’interès, incloent les seves unitats de mesura si en tenen, i els paràmetres poblacionals involucrats en el contrast Contrast \\[ \\left\\{\\begin{array}{l} H_{0}: ...\\\\ H_{1}: ... \\end{array} \\right. \\] I a partir d’aquí, si el feu “a mà”: Estadístic de contrast i distribució si la hipòtesi nul·la és vertadera Valor de l’estadístic sobre la mostra p-valor i si pot ser interval de confiança del nivell de significació demanat (0.05 per defecte) Conclusió I si el feu amb R: L’efectuau amb R Conclusió Per a la conclusió, emprau la plantilla següent Hem obtingut evidència estadísticament significativa que passa tal cosa (test realitzat, p-valor …, IC 95% …). No hem obtingut evidència estadísticament significativa que passa tal cosa (test realitzat, p-valor …, IC 95% …). 5.1 Contrastos de mitjanes 5.1.1 Test t per a una mitjana Si estam en una de les dues situacions següents: \\(X\\) una variable aleatòria normal amb mitjana \\(\\mu\\) i en prenem una mostra aleatòria simple de mida \\(n\\) qualsevol \\(X\\) una variable aleatòria qualsevol amb mitjana \\(\\mu\\) i en prenem una mostra aleatòria simple de mida \\(n\\) gran (diguem que de mida com a mínim 30) i volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq\\mu_0\\text{ o }\\mu &gt;\\mu_0\\text{ o }\\mu&lt;\\mu_0 \\end{array} \\right. \\] podem emprar el test t que ja hem explicat a la Secció 4.5, basat en l’estadístic de contrast \\[ T= \\frac{\\overline{X}-\\mu_{0}}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] que, en les condicions donades i si \\(\\mu=\\mu_0\\), té una distribució (aproximadament, si \\(X\\) no és normal però \\(n\\) és gran) \\(t_{n-1}\\). Exemple 5.1 Una organització ecologista afirma que el pes mitjà dels individus adults d’una espècie ha disminuït dràsticament. Se sap per les dades històriques que el pes mitjà poblacional era de 460 g. Una mostra aleatòria de 50 individus d’aquesta espècie ha donat una mitjana mostral de 428 g i una desviació típica mostral de 119 g. Amb aquestes dades, podem afirmar amb un nivell de significació del 5% que el pes mitjà és inferior a 460 g? Variable aleatòria d’interès: \\(X\\): “Prenem un animaló d’aquests i mesuram el seu pes, en grams”, amb mitjana \\(\\mu\\) Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=460\\\\ H_{1}:\\mu&lt;460 \\end{array} \\right. \\] Prenem nivell de significació \\(\\alpha=0.05\\). Estadístic de contrast: Com que \\(n=50\\) és gran, podem usar \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] que sí \\(H_0\\) és vertadera serà (aproximadament) t de Student amb \\(n-1=49\\) graus de llibertat Valor de l’estadístic: \\[ \\dfrac{428-460}{{119}/{\\sqrt{50}}}=-1.9 \\] p-valor: \\[ P(T\\leqslant-1.9)=\\texttt{pt(-1.9,49)}=0.032 \\] Interval de confiança del 95%: \\[ \\left(-\\infty, \\overline{X}+t_{n-1,1-\\alpha}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\right]=(-\\infty, 456.2] \\] Conclusió: Com que el p-valor és més petit que 0.05, concloem (amb \\(\\alpha=0.05\\)) que el pes mitjà actual és més petit que 460 g. De fet, amb un 95% de confiança podem afirmar que el pes mitjà actual és inferior a 456.2 g, que està per davall dels 460 g. Amb la plantilla que us hem donat: Hem obtingut evidència estadísticament significativa que el pes mitjà actual és menor que 460 g (test t, p-valor 0.03, IC 95% de \\(-\\infty\\) a 456.2) i que per tant ha minvat en els darrers anys. 5.1.2 Test t per a dues mitjanes Si estam en una de les situacions següents: \\(X_1,X_2\\) dues variables aleatòries normals de mitjanes \\(\\mu_1\\), \\(\\mu_2\\) i en prenem mostres aleatòries simples de mides \\(n_1\\), \\(n_2\\) qualssevol \\(X_1,X_2\\) dues variables aleatòries qualssevol de mitjanes \\(\\mu_1\\), \\(\\mu_2\\) i en prenem mostres aleatòries simples de mides \\(n_1\\), \\(n_2\\) grans (diguem que totes dues de mida com a mínim 30) i volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1=\\mu_2\\\\ H_{1}:\\mu_1 \\neq\\mu_2\\text{ o }\\mu_1 &gt;\\mu_2\\text{ o }\\mu_1&lt;\\mu_2 \\end{array} \\right. \\] podem usar un test t, basat en un estadístic de contrast \\(T\\) adequat que segueix una llei t de Student. L’estadístic de contrast concret i els graus de llibertat de la seva distribució t de Student depenen: De si les dues mostres són independents (hem mesurat \\(X_1\\) i \\(X_2\\) sobre dues mostres obtingudes de manera independent una de l’altra) o aparellades (hem mesurat \\(X_1\\) i \\(X_2\\) sobre els subjectes d’una mateixa mostra o hi ha un aparellament natural entre els subjectes de les dues mostres) Quan les mostres són independents, també depenen de si \\(X_1\\) i \\(X_2\\) tenen la mateixa variància o no (la qual cosa es pot decidir amb un altre contrast: vegeu la Secció 5.2); per a mostres de la mateixa mida de variables normals, la conclusió sol ser la mateixa Quan les mostres són aparellades, podem entendre que tenim una sola mostra, formada per les parelles, sobre les quals mesuram la diferència \\(X_1-X_2\\). En aquest cas, traduïm \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1=\\mu_2\\\\ H_{1}:\\mu_1 \\neq\\mu_2\\text{ o }\\mu_1 &gt;\\mu_2\\text{ o }\\mu_1&lt;\\mu_2 \\end{array} \\right. \\] en \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1-\\mu_2=0\\\\ H_{1}:\\mu_1-\\mu_2 \\neq0\\text{ o }\\mu_1-\\mu_2 &gt;0\\text{ o }\\mu_1-\\mu_2&lt;0 \\end{array} \\right. \\] on \\(\\mu_1-\\mu_2\\) és la mitjana de \\(X_1-X_2\\), i el consideram un contrast d’una sola mitjana, emprant com a mostra les diferències \\(X_1-X_2\\) a les parelles. Per tant, quan les mostres són aparellades, si diem \\(D\\) a \\(X_1-X_2\\), \\(\\overline{D}\\) a la mitjana mostral de \\(D\\) i \\(\\widetilde{S}_D\\) a la desviació típica mostral de \\(D\\) sobre la mostra de parelles i diem \\(n\\) a la mida de la mostra de parelles, l’estadístic de contrast és \\[ T=\\frac{\\overline{D}}{\\widetilde{S}_D/\\sqrt{n}} \\] que, quan \\(\\mu_D=(\\mu_1-\\mu_2)=0\\), té (aproximadament, si \\(X_1,X_2\\) no són normals però la \\(n\\) és gran) distribució \\(t_{n-1}\\). Quan les mostres són independents, siguin \\(\\overline{X}_1\\) i \\(\\widetilde{S}^2_1\\) la mitjana mostral i la variància mostral de la mostra de \\(X_1\\) i \\(\\overline{X}_2\\) i \\(\\widetilde{S}^2_2\\) la mitjana mostral i la variància mostral de la mostra de \\(X_2\\). Diguem, a més, \\(\\sigma_1^2\\) i \\(\\sigma_2^2\\) a les variàncies (poblacionals) de \\(X_1\\) i \\(X_2\\). Aleshores: Si \\(\\sigma_1^2=\\sigma_2^2\\), l’estadístic de contrast és \\[ T=\\frac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{(\\frac{1}{n_1}+\\frac{1}{n_2})\\cdot \\frac{(n_1-1)\\widetilde{S}_1^2+(n_2-1)\\widetilde{S}_2^2}{n_1+n_2-2}}} \\] que, quan \\(\\mu_1=\\mu_2\\), té distribució (aproximadament, si \\(X_1,X_2\\) no són normals però \\(n_1\\) i \\(n_2\\) són totes dues grans) \\(t_{n_1+n_2-2}\\) Si \\(\\sigma_1^2\\neq \\sigma_2^2\\), l’estadístic de contrast és \\[ T=\\frac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{\\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}}} \\] que, quan \\(\\mu_1=\\mu_2\\), té distribució (aproximadament, si \\(X_1,X_2\\) no són normals però \\(n_1\\) i \\(n_2\\) són totes dues grans) \\(t_{\\nu}\\) amb \\[ \\nu=\\frac{\\displaystyle \\left( \\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2} {\\displaystyle \\frac{1}{n_1-1}\\left(\\frac{\\widetilde{S}_1^2}{n_1}\\right)^2+\\frac{1}{n_2-1}\\left(\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2} \\] No cal que sapigueu aquestes fórmules per a mostres independents, només que l’estadístic de contrast i la seva distribució depenen de si les variàncies poblacionals són iguals o diferents. El nombre de graus de llibertat de la distribució t de Student usada en un contrast sobre dues mostres de mida \\(n\\): Si les mostres són aparellades, és \\(n-1\\) Si les mostres són independents, és aproximadament \\(2(n-1)\\) Això fa que la probabilitat d’error de Tipus I del contrast amb mostres aparellades (a igualtat de la resta de valors) sigui més petita. Per exemple, suposem que volem realitzar el contrast \\[ \\left\\{ \\begin{array}{l} H_0: \\mu_1=\\mu_2\\\\ H_1: \\mu_1&gt;\\mu_2 \\end{array} \\right. \\] i que l’estadístic de contrast \\(T\\) sobre dues mostres de mides \\(n_1=n_2=20\\) dóna 1.7. Aleshores Si les mostres són independents, \\[ \\text{p-valor}=P(T&gt;1.7)\\approx \\texttt{1-pt(1.7,38)}=0.0487 \\] Si les mostres són aparellades, \\[ \\text{p-valor}=P(T&gt;1.7)=\\texttt{1-pt(1.7,19)}=0.0527 \\] Per tant, amb nivell de significació \\(\\alpha=0.05\\), rebutjaríem la hipòtesi nul·la amb les mostres independents i l’acceptaríem amb les mostres aparellades. 5.1.3 Tests t amb R Tots aquests tests t estan implementats en la funció de R t.test(x, y, mu=..., alternative=..., paired=..., var.equal=..., conf.level=...) on: Entram com a x una mostra i a mu el valor amb el qual volem contrastar \\(\\mu\\), o entram com a x i y les mostres de \\(X_1\\) i de \\(X_2\\) A alternative hi hem d’indicar el tipus de contrast segons la hipòtesi alternativa: alternative=&quot;two.sided&quot; (\\(\\neq\\), el valor per defecte) alternative=&quot;less&quot; (\\(&lt;\\)) alternative=&quot;greater&quot; (\\(&gt;\\)) En el cas d’un contrast de dues mitjanes, a paired hi hem d’indicar si les mostres són independents, amb paired=FALSE (el valor per defecte), o aparellades, amb paired=TRUE En el cas d’un contrast de dues mitjanes amb mostres independents, a var.equal hi hem d’indicar si les variàncies són iguals, amb var.equal=TRUE, o diferents, amb var.equal=FALSE (el valor per defecte) A conf.level hi hem d’especificar el nivell de confiança \\(1-\\alpha\\): el seu valor per defecte és 0.95, que correspon al nivell de significació \\(\\alpha=0.05\\) usual 5.1.4 Exemples Exemple 5.2 La temperatura mitjana del cos humà, és el valor usualment acceptat de 98.6o F (37o C)? Per contrastar-ho, emprarem la taula de dades Body_Temperature.txt, construïda per P.A. Mackowiak, S. S. Wasserman i M.M. Levine en 1992 precisament per realitzar aquest contrast i que trobareu a l’Aula Digital. Variable aleatòria d’interès: \\(X\\): “Prenem una persona i li miram la temperatura, en graus F”, amb mitjana \\(\\mu\\) Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=98.6\\\\ H_{1}:\\mu \\neq 98.6 \\end{array} \\right. \\] Realitzarem aquest contrast amb R. Carregam la taula de temperatures, que prèviament hem guardat en el directori de treball de R, en un dataframe que anomenarem BT. BT=read.table(&quot;Body_Temperature.txt&quot;) head(BT) ## Gender HeartRate Temperature ## 1 M 69 97.0 ## 2 M 72 98.8 ## 3 M 68 96.2 ## 4 F 75 97.8 ## 5 F 68 98.8 ## 6 M 79 101.3 str(BT) ## &#39;data.frame&#39;: 230 obs. of 3 variables: ## $ Gender : chr &quot;M&quot; &quot;M&quot; &quot;M&quot; &quot;F&quot; ... ## $ HeartRate : int 69 72 68 75 68 79 71 73 77 81 ... ## $ Temperature: num 97 98.8 96.2 97.8 98.8 ... Veiem que la taula BT consta de 230 individus i 3 variables mesurades sobre cadascun d’ells: el sexe (variable Gender, amb nivells F per a dona i M per a home), les pulsacions per minut (variable HeartRate) i la temperatura en graus F (variable Temperature). Com que la mostra és gran, \\(n=230\\), podem emprar un test t. Emprarem la funció t.test, aplicant-la al vector de temperatures i al valor que contrastam, 98.6, entrat amb el parametre mu. El paràmetre alternative=&quot;two.sided&quot; indica que el test serà bilateral. t.test(BT$Temperature, mu=98.6, alternative=&quot;two.sided&quot;) ## ## One Sample t-test ## ## data: BT$Temperature ## t = -5.7205, df = 229, p-value = 3.301e-08 ## alternative hypothesis: true mean is not equal to 98.6 ## 95 percent confidence interval: ## 98.17563 98.39307 ## sample estimates: ## mean of x ## 98.28435 Del resultat cal destacar: El p-valor, p-value, en el nostre cas 3.301·10-8 (R l’ha escrit en notació científica: 3.301e-08). L’IC 95%, 95 percent confidence interval, per al valor que contrastam (aquí, la temperatura mitjana poblacional), en el nostre cas [98.17563, 98.39307]. La mitjana mostral de la mostra, sample of x, en el nostre cas 98.28435. Per tant: El p-valor és 3·10-8, per la qual cosa amb les dades d’aquesta taula obtenim evidència estadísticament significativa que la temperatura mitjana del cos humà no és de 98.6o F (37o C) A més, com que l’IC 95% per a la temperatura mitjana del cos humà que hem obtingut va de 98.2 a 98.4 (36.78 a 36.89o C), hem trobat evidència amb aquest nivell de confiança que aquesta temperatura mitjana és de fet (lleugerament) inferior 98.6o F Conclusió: Hem obtingut evidència estadísticament significativa que la temperatura mitjana del cos humà no és de 98.6o F (test t, p-valor 3·10-8, IC 95% de 98.2 a 98.4). Exemple 5.3 La temperatura dels homes, és més alta que la de les dones? Per resoldre aquesta qüestió, emprarem la mateixa taula de dades que abans. Variables aleatòries d’interès: \\(X_d\\): “Prenem una dona i li miram la temperatura, en graus F”, amb mitjana \\(\\mu_d\\) \\(X_h\\): “Prenem un home i li miram la temperatura, en graus F”, amb mitjana \\(\\mu_h\\) Contrast: Plantejarem el contrast en termes de temperatures mitjanes: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&lt; \\mu_h \\end{array} \\right. \\] Per poder emprar un t test, primer ens cal saber si hi ha nombres suficientment grans d’homes i dones a la nostra mostra per emprar-lo. Per això calcularem la taula de freqüències dels sexes, aplicant la funció table al vector BT$Gender dels sexes: table(BT$Gender) ## ## F M ## 116 114 Són prou grans. Anam a crear uns vectors amb les temperatures d’homes i de dones. Recordau que hi ha diverses maneres d’extreure d’un dataframe el vector de valors d’una variable V1 per als individus que prenen un valor concret X en una altra variable V2: per exemple dataframe$V1[V2==X] o dataframe[V2==X,V1]. Així, les temperatures dels homes (individus on la variable Gender és igual a M) són BT$Temperature[BT$Gender==&quot;M&quot;] ## [1] 97.0 98.8 96.2 101.3 99.2 97.5 97.3 98.6 99.0 98.0 97.0 97.6 ## [13] 99.0 97.1 98.9 98.6 98.9 97.2 98.0 99.4 98.8 98.5 99.6 97.3 ## [25] 96.5 97.8 98.3 98.1 98.8 97.7 98.3 97.7 99.1 98.8 97.4 96.9 ## [37] 98.0 98.4 100.3 97.0 99.0 100.6 98.0 98.5 97.0 97.0 98.6 97.8 ## [49] 97.3 96.3 96.7 96.9 97.0 97.1 97.1 97.1 97.2 97.3 97.4 97.4 ## [61] 97.4 97.4 97.5 97.5 97.6 97.6 97.6 97.7 97.8 97.8 97.8 97.8 ## [73] 97.9 97.9 98.0 98.0 98.0 98.0 98.0 98.0 98.1 98.1 98.2 98.2 ## [85] 98.2 98.2 98.3 98.3 98.4 98.4 98.4 98.4 98.5 98.5 98.6 98.6 ## [97] 98.6 98.6 98.6 98.6 98.7 98.7 98.8 98.8 98.8 98.9 99.0 99.0 ## [109] 99.0 99.1 99.2 99.3 99.4 99.5 Bé, cream els vectors \\(X_d\\) (dones) i \\(X_h\\) (homes) X_d=BT[BT$Gender==&quot;F&quot;,&quot;Temperature&quot;] #temperatures de dones X_h=BT[BT$Gender==&quot;M&quot;,&quot;Temperature&quot;] #temperatures d&#39;homes Per portar a terme un test t per comparar dues mitjanes, aplicam la funció t.test als vectors X_di X_h amb paràmetre alternative=&quot;less&quot; per indicar que el test és unilateral: la hipòtesi alternativa és que la mitjana de la primera població (dones) és més petita que la de la segona (homes). En aquest exemple, a més, especificarem que les mostres són independents amb paired=FALSE (no caldria, ja que és el valor per defecte) i a més hem d’especificar si les variàncies poblacionals són iguals (var.equal=TRUE) o diferents (var.equal=FALSE). El que farem aquí serà provar els dos casos: amb les variàncies iguals i amb les variàncies diferents. Si les dues conclusions són la mateixa, aquesta serà la conclusió que prendrem. Si dóna diferent, haurem de realitzar un contrast previ per decidir si hem de suposar que les variàncies són iguals o diferents. t.test(X_d, X_h, alternative=&quot;less&quot;,paired=FALSE, var.equal=TRUE) ## ## Two Sample t-test ## ## data: X_d and X_h ## t = 2.5379, df = 228, p-value = 0.9941 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf 0.4569566 ## sample estimates: ## mean of x mean of y ## 98.42155 98.14474 t.test(X_d, X_h, alternative=&quot;less&quot;,paired=FALSE, var.equal=FALSE) ## ## Welch Two Sample t-test ## ## data: X_d and X_h ## t = 2.5358, df = 225.32, p-value = 0.9941 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf 0.4571095 ## sample estimates: ## mean of x mean of y ## 98.42155 98.14474 En tots dos casos obtenim un p-valor (p-value) gran. L’IC 95 % (95 percent confidence interval) que ens dóna és per a la diferència de les mitjanes. Com que conté el 0, no podem descartar que les dues mitjanes siguin iguals. Conclusió: No hem obtingut evidència estadísticament significativa que la temperatura mitjana de les dones sigui més baixa que la dels homes (test t, p-valor 0.99, IC 95% per a la diferència de les mitjanes de \\(-\\infty\\) a 0.46). Vegem, si \\(\\overline{X_d}=98.42\\) i \\(\\overline{X_h}=98.14\\), com volíeu que obtinguéssim evidència que \\(\\mu_d&lt;\\mu_h\\)? Mirau sempre les dades primer! Si, per exemple, haguéssim dibuixat abans del contrast un diagrama de caixes de les temperatures separades per sexe, hauríem vist que era impossible obtenir evidència que les dones tenen temperatura mitjana inferior als homes, i no hauria fet falta continuar. boxplot(Temperature~Gender,data=BT,names=c(&quot;Dones&quot;,&quot;Homes&quot;),xlab=&quot;&quot;,ylab=&quot;Temperatura&quot;) Exercici: Emprant les mateixes dades, trobau evidència que \\(\\mu_h&lt;\\mu_d\\)? I que \\(\\mu_h\\neq \\mu_d\\)? Spoiler: Exemple 5.4 Desdijunar segó de civada (oat bran) en lloc de flocs de blat de moro (corn flakes), ajuda a reduir el nivell de colesterol? Per resoldre aquesta qüestió, emprarem la taula de dades oatbran.txt, que trobareu a l’Aula Digital. Aquestes dades es recolliren en un assaig creuat sobre 14 individus. A cada un d’ells se li assignà un dels dos desdijunis de manera aleatòria i el prengueren durant 15 dies. Al final d’aquest període, se’ls mesurà el nivell de colesterol en sang. Passat un mes de descans, cada participant va desdijunar durant 15 dies l’altre producte, i al final se’ls tornà a mesurar el nivell de colesterol en sang. En aquesta taula, aquests nivells de colesterol estan mesurats en milimols per litre Variables aleatòries d’interès: \\(X_{ob}\\): “Prenem una persona que desdijuna oat bran i li mesuram el nivell de colesterol en mmol/l”, amb mitjana \\(\\mu_{ob}\\) \\(X_{cf}\\): “Prenem una persona que desdijuna corn flakes i li mesuram el nivell de colesterol en mmol/l”, amb mitjana \\(\\mu_{cf}\\) Contrast: El plantejarem en termes de nivells mitjans de colesterol: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{ob}=\\mu_{cf}\\\\ H_{1}:\\mu_{ob}&lt; \\mu_{cf} \\end{array} \\right. \\] Carregam la taula de dades, que prèviament hem guardat en el directori de treball de R, en un dataframe al que anomenam OBR i consultam la seva estructura: OBR=read.table(&quot;oatbran.txt&quot;,header=TRUE) head(OBR) ## CORNFLK OATBRAN ## 1 4.61 3.94 ## 2 6.42 5.57 ## 3 5.40 5.85 ## 4 4.54 4.80 ## 5 3.98 3.68 ## 6 3.82 2.96 str(OBR) ## &#39;data.frame&#39;: 14 obs. of 2 variables: ## $ CORNFLK: num 4.61 6.42 5.4 4.54 3.98 3.82 5.01 4.34 3.8 4.56 ... ## $ OATBRAN: num 3.94 5.57 5.85 4.8 3.68 2.96 4.41 3.72 3.49 3.94 ... N’extraiem les dues variables en forma de vectors: OAT=OBR$OATBRAN CFL=OBR$CORNFLK Com que 14 dades són poques, si volem aplicar un test t necessitam que provinguin d’una distribució normal. Per decidir si és veritat o no, més endavant explicarem contrastos de bondat d’ajust, amb hipòtesi nul·la “Aquesta mostra prové d’una variable aleatòria amb tal distribució” i hipòtesi alternativa “No és veritat que aquesta mostra provengui d’una variable aleatòria amb tal distribució”. Per ara ens conformarem amb decidir-ho a partir d’un gràfic. A Matemàtiques I us explicàvem que podeu dibuixar un histograma d’una mostra afegint-hi la densitat estimada, a partir de la mostra, de la variable poblacional i la densitat d’una distribució normal amb mitjana i desviació típica les de la mostra, i mirar si sembla que les dades segueixen aquesta distribució normal. Però amb poques dades això és mal de veure: hist(OAT,freq=FALSE, breaks=4,col=&quot;light blue&quot;,xlab=&quot;Colesterol&quot;, ylab=&quot;Densitat&quot;, main=&quot;Histograma de OATBRAN&quot;,ylim=c(0,max(density(OAT)$y))) lines(density(OAT),lty=2,lwd=2) curve(dnorm(x,mean(OAT),sd(OAT)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;), col=c(&quot;black&quot;,&quot;red&quot;),lty=c(2,1),cex=0.75) # hist(CFL,freq=FALSE, breaks=4,col=&quot;light blue&quot;,xlab=&quot;Colesterol&quot;, ylab=&quot;Densitat&quot;, main=&quot;Histograma de CORNFLK&quot;,,ylim=c(0,max(density(CFL)$y))) curve(dnorm(x,mean(CFL),sd(CFL)),col=&quot;red&quot;,lwd=2,add=TRUE) lines(density(CFL),lty=2,lwd=2) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;), col=c(&quot;black&quot;,&quot;red&quot;),lty=c(2,1),cex=0.75) En aquest cas, una opció millor és dibuixar un q-q-plot. Un q-q-plot d’una mostra i una distribució teòrica és el gràfic dels q-q-punts: els punts de la forma (q-quantil de la distribució, q-quantil de la mostra), per a tots els valors de q que tengui sentit donada la mida de la mostra. Quan la distribució amb la que comparam la mostra és una normal, se’n diu un normal-plot. Si la mostra prové de la distribució emprada en el q-q-plot, és d’esperar que el q-quantil de la mostra sigui aproximadament igual al q-quantil de la distribució i per tant que aquests q-q-punts estiguin prop de la diagonal principal \\(y=x\\). La funció qqPlot del paquet car produeix uns q-q-plots que contenen una regió de confiança del 95% que especifica què vol dir això que “els q-q-punts estiguin prop de la diagonal principal \\(y=x\\)”, amb el significat usual de nivell de confiança. L’explicam amb detall a la lliçó de R sobre Contrastos de Bondat d’Ajust. library(car) qqPlot(OAT, distribution=&quot;norm&quot;, mean=mean(OAT), sd=sd(OAT), ylab=&quot;Quantils de OATBRAN&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) qqPlot(CFL, distribution=&quot;norm&quot;, mean=mean(CFL),sd=sd(CFL), ylab=&quot;Quantils de CORNFLK&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) Aceptarem per tant que les nostres dades provenen de dues distribucions normals: podem fer servir la funció t.test. En aquest cas, el test t és de mostres aparellades (hem mesurat les dues variable aleatòries sobre els mateixos individus), per la qual cosa hem d’especificar paired=TRUE i no hem d’especificar el paràmetre var.equal. Emprarem el paràmetre alternative=&quot;less&quot; per indicar que el test és unilateral: la hipòtesi alternativa és que la mitjana de la primera població és més petita que la de la segona. t.test(OAT,CFL,alternative=&quot;less&quot;, paired=TRUE) ## ## Paired t-test ## ## data: OAT and CFL ## t = -3.3195, df = 13, p-value = 0.002768 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.1626132 ## sample estimates: ## mean of the differences ## -0.3485714 Com abans, el resultat inclou el p-valor, l’IC 95% per a la mitjana de les diferències (que és igual a la diferència de les mitjanes: recordau que \\(E(X-Y)=E(X)-E(Y)\\)) i ara, com a novetat, la mitjana de les diferències (mean of the differences) en comptes de les dues mitjanes. Conclusió: Hem obtingut evidència estadísticament significativa que desdijunar oatbran redueix el nivell mitjà de colesterol respecte de desdijunar corn flakes (test t, p-valor 0.003, IC 95% per a la diferència de les mitjanes de \\(-\\infty\\) a -0.163). Exemple 5.5 Volem contrastar si el nivell de triglicèrids als nadons de 2 setmanes és més alt que el del seu cordó umbilical. Per fer-ho, emprarem les dades d’una mostra de 25 nadons als quals els mesuraren els nivells de triglicèrids en plasma a la sang del seu cordó umbilical i en la seva sang al cap de 2 setmanes de néixer (les dues en ng/dl). Tenim les dades a la taula trignadons.txt que trobareu a l’Aula Digital. Les seves variables són CU, les mesures del cordó umbilical, DS, les mesures al cap de dues setmanes, i Nin, que identifica el nadó. Variables aleatòries d’interès: \\(X_{cu}\\): “Prenem un recent nat i mesuram el nivell de triglicèrids en plasma a la sang del seu cordó umbilical en ng/dl”, amb mitjana \\(\\mu_{cu}\\) \\(X_{ds}\\): “Prenem un nadó de 2 setmanes i mesuram el seu nivell de triglicèrids en plasmaen ng/dl”, amb mitjana \\(\\mu_{cf}\\) Contrast: Plantejarem el contrast en termes dels nivells mitjans de triglicèrids: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{cu}=\\mu_{ds}\\\\ H_{1}:\\mu_{cu}&lt; \\mu_{ds} \\end{array} \\right. \\] Carregam la taula de dades, que prèviament hem guardat en el directori de treball de R, en un dataframe al que anomenam TGN i consultam la seva estructura: TGN=read.table(&quot;trignadons.txt&quot;,header=TRUE) head(TGN) ## Nin CU DS ## 1 1 45 80 ## 2 2 30 68 ## 3 3 30 83 ## 4 4 30 78 ## 5 5 31 79 ## 6 6 27 78 str(TGN) ## &#39;data.frame&#39;: 25 obs. of 3 variables: ## $ Nin: int 1 2 3 4 5 6 7 8 9 10 ... ## $ CU : int 45 30 30 30 31 27 27 30 33 32 ... ## $ DS : int 80 68 83 78 79 78 89 78 72 75 ... Com que 25 dades són poques, miram si segueixen distribucions normals amb els seus normal-plots: qqPlot(TGN$CU, distribution=&quot;norm&quot;, mean=mean(TGN$CU), sd=sd(TGN$CU), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) qqPlot(TGN$DS, distribution=&quot;norm&quot;, mean=mean(TGN$DS), sd=sd(TGN$DS), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, pch=20,id=FALSE) Vaja, no sembla que segueixin una distribució normal. Vegem els seus histogrames hist(TGN$CU, freq=FALSE, main=&quot;Histograma de TGN$CU&quot;, xlab=&quot;&quot;,ylab=&quot;&quot;,col=&quot;light blue&quot;) lines(density(TGN$CU),lty=2,lwd=2) curve(dnorm(x,mean(TGN$CU),sd(TGN$CU)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;),col=c(&quot;black&quot;,&quot;red&quot;), lty=c(2,1),cex=0.5) # hist(TGN$DS, freq=FALSE, main=&quot;Histograma de TGN$DS&quot;, xlab=&quot;&quot;,ylab=&quot;&quot;,col=&quot;light blue&quot;) lines(density(TGN$DS),lty=2,lwd=2) curve(dnorm(x,mean(TGN$DS),sd(TGN$DS)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;),col=c(&quot;black&quot;,&quot;red&quot;), lty=c(2,1),cex=0.5) Les dues mostres presenten una cua a la dreta, com podem veure als diagrames de caixa: par(mfrow=c(1,1)) boxplot(TGN$CU,TGN$DS,names=c(&quot;CU&quot;,&quot;DS&quot;),xlab=&quot;&quot;,ylab=&quot;Nivell triglicèrids&quot;) En casos així, de vegades els logaritmes seguexen aproximadament una distribució normal. Vegem si hi ha sort. LogCU=log(TGN$CU) qqPlot(LogCU, distribution=&quot;norm&quot;, mean=mean(LogCU), sd=sd(LogCU), ylab=&quot;Quantils dels logaritmes&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) # LogDS=log(TGN$DS) qqPlot(LogDS, distribution=&quot;norm&quot;, mean=mean(LogDS), sd=sd(LogCU), ylab=&quot;Quantils dels logaritmes&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) Aquests logaritmes ja poden passar per normals. Per tant, el que farem serà, en lloc de comparar les mitjanes dels nivells de triglicèrids, comparar les mitjanes dels seus logaritmes. Aquest tipus de transformació és molt usual en Bioestadística. No són contrastos equivalents, perquè el logaritme de la mitjana no és la mitjana del logaritme. Però en realitat la pregunta que originava aquesta investigació era si el nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons, i ho plantejàvem en termes de si és veritat que el nivell mitjà de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons. Ara, demanar-nos si “el nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons” sí que és equivalent a demanar-nos si “el logaritme del nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons”. I el que fem és plantejar aquesta pregunta en termes de si és veritat que el valor mitjà del logaritme del nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons Noves variables aleatòries d’interès: \\(\\log(X_{cu})\\): “Prenem un recent nat i calculam el logaritme del nivell de triglicèrids en plasma a la sang del seu cordó umbilical”, amb mitjana \\(\\mu_{logcu}\\) \\(\\log(X_{ds})\\): “Prenem un nadó de 2 setmanes i calculam el logaritme del seu nivell de triglicèrids en plasma”, amb mitjana \\(\\mu_{logds}\\) Nou contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{logcu}=\\mu_{logds}\\\\ H_{1}:\\mu_{logcu}&lt; \\mu_{logds} \\end{array} \\right. \\] Prenem com a mostres de \\(\\log(X_{cu})\\) i \\(\\log(X_{ds})\\) els vectors de logaritmes LogCU i LogDS de la nostra mostra original, que podem acceptar que provenen de distribucions normals, i els aplicam la funció t.test amb paired=TRUE, perquè són mostres aparellades, i alternative=&quot;less&quot;. t.test(LogCU, LogDS, paired=TRUE, alternative=&quot;less&quot;) ## ## Paired t-test ## ## data: LogCU and LogDS ## t = -26.112, df = 24, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.8353074 ## sample estimates: ## mean of the differences ## -0.8938758 Conclusió: Hem obtingut evidència estadísticament significativa que el valor mitjà del logaritme del nivell de triglicèrids a la sang del cordó umbilical d’un nadó és més petit que el valor mitjà del logaritme del nivell de triglicèrids a la sang d’un nadó de 2 setmanes (test t, p-valor&lt;10-16, IC 95% per a la diferència de les mitjanes dels logaritmes de \\(-\\infty\\) a -0.84). Concloem, per tant, que tenim evidència estadísticament significativa que el nivell de triglicèrids als nadons de 2 setmanes és més alt que el del seu cordó umbilical. 5.1.5 Tests no paramètrics Si les variables aleatòries d’interès no són (aproximadament) normals i alguna mostra és petita, no podem usar un test t per comparar mitjanes. En aquest cas, una possibilitat és provar de transformar les dades com a l’Exemple 5.5 per veure si la transformació esdevé normal, i si és el cas, plantejar el contrast en termes de mitjanes de les dades transformades Una altra possibilitat és emprar un test no paramètric, que no necessiti que les variables aleatòries siguin normals per que la conclusió sigui vàlida. La majoria de tests no paramètrics per comparar mitjanes en realitat comparen medianes, però normalment cometem l’abús de llenguatge de dir que són per contrastar mitjanes. A més, si les variables aleatòries són simètriques, les mitjanes coincideixen amb les medianes. Els més populars són: Test de Wilcoxon per a una mitjana o dues mitjanes usant mostres aparellades Test de Mann-Whitney per a dues mitjanes usant mostres independents Tots tres es calculen amb R amb la funció wilcox.test(x, y, mu=..., alternative=..., paired=..., conf.level=...) amb sintaxi idèntica a la de t.test (excepte que no s’hi empra el var.equal). Els millors tests no paramètrics solen tenir potència inferior als millors tests paramètrics. A més, els tests no paramètrics no solen produir intervals de confiança fiables. Però, per exemple, emprar un test t quan no és adequat pot portar a conclusions equivocades. Emprau tests paramètrics sempre que pogueu, però només quan pogueu. Com a exemple, vegem com funciona (una versió simplificada) del test de Wilcoxon d’una mitjana. Sigui \\(X\\) una variable aleatòria contínua simètrica al voltant de la seva mitjana \\(\\mu\\) desconeguda. Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq \\mu_0 \\text{ o }\\mu &gt;\\mu_0\\text{ o }\\mu&lt;\\mu_0 \\end{array} \\right. \\] Prenem una mostra aleatòria simple \\(x_1,\\ldots, x_n\\) de \\(X\\). El procediment d’aquest test es basa aleshores en els següents passos, que després il·lustram a l’Exemple 5.6: Per a cada \\(i=1,\\ldots,n\\), sigui \\(d_i=x_i-\\mu_0\\); s’eliminen els valors 0 Enumeram els valors \\(d_i\\) de menor a major valor absolut; en cas d’empats, a cada un dels valors empatats li assignam la mitjana de les posicions que ocuparien. A l’índex assignat d’aquesta manera a cada \\(d_i\\) li diem el seu rang. Per exemple, a l’Exemple 5.6 hi ha quatre \\(i\\) amb valors \\(d_i=\\pm 1\\), i els tocarien les posicions 1, 2, 3 i 4: aleshores el rang de cada un d’aquests quatre \\(d_i\\) és 2.5. Diem \\(T_+\\) a la suma dels rangs dels \\(d_i&gt;0\\) i \\(T_{-}\\) a la suma dels rangs dels \\(d_i&lt;0\\) Si \\(H_0\\) vertadera, és a dir, si \\(\\mu=\\mu_0\\), per la simetria de \\(X\\) al voltant de \\(\\mu\\) esperam que \\(T_+\\approx T_-\\). Per tant: Si \\(T_+\\) és molt petit, és evidència que \\(\\mu &lt;\\mu_0\\) En efecte, si \\(T_+\\) és molt més petit que \\(T_-\\), bàsicament significa que hi ha més valors a l’esquerra de \\(\\mu_0\\) que a la dreta, i per tant la mediana poblacional (que és el valor que deixa la meitat de la població a l’esquerra i l’altra meitat a la dreta) ha d’estar a l’esquerra de \\(\\mu_0\\). Si \\(T_+\\) és molt gran, és evidència que \\(\\mu &gt;\\mu_0\\) En efecte, si \\(T_+\\) és molt més gran que \\(T_-\\), bàsicament significa que hi ha més valors a la dreta de \\(\\mu_0\\) que a l’esquerra, i per tant la mediana ha d’estar a la dreta de \\(\\mu_0\\). Si \\(T_+\\) és molt petit o gran, és evidència que \\(\\mu\\neq \\mu_0\\) I resulta que, quan \\(X\\) és simètrica i \\(H_0\\) vertadera, la distribució de \\(T_+\\), per a cada \\(n\\), és coneguda, i es pot emprar per calcular el p-valor, que és el que fa la funció wilcox.test. Exemple 5.6 Alimentàrem amb una dieta especial 13 ratolins des del naixement fins a la setmana 12. Els augments de pes (en grams) varen ser els del vector següent pesos=c(69,61,69,65,70,68,69,68,72,67,74,69,76) Podem conclure que l’augment mitjà de pes en aquestes condicions és de menys de 70 g? Variable aleatòria d’interès: \\(X\\): “Prenem un ratolí alimentat amb aquesta dieta especial i mesuram el seu augment de pes en grams durant les seves primeres 12 setmanes de vida”, amb mitjana \\(\\mu\\). Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=70\\\\ H_{1}:\\mu &lt;70 \\end{array} \\right. \\] Si miram la mostra, veurem que no té pinta de venir d’una distribució normal però sí simètrica: qqPlot(pesos, distribution=&quot;norm&quot;, mean=mean(pesos), sd=sd(pesos), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) boxplot(pesos) Per tant, emprarem un test de Wilcoxon. Vegem com aniria a mà. Calculam els \\(d_i=x_i-70\\) \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\hline \\end{array} \\] Assignam índexos als \\(d_i\\neq 0\\) en ordre creixent al seu valor absolut. En cas d’empat, per ara els assignam els índexos ordenats d’esquerra a dreta. \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\textrm{Rang fals} &amp; 1 &amp; 12 &amp; 2 &amp; 10 &amp; &amp; 5 &amp; 3 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 4 &amp; 11 \\\\ \\hline \\end{array} \\] A continuació, assignam com a rang de cada \\(d_i\\) la mitjana de tots els “rangs falsos” dels \\(d_i\\) amb el seu mateix valor absolut. Així, el rang de tots els \\(d_i=-1\\) és \\((1+2+3+4)/4=2.5\\) i el rang dels \\(d_i=-2\\) o 2 és \\((5+6+7)/3=6\\). \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\textrm{Rang fals} &amp; 1 &amp; 12 &amp; 2 &amp; 10 &amp; &amp; 5 &amp; 3 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 4 &amp; 11 \\\\ \\textrm{Rang} &amp; 2.5 &amp; 12 &amp; 2.5 &amp; 10 &amp; &amp; 6 &amp; 2.5 &amp; 6 &amp; 6 &amp; 8 &amp; 9 &amp; 2.5 &amp; 11 \\\\ \\hline \\end{array} \\] Anotam quins \\(d_i\\) són positius i quins negatius: \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\textrm{Rang fals} &amp; 1 &amp; 12 &amp; 2 &amp; 10 &amp; &amp; 5 &amp; 3 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 4 &amp; 11 \\\\ \\textrm{Rang} &amp; 2.5 &amp; 12 &amp; 2.5 &amp; 10 &amp; &amp; 6 &amp; 2.5 &amp; 6 &amp; 6 &amp; 8 &amp; 9 &amp; 2.5 &amp; 11 \\\\ \\textrm{Signe} &amp; - &amp; - &amp; - &amp; - &amp; &amp; - &amp; - &amp; - &amp; + &amp; - &amp; + &amp; - &amp; +\\\\ \\hline \\end{array} \\] Sumam, d’una banda, els rangs dels \\(d_i\\) positius i de l’altra, els dels negatius: \\[ \\begin{array}{l} T_+=6+9+11=26\\\\ T_-=2.5+ 12 + 2.5 + 10 + 6 + 2.5 + 6 + 8 + 2.5=52 \\end{array} \\] I ara miraríem si \\(T_+\\) és prou més petit que \\(T_-\\) per que sigui evidència estadísticament significativa de que \\(\\mu &lt;\\mu_0\\). Això ja no ho podem fer a mà. Amb R, simplement entraríem wilcox.test(pesos,mu=70,alternative=&quot;less&quot;) ## ## Wilcoxon signed rank test with continuity correction ## ## data: pesos ## V = 26, p-value = 0.1621 ## alternative hypothesis: true location is less than 70 Conclusió: No hem obtingut evidència estadísticament significativa que l’augment mitjà de pes en aquestes condicions sigui més petit que 70 g (test de Wilcoxon, p-valor 0.16). El test de Wilcoxon per a dues mitjanes emprant mostres aparellades és bàsicament el test anterior aplicat a la diferència dels valors de les dues variables a les parelles. Exemple 5.7 Una alternativa a la transformació logarítmica portada a terme a l’Exemple 5.5 hagués estat emprar el test de Wilcoxon per a mostres aparellades. El contrast ara seria \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{cu}-\\mu_{ds}=0\\\\ H_{1}:\\mu_{cu}- \\mu_{ds}&lt;0 \\end{array} \\right. \\] que clarament correspon al contrast original \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{cu}=\\mu_{ds}\\\\ H_{1}:\\mu_{cu}&lt; \\mu_{ds} \\end{array} \\right. \\] però hem de tenir present que la hipòtesi nul·la en realitat significa que la mediana de les diferències dels nivells de triglicèrids en el cordó umbilical menys els nivells de triglicèrids al cap de dues setmanes és 0, és a dir Si restam del nivell de triglicèrids en la sang del cordó umbilical d’un nadó el seu nivell de triglicèrids en sang al cap de dues setmanes, la meitat de les vegades obtenim un valor \\(\\geqslant 0\\) i l’altra meitat de les vegades un valor \\(\\leqslant 0\\), o, equivalentment, La meitat dels nadons tenen el nivell de triglicèrids en la sang del cordó umbilical més alt o igual que el seu nivell de triglicèrids en sang al cap de dues setmanes, i l’altra meitat tenen el nivell de triglicèrids en la sang del cordó umbilical més petit o igual que el seu nivell de triglicèrids en sang al cap de dues setmanes. La hipòtesi alternativa que aquesta mediana és negativa. És a dir, la hipòtesi alternativa és Si restam el nivell de triglicèrids en la sang del cordó umbilical d’un nadó menys el nivell de triglicèrids en sang al cap de dues setmanes, més de la meitat de les vegades obtendríem un valor \\(&lt;0\\) o, equivalentment, Més de la meitat dels nadons tenen el nivell de triglicèrids en la sang del cordó umbilical més petit que el seu nivell de triglicèrids en sang al cap de dues setmanes. wilcox.test(TGN$CU,TGN$DS,alternative=&quot;less&quot;,paired=TRUE) ## ## Wilcoxon signed rank test with continuity correction ## ## data: TGN$CU and TGN$DS ## V = 0, p-value = 6.384e-06 ## alternative hypothesis: true location shift is less than 0 Com que el p-valor és de l’ordre de 10-6, rebutjam la hipòtesi nul·la en favor de la alternativa; abusarem del llenguatge i ho expressarem en termes de mitjanes: Conclusió: Hem obtingut evidència estadísticament significativa que el nivell mitjà de triglicèrids a la sang del cordó umbilical dels nadons és més petit que al cap de dues setmanes (test de Wilcoxon, p-valor 6.4·10-6). 5.2 Contrastos de variàncies 5.2.1 Test \\(\\chi^2\\) d’una variància Siguin \\(X\\) una variable aleatòria \\(N(\\mu,\\sigma)\\) i \\(X_1,\\ldots,X_n\\) una mostra aleatòria simple de \\(X\\) de mida \\(n\\) qualsevol. Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma=\\sigma_0\\\\ H_{1}:\\sigma \\neq\\sigma_0\\text{ o }\\sigma &gt;\\sigma_0\\text{ o }\\sigma&lt;\\sigma_0 \\end{array} \\right. \\] o equivalentment \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma^2=\\sigma_0^2\\\\ H_{1}:\\sigma^2 \\neq\\sigma_0^2\\text{ o }\\sigma^2 &gt;\\sigma_0^2\\text{ o }\\sigma^2&lt;\\sigma_0^2 \\end{array} \\right. \\] Si \\(H_0\\) és vertadera, sabem que l’estadístic de contrast \\[ \\chi^2=\\frac{(n-1) \\widetilde{S}_X^2}{\\sigma_{0}^2} \\] té distribució \\(\\chi_{n-1}^2\\), i aleshores ho podem emprar per calcular p-valors, regions crítiques etc. En concret, si el valor d’aquest estadístic de contrast sobre la mostra és \\(\\chi_0^2\\), aleshores: Si \\(H_{1}:\\sigma&gt;\\sigma_{0}\\), el p-valor és \\(P(\\chi^2\\geqslant\\chi_0^2)\\) Si \\(H_{1}:\\sigma&lt;\\sigma_{0}\\), el p-valor és \\(P(\\chi^2\\leqslant\\chi^2_0)\\) Si \\(H_{1}:\\sigma\\neq \\sigma_{0}\\), el p-valor es pren, per conveni, igual a \\(2\\text{min}\\big\\{P(\\chi^2\\geqslant\\chi^2_0), P(\\chi^2\\leqslant\\chi^2_0)\\big\\}\\) Alerta amb els p-valors dels contrastos bilaterals que no siguin ni tests t ni binomials, ja que per motius històrics no es calculen com “la probabilitat d’obtenir un valor de l’estadístic de contrast tant o més extrem que l’obtingut”, sinó per mitjà d’una fórmula de l’estil de la que hem donat aquí dalt. Exemple 5.8 Suposem que tenim una mostra aleatòria simple d’una variable \\(X\\) normal de mida 25, i ha donat \\(\\widetilde{S}_X^2=1.25\\). Volem realitzar alguns contrastos amb hipòtesi nul·la \\(\\sigma_X^2=0.8\\), i per tant tendrem \\[ \\chi_0^2=\\frac{(25-1)\\cdot 1.25}{0.8}=37.5 \\] Si volem realitzar el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_X^2=0.8 \\\\ H_{1}:\\sigma_X^2&gt; 0.8 \\end{array} \\right. \\] el p-valor és \\[ P(\\chi^2_{24} \\geqslant 37.5)=\\texttt{1-pchisq(37.5,24)}=0.039 \\] Amb nivell de confiança \\(\\alpha=0.05\\) rebutjam \\(H_0\\) en favor de \\(H_1\\) Si volem realitzar el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_X^2=0.8 \\\\ H_{1}:\\sigma_X^2\\neq 0.8 \\end{array} \\right. \\] El p-valor és \\[ \\begin{array}{l} 2\\min\\big\\{P(\\chi^2_{24}\\geqslant 37.5),P(\\chi^2_{24}\\leqslant 37.5)\\big\\}\\\\ \\qquad=2\\min\\{\\texttt{1-pchisq(37.5,24)},\\texttt{pchisq(37.5,24)}\\}\\\\ \\qquad=2\\min\\{0.039,0.961\\}= 0.078 \\end{array} \\] Amb nivell de confiança \\(\\alpha=0.05\\), no podem rebutjar \\(H_0\\). En resum: amb la nostra mostra trobam evidència estadísticament significativa que \\(\\sigma&gt;\\sigma_0\\), però no trobam evidència estadísticament significativa que \\(\\sigma\\neq \\sigma_0\\). No us ha de venir de nou, ja ens hi hem trobat en altres ocasions (recordau els Exemples 4.13 i 4.16): per rebutjar la hipòtesi nul·la en un contrast bilateral cal més evidència que en un contrast unilateral, perquè al contrast bilateral tenim dues fonts d’error de tipus I i al contrast unilateral només una. Exemple 5.9 S’ha analitzat el líquid amniòtic d’una mostra aleatòria de 15 embarassades de 3er trimestre, i s’han obtingut les mesures següents de proteïnes totals (en grams per 100 ml): amnio=c(0.69,1.04,0.39,0.37,0.64,0.73,0.69,1.04,0.83,1.01, 0.19,0.61,0.42,0.25,0.79) Podem concloure a partir d’aquestes dades, amb un nivell de significació del 5%, que la desviació típica poblacional (és a dir, la desviació típica de la quantitat de proteïna total en el líquid amniòtic de les embarassades de 3er trimestre expressada en grams per 100 ml) és diferent de 0.25? Variable aleatòria d’interès: \\(X\\): “Prenem una embarassada i li mesuram la quantitat de proteïna total en …”, amb desviació típica \\(\\sigma\\). Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma=0.25 \\\\ H_{1}:\\sigma\\neq 0.25 \\end{array} \\right. \\] amb \\(\\alpha=0.05\\) Per poder aplicar el test \\(\\chi^2\\), cal que \\(X\\) sigui normal. Vegem el normal-plot: qqPlot(amnio, distribution=&quot;norm&quot;, mean=mean(amnio), sd=sd(amnio), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) Acceptarem que \\(X\\) és normal. Estadístic de contrast: \\[ \\chi^2=\\frac{(n-1) \\widetilde{S}_X^2}{\\sigma_{0}^2} \\] que segueix una llei \\(\\chi^2_{n-1}\\) si \\(H_0\\) és certa. Valor de l’estadístic de contrast, \\(\\chi^2_0\\): n=length(amnio) n ## [1] 15 var(amnio) ## [1] 0.07624 khi0=(n-1)*var(amnio)/0.25^2 round(khi0,2) ## [1] 17.08 p-valor: \\[ \\begin{array}{l} 2\\min\\big\\{P(\\chi_{n-1}^2\\geqslant\\chi^2_0), P(\\chi_{n-1}^2\\leqslant\\chi^2_0)\\big\\}\\\\ \\qquad=2\\min\\{\\texttt{1-pchisq(17.08,14)},\\texttt{pchisq(17.08,14)}\\}\\\\ \\qquad=2\\min\\{0.252,0.748\\}= 0.504 \\end{array} \\] En aquest exemple, com que el contrast és bilateral, l’IC 95% seria el del tema anterior (amb \\(q=1-\\alpha=0.95\\)). El de la variància seria \\[ \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,0.975}^2}, \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,0.025}^2} \\right] \\] on \\(\\chi_{n-1,0.975}^2\\)=qchisq(0.975,14)=26.11895 i \\(\\chi_{n-1,0.025}^2\\)=qchisq(0.025,14)=26.11895. Dóna, per tant, \\[ \\left[ \\frac{14\\cdot 0.07624}{26.11895}, \\frac{14\\cdot 0.07624}{5.62873}\\right]=[0.0409, 0.1896] \\] L’interval de confiança del 95% per a la desviació típica serà aleshores \\[ [\\sqrt{0.0408}, \\sqrt{0.1895}]= [0.202,0.435] \\] i conté el valor 0.25 que contrastàvem. Conclusió: No hem obtingut evidència estadísticament significativa que la desviació típica (de la quantitat de proteïna total …) sigui diferent de 0.25 (test \\(\\chi^2\\), p-valor 0.504, IC 95% de 0.202 a 0.435). Aquest test \\(\\chi^2\\) d’una variància està implementat en la funció sigma.test del paquet TeachingDemos. La seva sintaxi és similar a la de t.test per a una mitjana, canviant la mu per sigma si contrastam la desviació típica o sigmasq si contrastam la variància. Per exemple, per realitzar aquest darrer contrast, simplement entraríem library(TeachingDemos) sigma.test(amnio,sigma=0.25,alternative=&quot;two.sided&quot;) ## ## One sample Chi-squared test for variance ## ## data: amnio ## X-squared = 17.078, df = 14, p-value = 0.5041 ## alternative hypothesis: true variance is not equal to 0.0625 ## 95 percent confidence interval: ## 0.04086535 0.18962728 ## sample estimates: ## var of amnio ## 0.07624 Ups, què ha passat amb l’interval de confiança? No res: fixau-vos que és el de la variància. L’interval de confiança que dóna la funció sigma.test és el de la variància, tant si contrastam la desviació típica (amb el paràmetre sigma) com si contrastam la variància (amb el paràmetre sigmasq). 5.2.2 Test F per a dues variàncies Siguin \\(X_1,X_2\\) dues variables aleatòries normals de desviacions típiques \\(\\sigma_1\\) i \\(\\sigma_2\\), respectivament. En prenem dues mostres aleatòries simples independents de mides \\(n_1\\) i \\(n_2\\) i variàncies mostrals \\(\\widetilde{S}^2_1\\) i \\(\\widetilde{S}^2_2\\). Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_1^2=\\sigma_2^2\\\\[1ex] H_{1}:\\sigma_1^2\\neq \\sigma_2^2\\text{ o }\\sigma_1^2&gt; \\sigma_2^2\\text{ o }\\sigma_1^2&lt; \\sigma_2^2 \\end{array} \\right. \\] L’interpretarem \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_1^2/\\sigma_2^2=1\\\\[1ex] H_{1}:\\sigma_1^2/\\sigma_2^2\\neq 1\\text{ o }\\sigma_1^2/\\sigma_2^2&gt;1 \\text{ o }\\sigma_1^2/\\sigma_2^2&lt; 1 \\end{array} \\right. \\] Per realitzar-lo, s’empra l’estadístic de contrast \\[ F={\\widetilde{S}_1^2}/{\\widetilde{S}_2^2} \\] que, si les dues poblacions són normals i \\[ H_0: \\sigma_1=\\sigma_2 \\] és vertadera, té distribució coneguda: la F de Fisher-Snedecor \\(F_{n_1-1,n_2-1}\\) amb \\(n_1-1\\) i \\(n_2-1\\) graus de llibertat. Per aquest motiu a aquest contrast se li diu un test F. De la distribució \\(F_{n,m}\\), on \\(n,m\\) són els seus graus de llibertat, heu de saber que: Els graus de llibertat \\(n,m\\) són els paràmetres dels quals depèn la funció de distribució, i l’ordre és important: si \\(n\\neq m\\), la distribució \\(F_{n,m}\\) i la distribució \\(F_{m,n}\\) són diferents. Amb R és f No és simètrica, té cua a la dreta i per tant, com explicam d’aquí a una estona, els p-valors dels contrastos bilaterals es calculen com al test \\(\\chi^2\\) d’una variància. El gràfic següent mostra les gràfiques de les densitats de les distribucions \\(F_{n,m}\\) per a \\(n=3,4\\) i \\(m=3,4,5\\). Es pot observar a cada una d’elles una cua a la dreta ben marcada, i també hi podeu observar que les distribucions \\(F_{3,4}\\) i \\(F_{4,3}\\) tenen densitats diferents. Per tant, si diem \\(F_0\\) al valor que pren l’estadístic \\(F\\) sobre la nostra mostra Si \\(H_{1}:\\sigma_1^2&gt;\\sigma_2^2\\), el p-valor del contrast és \\(P(F\\geqslant F_0)\\) Si \\(H_{1}:\\sigma_1^2&lt;\\sigma_2^2\\), el p-valor del contrast és \\(P(F\\leqslant F_0)\\) Si \\(H_{1}:\\sigma_1^2\\neq \\sigma_2^2\\), el p-valor es pren, per conveni, igual a \\(2\\text{min}\\big\\{P(F\\geqslant F_0), P(F\\leqslant F_0)\\big\\}\\) El test F està implementat en la funció var.test de R: s’aplica a les dues mostres, amb sintaxi similar a la de t.test. Exemple 5.10 Les variables \\(X_d\\) i \\(X_h\\) de l’Exemple 5.3, tenen la mateixa variància? Suposarem que totes dues són normals (les temperatures ho solen ser) i diguem \\(\\sigma_d^2\\) i \\(\\sigma_h^2\\) a les seves variàncies. Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_d^2=\\sigma_h^2\\\\ H_{1}:\\sigma_d^2\\neq \\sigma_h^2 \\end{array} \\right. \\] Estadístic de contrast: \\[ F=\\widetilde{S}_d^2/\\widetilde{S}_h^2 \\] Valor de l’estadístic de contrast a la nostra mostra, \\(F_0\\): F0=var(X_d)/var(X_h) round(F0,4) ## [1] 0.8322 Recordem que les mides de les nostres mostres eren \\(n_d=116\\) i \\(n_h=114\\) p-valor: \\[ \\begin{array}{l} 2\\min\\big\\{P(F_{n_d-1,n_h-1} \\geqslant F_0), P(F_{n_d-1,n_h-1}\\leqslant F_0)\\big\\}\\\\ \\qquad =2\\min\\big\\{P(F_{115,113} \\geqslant 0.8322), P(F_{115,113} \\leqslant 0.8322)\\big\\}\\\\ \\qquad =2\\min\\{\\texttt{1-pf(0.8322,115,113)},\\texttt{pf(0.8322,115,113)}\\} \\\\ \\qquad =2\\min\\{0.836,0.164\\}= 0.328 \\end{array} \\] Conclusió: No hem trobat evidència estadísticament significativa que les variables \\(X_h\\) i \\(X_d\\) tenguin variància diferent (test F, p-valor 0.33). Acceptarem que tenen la mateixa variància. Amb R entraríem: var.test(X_d, X_h) ## ## F test to compare two variances ## ## data: X_d and X_h ## F = 0.8322, num df = 115, denom df = 113, p-value = 0.3278 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.575234 1.203224 ## sample estimates: ## ratio of variances ## 0.8321984 Obtenim el mateix p-valor que abans. L’interval de confiança que dóna aquesta funció és per al quocient de les variàncies. Aleshores, com que l’IC 95% conté l’1, no podem rebutjar amb un nivell de significació del 5% que \\(\\sigma_d^2/\\sigma_h^2=1\\), és a dir, que \\(\\sigma_d^2=\\sigma_h^2\\). Podem ampliar la conclusió: Conclusió: No hem trobat evidència estadísticament significativa que les variables \\(X_h\\) i \\(X_d\\) tenguin variància diferent (test F, p-valor 0.33, IC 95% per al quocient de les variàncies de 0.57 a 1.2). Acceptarem que tenen la mateixa variància. Per tant, si els tests t amb var.equal=TRUE i var.equal=FALSE de l’Exemple 5.3 haguessin donat conclusions diferents, prendríem la corresponent a variàncies iguals. Hem emprat un test F per comparar aquestes variàncies, i per que la conclusió sigui fiable, cal que les variables poblacionals siguin normals, no és suficient que les mostres siguin grans; de fet, la seva validesa no depèn per res de la mida de les mostres. Podem suposar que efectivament les variables \\(X_d\\) i \\(X_h\\) són normals? Vegem els histogrames: hist(X_d,freq=FALSE, breaks=4,col=&quot;light blue&quot;,xlab=&quot;Temperatures&quot;, ylab=&quot;Densitat&quot;,main=&quot;Histograma de temperatures de dones&quot;,ylim=c(0,max(density(X_d)$y))) lines(density(X_d),lty=2,lwd=2) curve(dnorm(x,mean(X_d),sd(X_d)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;), col=c(&quot;black&quot;,&quot;red&quot;),lty=c(2,1),cex=0.5) # hist(X_h,freq=FALSE, breaks=4,col=&quot;light blue&quot;,xlab=&quot;Temperatures&quot;, ylab=&quot;Densitat&quot;,main=&quot;Histograma de temperatures d&#39;homes&quot;,ylim=c(0,dnorm(mean(X_h),mean(X_h),sd(X_h)))) lines(density(X_h),lty=2,lwd=2) curve(dnorm(x,mean(X_h),sd(X_h)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;), col=c(&quot;black&quot;,&quot;red&quot;),lty=c(2,1),cex=0.5) i els normal-plot: qqPlot(X_d, distribution=&quot;norm&quot;, mean=mean(X_d), sd=sd(X_d), ylab=&quot;Quantils de la mostra de dones&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) qqPlot(X_h, distribution=&quot;norm&quot;, mean=mean(X_h), sd=sd(X_h), ylab=&quot;Quantils de la mostra d&#39;homes&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) Seria millor haver emprat un test no paramètric, per més seguretat. 5.2.3 Tests no paramètrics Quan alguna de les variables poblacionals involucrades en un test de dues variàncies no és normal, no es pot fer servir el test F. En aquest cas, us recomanam emprar el test de Fligner-Killeen, implementat en R en la funció fligner.test, que en la pràctica ha mostrat ser més exacte per a variables aleatòries molt diferents de normals. Aquest test només serveix per a contrastos bilaterals, que en realitat són els únics interessants, i està implementat en la funció fligner.test de R. S’aplica a una list formada per les dues mostres o a una fórmula que separi una variable numèrica en dos grups. Per exemple, per emprar-lo en el contrast bilateral de variàncies de l’exemple anterior, entraríem: fligner.test(list(X_h,X_d)) ## ## Fligner-Killeen test of homogeneity of variances ## ## data: list(X_h, X_d) ## Fligner-Killeen:med chi-squared = 1.7736, df = 1, p-value = 0.1829 Seguim acceptant que \\(X_h\\) i \\(X_d\\) tenen la mateixa variància. 5.3 Contrastos per a proporcions 5.3.1 Contrastos per a una proporció Suposem que la variable poblacional \\(X\\) és Bernoulli de probabilitat d’èxit \\(p\\) i que volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:p=p_{0}\\\\ H_{1}:p\\neq p_{0}\\text{ o } p&gt;p_0 \\text{ o } p&lt;p_0 \\end{array} \\right. \\] Tenim dues opcions: Realitzar un test binomial exacte, que és el que explicàvem a la Secció 4.2 Realitzar un test aproximat basat en l’aproximació d’una distribució binomial per una normal, i que per tant només podem emprar si la mostra és gran Test binomial exacte Suposem que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) qualsevol i que hi obtenim \\(S_0\\) èxits, de manera que \\(\\widehat{p}_X=S_0/n\\). Si \\(H_0\\) és vertadera, el nombre d’èxits \\(S\\) en una mostra aleatòria simple segueix una distribució \\(B(n,p_0)\\). Ho podem usar per calcular p-valors de la manera usual: Si \\(H_{1}:p&gt;p_{0}\\), el p-valor és \\(P(S\\geqslant S_0)\\) Si \\(H_{1}:p&lt;p_{0}\\), el p-valor és \\(P(S\\leqslant S_0)\\) Si \\(H_{1}:p\\neq p_{0}\\), el p-valor és la probabilitat que \\(S\\) estigui tan o més allunyada que \\(S_0\\) del nombre d’èxits que esperaríem si \\(H_0\\) fos vertadera, que és \\(p_0\\cdot n\\). Per tant, és \\[ \\text{p-valor}=P(|S-p_0\\cdot n|\\geqslant|S_0-p_0\\cdot n|) \\] Aquesta probabilitat també es pot calcular com la probabilitat que \\(S\\) prengui un valor de probabilitat més petita o igual que la de \\(S_0\\): \\[ \\text{p-valor}=\\sum_{k\\ \\mathrm{tal\\ que}\\atop P(S=k)\\leqslant P(S=S_0)} P(S=k) \\] Una distribució binomial \\(B(n,p_0)\\) només és simètrica quan \\(p_0= 0.5\\). Aquest test binomial exacte està implementat en R en la funció binom.test binom.test(S, n, p=..., alternative=..., conf.level=...) on S indica al nombre d’èxits a la mostra, n la mida de la mostra, p la probablitat que es contrasta, i els altres dos paràmetres signifiquen el mateix que a les altres funcions explicades fins ara. L’interval de confiança que dóna en els contrastos bilaterals és el de Clopper-Pearson. Exemple 5.11 Ens demanam si la proporció d’estudiants esquerrans a la UIB, és diferent de la de l’estat espanyol, que és del 10%. Prenem un mostra de 30 estudiants de la UIB més o menys a l’atzar i hi trobam 1 esquerrà. Variable aleatòria d’interès: \\(X\\): “Prenem un estudiant de la UIB i miram si és esquerrà”, de probabilitat d’èxit \\(p\\) Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:p=0.1\\\\ H_{1}:p\\neq 0.1 \\end{array} \\right. \\] Emprarem el test binomial exacte Estadístic de contrast: Nombre d’èxits \\(S\\), que si \\(H_0\\) és vertadera, té distribució \\(B(n,0.1)\\) Valor de l’estadístic de contrast: 1 p-valor: Si la hipòtesi nul·la \\(p=0.1\\) fos vertadera, en una mostra aleatòria de 30 estudiants esperaríem 3 esquerrans, i n’hem trobat 1. Per tant el p-valor és la probabilitat la diferència en valor absolut entre \\(S\\) i 1 sigui més gran o igual que 2, és a dir, que \\(S\\) sigui més petit o igual que 1 o més gran o igual que 5: \\[ \\begin{array}{rl} P(|S-3|\\geqslant|S_0-3|) &amp; =P(|S-3|\\geqslant 2)\\\\ &amp;= P(S\\leqslant 1)+P(S\\geqslant 5)\\\\ &amp; =\\texttt{pbinom(1,30,0.1)+1-pbinom(4,30,0.1)}=0.359 \\end{array} \\] Conclusió: No hem obtingut evidència estadísticament significativa que el percentatge d’esquerrans a la UIB sigui diferent del 10% (test binomial, p-valor 0.36). Hem dit que el p-valor també es pot calcular com a \\[ \\text{p-valor}=\\sum_{P(S=k)\\leqslant P(S=S_0)} P(S=k) \\] Vegem-ho. Direm PB al vector que dóna els valors de la densitat de \\(S\\) sobre \\(k=0,\\ldots,30\\), que són tots els possibles valors de \\(k\\). Aleshores, els \\(k\\) tals que \\(P(S=k)\\leqslant P(S=S_0)\\) són els que satisfan PB&lt;=dbinom(1,30,0.1) (o també PB&lt;=PB[2], perquè \\(P(S=1)\\) és la segona entrada del vector PB; la primera és \\(P(S=0)\\)). Per tant, la suma de les seves probabilitats és: PB=dbinom(0:30,30,0.1) sum(PB[PB&lt;=dbinom(1,30,0.1)]) ## [1] 0.3591899 Amb R, entraríem: binom.test(1, 30, p=0.1, alternative=&quot;two.sided&quot;) ## ## Exact binomial test ## ## data: 1 and 30 ## number of successes = 1, number of trials = 30, p-value = 0.3592 ## alternative hypothesis: true probability of success is not equal to 0.1 ## 95 percent confidence interval: ## 0.0008435709 0.1721694556 ## sample estimates: ## probability of success ## 0.03333333 i a més obtenim l’IC 95% de Clopper-Pearson per a \\(p\\), per tant podem refinar la nostra conclusió: Conclusió: No hem obtingut evidència estadísticament significativa que el percentatge d’esquerrans a la UIB sigui diferent del 10% (test binomial, p-valor 0.37, IC 95% de 0.001 a 0.172). Test aproximat Suposem que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) gran, posem de 40 subjectes o més, i que hi obtenim una proporció mostral d’èxits \\(\\widehat{p}_X\\). En aquest cas, si \\(H_{0}:p=p_{0}\\) és vertadera, pel Teorema Central del Límit, la distribució de \\[ Z=\\frac{\\widehat{p}_X-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\] és aproximadament la d’una variable \\(N(0,1)\\). Ho podem emprar per calcular p-valors i intervals de confiança com en el test t. En particular, si \\(Z\\) pren el valor \\(z_0\\) sobre la nostra mostra, Quan \\(H_{1}:p&gt;p_{0}\\), el p-valor és \\(P(Z\\geqslant z_0)\\) Quan \\(H_{1}:p&lt;p_{0}\\), el p-valor és \\(P(Z\\leqslant z_0)\\) Quan \\(H_{1}:p\\neq p_{0}\\), el p-valor és \\(2P(Z\\geqslant|z_0|)\\) (recordau que \\(Z\\) és simètrica) Amb R, està implementat en la funció prop.test(x, n, p=...,alternative=..., conf.level=..., correct=...) on els paràmetres tenen el mateix significat que a binom.test excepte correct, que serveix per especificar si volem que s’apliqui una correcció de continuïtat com la que explicàvem al Tema de Repàs de la Distribució Normal (que és recomanable quan s’aproxima una variable discreta per una contínua però que nosaltres no aplicarem en realitzar contrastos “a mà” per no complicar-los) que millora els resultats. El seu valor per defecte és TRUE, i és el que us recomanan que empreu; el que hem explicat aquí correspon a correct=FALSE. L’interval de confiança que dóna aquesta funció en un contrast bilateral és el de Wilson (amb o sense correcció de continuïtat, segons el que valgui correct). Exemple 5.12 Continuant amb l’Exemple 5.11, ara hi emprarem el test aproximat, tot i que no és lo seu. Estadístic de contrast: \\[ Z=\\frac{\\widehat{p}_X-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\] que, si \\(H_0\\) és vertadera, seguiria una distribució (aproximadament) normal estándard. Valor sobre la nostra mostra: \\[ z_0=\\frac{\\frac{1}{30}-0.1}{\\sqrt{\\frac{0.1(1-0.1)}{30}}}=-1.22 \\] p-valor: \\(2P(Z\\geqslant|-1.22|)=\\texttt{2*(1-pnorm(1.22))}=0.222\\) Conclusió: Un altre cop, no obtenim evidència estadísticament significativa que el percentatge d’esquerrans a la UIB sigui diferent del 10% (prop-test, p-valor 0.22). Amb R, entraríem: prop.test(1, 30, p=0.1, alternative=&quot;two.sided&quot;) ## Warning in prop.test(1, 30, p = 0.1, alternative = &quot;two.sided&quot;): Chi-squared ## approximation may be incorrect ## ## 1-sample proportions test with continuity correction ## ## data: 1 out of 30, null probability 0.1 ## X-squared = 0.83333, df = 1, p-value = 0.3613 ## alternative hypothesis: true p is not equal to 0.1 ## 95 percent confidence interval: ## 0.001742467 0.190530216 ## sample estimates: ## p ## 0.03333333 No dóna el mateix p-valor que abans, perquè, com hem explicat, el nostre test correspon a correct=FALSE: prop.test(1, 30, p=0.1, alternative=&quot;two.sided&quot;, correct=FALSE) ## Warning in prop.test(1, 30, p = 0.1, alternative = &quot;two.sided&quot;, correct = ## FALSE): Chi-squared approximation may be incorrect ## ## 1-sample proportions test without continuity correction ## ## data: 1 out of 30, null probability 0.1 ## X-squared = 1.4815, df = 1, p-value = 0.2235 ## alternative hypothesis: true p is not equal to 0.1 ## 95 percent confidence interval: ## 0.00590859 0.16670391 ## sample estimates: ## p ## 0.03333333 Si llegiu amb cura la sortida del prop.test, veureu que no empra un estadístic de contrast que té una distribució normal, sinó un que té distribució \\(\\chi^2\\) amb 1 grau de llibertat: X-squared=..., df=1. El que passa és que R no empra l’estadístic \\(Z\\) que hem explicat, sinó el seu quadrat, \\(Z^2\\), que té distribució \\(\\chi_1^2\\) perquè \\(Z\\) és normal estàndard. El missatge d’advertència que ens ha donat R en aquestes dues execucions de la funció prop.test ens diu que no se satisfan les condicions necessàries per que el resultat d’aquest contrast sigui vàlid. Exemple 5.13 Quina és la potència del contrast realitzat a l’exemple anterior? Emprarem les funcions del paquet pwr per calcular-la; per més informació sobre les funcions d’aquest paquet, consultau la secció corresponent del manual de R. Primer calculam la mida de l’efecte observat amb la funció ES.h aplicada a la proporció poblacional contrastada i a la proporció mostral: library(pwr) ES.h(0.1,0.03) ## [1] 0.2953351 I ara aplicam la funció pwr.p.test a la mida de l’efecte observat, h, la mida de la mostra, n, el nivell de significació, sig.level, i el tipus de contrast, alternative, i ens donarà la potència: pwr.p.test(h=0.3, n=30, sig.level=0.05, alternative=&quot;two.sided&quot;) ## ## proportion power calculation for binomial distribution (arcsine transformation) ## ## h = 0.3 ## n = 30 ## sig.level = 0.05 ## power = 0.3758563 ## alternative = two.sided Què hagués passat si, en lloc d’1 esquerrà en una mostra de 30, haguéssim trobat 5 esquerrans en una mostra (aleatòria simple) de 150 estudiants, de manera que la proporció mostral fos la mateixa? prop.test(5, 150, p=0.1) ## ## 1-sample proportions test with continuity correction ## ## data: 5 out of 150, null probability 0.1 ## X-squared = 6.6852, df = 1, p-value = 0.009722 ## alternative hypothesis: true p is not equal to 0.1 ## 95 percent confidence interval: ## 0.01233588 0.08010876 ## sample estimates: ## p ## 0.03333333 Ara podríem rebutjar amb un nivell de significació del 5% que la proporció d’esquerrans a la UIB és del 10%. Quina ha estat la potència d’aquest test? pwr.p.test(h=0.3, n=150, sig.level=0.05, alternative=&quot;two.sided&quot;) ## ## proportion power calculation for binomial distribution (arcsine transformation) ## ## h = 0.3 ## n = 150 ## sig.level = 0.05 ## power = 0.9567605 ## alternative = two.sided Amb una mostra més gran, la potència és més gran, és més fàcil detectar que la hipòtesi alternativa sigui vertadera. Exemple 5.14 De quina mida hauríem d’haver pres la mostra per obtenir una potència del 90% amb \\(\\alpha=0.05\\) i esperant un efecte petit? Per determinar el valor d’un “efecte petit” entram cohen.ES(test=&quot;p&quot;,size=&quot;small&quot;) ## ## Conventional effect size from Cohen (1982) ## ## test = p ## size = small ## effect.size = 0.2 i ara, a l’argument pwr.p.test, en lloc d’entrar-hi la mida de la mostra n, hi entram la potència desitjada i ens donarà la mida necessària per assolir-la: pwr.p.test(h=0.2, power=0.9, sig.level=0.05, alternative=&quot;two.sided&quot;) ## ## proportion power calculation for binomial distribution (arcsine transformation) ## ## h = 0.2 ## n = 262.6855 ## sig.level = 0.05 ## power = 0.9 ## alternative = two.sided Ens caldria una mostra aleatòria simple de 263 estudiants. Com que en un contrast d’una proporció sempre hi podem emprar el test binomial exacte, no hi ha necessitat d’emprar-hi tests no paramètrics. 5.3.2 Contrastos per a 2 proporcions emprant mostres independents Siguin \\(X_1\\) i \\(X_2\\) dues variables aleatòries Bernoulli de paràmetres poblacionals d’èxit \\(p_1\\) i \\(p_2\\). Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2\\text{ o }p_1&gt; p_2\\text{ o }p_1&lt; p_2 \\end{array} \\right. \\] Suposem que, per realitzar aquest contrast, prenem una mostra aleatòria simple de cada variable, independents una de l’altra. Obtenim la taula de freqüències següent \\[ \\begin{array}{r|cc|c } &amp; X_1 &amp; X_2 &amp; \\textrm{Total} \\\\\\hline \\textrm{Èxits} &amp; n_{11} &amp; n_{12} &amp; E \\\\ \\textrm{Fracassos} &amp; n_{21} &amp; n_{22} &amp; F \\\\\\hline \\textrm{Total} &amp; n_{1} &amp; n_{2} \\end{array} \\] Aleshores tenim dues opcions: Realitzar un test \\(\\chi^2\\), que es basa en una aproximació a una normal i requereix algunes condicions sobre les dues mostres Realitzar un test de Fisher, que es pot emprar sempre però no dóna la informació exactament com la voldríem Test \\(\\chi^2\\) Suposem que les dues mostres són grans, per fixar idees \\(n_1,n_2\\geqslant 50\\), i que els nombres d’èxits i de fracasos a cada mostra no són molt petits, per fixar idees tots dos més grans o iguals que 5. Siguin \\(\\widehat{p}_1\\) i \\(\\widehat{p}_2\\) les proporcions mostrals d’èxits a les dues mostres. En aquestes condicions, si la hipòtesi nul·la \\(H_0: p_1=p_2\\) és vertadera, l’estadístic de contrast \\[ Z=\\frac{\\widehat{p}_1 -\\widehat{p}_2}{ \\sqrt{\\frac{E}{n_1 +n_2}\\cdot \\Big(1-\\frac{E}{n_1 +n_2}\\Big)\\cdot \\Big(\\frac{1}{n_1}+\\frac{1}{n_2} \\Big)}} \\] (on \\(E=n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2\\) és el nombre total d’èxits a les dues mostres) té distribució aproximadament normal estàndard, la qual cosa es pot emprar com sempre per calcular p-valors i intervals de confiança. Aquest test està implementat en la funció de R prop.test(c(x1,x2), c(n1,n2), alternative=..., correct=..., conf.level=...,) on x1 i x2 són els nombres d’èxits a les dues mostres i n1, n2 les seves mides. Com al cas d’una proporció, la versió que hem explicat correspon a correct=FALSE, però és més recomanable emprar el valor per defecte de correct, que és TRUE i fa que s’hi apliqui una correcció de continuïtat. Aquest test s’anomena prop-test, o també test \\(\\chi^2\\) perquè és un cas particular d’un test \\(\\chi^2\\) que veurem al proper tema. De fet, com en el cas d’una proporció, en la seva implementació en R no s’hi empra \\(Z\\) sinó \\(Z^2\\), que té distribució aproximadament \\(\\chi^2_1\\). Exemple 5.15 En un estudi es volgué saber si un determinat al·lel d’un gen és present o no amb la mateixa proporció entre els mallorquins i els menorquins. Es prengueren una mostra d’ADN de 100 individus amb almenys tres generacions familiars a l’illa de Mallorca, i una altra de 50 individus amb almenys tres generacions familiars a l’illa de Menorca: les mostres es prengueren de manera independent. A la mostra mallorquina, 20 individus tengueren l’al·lel, i a la mostra menorquina, 12. La taula de freqüències és, doncs \\[ \\begin{array}{r|cc } &amp; \\textrm{Mallorca} &amp; \\textrm{Menorca} \\\\\\hline \\textrm{Present} &amp; 20 &amp; 12 \\\\ \\textrm{Absent} &amp; 80 &amp; 38 \\\\\\hline \\textrm{Total} &amp; 100 &amp; 50 \\end{array} \\] Com és aquesta mostra, per conglomerats o estratificada? Variables d’interés: \\(X_1\\): “Prenem un mallorquí amb 3 generacions familiars a l’illa i miram si té aquest al·lel” \\(X_2\\): “Prenem un menorquí amb 3 generacions familiars a l’illa i miram si té aquest al·lel” Totes dues són Bernoulli, amb proporcions poblacionals d’èxit \\(p_1\\) i \\(p_2\\), respectivament. Contrast: \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1\\neq p_2 \\end{array}\\right. \\] Estam les condicions de poder emprar el test \\(\\chi^2\\), perquè les dues mostres i els seus nombres d’èxits (individus amb l’al·lel) i fracassos (individus sense l’al·lel) són prou grans. Estadístic de contrast: \\[ Z=\\frac{\\widehat{p}_1 -\\widehat{p}_2}{ \\sqrt{\\frac{E}{n_1+n_2}\\cdot \\Big(1-\\frac{E}{n_1 +n_2}\\Big)\\cdot\\Big(\\frac{1}{n_1}+\\frac{1}{n_2} \\Big)}} \\] que és aproximadament \\(N(0,1)\\) si \\(H_0\\) és vertadera. Valor de l’estadístic: Teim que \\(\\widehat{p}_1=0.2\\), \\(\\widehat{p}_2=0.24\\), \\(n_1=100\\), \\(n_2=50\\), \\(E=20+12=32\\) i per tant \\[ z_0=\\frac{0.2 -0.24}{ \\sqrt{\\frac{32}{150}\\Big(1-\\frac{32}{150}\\Big)\\Big(\\frac{1}{100}+\\frac{1}{50} \\Big)}} =-0.5637 \\] p-valor: \\(2\\cdot P(Z\\geqslant|-0.5637|)=0.573\\) Conclusió: No hem trobat evidència estadísticament significativa que les proporcions de mallorquins i menorquins amb aquest al·lel siguin diferents (test \\(\\chi^2\\), p-valor 0.57). Amb R, entraríem prop.test(c(20,12), c(100,50), alternative=&quot;two.sided&quot;) ## ## 2-sample test for equality of proportions with continuity correction ## ## data: c(20, 12) out of c(100, 50) ## X-squared = 0.12414, df = 1, p-value = 0.7246 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.1969858 0.1169858 ## sample estimates: ## prop 1 prop 2 ## 0.20 0.24 Bé, no exactament: com hem explicat, nosaltres hem fet la versió correct=FALSE. prop.test(c(20,12), c(100,50), alternative=&quot;two.sided&quot;, correct=FALSE) ## ## 2-sample test for equality of proportions without continuity ## correction ## ## data: c(20, 12) out of c(100, 50) ## X-squared = 0.3178, df = 1, p-value = 0.5729 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.1819858 0.1019858 ## sample estimates: ## prop 1 prop 2 ## 0.20 0.24 L’interval de confiança que dóna la funció prop.test en un contrast de dues proporcions és per a la diferència de les proporcions, \\(p_1-p_2\\). Test exacte de Fisher Si no se satisfan les condicions pel test \\(\\chi^2\\), sempre es pot aplicar el test exacte de Fisher, que es basa en la idea següent. Tenim la taula de freqüències \\[ \\begin{array}{r|cc|c } &amp; X_1 &amp; X_2 &amp; \\textrm{Total} \\\\\\hline \\textrm{Èxits} &amp; n_{11} &amp; n_{12} &amp; E \\\\ \\textrm{Fracassos} &amp; n_{21} &amp; n_{22} &amp; F \\\\\\hline \\textrm{Total} &amp; n_{1} &amp; n_{2} \\end{array} \\] Si \\(p_1=p_2\\), les dues variables \\(X_1\\) i \\(X_2\\) tenen la mateixa probabilitat d’èxit, i per tant les dues mostres podrien considerar-se com a dues mostres independents de la mateixa variable \\(X_1\\). Llavors, la probabilitat d’obtenir \\(n_{11}\\) èxits dins la mostra de \\(X_1\\) és la de: Si en una bossa hi tenim \\(E\\) bolles “Èxit” i \\(F\\) bolles “Fracàs”, la probabilitat d’obtenir \\(n_{11}\\) bolles “Èxit” si en triam \\(n_{1}\\) de cop. Per tant, la distribució de la variable \\(N_{11}\\) que dóna el valor de \\(n_{1,1}\\) (nombre d’èxits de \\(X_1\\) en una mostra amb els valors de \\(E,F,n_1\\) com la nostra) és hipergeomètrica \\(H(E,F,n_{1})\\). Podem emprar \\(N_{11}\\) com a estadístic de contrast i la distribució hipergeomètrica per calcular p-valors com en el test binomial. En particular, si \\(n_{1,1}\\) és el valor d’aquesta variable en la nostra mostra Si \\(H_1:p_1&gt;p_2\\), el p-valor és \\(P(N_{1,1}\\geqslant n_{1,1})\\), on, recordem, \\(N_{1,1}\\sim H(E,F,n_{1})\\) Si \\(H_1:p_1&lt;p_2\\), el p-valor és \\(P(N_{1,1}\\leqslant n_{1,1})\\) Si \\(H_1:p_1=p_2\\), sigui \\(n_0\\) el valor esperat de la variable \\(N_{1,1}\\sim H(E,F,n_{1})\\), que és \\(n_1\\cdot E/(E+F)\\). Aleshores el p-valor és la probabilitat que la variable \\(N_{1,1}\\) prengui un valor tan o més diferent d’aquest \\(n_0\\) que \\(n_{1,1}\\): \\[ P(|N_{1,1}-n_0|\\geqslant|n_{1,1}-n_0|) \\] També es pot calcular com la probabilitat que \\(N_{1,1}\\) prengui un valor de probabilitat més petita o igual que la de \\(n_{1,1}\\): \\[ \\sum_{k\\ \\mathrm{tal\\ que}\\atop P(N_{1,1}=k)\\leqslant P(N_{1,1}=n_{1,1})} P(N_{1,1}=k) \\] Exemple 5.16 Per determinar si la Síndrome de Mort Sobtada del Nadó (SIDS) té component genètic, es consideren els casos de SIDS en parelles de bessons monozigòtics i dizigòtics. Diguem: \\(p_1\\): proporció de parelles de bessons monozigòtics amb algun cas de SIDS on només un germà la sofrí \\(p_2\\): proporció de parelles de bessons dizigòtics amb algun cas de SIDS on només un germà la sofrí Si la SIDS té component genètic, hauria de passar que \\(p_1&lt;p_2\\). En efecte, si aquesta síndrome té component genètic i en una parella de bessons un d’ells mor per SIDS, és més probable que l’altre bessó també la sofreixi si els bessons són monozigòtics que si són dizigòtics, ja que els genomes dels monozigòtics són pràcticament idèntics i els dels dizigòtics no. És a dir, és més probable que l’altre bessó també mori per SIDS si els bessons són monozigòtics que si són dizigòtics, o el que és el mateix, és MENYS probable que l’altre bessó NO mori per SIDS si els bessons són monozigòtics que si són dizigòtics. Per tant les variables d’interès són: \\(X_1\\): “Prenem una parella de bessons monozigòtics amb algun cas de SIDS, i miram si només un germà la sofrí”, que és Bernoulli amb probabilitat d’èxit \\(p_1\\) \\(X_2\\): “Prenem una parella de bessons dizigòtics amb algun cas de SIDS, i miram si només un germà la sofrí”, que és Bernoulli amb probabilitat d’èxit \\(p_2\\) i el contrast que volem realitzar és \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1&lt; p_2 \\end{array}\\right. \\] En un estudi s’obtingueren les dades següents: \\[ \\begin{array}{c} \\hphantom{Monozigotic} \\textbf{Tipus de bessons} \\\\ \\begin{array}{lr|cc|c} &amp; &amp; \\textrm{Monozigòtics} &amp; \\textrm{Dizigòtics} &amp; \\textrm{Total} \\\\ \\hline \\textbf{Casos} &amp; \\textrm{Un} &amp; 23 &amp; 35 &amp; 58\\\\ \\textbf{de SIDS} &amp; \\textrm{Dos} &amp; 1 &amp; 2 &amp; 3\\\\\\hline &amp; \\textrm{Total} &amp; 24 &amp; 37 &amp; \\end{array} \\end{array} \\] Emprarem el test de Fisher, ja que ni les mostres ni els nombres de “fracassos” no són prou grans per poder emprar el test \\(\\chi^2\\). p-valor: \\[ P(H(58,3,24)\\leqslant 23) =\\texttt{phyper(23,58,3,24)}=0.7841 \\] Conclusió: No hem obtingut evidència estadísticament significativa que la SIDS tengui un component genètic (test de Fisher, p-valor 0.78). Amb R el test de Fisher està implementat en la funció fisher.test(M,alternative=...,conf.level=...) on M és la matriu de freqüències de la mostra tal i com l’hem donada: fileres Èxits i Fracassos (en aquest ordre) i columnes \\(X_1\\) i \\(X_2\\). En el nostre exemple, entraríem M=matrix(c(23,35,1,2), nrow=2, byrow=TRUE) fisher.test(M,alternative=&quot;less&quot;) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: M ## p-value = 0.7841 ## alternative hypothesis: true odds ratio is less than 1 ## 95 percent confidence interval: ## 0.00000 39.73954 ## sample estimates: ## odds ratio ## 1.308589 Obtenim el mateix p-valor, i un interval de confiança del 95% que va de 0 a 39.7. Ja us podeu imaginar que aquest interval de confiança no pot ser per a \\(p_1-p_2\\). De fet, la funció fisher.test no compara \\(p_1\\) i \\(p_2\\), sinó les seves odds (oportunitats; en castellà, també momios) \\[ \\frac{p_1}{1-p_1}\\text{ i }\\frac{p_2}{1-p_2}. \\] L’interval de confiança que dóna és per al quocient d’aquestes odds: la seva odds ratio (OR, raó d’oportunitats; en castellà, també razón de momios). Fem un incís sobre les odds. Les odds d’un esdeveniment \\(A\\) són \\[ \\text{Odds}(A)=\\frac{P(A)}{P(A^c)}=\\frac{P(A)}{1-P(A)} \\] i indiquen quantes vegades és més probable \\(A\\) que “no \\(A\\)”. Per exemple: Si \\(P(A)=0.3\\), \\(\\text{Odds}(A)=0.3/0.7=0.43\\) Si \\(P(A)=0\\), \\(\\text{Odds}(A)=0\\) Si \\(P(A)=0.5\\), \\(\\text{Odds}(A)=1\\) Si \\(P(A)=1\\), \\(\\text{Odds}(A)=\\infty\\) Les odds d’\\(A\\) se solen interpretar en termes d’apostes. Per desgràcia, si no estau acostumats a apostar, per exemple, a les carreres de trotons, aquesta interpretació no us aclarirà gaire. Però ho intentarem. Suposem que \\(\\text{Odds}(A)=m\\), és a dir, que \\(P(A)=m\\cdot P(A^c)\\), i suposem que: Per cada euro que jugueu a \\(A^c\\), la casa d’apostes us en paga 1 si passa \\(A^c\\) i 0 si passa \\(A\\) Per cada euro que jugueu a \\(A\\), la casa d’apostes us en paga \\(R\\) si passa \\(A\\) i 0 si passa \\(A^c\\) Això se sol abreviar dient que les apostes a favor d’\\(A\\) es paguen \\(R\\) a 1: per cada euro que es paga si “guanya” \\(A^c\\), es paguen \\(R\\) euros si “guanya” \\(A\\). Què ha de valer \\(R\\) per que si jugau 1 euro a \\(A\\), el que esperau guanyar sigui el mateix que si jugau 1 euro a \\(A^c\\)? (Es diu en aquest cas que les apostes estan equilibrades.) Vegem. Si jugau 1 euro a \\(A\\), esperau guanyar \\(R\\cdot P(A)=R\\cdot m\\cdot P(A^c)\\), i si jugau 1 euro a \\(A^c\\) esperau guanyar \\(1\\cdot P(A^c)\\). Per tant, si aquests guanys esperats han de ser iguals, ha de passar \\(R\\cdot m=1\\), és a dir \\(R=1/m\\). Així, per exemple, si \\(\\text{Odds}(A)=2\\) (la probabilitat que passi \\(A\\) és 2 vegades la de que passi \\(A^c\\)), per que les apostes estiguin equilibrades s’han de pagar 0.5 a 1 a favor d’\\(A\\): per cada euro que es paga si guanya \\(A^c\\), s’ha de pagar mig euro si guanya \\(A\\). Fixau-vos que si coneixeu \\(\\text{Odds}(A)\\), podeu aïllar \\(P(A)\\). Per exemple si \\(\\text{Odds}(A)=0.6\\) \\[ \\begin{array}{l} 0.6=\\dfrac{P(A)}{1-P(A)}\\Rightarrow 0.6-0.6P(A)=P(A)\\\\ \\qquad \\Rightarrow 0.6=1.6P(A)\\Rightarrow P(A)=\\dfrac{0.6}{1.6}=0.375 \\end{array} \\] En general \\[ P(A)=\\dfrac{\\text{Odds}(A)}{1+\\text{Odds}(A)} \\] D’aquí podeu deduir fàcilment que \\[ \\begin{array}{c} \\text{Odds}(A)&lt;\\text{Odds}(B)\\Longleftrightarrow P(A)&lt;P(B)\\\\ \\text{Odds}(A)&gt;\\text{Odds}(B)\\Longleftrightarrow P(A)&gt;P(B)\\\\ \\text{Odds}(A)=\\text{Odds}(B)\\Longleftrightarrow P(A)=P(B) \\end{array} \\] i per tant comparant les probabilitats o les odds de dos esdeveniments obteniu la mateixa informació sobre quin és més probable. La odds ratio de \\(A\\) i \\(B\\) és \\[ \\text{OR}(A,B)=\\frac{\\text{Odds}(A)}{\\text{Odds}(B)} \\] Aquest quocient sol ser mal d’interpretar, i per això precisament sempre que poguem evitarem el test exacte de Fisher. En tot cas, fixau-vos que si \\(\\text{OR}(A,B)=r\\), és a dir, \\(\\text{Odds}(A)=r\\cdot \\text{Odds}(B)\\), i les apostes a favor de \\(A\\) es paguen \\(R_A\\) a 1 i les de \\(B\\) es paguen \\(R_B\\) a 1 i les dues estan equilibrades, aleshores \\[ \\frac{1}{R_A}=r\\cdot \\frac{1}{R_B}\\Longrightarrow R_B=r\\cdot R_A \\] Per tant, si \\(\\text{OR}(A,B)=r\\) i les apostes a favor de \\(B\\) es paguen \\(R_B\\) a 1, les apostes a favor d’\\(A\\) s’han de pagar \\(rR_B\\) a 1. \\(\\text{OR}(A,B)=1\\) si, i només si, \\(\\text{Odds}(A)=\\text{Odds}(B)\\) i per tant, pel que acabam de dir, si, i només si, \\(P(A)=P(B)\\). Per tant, si l’interval de confiança per a la odds ratio que dóna la funció fisher.test conté l’1, no podem rebutjar que les dues proporcions poblacionals d’èxit siguin iguals. Exemple 5.17 Si, per exemple, la odds ratio de \\(A\\) i \\(B\\) és \\[ \\text{OR}(A,B)=\\frac{\\text{Odds}(A)}{\\text{Odds}(B)}=1.5 \\] i per tant \\(\\text{Odds}(A)=1.5\\cdot \\text{Odds}(B)\\): Com que en particular \\(\\text{Odds}(A)&gt; \\text{Odds}(B)\\), podeu concloure que \\(P(A)&gt;P(B)\\) Però el fet que \\(\\text{Odds}(A)=1.5\\cdot \\text{Odds}(B)\\) no implica que \\(P(A)=1.5P(B)\\). De fet, d’aquest valor de \\(OR(A,B)\\) no podeu deduir el valor de \\(P(A)/P(B)\\). Intentau-ho si no ens creieu. Exemple 5.18 Si realitzam el contrast de l’Exemple 5.15 amb el test \\(\\chi^2\\), obtenim prop.test(c(20,12),c(100,50),alternative=&quot;two.sided&quot;,correct=FALSE) ## ## 2-sample test for equality of proportions without continuity ## correction ## ## data: c(20, 12) out of c(100, 50) ## X-squared = 0.3178, df = 1, p-value = 0.5729 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.1819858 0.1019858 ## sample estimates: ## prop 1 prop 2 ## 0.20 0.24 El p-valor 0.5729 no ens permet rebutjar que les proporcions de mallorquins i menorquins amb l’al·lel objecte d’estudi siguin iguals L’IC 95% per a la diferència de proporcions va de -0.18 a 0.1: com que conté el 0, no podem rebutjar amb aquest nivell de confiança que les proporcions siguin iguals La diferència de proporcions mostrals \\(p_1-p_2\\) ha estat \\(0.2-0.24=-0.04\\): la proporció de menorquins amb l’al·lel a la nostra mostra ha estat 4 punts percentuals més gran que la dels mallorquins Si ara l’efectuam amb el test de Fisher: M.A=matrix(c(20,12,80,38), nrow=2, byrow=TRUE) fisher.test(M.A,alternative=&quot;two.sided&quot;) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: M.A ## p-value = 0.673 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.3287521 1.9742955 ## sample estimates: ## odds ratio ## 0.7929466 El p-valor 0.673 no ens permet rebutjar que les odds de tenir aquest al·lel entre els mallorquins i els menorquins siguin iguals; com que igualtat d’odds és equivalent a igualtat de probabilitats, no podem rebutjar que els mallorquins i menorquins tenguin la mateixa probabilitat de tenir l’al·lel objecte d’estudi Vegem que coincideix amb el p-valor del contrast bilateral de Fisher que hem explicat. Recordem la taula de dades: \\[ \\begin{array}{r|cc } &amp; \\textrm{Mallorca} &amp; \\textrm{Menorca} \\\\\\hline \\textrm{Present} &amp; 20 &amp; 12 \\\\ \\textrm{Absent} &amp; 80 &amp; 38 \\\\\\hline \\textrm{Total} &amp; 100 &amp; 50 \\end{array} \\] Si la hipòtesi nul·la és vertadera, el nombre \\(N_{1,1}\\) de mallorquins amb l’al·lel en una mostra com la nostra té distribució hipergeomètrica \\(H(32,118,100)\\) i per tant valor esperat \\(100\\cdot 32/150=21.333\\). Com que a la nostra mostra \\(n_{1,1}=20\\), el p-valor és \\[ \\begin{array}{l} P(|N_{1,1}-21.333|\\geqslant 1.333)=P(N_{1,1}\\leqslant 20\\text{ o }N_{1,1}\\geqslant 22.666)\\\\ \\qquad= P(N_{1,1}\\leqslant 20\\text{ o }N_{1,1}\\geqslant 23)\\qquad \\text{(perquè $N_{1,1}\\in \\mathbb{N}$)}\\\\ \\qquad= P(N_{1,1}\\leqslant 20)+P(N_{1,1}\\geqslant 23)\\\\ \\qquad= \\texttt{phyper(20,32,118,100)+(1-phyper(22,32,118,100))}\\\\ \\qquad=0.6729552 \\end{array} \\] i fisher.test(M.A,alternative=&quot;two.sided&quot;)$p.value ## [1] 0.6729552 L’IC 95% per a la odds ratio (per al quocient de les odds) va de 0.33 a 1.97: com que conté l’1, no podem rebutjar amb aquest nivell de confiança que la odds ratio sigui 1; és a dir, no podem rebutjar que les odds siguin iguals; és a dir, no podem rebutjar que les proporcions siguin iguals El quocient d’odds mostrals (la odds ratio mostral) ha estat 0.79: a la nostra mostra, les odds que un mallorquí tengués l’al·lel han estat 0.79 vegades (un 21% més petites que) les d’un menorquí; però això no ens dóna cap relació numèrica entre les proporcions mostrals de mallorquins i menorquins amb l’al·lel. 5.3.3 Contrastos per a 2 proporcions emprant mostres aparellades Siguin una altra vegada \\(X_1\\) i \\(X_2\\) dues variables aleatòries Bernoulli de paràmetres poblacionals \\(p_1\\) i \\(p_2\\). Seguim volent realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2\\text{ o }p_1&gt; p_2\\text{ o }p_1&lt; p_2 \\end{array} \\right. \\] però ara les mesuram sobre els subjectes d’una mateixa mostra, o sobre els subjectes de dues mostres aparellades, de mida \\(n\\). Suposem que tenim els resultats en una taula \\[ \\begin{array}{c} \\hphantom{Variablesssss} \\text{Variable $X_2$}\\\\ \\begin{array}{r|cc} \\text{Variable $X_1$} &amp;\\text{Èxit} &amp; \\text{Fracàs} \\\\ \\hline \\text{Èxit} &amp; a &amp; b \\\\ \\text{Fracàs} &amp; c &amp; d\\\\ \\end{array} \\end{array} \\] on cada entrada representa el nombre de subjectes (o parelles) que satisfan les condicions de la filera i la columna. En aquest cas tenim dues opcions: Realitzar un test de McNemar, que només serveix per a contrastos bilaterals i a més requereix algunes condicions sobre les dues mostres Realitzar un test binomial, que es pot emprar sempre però no dóna la informació exactament com la voldríem Test de McNemar Quan el test és bilateral, si el nombre de casos discordants (\\(b+c\\) en la taula anterior) és prou gran (posem, més gran o igual que 25), es pot emprar el test de McNemar, que empra l’estadístic de contrast \\[ Z^2=\\frac{(b-c)^2}{b+c} \\] el qual, si se satisfan les condicions esmentades, segueix aproximadament una distribució \\(\\chi^2_1\\) si \\(H_0\\) és vertadera. En aquest test se rebutja la hipòtesi nul·la si \\(b\\) i \\(c\\) són prou diferents i per tant, malgrat ser un contrast bilateral, es pren com a p-valor \\(P(Z^2\\geqslant Z_0^2)\\), on \\(Z_0^2\\) és el valor de l’estadístic a la nostra mostra i \\(Z^2\\) té distribució \\(\\chi_1^2\\). Aquest test està implementat en R en la funció mcnemar.test, que s’aplica a la taula de freqüències absolutes de la mostra tal i com l’hem donada. Exemple 5.19 En un assaig clínic es volgué comparar l’efectivitat d’un fàrmac nou contra la migranya amb la d’un placebo. Es prengué una mostra de 500 persones afectades per migranya. A cada una, a l’atzar, se li administrà el fàrmac o el placebo. Se’ls demanà si havien notat alleujament en el dolor. Al cap d’un temps, als mateixos individus se’ls subministrà l’altre tractament (fàrmac als que havien rebut placebo, placebo als que havien rebut fàrmac) i se’ls tornà a demanar si havien notat o no millora. Els resultats varen ser: \\[ \\begin{array}{c} \\hphantom{Variables} \\text{Placebo}\\\\ \\begin{array}{r|cc} \\text{Fàrmac} &amp;\\text{Sí} &amp; \\text{No} \\\\ \\hline \\text{Sí} &amp; 150 &amp; 41 \\\\ \\text{No} &amp; 19 &amp; 285\\\\ \\end{array} \\end{array} \\] on “Sí” indica que el malalt va dir que sí que havia notat alleujament en el dolor. Variables d’interès: \\(X_1\\): “Prenem un malalt, li administram el fàrmac i li demanam si nota millora del dolor”. És Bernoulli amb proporció poblacional d’èxit \\(p_1\\) \\(X_2\\): “Prenem un malalt, li administram el placebo i li demanam si nota millora del dolor”. És Bernoulli amb proporció poblacional d’èxit \\(p_2\\) Contrast: Com que la mostra i el nombre de casos discordants són prou grans, podem emprar el test de McNemar, però aleshores el contrast ha de ser bilateral \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1\\neq p_2 \\end{array}\\right. \\] Estadístic de contrast: \\[ Z^2=\\frac{(b-c)^2}{b+c} \\] que segueix una distribució aproximadament \\(\\chi_1^2\\) si \\(p_1=p_2\\). Valor sobre la nostra mostra: \\(Z_0^2=(41-19)^2/(41+19)=8.067\\) p-valor: \\(P(Z^2\\geqslant 8.067)=\\texttt{1-pchisq(8.067,1)}=0.0045\\) Conclusió: Hem obtingut evidència estadísticament significativa que la taxa d’efectivitat del placebo i del fàrmac són diferents (test de McNemar, p-valor 0.0045). I ara, com que la taxa d’efectivitat del fàrmac ha estat superior a la del placebo (191/500 contra 169/500), faríem la petita trampa de concloure que la diferència entre aquestes taxes d’efectivitat és perquè el fàrmac es més efectiu. Amb R, entraríem Dades.M=matrix(c(150,41,19,285), nrow=2, byrow=TRUE) mcnemar.test(Dades.M) ## ## McNemar&#39;s Chi-squared test with continuity correction ## ## data: Dades.M ## McNemar&#39;s chi-squared = 7.35, df = 1, p-value = 0.006706 Ups! No ha donat el mateix estadístic ni el mateix p-valor. Això passa perquè R també aplica per defecte una correcció de continuïtat al test de McNemar. El que nosaltres hem explicat correspon a mcnemar.test(Dades.M,correct=FALSE) ## ## McNemar&#39;s Chi-squared test ## ## data: Dades.M ## McNemar&#39;s chi-squared = 8.0667, df = 1, p-value = 0.004509 Test binomial exacte Si no podeu emprar el test de McNemar, sempre podeu emprar el test binomial exacte següent. Considerau la taula de probabilitats poblacionals \\[ \\begin{array}{c} \\hphantom{Variablesssss} \\text{Variable $X_2$}\\\\ \\begin{array}{r|cc} \\text{Variable $X_1$} &amp;\\text{Èxit} &amp; \\text{Fracàs} \\\\ \\hline \\text{Èxit} &amp; p_{11} &amp; p_{10} \\\\ \\text{Fracàs} &amp; p_{01} &amp; p_{00} \\end{array} \\end{array} \\] Llavors \\[ p_1=p_{11}+p_{10},\\ p_2=p_{11}+p_{01} \\] i per tant \\[ \\begin{array}{l} \\displaystyle p_1=p_2\\Longleftrightarrow p_{10}=p_{01}\\Longleftrightarrow \\frac{p_{10}}{p_{10}+p_{01}}=0.5\\\\[1ex] \\displaystyle p_1\\neq p_2\\Longleftrightarrow p_{10}\\neq p_{01}\\Longleftrightarrow \\frac{p_{10}}{p_{10}+p_{01}}\\neq 0.5\\\\[1ex] \\displaystyle p_1&lt; p_2\\Longleftrightarrow p_{10}&lt; p_{01}\\Longleftrightarrow \\frac{p_{10}}{p_{10}+p_{01}}&lt;0.5\\\\[1ex] \\displaystyle p_1&gt; p_2\\Longleftrightarrow p_{10}&gt; p_{01}\\Longleftrightarrow \\frac{p_{10}}{p_{10}+p_{01}}&gt;0.5\\\\[1ex] \\end{array} \\] Això permet traduir un contrast sobre \\(p_1\\) i \\(p_2\\) pbinom{27,71,0.5) Exemple 5.20 Tornem a la situació de l’Exemple 5.19. Ara volem fer el contrast que realment ens interessa, que és si la taxa d’efectivitat del fàrmac és més gran que la del placebo: \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1&gt;p_2 \\end{array}\\right. \\] Dient \\(p=p_{10}/(p_{10}+p_{01})\\), el traduïm en \\[ \\left\\{\\begin{array}{l} H_0:p=0.5\\\\ H_1:p&gt; 0.5 \\end{array}\\right. \\] Les dades eren \\[ \\begin{array}{c} \\hphantom{Variables} \\text{Placebo}\\\\ \\begin{array}{r|cc} \\text{Fàrmac} &amp;\\text{Sí} &amp; \\text{No} \\\\ \\hline \\text{Sí} &amp; 150 &amp; 41 \\\\ \\text{No} &amp; 19 &amp; 285 \\end{array} \\end{array} \\] I per tant al contrast sobre \\(p\\) emprarem la mostra de 60 casos discordants on 41 són Èxits. Ho fen directament amb R: binom.test(41, 60, p=0.5, alternative=&quot;greater&quot;) ## ## Exact binomial test ## ## data: 41 and 60 ## number of successes = 41, number of trials = 60, p-value = 0.003109 ## alternative hypothesis: true probability of success is greater than 0.5 ## 95 percent confidence interval: ## 0.5708296 1.0000000 ## sample estimates: ## probability of success ## 0.6833333 Conclusió: Hem obtingut evidència estadísticament significativa que el fàrmac té una taxa d’efectivitat més gran que el placebo (test binomial, p-valor 0.003). "],
["contrastos-de-bondat-dajust.html", "Tema 6 Contrastos de bondat d’ajust 6.1 Bondat d’ajust 6.2 Test \\(\\chi^2\\) de Pearson 6.3 Test de Kolmogorov-Smirnov 6.4 Test de Kolmogorov-Smirnov-Lilliefors", " Tema 6 Contrastos de bondat d’ajust Els contrastos d’un paràmetre del tema anterior els empràvem bàsicament per cercar evidència que a un paràmetre poblacional (una mitjana, una proporció) “li passava qualque cosa”: Tenim evidència que la mitjana poblacional és diferent de 2? Tenim evidència que la proporció poblacional d’èxits és més gran que el 10%? Però també podem entendre que hi cercàvem si podem acceptar que el paràmetre poblacional de la variable que havia produit la mostra era igual a qualque cosa: Podem acceptar que la mitjana poblacional és igual de 2? Podem acceptar que la proporció poblacional d’èxits és del 10%? Als contrastos de bondat d’ajust anam una passa més enllà, i ens demanam si podem acceptar que la variable poblacional té una distribució concreta, o si per contra seria molt estrany que la nostra mostra hagués estat produïda per una variable amb aquella distribució. Per exemple: Llençam un dau en l’aire moltes vegades, apuntam els resultats, i ens demanam si podem acceptar que el dau és honrat (és a dir, que tots els resultats són equiprobables) o si per contra hi ha evidència que està trucat. Anotam els ingressos diaris per una determinada malaltia en un hospital i ens demanam si podem acceptar que segueixen una distribució de Poisson o si per contra hi ha evidència que no és el cas, la qual cosa seria senyal que hi ha un brot estrany de la malaltia. Volem emprar una mostra petita en un t-test. Podem acceptar que prové d’una distribució normal? De fet, ja hem estudiat un tipus de contrast de bondat d’ajust: els contrastos bilaterals d’una proporció, on ens demanàvem si podem acceptar que la mostra prové de tal variable Bernoulli o si per contra hi ha evidència que no. 6.1 Bondat d’ajust Considerau l’exemple següent: Exemple 6.1 Les freqüències de les darreres xifres dels primers premis de la Grossa de la loteria de Nadal als 211 sortejos de la seva història han estat les següents: \\[ \\begin{array}{r|cccccccccc} \\hline \\text{xifra} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 \\\\ \\hline \\text{freqüència} &amp; 22 &amp; 8 &amp; 13 &amp; 21 &amp; 27 &amp; 31 &amp; 27 &amp; 22 &amp; 23 &amp; 17\\\\ \\hline \\end{array} \\] Hi ha evidència que no totes les xifres tenen la mateixa probabilitat de sortir com a darrera xifra de la Grossa? Aquesta és la típica pregunta d’un contrast de bondat d’ajust. En principi, estam disposats a acceptar que la nostra mostra prové d’una variable amb una certa distribució: Que totes les darreres xifres de la Grossa tenen la mateixa probabilitat d’aparèixer. Rebutjarem aquesta hipòtesi si seria molt estrany haver obtingut la nostra mostra si la variable seguís aquesta distribució: Si les darreres xifres tenguessin totes la mateixa probabilitat d’aparèixer, esperaríem una certa uniformitat en les seves freqüències a la nostra mostra. Si les freqüències reals se separen molt d’aquesta uniformitat, tendrem motius per dubtar que tots els dígits tenien la mateixa probabilitat d’aparèixer. Grossa=c(22,8,13,21,27,31,27,22,23,17) barplot(Grossa,col=&quot;light blue&quot;,names=0:9, main=&quot;Darreres xifres de la Grossa de Nadal&quot;) Més en general, un contrast de bondat d’ajust té la forma següent: \\[ \\left\\{ \\begin{array}{l} H_0: \\text{la mostra prové de la distribució esperada}\\\\ H_1: \\text{la mostra NO prové de la distribució esperada} \\end{array} \\right. \\] I, com sempre, Si obtenim evidència que ens permeti rebutjar la hipòtesi nul·la, conclourem que la mostra no prové de la distribució esperada Si no obtenim evidència que ens permeti rebutjar la hipòtesi nul·la, donarem per bo que la mostra prové de la distribució esperada Els tests de bondat d’ajust es basen bàsicament en: Comparar les freqüències observades amb les freqüències teòriques de la distribució que contrastam Determinar si les freqüències observades són prou diferents de les teòriques com per fer inversemblant la hipòtesi nul·la Per exemple, continuant amb el nostre exemple de la Grossa, si totes les darreres xifres tinguessin la mateixa probabilitat d’aparèixer, la seva probabilitat seria 1/10, i per tant el valor esperat d’aparicions de cadascuna d’elles seria 211/10=21.1. barplot(Grossa, col=&quot;light blue&quot;, names=0:9, main=&quot;Darreres xifres de la Grossa de Nadal&quot;) abline(h=21.1, col=&quot;red&quot;, lwd=2, lty=&quot;dashed&quot;) Les desviacions observades respecte d’aquest valor, representat per la línia vermella al gràfic anterior, són prou grans com per dubtar que aquestes xifres són equiprobables, o podem acceptar que es deuen a l’atzar? 6.2 Test \\(\\chi^2\\) de Pearson 6.2.1 El test bàsic El test més popular per a variables aleatòries qualitatives, ordinals i quantitatives discretes (o contínues agrupades) és el test \\(\\chi^2\\) de Pearson. Suposem que tenim una mostra aleatòria simple de mida \\(n\\). Agrupam tots els resultats possibles en \\(k\\) classes, \\(C_1,\\ldots,C_k\\) (poden ser tots els resultats individuals possibles, si només n’hi ha un conjunt finit). Així, al nostre exemple de les terminacions de la loteria, hi tenim 10 classes, definides pels 10 valors possibles de la darrera xifra: \\(C_1=\\{0\\}\\), \\(C_2=\\{1\\}\\),…, \\(C_{10}=\\{9\\}\\). Volem contrastar si les observacions segueixen una distribució totalment coneguda, per a la qual coneixem la probabilitat que una observació caigui dins cada una de les classes. El contrast és, recordem, \\[ \\left\\{\\begin{array}{l} H_{0}: \\text{La població té aquesta distribució }\\\\ H_{1}: \\text{La població no té aquesta distribució} \\end{array} \\right. \\] Per a cada classe \\(C_i\\), diguem \\(obs_i\\): la freqüència absoluta observada d’aquesta classe. Per exemple, en el nostre exemple de la loteria, \\(obs_1\\) és el nombre de vegades que la Grossa ha acabat en 0: 21; \\(obs_2\\) és el nombre de vegades que la Grossa ha acabat en 1: 8; etc. \\(p_i\\): la probabilitat teòrica que una observació pertanyi a aquesta classe si \\(H_0\\) és vertadera. En el nostre exemple de la loteria, totes les probabilitats \\(p_i\\) valen el mateix, 1/10. \\(esp_i\\): la freqüència absoluta esperada, o teòrica, d’aquesta classe si \\(H_0\\) és vertadera: \\(esp_i=p_i\\cdot n\\). En el nostre exemple de la loteria, totes aquestes freqüències absolutes \\(esp_i\\) valen el mateix, 211/10=21.1. Rebutjarem \\(H_0\\) si les \\(obs_i\\) són prou diferents de les \\(esp_i\\). Per mesurar-ho, empram el teorema següent: Teorema 6.1 Si \\(H_0\\) és vertadera, la distribució contrastada està completament determinada i se satisfan les condicions següents: La mida \\(n\\) de la mostra és gran (ho fixarem en \\(n\\geqslant 30\\)) Les classes cobreixen tots els resultats possibles: \\(\\sum\\limits_{i=1}^kesp_i= n\\) Totes les classes tenen prou probabilitat teòrica com per tenir-les en compte (nosaltres emprarem la Regla de Cochran: totes les \\(esp_i\\geqslant 5\\)) aleshores l’estadístic de contrast \\[ \\chi^2=\\sum_{i=1}^k \\frac{(obs_{i}-esp_{i})^2}{esp_{i}} \\] té (aproximadament) una distribució \\(\\chi_{k-1}^2\\). Si la distribució contrastada no estava completament determinada i se n’han estimat \\(m\\) paràmetres a partir de la mostra, s’ha de prendre com a distribució de l’estadístic de contrast una \\(\\chi_{k-1-m}^2\\). Fixau-vos que l’extadístic de contrast \\(\\chi^2\\) s’obté de la manera següent: Per cada classe \\(C_i\\): Se resta \\(obs_{i}-esp_{i}\\) S’eleva el resultat al quadrat: \\((obs_{i}-esp_{i})^2\\) Es divideix el resultat per \\(esp_i\\): \\((obs_{i}-esp_{i})^2/esp_{i}\\) Se sumen aquests valors per a totes les classes \\(C_i\\). Aleshores, el contrast se fa de la manera següent: Se calcula el valor que pren l’estadístic de contrast sobre la nostra mostra, diguem-li \\(\\chi_0^2\\) El p-valor del contrast és \\(P(\\chi^2\\geqslant\\chi_0^2)\\), calculada tenint en compte que \\(\\chi^2\\) té distribució \\(\\chi^2\\) amb nombre de graus de llibertat: Si no s’ha estimat cap paràmetre de la distribució amb la mostra, el nombre de classes menys 1: \\(\\chi^2_{k-1}\\) Si s’ha estimat qualque paràmetre de la distribució amb la mostra, el nombre de classes menys 1 i menys el nombre de paràmetres estimats: \\(\\chi^2_{k-1-m}\\) amb \\(m\\) el nombre de paràmetres estimats Com més gran sigui el nombre de classes emprades, més potència té el contrast, per tant procurau emprar-ne el màxim nombre possible tot respectant la regla de Cochran. Exemple 6.2 Tornem a l’Exemple 6.1. Recordem que la nostra mostra era \\[ \\begin{array}{r|cccccccccc} \\hline \\text{xifra} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 &amp; 6 &amp; 7 &amp; 8 &amp; 9 \\\\ \\hline \\text{freqüència} &amp; 22 &amp; 8 &amp; 13 &amp; 21 &amp; 27 &amp; 31 &amp; 27 &amp; 22 &amp; 23 &amp; 17\\\\ \\hline \\end{array} \\] Com que totes les feqüències esperades valen 21.1, el valor de l’estadístic de contrast sobre aquesta mostra és \\[ \\begin{array}{rl} \\chi_0^2&amp; \\displaystyle=\\frac{(22-21.1)^2}{21.1}+\\frac{(8-21.1)^2}{21.1}+\\cdots\\\\[2ex] &amp; \\qquad\\quad\\displaystyle +\\frac{(23-21.1)^2}{21.1} +\\frac{(17-21.1)^2}{21.1}=20.23 \\end{array} \\] Calculat amb R: Esp=rep(21.1,10) X2=sum((Grossa-Esp)^2/Esp) X2 ## [1] 20.23223 En resum, per resoldre la qüestió plantejada en l’Exemple 6.1 procedim de la manera següent: Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}: \\text{Les darreres xifres de la Grossa són equiprobables}\\\\ H_{1}: \\text{Les darreres xifres de la Grossa NO són equiprobables} \\end{array} \\right. \\] Estadístic de contrast: \\[ \\chi^2=\\sum_{i=1}^k \\frac{(obs_{i}-esp_{i})^2}{esp_{i}} \\] Estam en les condicions del Teorema 6.1: \\(n=211\\), gran Les classes, que corresponen als dígits 0,…,9, cobreixen tots els resultats possibles; \\(k=10\\) Cada \\(esp_i=21.1\\geqslant 5\\) Per tant, com que no estimam cap paràmetre de la distribució, aquest estadístic de contrast segueix una llei \\(\\chi^2_9\\). Valor de l’estadístic de contrast: Ja l’hem calculat, 20.23. p-valor: \\(P(\\chi_9^2\\geqslant 20.23)=\\texttt{1-pchisq(20.23,9)}= 0.0165\\) Conclusió: Hem obtingut evidència estadísticament significativa que les darreres xifres de la Grossa no apareixen de manera equiprobable (test \\(\\chi^2\\) de Pearson, p-valor 0.0165). Exemple 6.3 Anem a comprovar amb una simulació aquest p-valor. El que farem serà el següent: Repetirem 10000 vegades, amb un replicate, el procés d’extreure a l’atzar i de manera equiprobable 211 dígits, calcular-ne la taula de freqüències de cada una d’aquestes mostres i calcular l’estadístic de contrast \\(\\chi^2\\) sobre cada una d’aquestes taules. Finalment, calcularem la fracció de vegades que \\(\\chi^2\\) ha donat per sobre del valor de la nostra mostra, que era 20.23. set.seed(42) X2sim=replicate(10000,sum((table(sample(0:9,211,rep=TRUE))-21.1)^2/21.1)) length(which(X2sim&gt;=X2))/10000 ## [1] 0.0158 Només un 1.6% de les 10000 simulacions han donat un valor de \\(\\chi^2\\) més gran o igual que el de la mostra de Grosses de Nadal. Per tant, el valor de la \\(\\chi^2\\) de la mostra de Grosses de Nadal és anormalment gran si les darreres xifres tenen totes la mateixa probabilitat d’aparèixer. Naturalment, anormal no vol dir impossible, però… La funció per realitzar un test \\(\\chi^2\\) amb R és chisq.test(obs, p=...) on obs és el vector de les freqüències observades de les classes, \\((obs_i)_i\\) i p s’ha d’igualar al vector de les probabilitats teòriques de les classes, \\((p_i)_i\\). Si no s’especifica aquest paràmetre p, R entén que totes les probabilitats són iguals. La suma de les probabilitats entrades a p ha de ser igual a 1. Recordau que les classes han de cobrir tots els casos possibles. Al nostre exemple de la Grossa de Nadal, entraríem simplement chisq.test(Grossa) ## ## Chi-squared test for given probabilities ## ## data: Grossa ## X-squared = 20.232, df = 9, p-value = 0.01653 Obtenim el valor de \\(\\chi^2\\), X-squared, els graus de llibertat, df, i el p-valor, p-value. Exemple 6.4 Un tècnic de medi ambient vol estudiar l’augment de temperatura de l’aigua a dos quilòmetres dels abocaments d’aigua autoritzats d’una planta industrial. El responsable de l’empresa afirma que aquests augments de temperatura segueixen una llei normal amb \\(\\mu=3.5\\) dècimes de grau C i \\(\\sigma=0.7\\) dècimes de grau C. El tècnic ho posa en dubte. Per decidir-ho, pren una mostra aleatòria d’observacions de l’augment de les temperatures (en dècimes de grau). Les dades són les de la taula següent, ja agrupades en classes: \\[ \\begin{array}{c|c} \\text{Rang d&#39;augments} &amp; \\text{Freqüències}\\\\ \\hline 1.45\\text{ a }1.95 &amp; 2 \\\\ 1.95\\text{ a }2.45 &amp; 1 \\\\ 2.45\\text{ a }2.95 &amp; 4 \\\\ 2.95\\text{ a }3.45 &amp; 15 \\\\ 3.45\\text{ a }3.95 &amp; 10 \\\\ 3.95\\text{ a }4.45 &amp; 5 \\\\ 4.45\\text{ a }4.95 &amp; 3 \\\\ \\hline \\text{Total} &amp; 40\\\\ \\end{array} \\] Hi ha evidència que la sospita del tècnic sigui vertadera, amb un nivell de significació del 5%? Contrast: \\[ \\left\\{ \\begin{array}{l} H_{0}:\\text{La distribució dels augments de temp. és $N(3.5,0.7)$}\\\\ H_{1}: \\text{La distribució dels augments de temp. NO és $N(3.5,0.7)$} \\end{array} \\right. \\] Estadístic de contrast: Volem emprar el test \\(\\chi^2\\), així que l’estadístic de contrast serà \\[ \\chi^2=\\sum_{i=1}^k \\frac{(obs_{i}-esp_{i})^2}{esp_{i}} \\] Cal comprovar que se satisfan les condicions del Teorema 6.1. La mida de la mostra és \\(n=40\\), suficient. Les classes, cobreixen tots els resultats possibles? No, perquè els possible valors d’una variable normal són tots els nombres reals, i les nostres classes només cobreixen l’interval [1.45,4.95]. El que farem serà afegir les cues a les dues classes dels extrems, i considerar les classes \\[ \\begin{array}{l|c} \\text{Rang d&#39;augments} &amp; \\text{Freqüències}\\\\ \\hline \\text{menys de 1.95} &amp; 2 \\\\ 1.95 \\text{ a } 2.45 &amp; 1 \\\\ 2.45\\text{ a }2.95 &amp; 4 \\\\ 2.95\\text{ a }3.45 &amp; 15 \\\\ 3.45\\text{ a }3.95 &amp; 10 \\\\ 3.95\\text{ a }4.45 &amp; 5 \\\\ \\text{més de 4.45} &amp; 3 \\\\ \\hline \\text{Total} &amp; 40\\\\ \\end{array} \\] Ara ja cobreixen tots els resultats possibles. Totes les freqüències esperades són com a mínim 5? Doncs no ho sabem, les haurem de calcular. Recordem que són les freqüències esperades de cada classe suposant que la variable poblacional és \\(N(3.5,0.7)\\), i s’obtenen multiplicant la probabilitat de cada interval (amb aquesta distribució) per la mida de la mostra, 40. La probabilitat de la 1a classe és \\[ p_1 =P(X\\leqslant 1.95)=\\texttt{pnorm(1.95,3.5,0.7)}=0.0134 \\] i la seva freqüència esperada és \\[ esp_1=p_1\\cdot n= 0.0134\\cdot 40=0.536 \\] La probabilitat de la 2a classe és \\[ \\begin{array}{rl} p_2 &amp; =P(1.95\\leqslant X\\leqslant 2.45)\\\\ &amp; =\\texttt{pnorm(2.45,3.5,0.7)-pnorm(1.95,3.5,0.7)}=0.0534 \\end{array} \\] i per tant la seva freqüència esperada és \\[ esp_2=p_2\\cdot n= 0.0534\\cdot 40= 2.136 \\] Anam a calcular amb R totes les freqüències esperades d’aquesta manera i d’un sol cop: freq.obs=c(2,1,4,15,10,5,3) n=sum(freq.obs) lims=c(-Inf,1.95,2.45,2.95,3.45,3.95,4.45,Inf) lim.esq=lims[-length(lims)] #Els límits inferiors de les classes lim.dret=lims[-1] #Els límits superiors de les classes mu=3.5 sigma=0.7 prob.esp=pnorm(lim.dret,mu,sigma)-pnorm(lim.esq,mu,sigma) freq.esp=n*prob.esp round(freq.esp,3) ## [1] 0.536 2.136 5.968 10.220 10.733 6.912 3.495 Per tant, tenim la taula \\[ \\begin{array}{r|c|c} \\text{Rang de temperatures} &amp; obs_i &amp; esp_i\\\\ \\hline \\text{menys de 1.95} &amp; 2 &amp; 0.536 \\\\ 1.95\\text{ a }2.45 &amp; 1 &amp; 2.136 \\\\ 2.45\\text{ a }2.95 &amp; 4 &amp; 5.968 \\\\ 2.95\\text{ a }3.45 &amp; 15 &amp; 10.220 \\\\ 3.45\\text{ a }3.95 &amp; 10 &amp; 10.733 \\\\ 3.95\\text{ a }4.45 &amp; 5 &amp; 6.912 \\\\ \\text{més de 4.45} &amp; 3 &amp; 3.495 \\end{array} \\] Tenim freqüències esperades per davall de 5, per tant no podem aplicar el test \\(\\chi^2\\) tal qual. El que farem serà agrupar classes contigües a fi d’obtenir freqüències esperades més grans o iguals que 5 amb el màxim de classes. En concret, haurem d’agrupar per un costat les tres primeres classes, i per un altre costat les dues darreres classes \\[ \\begin{array}{r|c|c} \\text{Rang de temperatures} &amp; obs_i &amp; esp_i\\\\\\hline \\text{menys de 2.95} &amp; 7 &amp; 8.64\\\\ 2.95\\text{ a }3.45 &amp; 15 &amp; 10.22 \\\\ 3.45\\text{ a }3.95 &amp; 10 &amp; 10.733 \\\\ \\text{més de 3.95} &amp; 8&amp; 10.407 \\end{array} \\] Ara ja podem aplicar el text \\(\\chi^2\\) amb aquestes \\(k=4\\) classes. Com que no hem estimat cap paràmetre, prendrem com a distribució de l’estadístic de contrast una \\(\\chi^2_3\\). Valor de l’estadístic de contrast: \\[ \\begin{array}{rl} \\chi_0^2 &amp;\\displaystyle=\\frac{(7-8.64)^2}{8.64}+\\frac{(15-10.22)^2}{10.22}\\\\ &amp;\\displaystyle\\qquad\\quad +\\frac{(10-10.733)^2}{10.733}+\\frac{(8-10.407)^2}{10.407}=3.154 \\end{array} \\] p-valor: \\[ P(\\chi_{3}^2\\geqslant 3.154)=\\texttt{1-pchisq(3.154,3)}=0.37 \\] Conclusió: Podem acceptar que els augments de temperatures observats segueixen una llei normal \\(N(3.5,0.7)\\) (test \\(\\chi^2\\) de Pearson, p-valor=0.37). Amb R, si aplicam directament la funció chisq-test als vectors de freqüències i probabilitats de les classes originals (bé, de les esteses per cobrir tot \\(\\mathbb{R}\\)) R ens avisa que el resultat no és de fiar: chisq.test(freq.obs,p=prob.esp) ## Warning in chisq.test(freq.obs, p = prob.esp): Chi-squared approximation may be ## incorrect ## ## Chi-squared test for given probabilities ## ## data: freq.obs ## X-squared = 8.1337, df = 6, p-value = 0.2285 Haurem d’agrupar primer a mà les classes, abans d’aplicar chisq.test: freq.obs.agrup=c(sum(freq.obs[1:3]), freq.obs[4:5], sum(freq.obs[6:7])) prob.esp.agrup=c(sum(prob.esp[1:3]), prob.esp[4:5], sum(prob.esp[6:7])) chisq.test(freq.obs.agrup, p=prob.esp.agrup) ## ## Chi-squared test for given probabilities ## ## data: freq.obs.agrup ## X-squared = 3.1531, df = 3, p-value = 0.3686 6.2.2 Mètode de Montecarlo Quan volem realitzar un test \\(\\chi^2\\) i no es compleixen les condicions per que el p-valor tengui sentit, es pot emprar el mètode de Montecarlo (o basat en simulacions) per estimar el p-valor: Es genera un conjunt molt gran de mostres aleatòries amb la distribució esperada i de la mateixa mida que la nostra mostra Es calcula l’estadístic de contrast \\(\\chi^2\\) sobre cada mostra S’estima el p-valor mitjançant la fracció de mostres que han donat un \\(\\chi^2\\) més gran que el de la nostra mostra Recordau que ja hem emprat aquest mètode a l’Exemple 6.3 per “comprovar” el p-valor obtingut a l’Exemple 6.2 amb el test \\(\\chi^2\\) “exacte”. Però no cal complicar-se tant la vida per realitzar-lo. La funció chisq.test també permet usar el mètode de Montecarlo, entrant-hi el paràmetre simulate.p.value=TRUE i, si es vol, igualant el paràmetre B al nombre de simulacions desitjat (per defecte, en farà 2000). Naturalment, com que es basa en una simulació aleatòria, pot ser que en cada execució doni un p-valor diferent. Per exemple, podíem emprar el mètode de Montecarlo per realitzar el contrast de l’Exemple 6.4 amb les classes originals esteses, sense agrupar-les. set.seed(42) chisq.test(freq.obs, p=prob.esp, simulate.p.value=TRUE, B=5000) ## ## Chi-squared test for given probabilities with simulated p-value (based ## on 5000 replicates) ## ## data: freq.obs ## X-squared = 8.1337, df = NA, p-value = 0.2206 Conclusió: Podem acceptar que els augments de temperatures observats segueixen una llei normal \\(N(3.5,0.7)\\) (test \\(\\chi^2\\) de Montercarlo, p-valor=0.22). Arribam, doncs, a la mateixa conclusió que amb el test \\(\\chi^2\\) aplicat a les dades agrupades. 6.2.3 Test \\(\\chi^2\\) amb paràmetres poblacionals desconeguts De vegades ens interessarà contrastar si les observacions segueixen algun tipus determinat de distribució (Poisson, normal…) amb algun paràmetre indeterminat. En aquest cas, primer estimam els paràmetres desconeguts a partir de les observacions i a continuació contrastam l’ajustament de la mostra a la distribució amb aquests paràmetres. El test és exactament el mateix, excepte que ara cal restar al nombre \\(k-1\\) de graus de llibertat de la \\(\\chi^2\\) el nombre \\(m\\) de paràmetres que hem estimat. Exemple 6.5 Volem determinar si el nombre de vegades que apareix la seqüència GATACA en una cadena d’ADN humà de longitud 1000 segueix una llei de Poisson. Per fer-ho, prenem 576 mostres de cadenes d’ADN humà de longitud 1000 i hi comptam els nombres de GATACA. Els resultats són els de la taula següent: \\[ \\begin{array}{r|rrrrrr} \\hline \\text{nombre $x_i$ de vegades} &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\\\[-1ex] \\text{que hi apareix GATACA} &amp; &amp; &amp; &amp; &amp; &amp; \\\\ \\hline \\text{freqüència $obs_{i}$} &amp; 229 &amp; 211 &amp; 93 &amp; 35 &amp; 7 &amp; 1 \\\\ \\hline \\end{array} \\] Contrast: \\[ \\left\\{ \\begin{array}{ll} H_0: \\text{La mostra prové d&#39;una distribució $Po(\\lambda)$}\\\\ H_1: \\text{La mostra no prové d&#39;aquesta distribució} \\end{array} \\right. \\] Necessitam estimar el paràmetre \\(\\lambda\\), que és el valor esperat d’una variable Poisson i per tant l’estimarem amb la mitjana mostral: \\[ \\lambda =\\dfrac{229 + 211 + 93 + 35 +7 + 1 }{576}=\\dfrac{576}{576}=1 \\] Aquesta no és la mitjana de la mostra! Ara sí: \\[ \\begin{array}{rl} \\lambda &amp; =\\dfrac{229\\cdot 0+ 211\\cdot 1+ 93\\cdot 2+ 35\\cdot 3+7\\cdot 4+ 1\\cdot 5}{229+ 211+ 93 +35 + 7 + 1}\\\\ &amp; =\\dfrac{535}{576}=0.929 \\end{array} \\] Estadístic de contrast: Volem emprar el test \\(\\chi^2\\), així que l’estadístic de contrast serà \\[ \\chi^2=\\sum_{i=1}^k \\frac{(obs_{i}-esp_{i})^2}{esp_{i}} \\] Cal comprovar que se satisfan les condicions del Teorema 6.1. La mida de la mostra és \\(n=576\\), ben gran. Per veure si les freqüències esperades són totes més grans o iguals que 5, les hem de calcular. Recordem que, si \\(X\\) és una variable aleatòria de Poisson \\(Po(\\lambda)\\), \\[ P(X=k)=e^{-\\lambda}\\cdot \\frac{\\lambda^k}{k!} \\] Les probabilitats \\(p_i\\) d’obtenir \\(i=0,1,2,3,4,5\\) són round(dpois(0:5,0.929),3) ## [1] 0.395 0.367 0.170 0.053 0.012 0.002 i les freqüències esperades \\(esp_i=p_i\\cdot n\\) d’aquests valors són round(dpois(0:5,0.929)*576,2) ## [1] 227.49 211.34 98.17 30.40 7.06 1.31 Obtenim la taula \\[ \\begin{array}{l|rrrrrr} \\hline x_i &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; 5 \\\\ \\hline obs_{i} &amp; 229 &amp; 211 &amp; 93 &amp; 35 &amp; 7 &amp; 1 \\\\ \\hline p_i &amp;0.395 &amp; 0.367 &amp;0.170 &amp; 0.053 &amp; 0.012 &amp; 0.002 \\\\ \\hline esp_i &amp; 227.49 &amp; 211.34 &amp; 98.17 &amp; 30.40 &amp; 7.06 &amp; 1.31\\\\ \\hline \\end{array} \\] Aquestes classes estan malament! Recordau que les classes han de cobrir tots els resultats possibles! Els resultats possibles d’una variable Poisson són tots els nombres naturals. Per cobrir tots els resultats possibles, cal canviar el 5 per “5 o més” i recalcular la probabilitat i la freqüència esperada d’aquesta classe: la seva probabilitat és round(1-ppois(4,0.929),3) ## [1] 0.003 i la seva freqüència esperada és round((1-ppois(4,0.929))*576,2) ## [1] 1.55 Obtenim la taula \\[ \\begin{array}{l|rrrrrr} \\hline x_i &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; 4 &amp; \\geqslant 5 \\\\ \\hline obs_{i}&amp; 229 &amp; 211 &amp; 93 &amp; 35 &amp; 7 &amp; 1 \\\\ \\hline p_i &amp;0.395 &amp; 0.367 &amp;0.170 &amp; 0.053 &amp; 0.012 &amp; 0.003 \\\\ \\hline esp_i &amp; 227.49 &amp; 211.34 &amp; 98.17 &amp; 30.40 &amp; 7.06 &amp; 1.55\\\\ \\hline \\end{array} \\] Per que totes les classes tenguin freqüència esperada més gran o igual que 5, agruparem les dues darreres classes \\[ \\begin{array}{l|rrrrr} \\hline x_i &amp; 0 &amp; 1 &amp; 2 &amp; 3 &amp; \\geqslant 4 \\\\ \\hline obs_{i}&amp; 229 &amp; 211 &amp; 93 &amp; 35 &amp; 8 \\\\ \\hline p_i &amp;0.395 &amp; 0.367 &amp;0.170 &amp; 0.053 &amp; 0.015 \\\\ \\hline esp_i &amp; 227.49 &amp; 211.34 &amp; 98.17 &amp; 30.40 &amp; 8.61\\\\ \\hline \\end{array} \\] Ara totes les freqüències esperades són prou grans i les classes cobreixen tots els valors possibles de la variable. L’estadístic de contrast té distribució \\(\\chi_{k-1}^2\\) amb \\(k=5\\), per tant \\(\\chi_{4}^2\\). Com que hem estimat la \\(\\lambda\\), hem de considerar l’estadístic de contrast amb distribució \\(\\chi_{k-1-m}^2\\) amb \\(k\\) el nombre de classes i \\(m\\) el nombre de paràmetres estimats. Perdó. L’estadístic de contrast té distribució \\(\\chi_{3}^2\\). Podem continuar. Valor de l’estadístic de contrast: obs.gataca=c(229,211,93,35,8) n=sum(obs.gataca) probs.gataca=c(dpois(0:3,0.929),1-ppois(3,0.929)) esp.gataca=probs.gataca*n X02=sum((obs.gataca-esp.gataca)^2/esp.gataca) round(X02,2) ## [1] 1.02 p-valor: \\(P(\\chi_3^2\\geqslant 1.02)=\\texttt{1-pchisq(1.02,3)}=0.796\\) Conclusió: Podem acceptar que les observacions trobades segueixen una llei de Poisson (test \\(\\chi^2\\) de Pearson, p-valor 0.796). Amb R simplement ens estalviam el càlcul explícit de \\(\\chi_0^2\\) i del p-valor, perquè tota la saragata de calcular freqüències esperades i agrupar a fi que se satisfaci la llei de Cochran no ens la podem estalviar. chisq.test(obs.gataca,p=probs.gataca) ## ## Chi-squared test for given probabilities ## ## data: obs.gataca ## X-squared = 1.0215, df = 4, p-value = 0.9065 Conclusió: No podem rebutjar que les observacions trobades segueixin una llei de Poisson (test \\(\\chi^2\\) de Pearson, p-valor 0.9065????). No havíem quedat que el nombre de graus de llibertat era 3? R n’ha emprat 4, df=4, perquè no sap que hem estimat un paràmetre R ha calculat el p-valor prenent \\(\\chi_4^2\\), nosaltres l’hem de calcular amb \\(\\chi_3^2\\) 1-pchisq(1.0215,3) ## [1] 0.7960498 Ara ja tenim el mateix p-valor que abans. 6.3 Test de Kolmogorov-Smirnov El test de Kolgomorov-Smirnov (test K-S, per abreviar) és el test més popular per contrastar si una mostra segueix o no una distribució contínua concreta, sense restriccions sobre la mida de la mostra. Es pot emprar amb tota distribució contínua sempre que estigui completament especificada. Per a distribucions concretes, mides de mostres dins marges concrets o quan estimam els paràmetres, existeixen tests específics millors que el K-S, però no els veurem aquí. Estan a la lliçó corresponent de R i potser que les hàgiu d’emprar als tallers. Tot seguit explicam com funciona aquest test. Partim d’una mostra \\(x_1,x_2,\\ldots,x_n\\) amb tots els valors diferents i volem contrastar si ha estat produïda per una variable \\(X\\) contínua amb funció de distribució \\(F_X\\). Per exemple, suposem que volem constrastar si podem acceptar que els valors del vector següent provenen d’una distribució normal \\(N(3,1.5)\\). valors=c(5.84,4.57,1.34,3.58,1.54,2.25) Per tant, el contrast és \\[ \\left\\{ \\begin{array}{l} H_0: \\text{ aquesta mostra prové d&#39;una $X\\sim N(3,1.5)$}\\\\ H_0: \\text{ aquesta mostra no prové d&#39;una $X\\sim N(3,1.5)$} \\end{array} \\right. \\] Ordenam la mostra: \\(x_{(1)}&lt; x_{(2)}&lt;\\cdots&lt; x_{(n)}\\). valors=sort(valors) valors ## [1] 1.34 1.54 2.25 3.58 4.57 5.84 Consideram la funció de distribució mostral \\(F_{n}\\) d’aquesta mostra: la funció de distribució d’una variable \\(n\\) amb domini tot \\(\\mathbb{R}\\) per a la qual cada \\(x_{(i)}\\) tingués probabilitat \\(1/n\\) i la resta de reals tingués probabilitat 0: \\[ F_n(x)=\\left\\{\\begin{array}{ll} 0 &amp;\\text{ si } x&lt; x_{(1)} \\\\ \\dfrac{k}{n}&amp;\\text{ si } x_{(k)}\\leqslant x &lt; x_{(k+1)}\\\\ 1 &amp; \\text{ si } x_{(n)} \\leqslant x \\end{array} \\right. \\] A la nostra mostra ja ordenada, seria \\[ F_6(x)=\\left\\{\\begin{array}{ll} 0 &amp;\\text{ si } x&lt; 1.34 \\\\ 1/6 &amp;\\text{ si } 1.34\\leqslant x &lt;1.54\\\\ 2/6 &amp;\\text{ si } 1.54\\leqslant x &lt;2.25\\\\ 3/6 &amp;\\text{ si } 2.25\\leqslant x &lt;3.58\\\\ 4/6 &amp;\\text{ si } 3.58\\leqslant x &lt;4.57\\\\ 5/6 &amp;\\text{ si } 4.57\\leqslant x &lt;5.84\\\\ 1 &amp;\\text{ si } 5.84\\leqslant x \\end{array} \\right. \\] El gràfic d’aquesta distribució és el següent: plot(c(1,valors,7), c(0,(0:5)/5,1), type=&quot;s&quot;, lwd=1.5, xlab=&quot;&quot;, ylab=&quot;&quot;) Comparam \\(F_n(x)\\) amb \\(F_X(x)\\). Si són molt diferents, rebutjarem que la mostra s’ha produït amb distribució \\(F_X\\). plot(c(1,valors,6),c(0,(0:5)/5,1),type=&quot;s&quot;, xlab=&quot;&quot;,ylab=&quot;&quot;,lwd=1.5) curve(pnorm(x,3,1.5),col=&quot;red&quot;,lwd=1.5,add=TRUE) legend(&quot;topleft&quot;,col=c(&quot;black&quot;,&quot;red&quot;),lty=c(1,1), legend=c(expression(F[6]),&quot;N(3,1.5)&quot;),cex=0.7) Per comparar \\(F_n(x)\\) amb \\(F_X(x)\\), calcularem \\[ \\max\\{|F_n(x)-F_X(x)|\\mid x\\in \\mathbb{R}\\} \\] Com que \\(F_X\\) és creixent, aquest màxim s’assoleix a qualque escaló. Per tant, per calcular aquest màxim primer calculam, per a cada \\(x_{(i)}\\), la seva discrepància: la distància entre \\(F_X(x_{(i)})\\) i els extrems de l’escaló corresponent, \\[ D_n(x_{(i)})=\\max\\Big\\{\\Big| F_X(x_{(i)})-\\frac{i-1}{n}\\Big|, \\Big|F_{X}(x_{(i)})-\\frac{i}{n}\\Big|\\Big\\} \\] i prenem la discrepància màxima, és a dir, el màxim d’aquestes discrepàncies: \\[ D_n=\\max\\big\\{D_n(x_{(i)})\\mid i=1,\\ldots, n\\big\\} \\] Al nostre exemple, els valors \\(F_X(x_{(i)})\\) són: round(pnorm(valors,3,1.5),3) ## [1] 0.134 0.165 0.309 0.650 0.852 0.971 i per tant les discrepàncies són \\[ \\begin{array}{rl} D_6(x_{(1)}) &amp; =\\max\\{| F_X(1.34)-0|, |F_X(1.34)-1/6|\\}\\\\ &amp; =\\max\\{|0.134-0|, |0.134-1/6|\\}\\\\ &amp; =\\max\\{ 0.134, 0.033\\}=0.134\\\\[2ex] D_6(x_{(2)}) &amp; =\\max\\{| F_X(1.54)-1/6|, |F_X(1.54)-2/6|\\}\\\\ &amp; =\\max\\{| 0.165-1/6|, |0.165-2/6|\\}\\\\ &amp; =\\max\\{ 0.002, 0.168\\}=0.168\\\\[2ex] D_6(x_{(3)}) &amp; =\\max\\{| F_X(2.25)-2/6|, |F_X(2.25)-3/6|\\}\\\\ &amp; =\\max\\{|0.309-2/6|, |0.309-3/6|\\}\\\\ &amp; =\\max\\{ 0.024, 0.191\\}=0.191\\\\[2ex] D_6(x_{(4)}) &amp; =\\max\\{| F_X(3.58)-3/6|, |F_X(3.58)-4/6|\\}\\\\ &amp; =\\max\\{| 0.65-3/6|, |0.65-4/6|\\}\\\\ &amp; =\\max\\{ 0.15, 0.017\\}=0.15\\\\[2ex] D_6(x_{(5)}) &amp; =\\max\\{| F_X(4.57)-4/6|, |F_X(4.57)-5/6|\\}\\\\ &amp; =\\max\\{|0.852-4/6|, |0.852-5/6|\\}\\\\ &amp; =\\max\\{ 0.185, 0.019\\}=0.185\\\\[2ex] D_6(x_{(6)}) &amp; =\\max\\{| F_X(5.84)-5/6|, |F_X(5.84)-6/6|\\}\\\\ &amp; =\\max\\{| 0.971-5/6|, |0.971-1|\\}\\\\ &amp; =\\max\\{ 0.138, 0.029\\}=0.138 \\end{array} \\] i la discrepància màxima és \\[ D_6=\\max\\{0.134,0.168,0.191,0.15,0.185,0.138\\}=0.191 \\] Aquesta discrepància màxima segueix una distribució coneguda (que no depèn de la \\(X\\) mentre sigui contínua) que permet calcular el p-valor com la probabilitat que \\(D_n\\) prengui un valor més gran o igual que l’obtingut sobre la nostra mostra. La corresponent funció de distribució acumulada és donada per la funció pkolm del paquet kolmim. Per tant, el p-valor és library(kolmim) round(1-pkolm(0.191,6),3) ## [1] 0.951 Conclusió: Podem acceptar que la mostra prové d’una variable aleatòria normal amb \\(\\mu=3\\) i \\(\\sigma=1.5\\) (test de Kolmogorov-Smirnov, p-valor 0.95) Per realitzar un test K-S amb R, disposam de la instrucció ks.test(x,&quot;pdistribució&quot;,paràmetres) on x és el vector que conté la mostra, la pdistribució és la funció de distribució que contrastam, i els paràmetres són els de la distribució. Al nostre exemple, simplement entraríem valors=c(5.84,4.57,1.34,3.58,1.54,2.25) ks.test(valors,&quot;pnorm&quot;,3,1.5) ## ## One-sample Kolmogorov-Smirnov test ## ## data: valors ## D = 0.19146, p-value = 0.95 ## alternative hypothesis: two-sided Dóna el valor de l’estadístic (la D) i el p-valor 6.4 Test de Kolmogorov-Smirnov-Lilliefors Quan es vol emprar el test K-S per contrastar si una mostra prové de qualque distribució normal, i no d’una concreta, l’opció més popular és: Estimar els paràmetres de la normal a partir de la mostra Calcular l’estadístic del test K-S amb aquests paràmetres Emprar la distribució del test K-S-Lilliefors per calcular el p-valor Amb R, aquest test està implementat en la funció lillie.test del paquet nortest. Per exemple, si ens haguéssim demanat d’entrada si la nostra mostra prové de qualque variable normal, haguéssim entrat library(nortest) lillie.test(valors) ## ## Lilliefors (Kolmogorov-Smirnov) normality test ## ## data: valors ## D = 0.19912, p-value = 0.6425 L’estadístic de contrast no val el mateix que abans, perquè ara la variable normal que contrasta té paràmetres \\(\\mu=\\texttt{mean(valors)}=3.187\\) i \\(\\sigma=\\texttt{sd(valors)}=1.795\\). "],
["contrastos-dindependència-i-homogeneïtat.html", "Tema 7 Contrastos d’independència i homogeneïtat 7.1 Test \\(\\chi^2\\) d’independència 7.2 Test \\(\\chi^2\\) d’homogeneïtat 7.3 Test \\(\\chi^2\\) de tendència (Opcional)", " Tema 7 Contrastos d’independència i homogeneïtat En els contrastos d’independència de dues variables \\(X\\) i \\(Y\\), la hipòtesi nul·la és no hi ha cap relació entre \\(X\\) i \\(Y\\), és a dir, que són independents. Quan traduïm la independència de dues variables en termes de “la probabilitat de la intersecció és el producte de probabilitats”, resulta que un contrast d’independència és un tipus concret de contrast de bondat d’ajust. En els contrastos d’homogeneïtat de dues variables \\(X\\) i \\(Y\\), la hipòtesi nul·la és la distribució de \\(Y\\) condicionada a cada un dels valors que pot prendre \\(X\\) és sempre la mateixa, que és una altra manera de dir que \\(X\\) i \\(Y\\) són independents. Per tant, els contrastos d’homogeneïtat són formalment contrastos d’independència, però difereixen en la forma com s’hi recull la mostra: En un contrast d’independència, la mostra és transversal: es pren una mostra de la població on estan definides \\(X\\) i \\(Y\\) i es miren els valors de les dues variables sobre els individus de la mostra, i surt el que surt En un contrast d’homogeneïtat, la mostra és estratificada: es pren una mostra independent per a cada un dels valors que pot prendre \\(X\\), de mides fixades d’antuvi, i es mira el valor de \\(Y\\) sobre tots aquests individus 7.1 Test \\(\\chi^2\\) d’independència Suposem que tenim dues variables aleatòries \\(X\\) i \\(Y\\) que només poden prendre valors \\(X_{1},\\ldots,X_{s}\\) i \\(Y_{1},\\ldots,Y_{t}\\), respectivament. Les considerarem qualitatives i direm a aquests \\(X_i\\) i \\(Y_j\\) els seus nivells, però poden ser ordinals o quantitatives discretes. L’inportant és que només poden prendre un conjunt finit de valors cadascuna. Volem contrastar si \\(X\\) i \\(Y\\) són independents, és a dir \\[ \\begin{array}{l} \\hspace{-2ex}P(X=X_i\\mid Y=Y_j)=P(X=X_i\\mid Y=Y_{j&#39;})=P(X=X_i)\\text{ per a tots $i,j,j&#39;$}\\\\ \\hspace{-2ex}P(Y=Y_j\\mid X=X_i)=P(Y=Y_j\\mid X=X_{i&#39;})=P(Y=Y_j)\\text{ per a tots $i,i&#39;,j$} \\end{array} \\] o equivalentment \\[ P(X=X_i,Y=Y_j)=P(X=X_i)\\cdot P(Y=Y_j)\\text{ per a tots $i,j$} \\] El contrast serà \\[ \\left\\{\\begin{array}{l} H_0: \\mbox{$X$ i $Y$ són independents}\\\\ H_1: \\mbox{$X$ i $Y$ són dependents} \\end{array} \\right. \\] Sovint en lloc de dir que “\\(X\\) i \\(Y\\) són dependents”, direm que “hi ha associació entre \\(X\\) i \\(Y\\)”. Recordau que, en general, la hipòtesi nul·la representa, en el context del contrast, que “no passa res”. En els contrastos d’independència això correspon a “no hi ha cap relació entre \\(X\\) i \\(Y\\)”, és a dir, que són independents. Fixem-nos ara que la caracterització de la independència com a \\[ P(X=X_i,Y=Y_j)=P(X=X_i)\\cdot P(Y=Y_j)\\text{ per a tots $i,j$} \\] ens permet entendre el contrast d’independència com un contrast de bondat d’ajust, amb hipòtesi nul·la \\[ H_0: P(X=X_i,Y=Y_j)=P(X=X_i)\\cdot P(Y=Y_j)\\text{ per a tots $i,j$} \\] Hi farem servir un test \\(\\chi^2\\). El contrast d’igualtat de dues proporcions és un cas particular de contrast d’independència: que l’esdeveniment “Èxit” sigui independent de la variable. Exemple 7.1 En un estudi es volgué determinar si hi ha associació entre l’hàbit de fumar i patir tos nocturna entre els nins. S’entrevistà una mostra de 2847 nens de 12 anys i es recollí informació sobre el seu estatus de fumador i si patien de tos nocturna o no. S’obtingueren els resultats següents: \\[ \\begin{array}{l} \\hphantom{No fumador ocasional un }\\text{Fumador}\\\\ \\begin{array}{l|ccc|c} &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} &amp; \\text{Total} \\\\\\hline \\text{Tos} &amp; 266 &amp; 395 &amp; 80 &amp; 741\\\\ \\text{No tos}&amp; 1037 &amp; 977 &amp; 92 &amp; 2106\\\\\\hline \\text{Total} &amp;1303 &amp; 1372 &amp; 172 &amp; 2847 \\end{array} \\end{array} \\] En aquesta situació: Variables aleatòries d’interès: \\(X\\): “Prenem un nin i miram si té tos nocturna o no” \\(Y\\): “Prenem un nin i avaluam el seu estatus de fumador” Contrast: \\[ \\left\\{\\begin{array}{l} H_0: \\mbox{$X$ i $Y$ són independents}\\\\ H_1: \\mbox{Hi ha associació entre $X$ i $Y$} \\end{array} \\right. \\] Anem a traduir ara un contrast d’independència com l’anterior en un contrast d’igualtat de distribucions de probabilitat. Diguem \\[ \\begin{array}{c} p_{ij}=P(X=X_i, Y=Y_j)\\\\ p_i=P(X=X_i)\\quad q_{j}=P(Y=Y_j) \\end{array} \\] El test d’independència equival a contrastar \\[ \\left\\{ \\begin{array}{ll} H_0: p_{ij}=p_i \\cdot q_j \\text{ per a tots } 1\\leqslant i \\leqslant s,\\ 1\\leqslant j\\leqslant t \\\\ H_1: \\mbox{No totes aquestes igualtats són vertaderes} \\end{array} \\right. \\] És a dir, la hipòtesi nul·la és La distribució de probabilitats que ha donat la mostra de parells de valors \\((X,Y)\\) és el producte de la distribució de probabilitats de \\(X\\) per la distribució de probabilitats de \\(Y\\) i per tant podem entendre aquest contrast com un contrast de bondat d’ajust (sobre la distribució conjunta de \\((X,Y)\\)) i hi podem fer servir un test \\(\\chi^2\\). Els passos concrets seran els següents: Mesuram les variables aleatòries sobre una mostra aleatòria simple de \\(n\\) subjectes, i obtenim una taula de contingència de freqüències absolutes com la següent (on cada \\(n_{i,j}\\) indica el nombre de subjectes amb \\(X=X_i\\) i \\(Y=Y_j\\); \\(n_{i\\bullet}\\) indica el nombre de subjectes amb \\(X=X_i\\), és a dir, el nombre total de subjectes de la filera \\(i\\); i \\(n_{\\bullet j}\\) indica el nombre de subjectes amb \\(Y=Y_j\\), és a dir, el nombre total de subjectes de la columna \\(j\\)): \\[ \\begin{array}{c|cccccc|c} X\\backslash Y &amp; Y_1 &amp; Y_2 &amp; \\ldots &amp; Y_j &amp; \\ldots &amp; Y_t &amp; \\text{Total} \\\\ \\hline X_1 &amp; n_{11} &amp; n_{12} &amp; \\ldots &amp; n_{1j} &amp; \\ldots &amp; n_{1t} &amp; n_{1 \\bullet} \\\\ X_2 &amp; n_{21} &amp; n_{22} &amp; \\ldots &amp; n_{2j} &amp; \\ldots &amp; n_{2t} &amp; n_{2 \\bullet} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ X_i &amp; n_{i1} &amp; n_{i2} &amp; \\ldots &amp; n_{ij} &amp; \\ldots &amp; n_{it} &amp; n_{i \\bullet} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ X_s &amp; n_{s1} &amp; n_{s2} &amp; \\ldots &amp; n_{sj} &amp; \\ldots &amp; n_{st} &amp; n_{s \\bullet} \\\\ \\hline \\text{Total} &amp; n_{\\bullet 1} &amp; n_{\\bullet 2} &amp; \\ldots &amp; n_{\\bullet j} &amp; \\ldots &amp; n_{\\bullet t} &amp; n \\end{array} \\] Estimam cada \\(p_i\\) amb \\({n_{i\\bullet}}/{n}\\) i cada \\(q_j\\) amb \\({n_{\\bullet j}}/{n}\\) Si les variables aleatòries fossin independents, les probabilitats teòriques serien \\[ p_{ij}=\\frac{n_{i\\bullet}}{n}\\cdot \\frac{n_{\\bullet j}}{n} \\] i per tant la freqüència esperada de cada parell \\((X_i,Y_j)\\) si les variables aleatòries són independents seria \\[ esp_{ij}=p_{ij}\\cdot n=\\dfrac{n_{i\\bullet}}{n}\\cdot \\dfrac{n_{\\bullet j}}{n}\\cdot n=\\dfrac{n_{i\\bullet}\\cdot n_{\\bullet j}}{n} \\] L’estadístic del test \\(\\chi^2\\) és doncs \\[ \\chi^2=\\sum\\limits_{i=1}^s\\sum\\limits_{j=1}^t \\frac{ ( n_{ij}- esp_{ij})^2 } {esp_{ij}} \\] Arribats en aquest punt, el Teorema 6.1 ens diu que: Teorema 7.1 Si les variables \\(X\\) i \\(Y\\) són independents, \\(n\\) és gran (diguem \\(n\\geqslant 30\\)) i se satisfà la Regla de Cochran, és a dir, cada freqüència esperada \\[ esp_{ij}=\\frac{n_{i\\bullet}\\cdot n_{\\bullet j}}{n} \\] és \\(\\geqslant 5\\), l’estadístic \\[ \\chi^2=\\sum\\limits_{i=1}^s\\sum\\limits_{j=1}^t \\frac{ ( n_{ij}- esp_{ij})^2 } {esp_{ij}} \\] segueix (aproximadament) una llei \\(\\chi^2\\) amb \\((s-1) \\cdot (t -1)\\) graus de llibertat. D’on surt aquest nombre de graus de llibertat? Vegem, hem estimat les \\(p_i\\) i les \\(q_j\\), i per tant hem estimat \\(s+t-2\\) paràmetres (fixau-vos que en realitat només hem estimat \\(p_1,\\ldots,p_{s-1}\\) i \\(q_1,\\ldots,q_{t-1}\\), ja que \\(p_s\\) i \\(q_t\\) queden fixats per la regla “suma de probabilitats igual a 1”). Per tant el nombre de graus de llibertat és el nombre de classes, \\(st\\) (una per cada combinació \\((X_i,Y_j)\\) de possible valor de \\(X\\) i possible valor de \\(Y\\)) menys 1 i menys el nombre de paràmetres estimats: \\[ \\mbox{graus de llibertat}=st-1-(s+t-2)=(s-1)(t-1) \\] Fixau-vos que el Teorema 7.1 és un cas particular del Teorema 6.1, i per tant les hipòtesis per poder emprar el test \\(\\chi^2\\) en aquest context són les mateixes que en el cas general: mostra de mida com a mínim 30 i totes les freqüències esperades més grans o iguals que 5. Si \\(\\chi_0^2\\) és el valor que pren l’estadístic de contrast a la nostra mostra, el p-valor del contrast és \\[ \\text{p-valor}=P(\\chi_{(s-1) \\cdot (t -1)}^2\\geqslant\\chi_0^2) \\] Exemple 7.2 Continuem amb l’Exemple 7.1. Ja teníem les variables i el contrast. Les freqüències observades són \\[ \\begin{array}{l} \\hphantom{No fumador ocasional un }\\text{Fumador}\\\\ \\begin{array}{l|ccc|c} &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} &amp; \\text{Total} \\\\\\hline \\text{Tos} &amp; 266 &amp; 395 &amp; 80 &amp; 741\\\\ \\text{No tos}&amp; 1037 &amp; 977 &amp; 92 &amp; 2106\\\\\\hline \\text{Total} &amp;1303 &amp; 1372 &amp; 172 &amp; 2847 \\end{array} \\end{array} \\] La mida de la mostra és gran. Calculem les freqüències esperades, per veure si són totes més grans o iguals que 5. \\[ \\begin{array}{l|ccc} &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} \\\\\\hline \\text{Tos} &amp; 741\\cdot 1303/2847 &amp; 741\\cdot 1372/2847 &amp; 741\\cdot 172/2847 \\\\ \\text{No tos}&amp; 2106\\cdot 1303/2847 &amp; 2106\\cdot 1372/2847 &amp; 2106\\cdot 172/2847 \\end{array} \\] Operant: \\[ \\begin{array}{l|ccc} &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} \\\\\\hline \\text{Tos} &amp; 339.14 &amp; 357.1 &amp; 44.77 \\\\ \\text{No tos}&amp; 963.86 &amp; 1014.9 &amp; 127.23 \\end{array} \\] Són totes prou grans. Per tant l’estadístic de contrast \\[ \\chi^2=\\sum_{i=1}^s\\sum_{j=1}^t \\frac{(n_{ij}-esp_{ij})^2}{esp_{ij}} \\] (on \\(s=2\\) i \\(t=3\\)) seguirá una distribució \\(\\chi^2_{(s-1)(t-1)}=\\chi^2_2\\). Valor de l’estadístic de contrast: \\[ \\chi_0^2=\\frac{(266-339.14)^2}{339.14}+\\frac{(395-357.1)^2}{357.1}+\\cdots=64.24 \\] p-valor: \\(P(\\chi^2_2\\geqslant 64.24)=\\texttt{1-pchisq(64.24,2)}=1.1\\cdot 10^{-14}\\) Conclusió: Hem trobat evidència estadísticament significativa que hi ha associació entre l’estatus de fumador d’un nin i que pateixi tos nocturna (test \\(\\chi^2\\), p-valor 10-14). Podem efectuar un test \\(\\chi^2\\) d’independència aplicant la funció chisq.test a la taula de freqüències absolutes: Taula=matrix(c(266,395,80,1037,977,92),nrow=2,byrow=TRUE) Taula ## [,1] [,2] [,3] ## [1,] 266 395 80 ## [2,] 1037 977 92 chisq.test(Taula) ## ## Pearson&#39;s Chi-squared test ## ## data: Taula ## X-squared = 64.247, df = 2, p-value = 1.119e-14 Exemple 7.3 Volem contrastar si hi ha associació entre el grau de compliment del calendari de vacunacions (CCV) dels nins i el nivell sociocultural dels pares. La taula següent mostra la classificació d’una mostra de 444 nens segons el seu CCV i el nivell sociocultural dels pares: \\[ \\begin{array}{l} \\hphantom{Compli CCV BaixBB}\\text{Nivell sociocultural}\\\\ \\begin{array}{r|ccc|l} \\text{Compliment CCV} &amp;\\text{Baix}&amp; \\text{Mitjà} &amp;\\text{Alt} &amp;\\text{Total}\\\\ \\hline \\text{Baix} &amp;38 &amp;76 &amp;79 &amp; 193\\\\ \\text{Mitjà-baix}&amp; 2&amp; 41&amp; 92 &amp; 135\\\\ \\text{Mitjà-alt}&amp; 2&amp; 21&amp; 50 &amp; 73\\\\ \\text{Alt}&amp; 0 &amp;12&amp; 31 &amp; 43\\\\ \\hline \\text{Total} &amp; 42 &amp; 150 &amp; 252 &amp; 444 \\end{array} \\end{array} \\] Variable aleatòries d’interès: \\(X\\): “Prenem un nin i avaluam el seu grau de compliment del CCV” \\(Y\\): “Prenem un nin i avaluam el nivell sociocultural dels pares” Contrast: \\[ \\left\\{\\begin{array}{l} H_0: \\mbox{$X$ i $Y$ són independents}\\\\ H_1: \\mbox{Hi ha associació entre $X$ i $Y$} \\end{array} \\right. \\] Fem un test \\(\\chi^2\\) amb R: TaulaCCV=matrix(c(38,76,79,2,41,92,2,21,50,0,12,31), nrow=4, byrow=TRUE) chisq.test(TaulaCCV) ## Warning in chisq.test(TaulaCCV): Chi-squared approximation may be incorrect ## ## Pearson&#39;s Chi-squared test ## ## data: TaulaCCV ## X-squared = 56.378, df = 6, p-value = 2.441e-10 R ens avisa que no es compleixen les condicions per usar el test \\(\\chi^2\\); segurament hi ha freqüències esperades petites. Vegem-ho, i aprofitarem per comprovar-ho amb R: Les \\(n_{i\\bullet}\\) són les sumes de les fileres: Freq.CCV=rowSums(TaulaCCV) Freq.CCV ## [1] 193 135 73 43 Les \\(n_{\\bullet j}\\) són les sumes de les columnes: Freq.NSC=colSums(TaulaCCV) Freq.NSC ## [1] 42 150 252 La matriu de les \\((n_{i\\bullet}n_{\\bullet j}/n)\\) s’obté fent el producte matricial \\[ \\begin{array}{l} \\displaystyle \\frac{1}{n}\\left(\\begin{array}{c} n_{1\\bullet}\\\\ n_{2\\bullet}\\\\ \\vdots\\\\ n_{s\\bullet} \\end{array}\\right)\\cdot \\big(n_{\\bullet 1},n_{\\bullet 2},\\ldots,n_{\\bullet t}\\big)\\\\ \\qquad \\displaystyle = \\left( \\begin{array}{cccc} \\frac{n_{1\\bullet}n_{\\bullet 1}}{n} &amp; \\frac{n_{1\\bullet}n_{\\bullet 2}}{n} &amp; \\ldots &amp; \\frac{n_{1\\bullet}n_{\\bullet t}}{n}\\\\ \\frac{n_{2\\bullet}n_{\\bullet 1}}{n} &amp; \\frac{n_{2\\bullet}n_{\\bullet 2}}{n} &amp; \\ldots &amp; \\frac{n_{2\\bullet}n_{\\bullet t}}{n}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ \\frac{n_{s\\bullet}n_{\\bullet 1}}{n} &amp; \\frac{n_{s\\bullet}n_{\\bullet 2}}{n} &amp; \\ldots &amp; \\frac{n_{s\\bullet}n_{\\bullet t}}{n} \\end{array} \\right) \\end{array} \\] Freqs.Esp=(1/sum(TaulaCCV))*Freq.CCV%*%t(Freq.NSC) Freqs.Esp ## [,1] [,2] [,3] ## [1,] 18.256757 65.20270 109.54054 ## [2,] 12.770270 45.60811 76.62162 ## [3,] 6.905405 24.66216 41.43243 ## [4,] 4.067568 14.52703 24.40541 Efectivament, l’entrada (4,1) és menor que 5. Farem servir el mètode de Montecarlo: set.seed(42) chisq.test(TaulaCCV,simulate.p.value=TRUE,B=5000) ## ## Pearson&#39;s Chi-squared test with simulated p-value (based on 5000 ## replicates) ## ## data: TaulaCCV ## X-squared = 56.378, df = NA, p-value = 2e-04 Conclusió: Hem trobat evidència estadísticament significativa que hi ha associació entre el grau de compliment del calendari de vacunacions d’un nin i el nivell sociocultural dels seus pares (test \\(\\chi^2\\) de Montecarlo, p-valor 0.0002). 7.2 Test \\(\\chi^2\\) d’homogeneïtat En un contrast d’homogeneïtat de proporcions, tenim una variable aleatòria \\(X\\) que pot prendre els valors \\(X_1,\\ldots,X_k\\) i una variable aleatòria Bernoulli \\(Y\\) que pot prendre els valors “Èxit” i “Fracàs”. Per a cada \\(i=1,\\ldots,k\\), diguem \\(p_i=P(Y=\\text{Èxit}|X=X_i)\\). És a dir, \\(p_i\\) és la probabilitat que \\(Y\\) doni Èxit sobre un individu per al qual \\(X\\) val \\(X_i\\). Volem contrastar si aquestes probabilitats \\(p_1,\\ldots,p_k\\) són totes iguals o no. El contrast és, doncs, \\[ \\left\\{ \\begin{array}{ll} H_0: \\text{ $p_1=\\cdots=p_k$}\\\\ H_1: \\text{ Hi ha $i,j$ tals que $p_i \\neq p_j$} \\end{array} \\right. \\] Per efectuar el contrast, per a cada \\(i=1,\\ldots,k\\) prenem una mostra aleatòria simple d’individus per als quals \\(X\\) val \\(X_i\\), independents cada una de les altres. Com que dir que \\[ P(Y=\\text{Èxit}|X=X_1)=\\cdots=P(Y=\\text{Èxit}|X=X_k) \\] és exactament el mateix que dir que \\(X\\) i \\(Y\\) són independents, el contrast d’homogeneïtat que hem plantejat és equivalent a \\[ \\left\\{ \\begin{array}{ll} H_0: \\text{ $X$ i $Y$ són independents}\\\\ H_1: \\text{ $X$ i $Y$ no són independents} \\end{array} \\right. \\] Però el disseny de l’experiment és diferent: En un contrast d’independència prenem una mostra transversal de la població, sense controlar el nombre de subjectes que hi surten de cada nivell \\(X_i\\). En un contrast d’homogeneïtat prenem una mostra estratificada, és a dir, una mostra de cada nivell \\(X_i\\) de \\(X\\), triant a priori el nombre de subjectes de cada un d’aquests nivells; per exemple, imposant que totes aquestes mostres tenguin la mateixa mida, o que la mida de cada mostra sigui proporcional al nombre d’individus de la població sobre els que \\(X\\) val \\(X_i\\). Exemple 7.4 Volem comparar 3 tractaments per baixar el nivell de colesterol, A, B i C, per veure si tenen taxes d’èxit diferents. En una primera aproximació, entendrem com a “Èxit” que el nivell de colesterol baixi dels 240 mg/dl a les 5 setmanes de tractament. En un assaig clínic, assignam cada tractament a 100 pacients amb colesterol alt escollits de manera independent uns dels altres, i anotam si el tractament ha tengut èxit. Els resultats són \\[ \\begin{array}{l} \\hphantom{FracasAAa}\\text{Tractament}\\\\ \\begin{array}{l|ccc|c} &amp; A &amp; B &amp; C &amp; \\text{Total} \\\\\\hline \\text{Èxit} &amp; 43 &amp; 61 &amp; 53 &amp; 157\\\\ \\text{Fracàs} &amp; 57 &amp; 39 &amp; 47 &amp; 143\\\\\\hline \\text{Total} &amp; 100 &amp; 100 &amp; 100 &amp; 300 \\end{array} \\end{array} \\] Volem contrastar si la probabilitat d’èxit de cada tractament és la mateixa o no. Fixem-nos que és un contrast d’homogeneïtat, perquè hem pres una mostra de mida prefixada de cada tractament. Per que fos un contrast d’independència, hauríem d’haver pres 300 malalts d’hipercolesterolèmia que estiguessin prenent algun d’aquests tractaments, i hauríem anotat de cada un quin tractament pren i si ha tengut èxit. Amb una mostra transversal obtinguda d’aquesta darrera manera, hi havia el risc que algun tractament fos seguit per molt pocs, o fins i tot cap, malalt. Variables aleatòries: En realitat, aquí tendríem dues interpretacions correctes. Per una banda, la usual, en termes de dues variables mesurades sobre els mateixos individus: \\(X\\): “Prenem un pacient i miram quin tractament segueix” \\(Y\\): “Prenem un pacient i miram si al cap de 5 setmanes el seu nivell de colesterol està per davall dels 240 mg/dl” Però d’altra banda, tal i com hem pres la mostra, seria perfectament vàlid contestar que les variables aleatòries en joc són: \\(Y_A\\): “Prenem un pacient sota el tractament A i miram si al cap de 5 setmanes el seu nivell de colesterol està per davall dels 240 mg/dl” \\(Y_B\\): “Prenem un pacient sota el tractament B i miram si al cap de 5 setmanes el seu nivell de colesterol està per davall dels 240 mg/dl” \\(Y_C\\): “Prenem un pacient sota el tractament C i miram si al cap de 5 setmanes el seu nivell de colesterol està per davall dels 240 mg/dl” En aquest cas, les variables estan definides sobre poblacions diferents. Dos comentaris: Als contrastos d’independència com el de l’Exemple 7.1, la segona interpretació és incorrecta, ja que allà sí que preníem una mostra transversal de nins i sobre cada un d’ells miràvem dues coses. En canvi, aquí podem entendre que prenem malalts de tres poblacions diferents i mesuram sobre ells una cosa, la qual cosa defineix tres variables diferents. Si volguéssim comparar taxes d’èxit de coses diferents sobre poblacions diferents per mitjà d’un contrast d’homogeneïtat, la interpretació en termes de dues variables \\(X,Y\\) mesurades sobre una mateixa població quedaria una mica artificial. Imaginau per exemple que us deman que contrasteu si són iguals o diferents les proporcions de Estudiants de Matemàtiques I que enguany aprovaren l’assignatura Malalts d’hipercolesterolèmia sobre els quals el tractament A és efectiu Nins fumadors ocasionals amb tos nocturna A veure com vos ho faríeu per plantejar-ho en termes de dues variables, una \\(X\\) que digui què miram i una \\(Y\\) que doni “Èxit” o “Fracàs”, i que no us quedàs un nyap de redacció. Contrast: Si diem \\(p_A\\), \\(p_B\\) i \\(p_C\\) a les probabilitats que un pacient amb el tractament A, B o C, respectivament, davalli dels 240 mg/dl de colesterol al cap de 5 setmanes de tractament, \\[ \\left\\{\\begin{array}{l} H_0: p_A=p_B=p_C\\\\ H_1: \\mbox{No és veritat que $p_A=p_B=p_C$} \\end{array}\\right. \\] Emprarem un test \\(\\chi^2\\): TaulaC=matrix(c(43,61,53,57,39,47), nrow=2 ,byrow=TRUE) TaulaC ## [,1] [,2] [,3] ## [1,] 43 61 53 ## [2,] 57 39 47 chisq.test(TaulaC) ## ## Pearson&#39;s Chi-squared test ## ## data: TaulaC ## X-squared = 6.5209, df = 2, p-value = 0.03837 Conclusió: Hem trobat evidència significativa que els tres tractaments no tenen la mateixa taxa d’èxit (test \\(\\chi^2\\) d’homogeneïtat, p-valor 0.04). Ara seria necessari efectuar 3 contrastos de parelles de proporcions per trobar quines parelles de tractaments tenes taxes d’èxit diferents. Us ho deixam com a exercici. De la mateixa manera que les dues variables involucrades en un contrast d’independència podien tenir més de dos nivells, podem efectuar contrastos d’homogeneïtat en situacions més generals que la comparació de proporcions. Suposem doncs que tenim una variable aleatòria qualitativa \\(X\\) de nivells \\(X_1,\\ldots,X_k\\), i una variable aleatòria qualitativa \\(Y\\) de nivells \\(Y_1,\\ldots,Y_l\\), i volem contrastar si la probabilitat que \\(Y\\) prengui els seus diferents valors sobre un individu depèn o no del valor de \\(X\\) sobre aquest individu. És a dir, volem contrastar si \\(P(Y=Y_h|X=X_i)=P(Y=Y_h|X=X_j)\\) per a tots \\(i,j,h\\). Exemple 7.5 Tornem a la situació de l’Exemple 7.4. Volem comparar 3 tractaments, A, B i C, per baixar el nivell de colesterol, per veure si tenen taxes d’èxit diferents. Però ara, en lloc de considerar l’èxit com una variable dicotòmica (baixes dels 240 mg/dl o no) distingirem si al cap de 5 setmanes de tractament s’ha baixat dels 200 mg/dl (el nivell desitjable de colesterol), s’ha assolit un nivell entre 200 i 240 mg/dl (el nivell límit), o si no s’ha baixat de 240 (nivell alt). Les dades de l’estudi esmentat a l’Exemple 7.4 amb aquesta nova classificació dels resultats són: \\[ \\begin{array}{l} \\hphantom{200-240AAaa}\\text{Tractament}\\\\ \\begin{array}{r|ccc|c} \\text{Nivell} &amp; A &amp; B &amp; C &amp; \\text{Total} \\\\\\hline \\text{Desitjable} &amp; 12 &amp; 21 &amp; 13 &amp; 46\\\\ \\text{Límit} &amp; 31 &amp; 40 &amp; 40 &amp; 111\\\\ \\text{Alt} &amp; 57 &amp; 39 &amp; 47 &amp; 143 \\\\\\hline \\text{Total} &amp; 100 &amp; 100 &amp; 100 &amp; 300\\\\\\hline \\end{array} \\end{array} \\] Variables aleatòries: Com abans, tenim dues interpretacions correctes: \\(X\\): “Prenem un pacient i miram quin tractament segueix” \\(Y\\): “Prenem un pacient i miram al cap de 5 setmanes en quina classe està el seu nivell de colesterol” o \\(Y_A\\): “Prenem un pacient sota el tractament A i miram al cap de 5 setmanes en quina classe està el seu nivell de colesterol” \\(Y_B\\): “Prenem un pacient sota el tractament B i miram al cap de 5 setmanes en quina classe està el seu nivell de colesterol” \\(Y_C\\): “Prenem un pacient sota el tractament C i miram al cap de 5 setmanes en quina classe està el seu nivell de colesterol” : \\[ \\left\\{\\begin{array}{l} H_0: P(Y=L|X=T)=P(Y=L|X=T&#39;)\\\\ \\hphantom{H_0: }\\quad\\text{ per a cada nivell $L$ de colesterol}\\\\ \\hphantom{H_0: }\\quad \\text{ i cada parell de tractaments $T,T&#39;$}\\\\ H_1: \\mbox{Alguna d&#39;aquestes igualtats és falsa} \\end{array}\\right. \\] És un test d’homogeneïtat, farem servir un test \\(\\chi^2\\): TaulaC2=matrix(c(12,21,13,31,40,40,57,39,47), nrow=3, byrow=TRUE) TaulaC2 ## [,1] [,2] [,3] ## [1,] 12 21 13 ## [2,] 31 40 40 ## [3,] 57 39 47 chisq.test(TaulaC2) ## ## Pearson&#39;s Chi-squared test ## ## data: TaulaC2 ## X-squared = 8.046, df = 4, p-value = 0.08991 Conclusió: No hem trobat evidència estadísticament significativa que A, B i C no tenguin el mateix efecte quan distingim tres classes de nivell de colesterol (test \\(\\chi^2\\) d’homogeneïtat, p-valor 0.09). La conclusió concreta ja dependria de si prenguéssim nivell de significació 0.05 o 0.1. 7.3 Test \\(\\chi^2\\) de tendència (Opcional) Un contrast de tendència és una generalització del contrast d’homogeneïtat de proporcions. En el contrast de tendència, tenim una variable aleatòria ordinal \\(X\\) de nivells ordenats \\(X_1&lt;\\cdots&lt; X_k\\), i una variable aleatòria Bernoulli \\(Y\\) de nivells “Èxit” i “Fracàs”. Diguem \\(p_i=P(Y=\\text{Èxit}|X=X_i)\\), per a tot \\(i\\). El contrast que volem realitzar és \\[ \\left\\{ \\begin{array}{ll} H_0: \\text{ $p_1=\\cdots=p_k$}\\\\ H_1: \\text{ $p_1\\leqslant\\cdots \\leqslant p_k$ i almenys una }\\\\ \\hphantom{H_1: } \\text{ d&#39;aquestes desigualtats és estricta} \\end{array} \\right. \\] Es duu a terme amb un test \\(\\chi^2\\) de Cochran-Armitage, una variant del test \\(\\chi^2\\) explicat fins ara. Per utilitzar-lo, basta que la mostra total sigui gran (\\(\\geqslant 30\\)), no cal la condició de Cochran. (Si teniu curiositat sobre com es fa, podeu consultar la seva entrada de la Wikipedia) Amb R s’efectua amb la funció prop.trend.test, aplicada al vector de freqüències d’èxits i el vector de freqüències de cada nivell de \\(X\\). Exemple 7.6 Continuem amb l’Exemple 7.1. Recordem que hi volíem determinar si hi ha associació entre l’hàbit de fumar i patir tos nocturna entre els nins. Les dades recollides varen ser: \\[ \\begin{array}{l} \\hphantom{No fumador ocasional un }\\text{Fumador}\\\\ \\begin{array}{l|ccc|c} &amp; \\text{No fumador} &amp; \\text{Ocasional} &amp; \\text{Regular} &amp; \\text{Total} \\\\\\hline \\text{Tos} &amp; 266 &amp; 395 &amp; 80 &amp; 741\\\\ \\text{No tos}&amp; 1037 &amp; 977 &amp; 92 &amp; 2106\\\\\\hline \\text{Total} &amp;1303 &amp; 1372 &amp; 172 &amp; 2847\\\\ \\end{array} \\end{array} \\] Com que l’estatus de fumador és una variable ordinal i, naturalment, en darrera instància cercam proves que el fumar “causa” la tos nocturna, ens pot interessar contrastar si la probabilitat de tos nocturna creix amb la freqüència de fumar. Variables d’interès: \\(X\\): “Prenem un nin i avaluam el seu estatus de fumador”; la considerarem una variable ordinal amb nivells “No fumador” &lt; “Ocasional” &lt; “Regular” \\(Y\\): “Prenem un nin i miram si té tos nocturna o no” Contrast: Si diem \\(p_N\\), \\(p_O\\) i \\(p_R\\) a la probabilitat que tengui tos nocturna un nin no fumador, un nin fumador ocasional i un nin fumador regular, respectivament, \\[ \\left\\{ \\begin{array}{ll} H_0: \\text{ $p_N=p_O=p_R$}\\\\ H_1: \\text{ $p_N\\leqslant p_O \\leqslant p_R$ i $p_N&lt;p_R$} \\end{array} \\right. \\] Fixau-vos que, a la hipòtesi alternativa, dir “\\(p_N\\leqslant p_O \\leqslant p_R\\) i almenys una d’aquestes desigualtats és estricta” és equivalent a dir “\\(p_N\\leqslant p_O \\leqslant p_R\\) i \\(p_N&lt;p_R\\)” només que aquesta darrera reformulació és més curta. Emprarem un test \\(\\chi^2\\) de tendència: Tos=c(266,395,80) Fum=c(1303,1372,172) prop.trend.test(Tos,Fum) ## ## Chi-squared Test for Trend in Proportions ## ## data: Tos out of Fum , ## using scores: 1 2 3 ## X-squared = 59.47, df = 1, p-value = 1.242e-14 Conclusió: Hem trobat evidència estadísticament significativa que la probabilitat de patir tos nocturna creix amb la freqüència de fumar (test \\(\\chi^2\\) de Cochran-Armitage, p-valor 10-14) "],
["introducció-a-lestadística-multidimensional.html", "Tema 8 Introducció a l’estadística multidimensional 8.1 Poblacions: vectors aleatoris 8.2 Estadística descriptiva: Mostres", " Tema 8 Introducció a l’estadística multidimensional En general, les dades que es recullen en experiments són multidimensionals: mesuram diverses variables aleatòries sobre una mateixa mostra d’individus i organitzam aquesta informació en taules de dades on les fileres representen els individus observats i cada columna correspon a una variable diferent. És a dir, el que fem és avaluar un vector de variables aleatòries (en direm un vector aleatori) sobre els individus d’una població. En aquesta lliçó introduïm alguns conceptes nous sobre vectors de variables aleatòries i taules multidimensionals de dades quantitatives. 8.1 Poblacions: vectors aleatoris Un vector aleatori de dimensió \\(p\\) és un vector format per \\(p\\) variables aleatòries \\[ \\underline{X}=(X_1,X_2,\\ldots,X_p). \\] Una realització de \\(\\underline{X}\\) és un vector \\((x_1,\\ldots,x_p)\\) format pels valors de \\(X_1,\\ldots,X_p\\) sobre un individu. Una mostra de \\(\\underline{X}\\) és un conjunt de realitzacions. Usualment, organitzam una mostra de \\(\\underline{X}\\) per mitjà d’una taula de dades amb les columnes definides per les variables \\(X_1,\\ldots,X_p\\) i on cada filera és una realització d’aquestes variables, és a dir, un vector format pels valors de \\(X_1,\\ldots,X_p\\) sobre un individu de la mostra. Exemple 8.1 Si diem \\(\\textit{BMI}\\) a la variable aleatòria que dóna l’Índex de Massa Corporal (BMI) d’una persona, \\(C\\) a la variable aleatòria que dóna el nivell de colesterol en mg/dl d’una persona i \\(E\\) a la variable aleatòria que dóna l’edat d’una persona en anys, llavors \\[ \\underline{X}=(\\textit{BMI},C,E) \\] és un vector aleatori de dimensió 3. Cada cop que prenem una persona i n’anotam el BMI, el nivell de colesterol i l’edat i organitzam aquestes mesures en aquest ordre en un vector, obtenim una realització d’aquest vector aleatori \\(\\underline{X}\\). Llavors,una mostra de \\(\\underline{X}\\) serà un conjunt de vectors amb el BMI, el nivell de colesterol i l’edat d’un grup de persones de la població. Per exemple BMI C E 18.3 170 49 24.4 202 39 24.6 215 50 24.4 218 44 22.2 210 40 19.5 210 36 No confongueu vector aleatori amb mostra aleatòria. Tot i que tots dos es representen formalment per mitjà de vectors de variables aleatòries, En un vector aleatori, en principi totes les variables són diferents i les avaluam sobre el mateix individu, obtenint un vector de mesures d’aquest individu En una mostra aleatòria, totes les variables són còpies de la mateixa variable \\(X\\) i les avaluam cada una sobre un individu diferent, obtenint una mostra de valors de \\(X\\) Siguin \\(\\underline{X}=(X_1,X_2,\\ldots,X_p)\\) un vector aleatori i \\(\\mu_i\\) i \\(\\sigma_i\\) la mitjana i la desviació típica, respectivament, de cada \\(X_i\\). El valor esperat, o vector de mitjanes, de \\(\\underline{X}\\) és el vector format pels valors esperats, o mitjanes, de les seves components: \\[ E(\\underline{X})=(\\mu_1,\\ldots,\\mu_p). \\] Per abreviar, de vegades indicarem aquest vector simplement amb \\(\\boldsymbol\\mu\\). El vector de variàncies de \\(\\underline{X}\\) és el vector format per les variàncies de les seves components: \\[ \\sigma^2(\\underline{X})=(\\sigma_1^2,\\ldots,\\sigma_p^2). \\] El vector de desviacions típiques de \\(\\underline{X}\\) és el vector format per les desviacions típiques de les seves components: \\[ \\sigma(\\underline{X})=(\\sigma_1,\\ldots,\\sigma_p). \\] 8.1.1 Covariància La covariància de dues variables \\(X\\) i \\(Y\\) és una mesura del seu comportament conjunt. Formalment, donades dues variables aleatòries \\(X,Y\\) de mitjanes \\(\\mu_X\\) i \\(\\mu_Y\\), respectivament, la seva covariància és \\[ \\sigma_{X,Y}=E((X-\\mu_X)\\cdot ( Y-\\mu_Y)). \\] És fàcil comprovar que \\[ \\sigma_{X,Y}=E(X\\cdot Y) -\\mu_X\\cdot \\mu_Y. \\] En efecte, \\[ \\begin{array}{rl} \\sigma_{X,Y} &amp; =E((X-\\mu_X) ( Y-\\mu_Y))= E(XY-\\mu_XY-\\mu_YX+\\mu_X\\mu_Y)\\\\ &amp; =E(XY)-\\mu_XE(Y)-\\mu_YE(X)+\\mu_X\\mu_Y\\\\ &amp;= E(XY)-\\mu_X\\mu_Y-\\mu_Y\\mu_X+\\mu_X\\mu_Y =E(XY)-\\mu_X\\mu_Y \\end{array} \\] La covariància de \\(X\\) i \\(Y\\) pot prendre qualsevol valor real (no com la variància, que sempre és positiva), i mesura el grau de variació conjunta de les variables en el sentit següent. Si quan \\(X\\) pren un valor gran sobre un individu, \\(Y\\) tendeix a també prendre’l gran, i quan \\(X\\) pren un valor petit sobre un individu, \\(Y\\) tendeix a també prendre’l petit, la seva covariància és positiva. Si, en canvi, quan \\(X\\) pren un valor gran sobre un individu, \\(Y\\) tendeix a prendre’l petit i vice versa, la seva covariància és negativa. El signe de la covariància reflecteix la tendència de la relació entre les variables: Covariància positiva: Si \\(X\\) creix, \\(Y\\) tendeix a créixer, i si \\(X\\) decreix, \\(Y\\) tendeix a decréixer Covariància negativa: Si \\(X\\) creix, \\(Y\\) tendeix a decréixer, i si \\(X\\) decreix, \\(Y\\) tendeix a créixer Si \\(X\\) i \\(Y\\) són variables independents, la seva covariància es 0, perquè en aquest cas \\(E(X\\cdot Y) =\\mu_X\\mu_Y\\) i per tant \\[ \\sigma_{X,Y}=E(X\\cdot Y) -\\mu_X\\cdot \\mu_Y=\\mu_X\\cdot \\mu_Y-\\mu_X\\cdot \\mu_Y=0. \\] El recíproc és fals: dues variables aleatòries poden tenir covariància 0 i no ser independents. Vegem un exemple d’aquest darrer fet: Exemple 8.2 Suposem que tenim un dau tetraèdric no trucat amb les cares marcades amb els valors -2, -1, 1 i 2. Siguin \\(X\\) la variable aleatòria que consisteix a llançar el dau i anotar el resultat, i \\(Y\\) la variable aleatòria que consisteix a llançar el dau i anotar el quadrat del resultat obtingut. Com que les quatre cares del dau són equiprobables, \\[ \\begin{array}{l} \\displaystyle P(X=-2)=P(X=-1)=P(X=1)=P(X=2)=\\frac{1}{4}\\\\ \\displaystyle P(Y=1)=P(Y=4)=\\frac{1}{2} \\end{array} \\] Com que \\(Y\\) és funció de \\(X\\), ja que \\(Y=X^2\\), \\(X\\) i \\(Y\\) no poden ser mai independents. Vegem que, en efecte, no ho són. Observau que els únics possibles valors per al vector \\((X,Y)\\) en una tirada del dau són (-2,4), (-1,1), (1,1) i (2,4), cadascun amb probabilitat 1/4. Llavors, per exemple, la probabilitat d’obtenir en una tirada \\(X=-1\\) i \\(Y=4\\) és 0, perquè és impossible, mentre que \\[ P(X=-1)\\cdot P(Y=4)=\\frac{1}{4}\\cdot\\frac{1}{2}=\\frac{1}{8}\\neq 0. \\] Vegem ara que la covariància de \\(X\\) i \\(Y\\) es 0. Per calcular-la, primer necessitam calcular els valors esperats de les variables: \\[ \\begin{array}{l} \\displaystyle \\mu_X=(-2)\\cdot \\frac{1}{4}+(-1)\\cdot \\frac{1}{4}+1\\cdot \\frac{1}{4}+2\\cdot \\frac{1}{4}=0\\\\ \\displaystyle \\mu_Y=1\\cdot \\frac{1}{2}+4\\cdot \\frac{1}{2}=2.5 \\end{array} \\] Per tant \\[ \\begin{array}{l} \\sigma_{X,Y}=E\\big(X\\cdot Y\\big)-\\mu_X\\cdot \\mu_Y=E\\big(X\\cdot Y\\big)-0\\cdot 2.5=E\\big(X\\cdot Y\\big)\\\\ \\qquad =P\\big(X=-2,Y=4\\big)\\cdot (-2\\cdot 4)+P\\big(X=-1,Y=1\\big)\\cdot (-1\\cdot 1)\\\\ \\qquad\\qquad\\qquad +P\\big(X=1,Y=1\\big)\\cdot (1\\cdot 1)+P\\big(X=2,Y=4\\big)\\cdot (2\\cdot 4)\\\\ \\qquad =\\displaystyle \\frac{1}{4}\\cdot (-8)+\\frac{1}{4}\\cdot (-1)+\\frac{1}{4}\\cdot 1+\\frac{1}{4}\\cdot 8=0. \\end{array} \\] Així doncs, \\(X\\) i \\(Y\\) són variables dependents, però la seva covariància és 0. Dues propietats importants més de la covariància: La covariància és simètrica: \\[ \\sigma_{X,Y}=E((X-\\mu_X)\\cdot ( Y-\\mu_Y))=E(( Y-\\mu_Y)\\cdot (X-\\mu_X))=\\sigma_{Y,X} \\] La covariància d’una variable aleatòria amb ella mateixa és la seva variància: \\[ \\sigma_{X,X}=E((X-\\mu_X)^2)=\\sigma^2(X) \\] La matriu de covariàncies d’un vector aleatori \\(\\underline{X}=(X_1,\\ldots,X_p)\\) és la matriu formada per les covariàncies dels parells de variables que la formen: \\[ \\sigma_{\\underline{X},\\underline{X}}=\\begin{pmatrix} \\sigma_{X_1,X_1} &amp; \\sigma_{X_1,X_2} &amp; \\ldots &amp; \\sigma_{X_1,X_p}\\\\ \\sigma_{X_2,X_1} &amp; \\sigma_{X_2,X_2} &amp; \\ldots &amp; \\sigma_{X_2,X_p}\\\\ \\vdots &amp; \\vdots &amp;\\ddots &amp; \\vdots\\\\ \\sigma_{X_p,X_1} &amp; \\sigma_{X_p,X_2} &amp; \\ldots &amp; \\sigma_{X_p,X_p}\\\\ \\end{pmatrix} \\] Aquesta matriu és simètrica i les entrades de la diagonal són les variàncies de les variables del vector, perquè \\(\\sigma_{X_i,X_i}=\\sigma^2_{X_i}\\). 8.1.2 Correlació Com hem dit, el signe de la covariància té una interpretació senzilla, ja que reflecteix la tendència de la relació entre les variables. Emperò, la seva magnitud no té una interpretació senzilla. Aleshores, per mesurar la relació lineal entre dues variables aleatòries contínues s’usa l’anomenat coeficient de correlació lineal de Pearson (o correlació a seques), que ve a ser una versió normalitzada de la covariància. En concret, la correlació de les variables \\(X\\) i \\(Y\\) es defineix com el quocient de la seva covariància pel producte de les seves desviacions típiques: \\[ \\rho_{X,Y}=\\frac{\\sigma_{X,Y}}{\\sigma_{X} \\sigma_{Y}}, \\] La correlació té les propietats importants següents: No té unitats (perquè les unitats de \\(\\sigma_X\\) són les de \\(X\\), les unitats de \\(\\sigma_Y\\) són les de \\(Y\\), i les unitats de \\(\\sigma_{X,Y}\\) són les de \\(X\\) per les de \\(Y\\)) Pren valors entre -1 i 1: \\(-1\\leqslant\\rho_{X,Y}\\leqslant 1\\) És simètrica, \\(\\rho_{X,Y}= \\rho_{Y,X}\\) La correlació d’una variable amb ella mateixa és 1: \\(\\rho_{X,X}=1\\) Si \\(\\rho_{X,Y}=\\pm 1\\), les variables \\(X,Y\\) tenen una relació lineal perfecta, és a dir, existeixen \\(a,b\\in \\mathbb{R}\\) tals que \\(Y=a X+b\\). La pendent \\(a\\) d’aquesta recta té el mateix signe que \\(\\rho_{X,Y}\\). Si \\(\\rho_{X,Y}=0\\), diem que les variables \\(X\\) i \\(Y\\) són incorrelades. Notem que la correlació és 0 si, i només si, la covariància és 0. Per tant, si \\(X\\) i \\(Y\\) són independents, també són incorrelades. El recíproc en general és fals, com mostra l’Exemple 8.2. La matriu de correlacions d’un vector aleatori \\(\\underline{X}=(X_1,\\ldots,X_p)\\) és la matriu formada per les correlacions de parells de les seves variables: \\[ \\rho(\\underline{X}) =\\begin{pmatrix} 1 &amp; \\rho_{X_1,X_2} &amp; \\ldots &amp; \\rho_{X_1,X_p}\\\\ \\rho_{X_2,X_1} &amp; 1 &amp; \\ldots &amp; \\rho_{X_2,X_p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\rho_{X_p,X_1} &amp; \\rho_{X_p,X_2} &amp; \\ldots &amp; 1\\\\ \\end{pmatrix}. \\] Aquesta matriu és simètrica per la simetria de la correlació. 8.2 Estadística descriptiva: Mostres 8.2.1 Covariàncies Siguin \\(x=(x_1,\\ldots,x_n)\\) i \\(y=(y_1,\\ldots,y_n)\\) dos vectors obtinguts mesurant dues variables aleatòries \\(X\\) i \\(Y\\) sobre una mateixa mostra ordenada d’individus de mida \\(n\\) d’una població. Siguin \\(\\overline{x}\\) i \\(\\overline{y}\\) les seves mitjanes mostrals. Aleshores la seva covariància mostral és \\[ \\widetilde{s}_{x,y} =\\frac{1}{n-1} \\sum_{i =1}^n\\big((x_{i}-\\overline{{x}})(y_i-\\overline{y})\\big) \\] i la seva covariància (a seques) és \\[ {s}_{x,y} =\\frac{1}{n} \\sum_{i =1}^n\\big((x_{i}-\\overline{{x}})(y_i-\\overline{y})\\big)=\\frac{n-1}{n}\\widetilde{s}_{XY}. \\] És a dir, com sempre, la diferència entre la versió “mostral” i la versió “a seques” rau en el denominador, \\(n-1\\) i \\(n\\) respectivament. La covariància de dos vectors només té sentit quan aquests vectors representen els valors de dues variables quantitatives sobre els mateixos individus i en el mateix ordre. En particular, els dos vectors han de tenir la mateixa longitud. Com en el cas poblacional, la covariància entre dos vectors mesura la tendència que tenen les seves dades a variar conjuntament. Quan la covariància és positiva, si una \\(x_i\\) és gran o petita, la corresponent \\(y_i\\) tendeix a tenir el mateix comportament. Quan la covariància és negativa, aquesta tendència s’inverteix: si una \\(x_i\\) és gran, la corresponent \\(y_i\\) tendeix a ser petita, i viceversa. És fàcil comprovar que: Les dues covariàncies són simètriques \\[ \\widetilde{s}_{x,y}=\\widetilde{s}_{y,x},\\ {s}_{x,y}={s}_{y,x} \\] La variància d’un vector és la seva covariància amb ell mateix \\[ \\widetilde{s}_{x,x}=\\widetilde{s}^2_{x},\\ {s}_{x,x}={s}^2_{x}. \\] Les covariàncies de dos vectors estimen la covariància poblacional de les variables que han produït els vectors: La covariància mostral \\(\\widetilde{s}_{x,y}\\) sempre és un estimador no esbiaixat de la covariància poblacional \\(\\sigma_{X,Y}\\) La covariància a seques \\(s_{x,y}\\) és l’estimador màxim versemblant de \\(\\sigma_{X,Y}\\) quan la distribució conjunta de les variables \\(X,Y\\) és el que s’anomena normal bivariant. Exemple 8.3 Hem mesurat l’índex de massa corporal, BMI, i el nivell de colesterol en 5 individus sans. Guardam els resultats en un data frame i en calculam les mitjanes: BMI= c(18.3,24.4,24.6,24.4,22.2,19.5) Chol=c(170,202,215,218,210,210) DF=data.frame(BMI,Chol) mean(BMI) ## [1] 22.23333 mean(Chol) ## [1] 204.1667 Aleshores la covariància mostral d’aquests dos vectors és \\[ \\begin{array}{l} \\dfrac{1}{5}\\Big((18.3-22.23)(170-204.17)+(24.4-22.23)(202-204.17)\\\\ \\qquad +(24.6-22.23)(215-204.17)+(24.4-22.23)(218-204.17)\\\\ \\qquad +(22.2-22.23)(210-204.17)+(19.5-22.23)(210-204.17)\\Big)=33.8333 \\end{array} \\] i la seva covariància a seques és \\[ \\begin{array}{l} \\dfrac{1}{6}\\Big((18.3-22.23)(170-204.17)+(24.4-22.23)(202-204.17)\\\\ \\qquad +(24.6-22.23)(215-204.17) +(24.4-22.23)(218-204.17)\\\\ \\qquad +(22.2-22.23)(210-204.17)+(19.5-22.23)(210-204.17)\\Big)=27.0667 \\end{array} \\] La covariància mostral de dos vectors numèrics de la mateixa longitud \\(n\\) es calcula amb R amb la funció cov. Per obtenir la seva covariància a seques, cal multiplicar el resultat de cov per \\((n-1)/n\\). cov(BMI,Chol) ## [1] 33.83333 Considerem una taula de dades de la forma \\[ \\begin{array}{cccc} X_1 &amp; X_2 &amp; \\ldots &amp; X_p\\\\ \\hline x_{1 1} &amp; x_{1 2} &amp;\\ldots &amp; x_{1 p}\\\\ x_{2 1} &amp; x_{2 2} &amp;\\ldots &amp; x_{2 p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ x_{n 1} &amp; x_{n 2} &amp;\\ldots &amp; x_{n p} \\end{array} \\] on cada columna representa els valors d’una certa variable \\(X_i\\) i cada filera un individu d’una mostra de la població, de manera que l’entrada \\(x_{ij}\\) d’aquesta taula és el valor de \\(X_j\\) sobre l’individu \\(i\\)-èssim de la mostra. La matriu de covariàncies mostrals d’aquesta taula és la matriu \\[ \\widetilde{{S}}= \\begin{pmatrix} \\widetilde{s}^2_{X_1} &amp; \\widetilde{s}_{X_1,X_2} &amp; \\ldots &amp; \\widetilde{s}_{X_1,X_p}\\\\ \\widetilde{s}_{X_2,X_1} &amp; \\widetilde{s}^2_{X_2} &amp; \\ldots &amp; \\widetilde{s}_{X_2,X_p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ \\widetilde{s}_{X_p,X_1} &amp; \\widetilde{s}_{X_p,X_2} &amp; \\ldots &amp; \\widetilde{s}^2_{X_p} \\end{pmatrix} \\] i la matriu de covaiàncies (a seques) es defineix de manera similar, però amb les covariàncies a seques: \\[ {S}= \\begin{pmatrix} s^2_{X_1} &amp; s_{X_1,X_2} &amp; \\ldots &amp; s_{X_1,X_p}\\\\ s_{X_2,X_1} &amp; s^2_{X_2} &amp; \\ldots &amp; s_{X_2,X_p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ s_{X_p,X_1} &amp; s_{X_p,X_2} &amp; \\ldots &amp; s^2_{X_p} \\end{pmatrix} \\] Totes dues són simètriques. La matriu de covariàncies mostrals es calcula amb la funció cov aplicada a la matriu o el data frame de variables numèriques que emmagatzema la taula de dades. Per calcular la matriu de covariàncies a seques, es multiplica el resultat de cov per \\((n-1)/n\\), on \\(n\\) és el nombre de fileres de la taula. Exemple 8.4 Afegirem a la taula de dades de l’Exemple 8.3 una tercera variable amb les edats dels 6 individus representats en ella. DF$Edats=c(49,39,50,44,40,36) DF ## BMI Chol Edats ## 1 18.3 170 49 ## 2 24.4 202 39 ## 3 24.6 215 50 ## 4 24.4 218 44 ## 5 22.2 210 40 ## 6 19.5 210 36 La matriu de covariàncies mostrals d’aquesta taula és cov(DF) ## BMI Chol Edats ## BMI 7.586667 33.83333 1.14 ## Chol 33.833333 309.76667 -33.00 ## Edats 1.140000 -33.00000 32.00 Podreu observar que és simètrica, que a la diagonal hi obtenim les variàncies mostrals de les variables de la taula: apply(DF,MARGIN=2,FUN=var) ## BMI Chol Edats ## 7.586667 309.766667 32.000000 i que l’entrada (2,1) coincideix amb la covariància de BMI i Chol que hem calculat abans. 8.2.2 Correlació de Pearson Siguin \\(x=(x_1,\\ldots,x_n)\\) i \\(y=(y_1,\\ldots,y_n)\\) dos vectors obtinguts mesurant dues variables aleatòries \\(X\\) i \\(Y\\) sobre una mateixa mostra d’individus de mida \\(n\\) d’una població. La correlació de Pearson de \\(x\\) i \\(y\\) és la seva covariància mostral dividida pel producte de les seves desviacions típiques mostrals: \\[ r_{x,y}=\\frac{\\widetilde{s}_{x,y}}{\\widetilde{s}_x\\cdot \\widetilde{s}_y}. \\] També és igual a la seva covariància dividida pel producte de les seves desviacions típiques, perquè els canvis de denominador se cancel·len: \\[ r_{x,y}=\\frac{\\widetilde{s}_{x,y}}{\\widetilde{s}_x\\cdot \\widetilde{s}_y}= \\frac{\\frac{n}{n-1}\\cdot {s}_{x,y}}{\\sqrt{\\frac{n}{n-1}}\\cdot {s}_x \\cdot\\sqrt{\\frac{n}{n-1}}\\cdot{s}_y}= \\frac{s_{x,y}}{s_x \\cdot s_y}=r_{x,y}. \\] Exemple 8.5 Tornem a la situació de l’Exemple 8.3. La covariància mostral i les desviacions típiques mostrals dels vectors BMI i Chol són sd(BMI) ## [1] 2.75439 sd(Chol) ## [1] 17.60019 cov(BMI,Chol) ## [1] 33.83333 i per tant la seva correlació de Pearson és \\[ r_{BMI,Chol}=\\frac{33.833}{2.754\\cdot 17.6}= 0.698 \\] La correlació de Pearson de dos vectors estima la correlació de les variables poblacionals que han produït els vectors. En concret \\(r_{x,y}\\) és un estimador màxim versemblant de \\(\\rho_{X,Y}\\) quan la seva distribució conjunta és normal bivariant. N’és un estimador esbiaxiat, però el seu biaix tendeix a 0. Altres propietats importants de la correlació de Pearson: La correlació de Pearson és simètrica: \\(r_{x,y}=r_{y,x}\\) La correlació de Pearson pren valors només entre -1 i 1: \\(-1\\leqslant r_{x,y}\\leqslant 1\\) La correlació de Pearson d’un vector amb ell mateix és 1: \\(r_{x,x}=1\\) \\(r_{x,y}\\) té el mateix signe que \\(s_{x,y}\\) \\(r_{x,y}=\\pm 1\\) si, i només si, existeixen \\(a, b\\in \\mathbb{R}\\) tals que \\(y=ax+b\\), és a dir, \\(y_i=ax_i+b\\) per a cada \\(i=1,\\ldots,n\\). La pendent \\(a\\) d’aquesta relación lineal té el mateix signe que \\(r_{x,y}\\). El coeficient de determinació \\(R^2\\) de la regressió lineal per mínims quadrats de \\(y\\) respecte de \\(x\\) és igual al quadrat de la seva correlació de Pearson: \\[ R^2=r_{x,y}^2 \\] Per tant, com més s’acosta \\(|r_{x,y}|\\) a 1, més s’acosten els vectors \\(x,y\\) a dependre linealment l’un de l’altre. El signe de \\(r_{x,y}\\) indica si dependència és creixent (\\(r_{x,y}&gt;0\\)) o decreixent (\\(r_{x,y}&lt;0\\)). Amb R, la correlació de Pearson de dos vectors es pot calcular amb la funció cor. Per exemple, la correlació del Pearson dels vectors BMI i Chol s’obté amb cor(BMI,Chol) ## [1] 0.6979141 Vegem que el seu quadrat és igual al \\(R^2\\) de la regressió lineal de Chol en funció de BMI: cor(BMI,Chol)^2 ## [1] 0.487084 summary(lm(Chol~BMI))$r.squared ## [1] 0.487084 Per fer-nos una idea de què representa aquest valor de la correlació, vegem el gràfic dels punts (BMI,Chol) amb la seva recta de regressió lineal: plot(BMI,Chol,pch=20) abline(lm(Chol~BMI),col=&quot;red&quot;,lwd=1.5) Hi podem observar com Chol tendeix a créixer quan BMI creix. Les funcions del paquet datasaurus us permeten crear conjunts de punts de “formes” diferents i mateixos estadístics, i en particular la mateixa correlació. Per exemple, tots els conjunts de punts del gràfic següent tenen la mateixa correlació. Suposem que tenim una taula de dades de la forma \\[ \\begin{array}{cccc} X_1 &amp; X_2 &amp; \\ldots &amp; X_p\\\\ \\hline x_{1 1} &amp; x_{1 2} &amp;\\ldots &amp; x_{1 p}\\\\ x_{2 1} &amp; x_{2 2} &amp;\\ldots &amp; x_{2 p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp;\\vdots\\\\ x_{n 1} &amp; x_{n 2} &amp;\\ldots &amp; x_{n p} \\end{array} \\] on cada columna representa els valors d’una certa variable \\(X_i\\) i cada filera un individu d’una mostra de la població, de manera que l’entrada \\(x_{ij}\\) d’aquesta taula és el valor de \\(X_j\\) sobre l’individu \\(i\\)-èssim de la mostra. La seva matriu de correlacions de Pearson és la matriu simètrica \\[ \\begin{pmatrix} 1 &amp; r_{X_1,X_2} &amp; \\ldots &amp; r_{X_1,X_p}\\\\ r_{X_2,X_1} &amp; 1 &amp; \\ldots &amp; r_{X_2,X_p}\\\\ \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots\\\\ r_{X_p,X_1} &amp; r_{X_p,X_2} &amp; \\ldots &amp; 1 \\end{pmatrix} \\] Aquesta matriu de correlacions es calcula amb la funció cor aplicada a la matriu o el data frame de variables numèriques que emmagatzema la taula de dades. Per exemple, la matriu de correlacions de Pearson de la taula de dades DF de l’Exemple 8.4 és cor(DF) ## BMI Chol Edats ## BMI 1.00000000 0.6979141 0.07316517 ## Chol 0.69791406 1.0000000 -0.33145274 ## Edats 0.07316517 -0.3314527 1.00000000 8.2.3 Correlació de Spearman La correlació de Pearson mesura específicament la tendència de dues variables contínues a dependre linealment l’una de l’altra. En circumstàncies en les quals no esperem aquesta dependència lineal, o en les quals les nostres variables siguin quantitatives discretes o simplement ordinals, emprar la correlació de Pearson per a analitzar la relació entre dues variables no és el més adequat. Entre les propostes alternatives, la més popular és la correlació de Spearman. La correlació de Spearman de dos vectors \\(x\\) i \\(y\\) és la correlació de Pearson dels vectors de rangs de \\(x\\) i \\(y\\). El vector de rangs d’un vector \\(x\\) s’obté substituïnt cada valor de \\(x\\) per la seva posició en el vector ordenat de menor a major, i en cas d’empats assigna la mitjana de les posicions que ocuparien tots els empats (aquests rangs ja han sortit, al test de bondat d’ajust de Kolmogorov-Smirnov). Per exemple, el vector de rangs de \\[ x=(4,5,1,5,1,3,4,4) \\] és \\[ (5,7.5,1.5,7.5,1.5,3,5,5) \\] Com hem calculat aquest vector? Als dos elements 1 de \\(x\\) els tocarien les posicions 1, 2 del vector ordenat, i per tant el seu rang és la mitjana d’aquestes dues posicions: 1.5. A l’element 3 li tocaria la posició 3 del vector ordenat, i com que només n’hi ha un, aquest és el seu rang. Als tres elements 4 els tocarien les posicions 4, 5 i 6 del vector ordenat, i per tant el seu rang és la mitjana d’aquestes tres posicions: 5. Finalment, als dos elements 5 els tocarien les posicions 7, 8 del vector ordenat, i per tant el seu rang és la mitjana d’aquestes dues posicions: 7.5. Per cert, amb R els rangs es calculen amb la funció rank: rank(c(4,5,1,5,1,3,4,4)) ## [1] 5.0 7.5 1.5 7.5 1.5 3.0 5.0 5.0 Amb R, la correlació de Spearman es calcula directament amb la funció cor entrant-li el paràmetre method=&quot;spearman&quot;. (El valor per defecte del paràmetre method és &quot;pearson&quot; i per això no l’indicam quan calculam la correlació de Pearson.) Exemple 8.6 Calculem a mà la correlació de Spearman dels vectors BMI i Chol. El primer que farem serà calcular els rangs dels valors \\[ \\begin{array}{|c|c||c|c|} \\hline \\mathit{BMI} &amp; \\mathit{Rang} &amp; \\mathit{Chol}&amp; \\mathit{Rang} \\\\\\hline\\hline 18.3&amp; 1 &amp; 170&amp; 1 \\\\ 24.4&amp;4.5 &amp; 202 &amp; 2\\\\ 24.6&amp;6 &amp; 215&amp; 5 \\\\ 24.4&amp;4.5 &amp; 218&amp; 6\\\\ 22.2&amp;3 &amp; 210&amp; 3.5\\\\ 19.5&amp;2 &amp; 210&amp; 3.5\\\\\\hline \\end{array} \\] Per tant, la correlación de Spearman de \\[ \\mathit{BMI}=(18.3, 24.4, 24.6, 24.4, 22.2, 19.5)\\mbox{ i }\\mathit{Chol}=(170, 202, 215, 218, 210, 210) \\] és la correlació de Pearson de \\[ (1, 4.5, 6, 4.5, 3, 2)\\mbox{ i }(1, 2, 5, 6, 3.5, 3.5) \\] Comprovem-ho: cor(BMI,Chol,method=&quot;spearman&quot;) ## [1] 0.6470588 cor(c(1,4.5,6,4.5,3,2),c(1,2,5,6,3.5,3.5)) ## [1] 0.6470588 8.2.4 Contrastos de correlació En un contrast de correlació de dues variables poblacionals \\(X\\) i \\(Y\\), la hipòtesi nul·la és que no hi ha correlació entre les dues variables, la qual cosa s’entén que tradueix que no hi ha cap relació entre elles. \\[ \\left\\{ \\begin{array}{ll} H_0: &amp; \\rho_{XY}=0\\\\ H_1: &amp; \\rho_{XY}&gt; 0\\text{ o }\\rho_{XY}&lt; 0\\text{ o }\\rho_{XY}\\neq 0 \\end{array}\\right. \\] Si en un contrast de correlació rebutjam la hipòtesi nul·la, en particular concloem que les variables \\(X\\) i \\(Y\\) són dependents (perquè si fossin independents, la seva correlació seria 0). No explicarem com es fa a mà aquest contrast ni quines hipòtesis han de satisfer les variables poblacionals per que el resultat sigui fiable. Simplement heu de saber que s’efectua amb la funció cor.test. Si estau interessats en el detall, podeu consultar la corresponent entrada de la Wikipedia. Exemple 8.7 Volem contrastar si hi ha correlació positiva entre el BMI i el nivell de colesterol d’un adult sa, amb un nivell de significació del 5%. Variables poblacionals d’interès: \\(\\mathit{BMI}\\): “Prenem un adult sa i mesuram el seu BMI” \\(\\mathit{Chol}\\): “Prenem un adult sa i mesuram el nivell de colesterol en mg/dl” Contrast: \\[ \\left\\{ \\begin{array}{ll} H_0: &amp; \\rho_{\\textit{BMI,Chol}}=0\\\\ H_1: &amp; \\rho_{\\textit{BMI,Chol}}&gt;0 \\end{array}\\right. \\] Emprarem les mostres BMI i Chol de l’Exemple8.3. cor.test(BMI,Chol,alternative=&quot;greater&quot;) ## ## Pearson&#39;s product-moment correlation ## ## data: BMI and Chol ## t = 1.949, df = 4, p-value = 0.06155 ## alternative hypothesis: true correlation is greater than 0 ## 95 percent confidence interval: ## -0.08621998 1.00000000 ## sample estimates: ## cor ## 0.6979141 Conclusió: No hem obtingut evidència estadísticament significativa que el BMI i el nivell de colesterol d’un adult sa tenguin correlació positiva (test de correlació, p-valor 0.06, IC 95% per a la correlació de \\(-0.086\\) a 1). "],
["anova.html", "Tema 9 ANOVA 9.1 Nocions bàsiques 9.2 ANOVA d’1 via 9.3 ANOVA de blocs 9.4 ANOVA de 2 vies", " Tema 9 ANOVA L’objectiu d’aquest tema és generalitzar el contrast bilateral de dues mitjanes emprant un test t a més de dues mitjanes, de tal manera que amb un sol test poguem decidir si hi ha evidència que alguna parella d’aquestes mitjanes siguin diferents o si pel contrari podem acceptar que totes les mitjanes són iguals. 9.1 Nocions bàsiques Comencem considerant un problema concret. Exemple 9.1 Es realitzà un estudi per investigar l’efecte del CO2 sobre la taxa de creixement de Pseudomonas fragi, un corruptor d’aliments. Per contrastar si el seu creixement es veu afectat per la quantitat de CO2 en l’aire, s’administrà CO2 a 5 pressions atmosfèriques diferents a 10 cultius diferents per cada nivell de pressió de CO2 i s’anotà el percentatge d’increment de la massa cel·lular de cada cultiu al cap d’una hora. Les dades obtingudes varen ser: \\[ \\begin{array}{c} \\text{Pressió de CO${}_2$ (en atmosferes)}\\\\ \\begin{array}{rrrrr} 0.0 &amp; 0.08 &amp; 0.29 &amp; 0.50 &amp; 0.86 \\\\\\hline 62.6 &amp; 50.9 &amp; 45.5 &amp; 29.5 &amp; 24.9 \\\\ 59.6 &amp; 44.3 &amp; 41.1 &amp; 22.8 &amp; 17.2 \\\\ 64.5 &amp; 47.5 &amp; 29.8 &amp; 19.2 &amp; 7.8 \\\\ 59.3 &amp; 49.5 &amp; 38.3 &amp; 20.6 &amp; 10.5 \\\\ 58.6 &amp; 48.5 &amp; 40.2 &amp; 29.2 &amp; 17.8 \\\\ 64.6 &amp; 50.4 &amp; 38.5 &amp; 24.1 &amp; 22.1 \\\\ 50.9 &amp; 35.2 &amp; 30.2 &amp; 22.6 &amp; 22.6 \\\\ 56.2 &amp; 49.9 &amp; 27.0 &amp; 32.7 &amp; 16.8 \\\\ 52.3 &amp; 42.6 &amp; 40.0 &amp; 24.4 &amp; 15.9 \\\\ 62.8 &amp; 41.6 &amp; 33.9 &amp; 29.6 &amp; 8.8 \\end{array} \\end{array} \\] El contrast que es volia realitzar era: \\(H_0\\): El percentatge mitjà d’increment del volum cel·lular d’un cultiu de P. fragi al cap d’una hora és el mateix per a totes les pressions de CO2 considerades. \\(H_1\\): El percentatge mitjà d’increment del volum cel·lular d’un cultiu de P. fragi al cap d’una hora depèn de la pressió de CO2 que en el nostre experiment traduïm en: \\(H_1\\): No és veritat que el percentatge mitjà d’increment del volum cel·lular d’un cultiu de P. fragi al cap d’una hora sigui el mateix per a totes les pressions de CO2 considerades És a dir: \\(H_1\\): Hi ha almenys dues d’aquestes pressions de CO2 sota les quals els percentatges mitjans d’increment del volum cel·lular d’un cultiu de P. fragi al cap d’una hora són diferents La hipòtesi alternativa en un contrast d’hipòtesis ha de ser complementària a la nul·la, sense que hi hagi cap opció intermèdia entre la nul·la i l’alternativa. D’aquesta manera, si no s’obté evidència de la hipòtesi alternativa, hem d’acceptar la nul·la. Amb aquesta idea al cap, observau que si la hipòtesi nul·la és “totes les mitjanes són iguals”, l’alternativa no pot ser “totes les mitjanes són diferents”, sinó hi ha almenys dues mitjanes que són diferents. Aquest experiment és un cas particulat del problema següent: Tenim \\(k&gt;2\\) poblacions. Volem decidir si la mitjana d’una certa variable aleatòria és la mateixa a totes aquestes poblacions, o no. Usualment, aquestes \\(k\\) poblacions seran subpoblacions d’una única població, definides per nivells d’un o diversos factors. Per exemple, a l’estudi del creixement del P. fragi, les poblacions que consideram estan totes formades per cultius d’aquest bacteri, i es diferencien en la pressió de CO2. En el context d’aquest tipus d’estudis, a aquests nivells els anomenam tractaments. És a dir, tornant a l’exemple anterior, els nivells de pressió de CO2 serien els tractaments que analitzam en aquest estudi. Per simplificar el llenguatge, sovint cometrem l’abús d’identificar una subpoblació d’aquestes amb el nivell, o tractament, que la defineix. D’aquesta manera, parlarem per exemple de la mitjana poblacional del tractament “0.29 atmosferes” per referir-nos a la mitjana de la població definida pel tractament “0.29 atmosferes”, és a dir, al percentatge mitjà d’increment del volum cel·lular en una hora d’un cultiu de P. fragi a 0.29 atmosferes de pressió de CO2. I de la mitjana mostral del tractament “0.29 atmosferes” per referir-nos a la mitjana de la nostra mostra de la població definida pel tractament “0.29 atmosferes”, és a dir, a la mitjana dels percentatges d’increment del volum cel·lular dels cultius de P. fragi a 0.29 atmosferes obtinguts en aquest experiment. Si diem \\(\\mu_1,\\ldots,\\mu_k\\) a les mitjanes d’aquesta variable en aquestes \\(k\\) poblacions, aquesta pregunta correspon al contrast: \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_1 =\\mu_2 =\\cdots =\\mu_k \\\\ H_1 : \\text{Hi ha }i,j\\text{ tals que } \\mu_i \\neq\\mu_j \\end{array} \\right. \\] Aleshores, prendrem una mostra aleatòria de cada població (una mostra estratificada de la població total, recordau?), i a partir d’aquestes mostres decidirem aquest contrast. Exemple 9.2 Continuem amb el nostre Exemple 9.1. Per a cada \\(\\ell=0,0.08,0.29,0.50,0.86\\), consideram la variable aleatòria \\(X_\\ell\\): “Percentatge de creixement del volum cel·lular en una hora d’un cultiu de P. fragi a \\(\\ell\\) atmòsferes de CO2”, de mitjana \\(\\mu_\\ell\\) Volem realitzar el contrast \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_0=\\mu_{0.08}=\\mu_{0.29}=\\mu_{0.50}=\\mu_{0.86} \\\\ H_1 : \\text{No totes aquestes mitjanes són iguals} \\end{array} \\right. \\] En temes anteriors, per comparar les mitjanes d’una variable sobre dues poblacions, calculàvem les mitjanes de dues mostres i les comparàvem. Per comparar les mitjanes de \\(k\\geqslant 3\\) poblacions, podríem fer-ho per parelles, però hauríem de fer \\(\\binom{k}{2}\\) contrastos i això augmenta la probabilitat d’error. A més, les hem de comparar totes amb totes, perquè podria passar que no poguéssim rebutjar que \\(\\mu_1= \\mu_2\\) ni que \\(\\mu_2= \\mu_3\\) però en canvi sí que poguéssim rebutjar que \\(\\mu_1= \\mu_3\\). El que volem és un test que ens digui en un sol pas si totes les mitjanes són iguals o no; si concloem que no, després ja cercarem quines mitjanes són diferents si volem. La tècnica més usual per efectuar aquest tipus de contrast és l’Anàlisi de la Variància o ANOVA (de l’anglès ANalysis Of VAriance; en llibres en castellà o català de vegades hi trobareu el terme ANDEVA, d’ANàlisi DE la VAriància, però no el farem servir, perquè trobam que sona més a marca de producte d’higiene íntima femenina que a tècnica estadística seriosa). L’ANOVA és tot un món, i té moltes variants segons el disseny de l’experiment que ha produït les dades: Segons quants factors emprem per separar la població en subpoblacions Segons com triem els nivells dels factors Segons com prenguem les mostres En aquest curs veurem els tres dissenys més bàsics: L’ANOVA d’1 via, que generalitza el test t de dues mitjanes a partir de dues mostres independents a \\(k\\) mitjanes de poblacions definides pels nivells d’un únic factor, a partir de \\(k\\) mostres independents L’ANOVA de blocs, que generalitza el test t de dues mitjanes a partir de dues mostres aparellades a \\(k\\) mitjanes de poblacions definides pels nivells d’un únic factor, a partir de \\(k\\) mostres aparellades L’ANOVA de 2 vies, que generalitza el test t de dues mitjanes a partir de dues mostres independents a més de dues mitjanes de poblacions definides per les combinacions de nivells de dos factors, a partir de mostres independents Recordau que en català “Anàlisi” és femení, mentre que en castellà “Análisis” és masculí. Per tant en català diem “una ANOVA” i en castellà “un ANOVA”. Expressau-vos bé, per favor. ANO…VA? Que no volíem comparar mitjanes? Idò com és que analitzam variàncies? L’estratègia per comparar les mitjanes de 3 o més poblacions serà fixar-nos en tres fonts de variabilitat, o dispersió, de les dades: La variabilitat total de les dades (respecte de la mitjana mostral global) La variabilitat dins cada mostra (respecte de la mitjana mostral corresponent) La variabilitat de les mitjanes mostrals (respecte de la mitjana mostral global) La idea és que si les mitjanes mostrals tenen molta variabilitat, ho prendrem com a senyal que les mitjanes poblacionals no poden ser totes iguals. Com ho mesurarem? Amb definicions adients de les “variabilitats”, resultarà que La variabilitat total de les dades és igual a la suma de la variabilitat de les mitjanes mostrals més la suma de les variabilitats dins les mostres. Aleshores, la idea bàsica anterior es tradueix en: Si la variabilitat total de les dades és molt més gran que la suma de les variabilitats dins les mostres, hi haurà una gran variabilitat de les mitjanes mostrals, i ho prendrem com a senyal que les mitjanes poblacionals no són iguals. Per exemple, si teniu molta variabilitat global i molt poca dins cada tractament serà evidència que les mitjanes poblacionals són diferents Si en canvi teniu molta variabilitat global però també molta dins cada tractament no podrem concloure que les mitjanes poblacionals siguin diferents. La pregunta és ara com quantificam aquestes variabilitats i com definim què significa “molt més gran”. Es tractarà de trobar un estadístic de contrast del qual en coneguem la distribució mostral si la hipòtesi nul·la és vertadera i que esperem que prengui un valor petit si la hipòtesi nul·la és vertadera. 9.2 ANOVA d’1 via 9.2.1 Contrast bàsic La situació és la següent. Tenim una variable aleatòria \\(X\\) i un (únic) factor, els \\(k\\) nivells (o tractaments) del qual classifiquen la població en \\(k\\) subpoblacions. Diguem \\(\\mu_i\\) a la mitjana de \\(X\\) en els individus del nivell \\(i\\)-èsim. Volem comparar aquestes mitjanes \\(\\mu_1\\),…,\\(\\mu_k\\) i en concret decidir si són totes iguals o no. En un experiment de disseny d’ANOVA d’1 via (en anglès, 1 way; el motiu d’aquest nom és que empram una única “manera” de classificar la població, en anglès one way que també es tradueix per “una via”, i així ha quedat el nom en les nostres llengües): S’empra un factor amb \\(k&gt;2\\) nivells per classificar una població en subpoblacions Es pren una m.a.s. de cada subpoblació, de manera independent les unes de les altres, i es mesura sobre tots els subjectes de les mostres la variable d’interès \\(X\\) Per exemple, l’experiment del nostre Exemple 9.1 té disseny d’ANOVA d’1 via: La variable \\(X\\) és el percentatge d’increment cel·lular en una hora d’un cultiu de P. fragi El factor emprat per classificar la població és la pressió de CO2: es consideren 5 nivells diferents, sota els quals es realitzen els cultius S’hi ha pres una m.a.s. per a cada nivell de pressió, i de manera independent les unes de les altres Ja que hi som, anam a organitzar les dades d’aquest experiment de manera adient. Les emmagatzemarem en un dataframe que anomenarem CO2 amb dues variables: Inc: Percentatge d’increment de la massa cel·lular (al cap d’una hora); una variable numèrica Pre: Nivell de pressió, com a factor De cara a fer-ho amb R, és important que recordeu que la variable que defineix les subpoblacions, en aquest cas la que dóna el nivell de pressió de CO2, sigui un factor. Les dades eren: \\[ \\begin{array}{c} \\text{Pressió de CO${}_2$ (en atmosferes)}\\\\ \\begin{array}{rrrrr} 0.0 &amp; 0.08 &amp; 0.29 &amp; 0.50 &amp; 0.86 \\\\\\hline 62.6 &amp; 50.9 &amp; 45.5 &amp; 29.5 &amp; 24.9 \\\\ 59.6 &amp; 44.3 &amp; 41.1 &amp; 22.8 &amp; 17.2 \\\\ 64.5 &amp; 47.5 &amp; 29.8 &amp; 19.2 &amp; 7.8 \\\\ 59.3 &amp; 49.5 &amp; 38.3 &amp; 20.6 &amp; 10.5 \\\\ 58.6 &amp; 48.5 &amp; 40.2 &amp; 29.2 &amp; 17.8 \\\\ 64.6 &amp; 50.4 &amp; 38.5 &amp; 24.1 &amp; 22.1 \\\\ 50.9 &amp; 35.2 &amp; 30.2 &amp; 22.6 &amp; 22.6 \\\\ 56.2 &amp; 49.9 &amp; 27.0 &amp; 32.7 &amp; 16.8 \\\\ 52.3 &amp; 42.6 &amp; 40.0 &amp; 24.4 &amp; 15.9 \\\\ 62.8 &amp; 41.6 &amp; 33.9 &amp; 29.6 &amp; 8.8 \\end{array} \\end{array} \\] Entrarem els increments per fileres (és més fàcil de copiar i aferrar), per tant el factor Pre ha d’estar format per 10 còpies consecutives del vector (0.0,0.08,0.29,0.50,0.86). Inc=c(62.6,50.9,45.5,29.5,24.9,59.6,44.3,41.1,22.8,17.2,64.5, 47.5,29.8,19.2,7.8,59.3,49.5,38.3,20.6,10.5,58.6,48.5, 40.2,29.2,17.8,64.6,50.4,38.5,24.1,22.1,50.9,35.2,30.2, 22.6,22.6,56.2,49.9,27.0,32.7,16.8,52.3,42.6,40.0,24.4, 15.9,62.8,41.6,33.9,29.6,8.8) Pre=as.factor(rep(c(&quot;0.0&quot;,&quot;0.08&quot;,&quot;0.29&quot;,&quot;0.50&quot;,&quot;0.86&quot;), times=10)) CO2=data.frame(Inc,Pre) str(CO2) ## &#39;data.frame&#39;: 50 obs. of 2 variables: ## $ Inc: num 62.6 50.9 45.5 29.5 24.9 59.6 44.3 41.1 22.8 17.2 ... ## $ Pre: Factor w/ 5 levels &quot;0.0&quot;,&quot;0.08&quot;,&quot;0.29&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... head(CO2,7) ## Inc Pre ## 1 62.6 0.0 ## 2 50.9 0.08 ## 3 45.5 0.29 ## 4 29.5 0.50 ## 5 24.9 0.86 ## 6 59.6 0.0 ## 7 44.3 0.08 Veiem que hem definit del dataframe com toca. Donem ara una ullada a les dades. Primer un diagrama de punts de cada nivell de CO2 (amb només 10 valors per nivell, és més adient dibuixar-los tots que resumir-los en diagrames de caixes): stripchart(Inc~Pre,data=CO2,xlab=&quot;Pressions&quot;,ylab=&quot;Increment&quot;,method=&quot;stack&quot;, vertical=TRUE,pch=20,cex=0.75) I ara un que mostri la variabilitat de les dades i les mitjanes com els del final de la secció anterior. Aquest gràfic normalment no el dibuixarem, simplement és per comparar-lo amb aquells gràfics. # Els paràmetres generals plot(1:50,c(CO2$Inc[CO2$Pre==&quot;0.0&quot;],CO2$Inc[CO2$Pre==&quot;0.08&quot;],CO2$Inc[CO2$Pre==&quot;0.29&quot;],CO2$Inc[CO2$Pre==&quot;0.50&quot;],CO2$Inc[CO2$Pre==&quot;0.86&quot;]),type=&quot;n&quot;,xlab=&quot;Número del cultiu&quot;,ylab=&quot;Increment&quot;) # Els punts points(1:10,CO2$Inc[CO2$Pre==&quot;0.0&quot;],pch=16,col=&quot;red&quot;) points(11:20,CO2$Inc[CO2$Pre==&quot;0.08&quot;],pch=15,col=&quot;blue&quot;) points(21:30,CO2$Inc[CO2$Pre==&quot;0.29&quot;],pch=17,col=&quot;green&quot;) points(31:40,CO2$Inc[CO2$Pre==&quot;0.50&quot;],pch=19,col=&quot;brown2&quot;) points(41:50,CO2$Inc[CO2$Pre==&quot;0.86&quot;],pch=18,col=&quot;brown&quot;) # La mitjana mostral global lines(c(0,50),c(mean(CO2$Inc),mean(CO2$Inc)),lwd=2) text(5,34,&quot;Mitjana global&quot;,cex=0.75) # Les mitjanes mostrals de les mostres lines(c(0,10),c(mean(CO2$Inc[CO2$Pre==&quot;0.0&quot;]),mean(CO2$Inc[CO2$Pre==&quot;0.0&quot;])),lwd=2,col=&quot;red&quot;) lines(c(10,20),c(mean(CO2$Inc[CO2$Pre==&quot;0.08&quot;]),mean(CO2$Inc[CO2$Pre==&quot;0.08&quot;])),lwd=2,col=&quot;blue&quot;) lines(c(20,30),c(mean(CO2$Inc[CO2$Pre==&quot;0.29&quot;]),mean(CO2$Inc[CO2$Pre==&quot;0.29&quot;])),lwd=2,col=&quot;green&quot;) lines(c(30,40),c(mean(CO2$Inc[CO2$Pre==&quot;0.50&quot;]),mean(CO2$Inc[CO2$Pre==&quot;0.50&quot;])),lwd=2,col=&quot;brown2&quot;) lines(c(40,50),c(mean(CO2$Inc[CO2$Pre==&quot;0.86&quot;]),mean(CO2$Inc[CO2$Pre==&quot;0.86&quot;])),lwd=2,col=&quot;brown&quot;) text(20,mean(CO2$Inc[CO2$Pre==&quot;0.0&quot;]),&quot;Mitjana del nivell 0.0&quot;,col=&quot;red&quot;,cex=0.75) text(30,mean(CO2$Inc[CO2$Pre==&quot;0.08&quot;]),&quot;Mitjana del nivell 0.083&quot;,col=&quot;blue&quot;,cex=0.75) text(40,mean(CO2$Inc[CO2$Pre==&quot;0.29&quot;]+2),&quot;Mitjana del nivell 0.29&quot;,col=&quot;green&quot;,cex=0.75) text(20,mean(CO2$Inc[CO2$Pre==&quot;0.50&quot;]),&quot;Mitjana del nivell 0.50&quot;,col=&quot;brown2&quot;,cex=0.75) text(30,mean(CO2$Inc[CO2$Pre==&quot;0.86&quot;]),&quot;Mitjana del nivell 0.86&quot;,col=&quot;brown&quot;,cex=0.75) Veiem que hi ha una gran dispersió dins la mostra completa, no massa dispersió dins cada mostra per nivell, i les mitjanes mostrals per nivells són bastant diferents. Naturalment, fins que no fem una anàlisi estadística no sabrem si aquestes variabilitats i diferències són estadísticament significatives o no. En un experiment amb disseny d’ANOVA d’1 via, disposarem les dades en una taula com la de l’Exemple anterior, amb les columnes representant els tractaments: \\[ \\begin{array}{c} \\text{Tractaments}\\\\ \\begin{array}{cccc} 1 &amp; 2 &amp;\\ldots &amp; k \\\\\\hline X_{11} &amp; X_{21} &amp; \\cdots &amp; X_{k1} \\\\ X_{12} &amp; X_{22} &amp; \\cdots &amp; X_{k2} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; X_{kn_k} \\\\ X_{1n_1} &amp; \\vdots &amp; \\vdots &amp; \\\\ &amp; X_{2n_2} &amp; &amp; \\\\\\hline \\end{array} \\end{array} \\] on Cada \\(n_i\\) és la mida de la mostra del tractament \\(i\\); com hem intentat representar a la taula, aquests \\(n_i\\) no tenen perquè ser tots iguals (però millor si ho són, perquè la potència d’un contrast ANOVA depèn del mínim d’aquests \\(n_i\\)) \\(X_{ij}\\) és el valor de la variable sota estudi al subjecte \\(j\\) del tractament \\(i\\) \\(N=n_1+\\cdots+n_k\\) és la mida total de la mostra ALERTA! Les notacions són diferents que les usuals a les matrius o a les taules de dades. A \\(X_{ij}\\), \\(i\\) hi indica la columna i \\(j\\) la filera. Fixau-vos que aquí no és veritat que cada filera representi un individu: en realitat cada columna pot tenir una alçada diferent. En aquesta taula cada \\(X_{ij}\\) representa un individu diferent. Perquè es pugui realitzar un contrast ANOVA d’1 via, s’han de satisfer les condicions següents: Les \\(k\\) mostres han de ser m.a.s. independents extretes de \\(k\\) poblacions específiques, amb mitjanes \\(\\mu_1,\\ldots,\\mu_k\\) \\(N\\geqslant k+1\\) (alguna mostra ha de tenir més d’un subjecte) Cadascuna de les \\(k\\) poblacions ha de seguir una llei normal Homogeneïtat de les variàncies, o homocedasticitat: Totes aquestes poblacions han de tenir la mateixa variància, que indicarem amb \\(\\sigma^2\\) No basten mostres grans. Aquí no hi juga cap paper el Teorema Central del Límit. Però, per sort, les conclusions d’una ANOVA són bastant robustes encara que falli la condició de normalitat de les subpoblacions. En canvi són molt sensibles a l’heterocedasticitat (el contrari d’homocedasticitat; “hetero” indica el contrari de “homo”). Donades diverses variables, hi tenim homocedasticitat quan totes tenen la mateixa variància, i heterocedasticitat quan no totes tenen la mateixa variància. Fixau-vos que ens referim a les variàncies de les poblacions, no de les mostres. Per exemple, les tres mostres del gràfic de l’esquerra següent provenen de variables normals amb la mateixa variància, representades al gràfic de la dreta: hi ha homocedasticitat: En canvi, al gràfic següent dues mostres provenen de variables normals amb la mateixa variància, però la tercera prové d’una normal amb una variància molt més gran: hi ha heterocedasticitat: L’homocedasticitat no és que les mostres dels tractaments tenguin la mateixa variància, sinó que els tractaments tenguin la mateixa variància poblacional. Diguem \\(\\mu\\) a la mitjana poblacional de la població global (sense tenir en compte la classificació donada pels tractaments). Recordau que la hipòtesi nul·la del contrast que volem realitzar és \\[ H_0: \\mu_1=\\cdots=\\mu_k \\] Si és vertadera, aleshores en realitat passarà que \\[ \\mu_1=\\cdots=\\mu_k=\\mu \\] perquè si totes les subpoblacions tenen la mateixa mitjana, aquesta mitjana comuna serà la mitjana de tota la població. En aquest tema és el primer cop que tenim ocasió de parlar de models estadístics. Informalment, un model no és res més que una descripció matemàtica del comportament d’una o vàries variables aleatòries sobre una població. Aquests models inclouen assumpcions sobre la població que poden ser veritat o no, i que si no ho són aleshores les conclusions de l’anàlisi estadística que fem basant-nos en aquest model no tendran cap sentit. En concret, l’ANOVA d’1 via es basa en el model següent: per a cada \\(i=1,\\ldots,k\\), \\[ X_i=\\mu+(\\mu_i-\\mu)+(X_i-\\mu_i) \\] on: \\(X_i\\) representa el valor de la variable \\(X\\) sobre un individu del nivell \\(i\\)-èsim \\(\\mu_i-\\mu\\) representa la desviació de la mitjana de \\(X\\) en el nivell \\(i\\)-èsim respecte de la mitjana global \\(\\mu\\); en direm l’efecte del tractament \\(i\\)-èsim i representa la contribució al valor de \\(X\\) sobre un individu del nivell \\(i\\)-èsim del fet de pertànyer a aquest nivell \\(X_i-\\mu_i\\), la desviació de la variable \\(X\\) sobre un individu del nivell \\(i\\)-èsim respecte de la mitjana d’aquest nivell, \\(\\mu_i\\), representa el component aleatori en una medició concreta de \\(X\\) sobre un individu del nivell \\(i\\)-èsim, és a dir, “la part de la diferència entre \\(X_{i}\\) i \\(\\mu\\) que no explica el tractament”; en diem l’error aleatori, o el residu. Fixau-vos que la fórmula que descriu aquest model és sempre veritat (podeu simplificar les \\(\\mu_i\\) i les \\(\\mu\\) de la dreta), i bàsicament diu que el valor de \\(X\\) sobre un individu és la suma de tres components: La mitjana global L’efecte del tractament L’error aleatori i en particular que res més no influeix en el valor de \\(X\\) sobre un individu. Per tant, si això no és veritat, és a dir, si aquest valor pot dependre d’altres efectes que no tinguem en compte, el model no és vàlid, i les conclusions de l’ANOVA tampoc. Passem ara a la mostra amb la que volem realitzar el contrast. Siguin: \\(\\overline{X}_{i}\\): Mitjana mostral de la mostra del tractament \\(i\\)-èsim: \\[ \\overline{X}_{i} = \\frac{\\sum_{j=1}^{n_i} X_{ij}}{n_i} \\] Estima la mitjana \\(\\mu_i\\) de la subpoblació definida pel tractament \\(i\\)-èsim \\(\\overline{X}\\): Mitjana mostral de tota la mostra: \\[ \\overline{X}=\\frac{\\sum_{i=1}^k \\sum_{j=1}^{n_i} X_{ij}}{N} \\] Estima la mitjana \\(\\mu\\) de la població global Es té la identitat següent: Teorema 9.1 (Identitat de les sumes de quadrats) \\[ SS_{Total}=SS_{Tr}+SS_E \\] on \\(SS_{Total}=\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^{n_i} (X_{ij}-\\overline{X})^2\\); és la Suma Total de Quadrats \\(SS_{Tr}=\\displaystyle\\sum_{i=1}^k n_i(\\overline{X}_{i}-\\overline{X})^2\\); és la Suma de Quadrats dels Tractaments \\(SS_E=\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^{n_i} (X_{ij}-\\overline{X}_{i})^2\\); és la Suma de Quadrats dels Residus o dels Errors Fixau-vos que \\(SS_{Total}\\) representa la variabilitat total de les dades: de fet, és el numerador de la variància de la mostra total \\(SS_{Tr}\\) representa la variabilitat de les mitjanes: és molt semblant al que seria el numerador de la variància d’un vector format per \\(n_1\\) còpies de \\(\\overline{X}_1\\), \\(n_2\\) còpies de \\(\\overline{X}_2\\), …, \\(n_k\\) còpies de \\(\\overline{X}_k\\) (i seria aquest numerador si \\(n_1=\\cdots=n_k\\)) \\(SS_E\\) representa la suma de les variabilitats de les dades de la mostra de cada tractament: de fet, és la suma dels numeradors de les variàncies de les \\(k\\) mostres dels diferents tractaments \\(SS_{Total}=SS_{Tr}+SS_E\\) diu que la variabilitat total de la mostra descompon en la suma de la variabilitat de les mitjanes i la suma de les variabilitats de les mostres de cada tractament Fixau-vos que, amb la terminologia introduïda quan explicàvem el model de l’ANOVA d’1 via, cada \\(X_{ij}-\\mu_i\\) estima el residu, o error, sobre l’individu \\(j\\)-èsim del nivell \\(i\\)-èsim. Per això a \\(\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^{n_i} (X_{ij}-\\overline{X}_{i})^2\\) li diem la Suma de Quadrats dels Residus o dels Errors. Exemple 9.3 Tornem al nostre Exemple 9.1. Tenim les dades guardades en el dataframe CO2 str(CO2) ## &#39;data.frame&#39;: 50 obs. of 2 variables: ## $ Inc: num 62.6 50.9 45.5 29.5 24.9 59.6 44.3 41.1 22.8 17.2 ... ## $ Pre: Factor w/ 5 levels &quot;0.0&quot;,&quot;0.08&quot;,&quot;0.29&quot;,..: 1 2 3 4 5 1 2 3 4 5 ... Aleshores: Les mitjanes mostrals dels tractaments, \\(\\overline{X}_{i}\\), es calculen amb mitjanes.tracts=aggregate(Inc~Pre,data=CO2,mean) mitjanes.tracts ## Pre Inc ## 1 0.0 59.14 ## 2 0.08 46.04 ## 3 0.29 36.45 ## 4 0.50 25.47 ## 5 0.86 16.44 La mitjana mostral global, \\(\\overline{X}\\), és: mitjana.total=mean(CO2$Inc) mitjana.total ## [1] 36.708 La \\(SS_{Total}=\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^{n_i} (X_{ij}-\\overline{X})^2\\) és SSTotal=sum((CO2$Inc-mitjana.total)^2) SSTotal ## [1] 12522.36 Per calcular \\[ SS_{Tr}=\\displaystyle\\sum_{i=1}^k n_i(\\overline{X}_{i}-\\overline{X})^2 \\] hem d’observar que les mitjanes \\(\\overline{X}_{i}\\) formen la variable Inc del dataframe mitjanes.tracts i els \\(n_i\\) són les freqüències absolutes de cada nivell dins la variable CO2$Pre. SSTr=sum(table(CO2$Pre)*(mitjanes.tracts$Inc-mitjana.total)^2) SSTr ## [1] 11274.32 Per calcular \\[ SS_E=\\displaystyle\\sum_{i=1}^k\\sum_{j=1}^{n_i} (X_{ij}-\\overline{X}_{i})^2 \\] podem fixar-nos que, tal i com hem construït el dataframe CO2, les entrades de CO2$Inc que difereixen en un múltiple de 5 són del mateix tractament; per exemple, les entrades que corresponen a pressió 0 són la 1a, la 6a, la 11a etc.; les entrades que corresponen a pressió 0.83 són la 2a, la 7a, la 12a etc.; i així successivament. Per tant, si fem CO2$Inc-mitjanes.tracts$Inc, com que la longitud de CO2$Inc és 10 vegades la de mitjanes.tracts$Inc, el que estarem dient és que a CO2$Inc se li resti un vector format per 10 còpies consecutives de mitjanes.tracts$Inc, i d’aquesta manera justament a cada entrada de CO2$Inc se li restarà l’entrada de mitjanes.tracts$Inc que és la mitjana del seu tractament. Per tant, \\(SS_E\\) es pot calcular amb SSE=sum((CO2$Inc-mitjanes.tracts$Inc)^2) SSE ## [1] 1248.038 Comprovem la identitat de les sumes de quadrats: SSTotal ## [1] 12522.36 SSTr+SSE ## [1] 12522.36 La idea del contrast ANOVA és que Rebutjam la hipòtesi nul·la si \\(SS_{Tr}\\) és prou gran Per la identitat de les sumes de quadrats \\(SS_{Total}=SS_{Tr}+SS_E\\), això ho podem traduir en Rebutjam la hipòtesi nul·la si \\(SS_{Total}\\) és molt més gran que \\(SS_E\\) I això en realitat ho traduïm en Rebutjam la hipòtesi nul·la si \\(SS_{Tr}\\) és prou més gran que \\(SS_E\\) Per mesurar-ho emprarem els estadístics següents: Quadrat mitjà dels tractaments: \\[ MS_{Tr}=\\frac{SS_{Tr}}{k-1} \\] Quadrat mitjà residual: \\[ MS_E=\\frac{SS_E}{N-k} \\] Aquests estadístics són variables aleatòries, i sota les condicions necessàries per poder fer una ANOVA (mostres aleatòries simples independents, variable poblacional normal per a cada tractament, homocedasticitat), satisfan que \\(E(MS_{Tr})=\\displaystyle\\sigma^2 + \\sum_{i=1}^k \\frac{n_i (\\mu_i-\\mu)^2}{k-1}\\) \\(E(MS_E)=\\sigma^2\\) En particular, es pot usar \\(MS_E\\) per estimar la variància poblacional comuna \\(\\sigma^2\\) de tots els tractaments. Ara, si \\(H_0:\\mu_1=\\cdots=\\mu_k (=\\mu)\\) és certa, \\[ \\sum_{i=1}^k \\frac{n_i (\\mu_i -\\mu)^2}{k-1}=0, \\] i si \\(H_0\\) no és certa, aquesta quantitat és \\(&gt;0\\) Per tant Si \\(H_0\\) és certa, \\(E(MS_E)=E(MS_{Tr})\\) i per tant hauríem d’esperar que aquests dos estadístics tinguessin valors propers, és a dir, hauríem d’esperar que \\[ \\frac{MS_{Tr}}{MS_E}\\approx 1 \\] Si \\(H_0\\) és falsa, \\(E(MS_E)&lt;E(MS_{Tr})\\) i hauríem d’esperar que \\(MS_{Tr}\\) donàs valors més grans que \\(MS_E\\), és a dir, hauríem d’esperar que \\[ \\frac{MS_{Tr}}{MS_E}&gt; 1 \\] Aleshores, prenem com a estadístic de contrast el quocient \\[ F=\\frac{MS_{Tr}}{MS_E} \\] el qual satisfà la propietat següent. Teorema 9.2 Sota les condicions necessàries per poder realitzar una ANOVA i si \\(H_0:\\mu_1=\\cdots=\\mu_k\\) és certa, La distribució de \\(F\\) és una F de Fisher amb \\(k-1\\) i \\(N-k\\) graus de llibertat, \\(F_{k-1,N-k}\\) El seu valor és proper a 1 Per tant, en una ANOVA rebutjarem la hipòtesi nul·la si el valor \\(F_0\\) de \\(F\\) obtingut sobre la nostra mostra és molt gran. Això ho traduirem en que rebutjarem la hipòtesi nul·la si la probabilitat que \\(F\\) sigui més gran que \\(F_0\\) és petita, i aquesta probabilitat serà el p-valor del contrast. Si \\(k=2\\), aquesta \\(F\\) és igual al quadrat de l’estadístic del test t de 2 mostres independents i variàncies iguals. Per tant, efectuar una ANOVA d’1 via amb només 2 tractaments és equivalent a efectuar un test t amb mostres independents i mateixa variància poblacional. Per si qualcú necessita una dosi d’àlgebra, recordau que el quadrat de l’estadístic del test t de 2 mostres independents i variàncies iguals és \\[ T^2=\\frac{(\\overline{X}_1-\\overline{X}_2)^2}{(\\frac{1}{n_1}+\\frac{1}{n_2})\\cdot \\frac{(n_1-1)\\widetilde{S}_1^2+(n_2-1)\\widetilde{S}_2^2}{n_1+n_2-2}} \\] i que el nostre \\(F\\) és \\(MS_{Tr}/MS_E\\). Ara, en el cas \\(k=2\\), \\[ MS_E=\\frac{\\sum_{j=1}^{n_1}(X_{1j}-\\overline{X}_1)^2+\\sum_{j=1}^{n_2}(X_{2j}-\\overline{X}_2)}{N-2}= \\frac{(n_1-1)\\widetilde{S}_{X_1}+(n_2-1)\\widetilde{S}_{X_2}}{n_1+n_2-2} \\] que surt al denominador de \\(T^2\\). Per tant ens queda veure que \\(MS_{Tr}\\) és igual a \\[ \\frac{(\\overline{X}_1-\\overline{X}_2)^2}{\\frac{1}{n_1}+\\frac{1}{n_2}} \\] Per simplificar, diguem \\(S_1=n_1\\overline{X}_1=\\sum_{j=1}^{n_1} X_{1j}\\), \\(S_2=n_2\\overline{X}_2=\\sum_{j=1}^{n_2} X_{2j}\\) i \\[ S=(n_1+n_2)\\overline{X}=\\sum_{i=1}^2\\sum_{j=1}^{n_i} X_{ij}=S_1+S_2=n_1\\overline{X}_1+n_2\\overline{X}_2. \\] Doncs va, desenvolupem \\(MS_{Tr}\\) en aquest cas \\(k=2\\): \\[ \\begin{array}{rl} MS_{Tr} &amp; \\displaystyle = \\frac{n_1(\\overline{X}_1-\\overline{X})^2+n_2(\\overline{X}_2-\\overline{X})^2}{1}\\\\ &amp; \\displaystyle = n_1\\overline{X}_1^2-2n_1\\overline{X}_1\\overline{X}+n_1\\overline{X}^2+ n_2\\overline{X}_2^2-2n_2\\overline{X}_2\\overline{X}+n_2\\overline{X}^2\\\\ &amp; \\displaystyle = S_1\\overline{X}_1+S_2\\overline{X}_2-2S_1\\overline{X}-2S_2\\overline{X}+(n_1+n_2)\\overline{X}^2\\\\ &amp; \\displaystyle =S_1\\overline{X}_1+S_2\\overline{X}_2-2(S_1+S_2)\\overline{X}+(S_1+S_2)\\overline{X}\\\\ &amp; \\displaystyle =S_1\\overline{X}_1+S_2\\overline{X}_2-(S_1+S_2)\\overline{X}\\\\ &amp; \\displaystyle = S_1\\overline{X}_1+S_2\\overline{X}_2 -\\frac{(S_1+S_2)(n_1\\overline{X}_1+n_2\\overline{X}_2)}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{(n_1+n_2)S_1\\overline{X}_1+(n_1+n_2)S_2\\overline{X}_2-n_1S_1\\overline{X}_1-n_1S_2\\overline{X}_1-n_2S_1\\overline{X}_2-n_2S_2\\overline{X}_2}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{n_2S_1\\overline{X}_1+n_1S_2\\overline{X}_2-n_1S_2\\overline{X}_1-n_2S_1\\overline{X}_2}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{n_2n_1\\overline{X}_1^2+n_1n_2\\overline{X}_2^2-n_1n_2\\overline{X}_2\\overline{X}_1-n_2n_1\\overline{X}_1\\overline{X}_2}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{n_1n_2(\\overline{X}_1^2+\\overline{X}_2^2-2\\overline{X}_1\\overline{X}_2)}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{n_1n_2(\\overline{X}_1-\\overline{X}_2^2}{n_1+n_2}\\\\ &amp; \\displaystyle =\\frac{(\\overline{X}_1-\\overline{X}_2)^2}{\\frac{n_1+n_2}{n_1n_2}}\\\\ &amp; \\displaystyle =\\frac{(\\overline{X}_1-\\overline{X}_2)^2}{\\frac{1}{n_1}+\\frac{1}{n_2}} \\end{array} \\] En resum, per realitzar una ANOVA d’1 via a partir d’una mostra: Calculam les sumes de quadrats \\[ SS_{Tr},\\ SS_E \\] Calculam els quadrats mitjans \\[ MS_{Tr}=\\frac{SS_{Tr}}{k-1},\\ MS_E=\\frac{SS_E}{N-k} \\] Calculam l’estadístic de contrast sobre la nostra mostra \\[ F_0=\\frac{MS_{Tr}}{MS_E} \\] Calculam el p-valor \\[ P(F_{k-1,N-k}\\geqslant F_0) \\] Si el p-valor és més petit que el nivell de significació \\(\\alpha\\), rebutjam \\(H_0\\) i concloem que no totes les mitjanes són iguals. En cas contrari, acceptam que totes les mitjanes són iguals. Exemple 9.4 Continuem amb el nostre Exemple 9.1. Ja sabem que \\(N=50\\), \\(k=5\\), \\(SS_{Total}=12522.36\\), \\(SS_{Tr}=11274.32\\) i \\(SS_E=1248.038\\). Els quadrats mitjans són: N=50 k=5 MSTr=SSTr/(k-1) MSTr ## [1] 2818.58 MSE=SSE/(N-k) MSE ## [1] 27.73418 L’estadístic de contrast val: F0=MSTr/MSE F0 ## [1] 101.6284 El p-valor \\(P(F_{k-1,N-k}\\geqslant F_0)\\) val 1-pf(F0,k-1,N-k) ## [1] 0 Conclusió: Hem trobat evidència estadística que el nivell de pressió de CO2 influeix en el creixement mitjà del microorganisme Pseudomonas fragi (ANOVA, p-valor 0). Per ara només concloem que no totes les mitjanes (dels percentatges d’increment de volum cel·lular) són iguals: no concloem que totes aquestes mitjanes siguin diferents. No és el mateix! Un contrast ANOVA d’1 via se sol resumir en la taula ANOVA següent: \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; k-1 &amp; SS_{Tr}&amp; MS_{Tr} &amp; F &amp; \\text{p-valor} \\\\ \\text{Residus} &amp; N-k &amp; SS_E &amp; MS_E &amp; \\\\\\hline \\end{array} \\] Així, la taula de l’ANOVA de l’Exemple 9.1 és \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; 4 &amp; 11274.32&amp; 2818.58 &amp; 101.63 &amp; 0 \\\\ \\text{Residus} &amp; 45 &amp; 1248.04 &amp; 27.73 &amp; \\\\\\hline \\end{array} \\] En aquesta taula, a banda de l’estadístic de contrast i el p-valor, ens pot interessar el valor del \\(MS_E\\), que estima la variància comuna de tots els tractaments. En el nostre exemple, (si se satisfan les condicions per poder efectuar una ANOVA d’1 via) estimam que les variables que ens donen els percentatges d’increment en 1 hora de les poblacions de P. fragi sota les diferents pressions de CO2 considerades tenen totes variància (poblacional) 27.73. Vegem un altre exemple. Exemple 9.5 Disposam de quatre tractaments genètics diferents, numerats de l’1 al 4, per corregir un cert gen defectuós responsable d’una malaltia. Els investigadors volen saber si els quatre tractaments tenen una eficàcia similar o no. Per contrastar-ho, en un assaig clínic es varen prendre 20 pacients amb aquesta malaltia, els repartiren aleatòriament en 4 grups de 5 malalts cadascun, i assignaren de forma aleatòria un dels quatre tractaments a cada grup. Després d’aplicar el tractament, es va mesurar a cada pacient l’expressió del gen defectuós sota estudi. Les dades obtingudes varen ser \\[ \\begin{array}{c} \\text{Tractament}\\\\ \\begin{array}{llll} 1 &amp; 2 &amp; 3 &amp; 4 \\\\ \\hline 96 &amp; 93 &amp; 70 &amp; 78 \\\\ 99 &amp; 90 &amp; 90 &amp; 87 \\\\ 100 &amp; 75 &amp; 84 &amp; 57 \\\\ 104 &amp; 80 &amp; 76 &amp; 66 \\\\ 84 &amp; 90 &amp; 78 &amp; 76 \\end{array} \\end{array} \\] Aquest experiment té disseny d’ANOVA d’1 via: La variable \\(X\\) és l’expressió del gen defectuós El factor emprat per classificar les expressions té per nivells els 4 tractaments objecte d’estudi S’hi ha pres una m.a.s. per a cada tractament, i de manera independent les unes de les altres Efectuau a mà l’ANOVA d’1 via d’aquestes dades. Els resultats parcials us haurien de donar: \\(N=20\\), \\(k=4\\), Les mitjanes: \\(\\overline{X}_{1}=96.6\\), \\(\\overline{X}_{2}=85.6\\), \\(\\overline{X}_{3}=79.6\\), \\(\\overline{X}_{4}=72.8\\), \\(\\overline{X}=83.65\\) Les sumes de quadrats: \\(SS_{Total}=2766.55\\), \\(SS_{Tr}=1528.15\\), \\(SS_E=1238.4\\) Els quadrats mitjans: \\(MS_{Tr}=509.4\\), \\(MS_{E}=77.4\\) L’estadístic de contrast, \\(F_0=6.6\\) El p-valor: \\(P(F_{3,16}&gt;6.6)=\\texttt{1-pf(6.6,3,16)}=0.004\\) La taula de l’ANOVA \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; 3&amp; 1528.15 &amp; 509.4 &amp; 6.6 &amp; 0.004 \\\\ \\text{Residus} &amp; 16 &amp; 1238.4 &amp; 77.4 &amp; \\\\\\hline \\end{array} \\] Conclusió: Hem trobat evidència estadísticament significativa que les quatre teràpies no tenen totes la mateixa eficàcia mitjana (ANOVA, p-valor 0.004). 9.2.2 Amb R Per realitzar una ANOVA, s’aplica la funció summary(aov( )) a la fórmula que separa les dades numèriques segons els nivells del factor (ha de ser un factor o, a partir de la versió 4.0 de R, un vector de paraules). Si la fórmula només especifica els noms de les variables, s’hi ha d’indicar el nom del dataframe amb el paràmetre data. Per exemple, l’ANOVA de l’Exemple 9.1 s’obté amb summary(aov(CO2$Inc~CO2$Pre)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## CO2$Pre 4 11274 2818.6 101.6 &lt;2e-16 *** ## Residuals 45 1248 27.7 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 o, equivalentment, amb summary(aov(Inc~Pre,data=CO2)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Pre 4 11274 2818.6 101.6 &lt;2e-16 *** ## Residuals 45 1248 27.7 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 D’aquesta manera obtenim la taula de l’ANOVA que hem explicat fa una estona. La primera filera, Pre, correspon als tractaments, que són els nivells del factor Pre de CO2. El valor de Pr(&gt; F) és el p-valor del contrast. Exemple 9.6 Per realitzar l’ANOVA de l’Exemple 9.5, primer hem d’entrar les dades en un dataframe. Un altre cop, entrarem les dades per fileres i per tant els indicadors dels tractaments s’han d’entrar com el vector (1,2,3,4) repetit 5 vegades. Expr=c(96,93,70,78,99,90,90,87,100,75,84,57,104,80,76,66,84,90,78,76) Tract=rep(1:4,5) EG=data.frame(Expr,Tract) str(EG) ## &#39;data.frame&#39;: 20 obs. of 2 variables: ## $ Expr : num 96 93 70 78 99 90 90 87 100 75 ... ## $ Tract: int 1 2 3 4 1 2 3 4 1 2 ... summary(aov(Expr~Tract,data=EG)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Tract 1 1498 1497.7 21.25 0.000218 *** ## Residuals 18 1269 70.5 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 No ha donat el mateix p-valor que quan l’hem fet a mà! No hem entrat els tractaments com un factor. Fixau-vos que el nombre de graus de llibertat a la filera dels tractaments en aquesta taula és 1 i no 3, que és el que tocaria. Va, fem-ho bé: Expr=c(96,93,70,78,99,90,90,87,100,75,84,57,104,80,76,66,84,90,78,76) Tract=as.factor(rep(1:4,5)) EG=data.frame(Expr,Tract) str(EG) ## &#39;data.frame&#39;: 20 obs. of 2 variables: ## $ Expr : num 96 93 70 78 99 90 90 87 100 75 ... ## $ Tract: Factor w/ 4 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;: 1 2 3 4 1 2 3 4 1 2 ... head(EG) ## Expr Tract ## 1 96 1 ## 2 93 2 ## 3 70 3 ## 4 78 4 ## 5 99 1 ## 6 90 2 summary(aov(Expr~Tract,data=EG)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Tract 3 1528 509.4 6.581 0.00417 ** ## Residuals 16 1238 77.4 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Ara sí que hem obtingut el mateix. 9.2.3 Comparacions posteriors per parelles Si hem rebutjat la hipòtesi nul·la \\(H_0:\\mu_1=\\cdots =\\mu_k\\), podem demanar-nos quins són els tractaments que donen mitjanes diferents. Això es pot fer de diverses maneres, aquí veurem la més “òbvia”: comparar totes les parelles de mitjanes per mitjà de tests t. És a dir, per a cada parell de tractaments, realitzar el contrast \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_i=\\mu_j \\\\ H_1 : \\mu_i\\neq\\mu_j \\end{array} \\right. \\] L’estadístic que fem servir en cada un d’aquests contrastos és ara \\[ T=\\frac{\\overline{X}_{i} - \\overline{X}_{j}}{\\sqrt{{MS_E}\\cdot (\\frac{1}{n_i} +\\frac{1}{n_j})}} \\] que, si la hipòtesi nul·la d’aquest contrast és vertadera, segueix una distribució \\(t\\) de Student amb \\(N-k\\) graus de llibertat, \\(t_{N-k}\\). Tots aquests contrastos per parelles serien tests t amb mostres independents i la mateixa variància. Per ventura alguns recordeu que la fórmula que us hem explicat al tema de Contrastos paramètrics per a aquests tests no és aquesta, sinó \\[ T=\\frac{\\overline{X}_i-\\overline{X}_j}{\\sqrt{ \\frac{(n_i-1)\\widetilde{S}_i^2+(n_j-1)\\widetilde{S}_j^2}{n_i+n_j-2}\\cdot \\Big(\\frac{1}{n_i}+\\frac{1}{n_j}\\Big)}} \\] que, si \\(\\mu_i=\\mu_j\\) és vertadera, té distribució \\(t_{n_i+n_j-2}\\). En aquesta fórmula, el factor \\[ \\frac{(n_i-1)\\widetilde{S}_i^2+(n_j-1)\\widetilde{S}_j^2}{n_i+n_j-2} \\] dins l’arrel quadrada del denominador estima la variància comuna de \\(X_i\\) i \\(X_j\\). Però en una ANOVA tenim més dades (les mostres de tots els tractaments, no només d’una parella) i les podem emprar totes per estimar la variància comuna de tots els tractaments. Com ja hem dit quan parlàvem de la distribució dels Quadrats Mitjans, aquesta estimació és \\(MS_E\\), que és el que apareix ara dins l’arrel quadrada del denominador. I com que hem emprat totes les dades que tenim per estimar aquesta variància, i no només les de dues mostres, també canvia el nombre de graus de llibertat. El p-valor de cada contrast serà \\(2P(t_{N-k}\\geqslant|t_{i,j}|)\\), on \\(t_{i,j}\\) és el valor que hi pren aquest estadístic \\(T\\). Ara bé, observau que d’aquesta manera realitzam \\(\\binom{k}{2}\\) contrastos. Com més contrastos fem, més probabilitat tenim d’equivocar-nos. Si es realitzen \\(c\\) contrastos amb nivell de significació \\(\\alpha\\), la probabilitat d’Error de Tipus I a qualcun és més gran que \\(\\alpha\\): de fet, és \\(1-(1-\\alpha)^c\\). Per exemple, a l’Exemple 9.1, si realitzam els \\(c=\\binom{5}{2}=10\\) contrastos (totes les pressions contra totes les pressions) amb nivell de significació \\(\\alpha =0.05\\), la probabilitat de cometre almenys un Error de Tipus I a qualcun (si totes les mitjanes fossin iguales en la realitat) és \\(1-(1-0.05)^{10} \\approx 0.4\\). Per tant, haurem de reduir el nivell de significació de cada contrast per que la probabilitat global de cometre qualque Error de Tipus I sigui \\(\\alpha\\). O, equivalentement, augmentar (s’en diu ajustar) el p-valor de cada contrast abans de comparar-lo amb l’\\(\\alpha\\) global fixat. Tot seguit explicam dos d’aquests mètodes d’ajust de p-valors. 9.2.3.1 Mètode de Bonferroni El mètode d’ajust de p-valors més popular és el de Bonferroni. Emprant que \\(1-(1-x)^c \\leqslant c\\cdot x\\), si volem efectuar \\(c\\) contrastos amb nivell de significació (global) \\(\\alpha\\), realitzam cada contrast amb nivell de significació \\(\\alpha/c\\) i així el nivell de significació global segur que serà menor o igual que \\(c\\cdot \\alpha/c=\\alpha\\). O, equivalentment multiplicam el p-valor de cada contrast per \\(c\\) abans de comparar-lo amb el nivell de significació \\(\\alpha\\) Les dues accions són equivalents, perquè \\[ p&lt;\\alpha/c \\Longleftrightarrow c\\cdot p&lt;\\alpha \\] Bé, gairebé equivalents. Si quan multiplicau un dels p-valors per \\(c\\) us dóna un valor més gran que 1, heu de donar com a p-valor ajustat 1. Pensau que, ajustats o no, els p-valors representen probabilitats, i per tant no poden ser més grans que 1. Exemple 9.7 A l’Exemple 9.1, si realitzam els 10 contrastos per parelles, per obtenir un nivell de significació global \\(\\alpha =0.05\\) amb el mètode de Bonferroni, Hem de efectuar cada contrast amb nivell de significació 0.05/10=0.005 o equivalentment Hem de multiplicar cada p-valor per 10 i comparar-los amb 0.05 A l’Exemple 2, si realitzam els 6 contrastos de totes les parelles possibles, per obtenir un nivell de significació global \\(\\alpha =0.05\\), Hem de efectuar cada contrast amb nivell de significació 0.05/6=0.0083 o equivalentment Hem de multiplicar cada p-valor per 6 Amb R, Per calcular tots els p-valors de cop (sense ajustar) podem emprar la funció pairwise.t.test(variable numèrica, factor, p.adjust.method=&quot;none&quot;) Per calcular tots els p-valors ajustats amb qualque mètode, s’ha d’especificar al paràmetre p.adjust.method. Per exemple, per ajustar-los amb el mètode de Bonferroni, s’hauria d’entrar p.adjust.method=&quot;bonferroni&quot; (fixau-vos que bonferroni hi va entre cometes i començant amb minúscula). Exemple 9.8 Tornem a l’Exemple 9.5. Per obtenir tots els p-valors, que després nosaltres haurem de comparar amb \\(\\alpha/6\\), executam pairwise.t.test(EG$Expr,EG$Tract, p.adjust.method=&quot;none&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: EG$Expr and EG$Tract ## ## 1 2 3 ## 2 0.06554 - - ## 3 0.00756 0.29688 - ## 4 0.00058 0.03522 0.23937 ## ## P value adjustment method: none Per obtenir tots els p-valors ajustats segons Bonferroni, que després nosaltres haurem de comparar amb \\(\\alpha\\), entram pairwise.t.test(EG$Expr,EG$Tract,p.adjust.method=&quot;bonferroni&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: EG$Expr and EG$Tract ## ## 1 2 3 ## 2 0.3933 - - ## 3 0.0453 1.0000 - ## 4 0.0035 0.2113 1.0000 ## ## P value adjustment method: bonferroni Podeu comprovar que els p-valors d’aquest segon resultat són els del primer resultat multiplicats per 6 (llevat d’arrodoniments i dels 1 que poden representar resultats més grans que 1). Suposem que fixam el nivell de significació global usual \\(\\alpha=0.05\\). En la primera execució de pairwise.t.test, els únics p-valors per davall de \\(0.05/6=0.0083\\) han estat els dels parells (1,3) i (1,4). En la segona, els únics p-valors per davall de 0.05 han estat també els dels parells (1,3) i (1,4). Casualitat? No, havien de coincidir les conclusions, perquè les dues tècniques són equivalents. Conclusió: Hem trobat evidència estadísticament significativa que la teràpia 1 té una eficàcia mitjana diferent de la de les teràpies 3 i 4 (ANOVA d’1 via, test posterior de Bonferroni, p-valors 0.0453 i 0.0035, respectivament), i no trobam evidència estadísticament significativa de cap altra diferència en les eficàcies mitjanes. 9.2.3.2 Mètode de Holm Un altre mètode popular d’ajust de p-valors, més potent que el de Bonferroni, i que de fet és el mètode que empra R per defecte és el mètode de Holm, que funciona bàsicament de la forma següent: Siguin \\(C_{1},\\ldots ,C_{c}\\) els contrastos per parelles que es volen realitzar i \\(p_{1},\\ldots ,p_{c}\\) els p-valors corresponents Ordenam aquests p-valors en ordre creixent \\(p_{(1)}&lt; \\cdots&lt; p_{(c)}\\) i reenumeram consistentment els contrastos \\(C_{(1)},\\ldots, C_{(c)}\\) Per a cada \\(j=1,\\ldots,c\\), calculam el p-valor ajustat \\(\\widetilde{p}_{(j)}=(c+1-j)\\cdot p_{(j)}\\) Aleshores rebutjam la hipòtesi nul·la als contrastos \\(C_{(j)}\\) on \\(\\widetilde{p}_{(j)}&lt;\\alpha\\) Exemple 9.9 Anem a fer a mà l’ajust dels p-valors segons Holm a l’Exemple 9.5. Taula amb els p-valors dels contrastos \\[ \\begin{array}{c|c} \\text{Contrast} &amp; \\text{p-valor} \\\\ \\hline \\text{1-2} &amp; 0.06554\\\\ \\text{1-3} &amp; 0.00756\\\\ \\text{1-4} &amp; 0.00058\\\\ \\text{2-3} &amp;0.29688\\\\ \\text{2-4} &amp; 0.03522\\\\ \\text{3-4} &amp; 0.23937 \\end{array} \\] Ordenam en ordre creixent del p-valor \\[ \\begin{array}{c|c} \\text{Contrast} &amp; \\text{p-valor} \\\\ \\hline \\text{1-4} &amp; 0.00058\\\\ \\text{2-3} &amp; 0.00756\\\\ \\text{2-4} &amp; 0.03522\\\\ \\text{1-2} &amp; 0.06554\\\\ \\text{3-4} &amp; 0.23937\\\\ \\text{2-3} &amp;0.29688\\\\ \\end{array} \\] Ajustam: per a cada \\(j\\), multiplicam el \\(j\\)-èsim p-valor (en ordre decreixent) per \\(6+1-j\\) \\[ \\begin{array}{c|cc} \\text{Contrast} &amp; \\text{p-valor} &amp; \\text{p-valor ajustat}\\\\ \\hline \\text{1-4} &amp; 0.00058 &amp; 6\\times 0.00058 = 0.00348\\\\ \\text{1-3} &amp; 0.00756 &amp; 5\\times 0.00756 = 0.03780\\\\ \\text{2-4} &amp; 0.03522 &amp; 4\\times 0.03522 = 0.14088\\\\ \\text{1-2} &amp; 0.06554 &amp; 3\\times 0.06554 = 0.19662\\\\ \\text{3-4} &amp; 0.23937 &amp; 2\\times 0.23937 = 0.47874\\\\ \\text{2-3} &amp; 0.29688 &amp; 1\\times 0.29688 = 0.29688\\\\ \\end{array} \\] Comparam els p-valors ajustats amb \\(\\alpha\\). En aquest cas, amb \\(\\alpha=0.05\\) arribam a la mateixa conclusió que amb el mètode de Bonferroni: concloem que \\(\\mu_1\\neq \\mu_4\\) i \\(\\mu_1\\neq \\mu_3\\) i que no podem rebutjar que les altres parelles de mitjanes siguin iguals Amb R, s’ha d’especificar a la funció pairwise.t.test el paràmetre p.adjust.method=&quot;holm&quot;, o no especificar aquest paràmetre perquè “holm” és el valor per defecte de p.adjust.method. pairwise.t.test(EG$Expr,EG$Tract,p.adjust.method=&quot;holm&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: EG$Expr and EG$Tract ## ## 1 2 3 ## 2 0.1966 - - ## 3 0.0378 0.4787 - ## 4 0.0035 0.1409 0.4787 ## ## P value adjustment method: holm Exemple 9.10 Els tests posteriors per parelles de l’Exemple 9.1 amb el mètode de Bonferroni i de Holm són: pairwise.t.test(CO2$Inc,CO2$Pre,p.adjust.method=&quot;bonferroni&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: CO2$Inc and CO2$Pre ## ## 0.0 0.08 0.29 0.50 ## 0.08 1.4e-05 - - - ## 0.29 1.6e-11 0.00186 - - ## 0.50 &lt; 2e-16 3.0e-10 0.00028 - ## 0.86 &lt; 2e-16 2.5e-15 6.6e-10 0.00389 ## ## P value adjustment method: bonferroni pairwise.t.test(CO2$Inc,CO2$Pre,p.adjust.method=&quot;holm&quot;) ## ## Pairwise comparisons using t tests with pooled SD ## ## data: CO2$Inc and CO2$Pre ## ## 0.0 0.08 0.29 0.50 ## 0.08 5.6e-06 - - - ## 0.29 1.2e-11 0.00037 - - ## 0.50 &lt; 2e-16 1.8e-10 8.4e-05 - ## 0.86 &lt; 2e-16 2.0e-15 3.3e-10 0.00039 ## ## P value adjustment method: holm Conclusió: Hem trobat evidència estadísticament significativa que cada una de les diferents pressions de CO2 considerades dona lloc a un increments mitjà diferent del volum cel·lular de P. fragi al cap d’una hora (ANOVA d’1 via, test posterior de Holm, p-valors ajustats tots més petits que 0.0004). Ara sí que hem trobat evidència que totes les mitjanes són diferents. Amb l’ANOVA, només podíem concloure que algunes mitjanes són diferents, però no quines. 9.2.4 Verificació de les condicions Recordau que per a que la conclusió d’una ANOVA d’1 via tengui sentit: Les mostres de cada tractament han de ser aleatòries simples i independents i almenys una ha de tenir més d’un element. La població definida per cada tractament ha de ser normal. Totes aquestes poblacions han de tenir la mateixa variància (homocedasticitat). El punt (1) és responsabilitat de l’investigador, però (2) i (3) s’han de contrastar. Si fallen, sobretot si falla (3), no es pot usar una ANOVA: convé emprar un test no paramètric. La normalitat de les mostres s’ha de contrastar amb algun test de normalitat. A la corresponent lliçó de R explicam com automatitzar el procés per fer-ho per totes les mostres de cop (spoiler: emprant la funció aggregate). Aquí ho farem de manera planera, variable a variable. Per exemple, emprarem el test de Shapiro-Wilkis per contrastar la normalitat dels nostres dos exemples: A l’exemple del CO2: shapiro.test(CO2$Inc[CO2$Pre==&quot;0.0&quot;])$p.value ## [1] 0.320568 shapiro.test(CO2$Inc[CO2$Pre==&quot;0.08&quot;])$p.value ## [1] 0.1023687 shapiro.test(CO2$Inc[CO2$Pre==&quot;0.29&quot;])$p.value ## [1] 0.5197501 shapiro.test(CO2$Inc[CO2$Pre==&quot;0.50&quot;])$p.value ## [1] 0.465208 shapiro.test(CO2$Inc[CO2$Pre==&quot;0.86&quot;])$p.value ## [1] 0.4840276 A l’exemple de l’expressió de gens: shapiro.test(EG$Expr[EG$Tract==&quot;1&quot;])$p.value ## [1] 0.306206 shapiro.test(EG$Expr[EG$Tract==&quot;2&quot;])$p.value ## [1] 0.2722278 shapiro.test(EG$Expr[EG$Tract==&quot;3&quot;])$p.value ## [1] 0.9611411 shapiro.test(EG$Expr[EG$Tract==&quot;4&quot;])$p.value ## [1] 0.9065984 En tots dos casos podem acceptar que totes les mostres provenen de variables normals. Si efectuam \\(k\\) contrastos de normalitat amb nivell de significació \\(\\alpha\\), tenim una probabilitat de cometre algun error de tipus I de \\(1-(1-\\alpha)^k\\). Per tant, com als contrastos posteriors per parelles, convé ajustar els p-valors a fi que el nivell de significació global sigui \\(\\alpha\\). En aquests dos exemple això no afecta les conclusions. Pel que fa a contrastar l’homocedasticitat, els dos tests més populars són: Si acceptam que les mostres provenen de distribucions normals, el test de Bartlett, implementat en R en la funció bartlett.test. Si no acceptam que les mostres provenen de distribucions normals, el test de Fligner-Killeen, implementat en R en la funció fligner.test. En tots dos casos, la funció s’aplica a una fórmula, exactament igual que aov. Per exemple, per contrastar l’homocedasticitat dels increments de volum cel·lular sota diferents pressions de CO2 de l’Exemple 9.1 amb un test de Bartlett, entraríem: bartlett.test(CO2$Inc~CO2$Pre) ## ## Bartlett test of homogeneity of variances ## ## data: CO2$Inc by CO2$Pre ## Bartlett&#39;s K-squared = 1.0701, df = 4, p-value = 0.899 Podem acceptar que les variàncies de les subpoblacions definides pels percentatges d’increment del volum cel·lular sota les diferents pressions de CO2 considerades són totes iguals. Ja que hi som, comprovem l’homocedasticitat de l’Exemple 9.5, ara amb el test de Fligner-Killeen i emprant l’altra sintaxi possible per que la vegeu fligner.test(Expr~Tract, data=EG) ## ## Fligner-Killeen test of homogeneity of variances ## ## data: Expr by Tract ## Fligner-Killeen:med chi-squared = 0.89109, df = 3, p-value = 0.8276 9.2.5 Test no paramètric Si en un experiment de disseny d’ANOVA d’1 via no podem emprar una ANOVA perquè no se satisfaci la normalitat de les poblacions o, sobretot, l’homocedasticitat, cal emprar un test no paramètric. El més popular es el test de Kruskal-Wallis, que generalitza el test de Mann-Whitney a més de 2 poblacions igual que l’ANOVA generalitza el test t; es fa amb la funció kruskal.test. Per exemple, per aplicar-lo a les dades de l’Exemple 9.1: kruskal.test(CO2$Inc~CO2$Pre) ## ## Kruskal-Wallis rank sum test ## ## data: CO2$Inc by CO2$Pre ## Kruskal-Wallis chi-squared = 44.716, df = 4, p-value = 4.555e-09 Seguim concloent que no totes les mitjanes (en realitat, les medianes) són iguals. Si el test de Kruskal-Wallis permet rebutjar la igualtat de mitjanes, i voleu determinar quins parells són diferents, disposau de la funció pairwise.wilcox.test que efectua contrastos per parelles de Mann-Whitney (amb el paràmetre paired=FALSE). Té la mateixa sintaxi que pairwise.t.test i com en aquella funció, el mètode d’ajust dels p-valors s’hi entra amb el paràmetre p.adjust.method, el valor per defecte del qual és el mètode de Holm. Per exemple, per realitzar tots els contrastos de Mann-Whitney en l’exemple del CO2 emprant el mètode d’ajust de Bonferroni, entram: pairwise.wilcox.test(CO2$Inc, CO2$Pre, paired=FALSE, p.adjust.method=&quot;bonferroni&quot;) ## ## Pairwise comparisons using Wilcoxon rank sum test with continuity correction ## ## data: CO2$Inc and CO2$Pre ## ## 0.0 0.08 0.29 0.50 ## 0.08 0.00211 - - - ## 0.29 0.00011 0.01050 - - ## 0.50 0.00011 0.00011 0.00325 - ## 0.86 0.00011 0.00011 0.00011 0.03186 ## ## P value adjustment method: bonferroni Tornam a concloure que els percentatges mitjans d’increment són tots diferents. 9.3 ANOVA de blocs De la mateixa manera que l’ANOVA d’1 via generalitza a més de dues mitjanes el contrast d’igualtat de dues mitjanes emprant mostres independents, l’ANOVA de blocs generalitza a més de dues mitjanes el contrast d’igualtat de dues mitjanes emprant mostres aparellades. 9.3.1 Contrast bàsic Comencem amb un exemple Exemple 9.11 Volem determinar si l’energia que es requereix per dur a terme tres activitats físiques (córrer, caminar i muntar amb bicicleta) és la mateixa o no. Quantificam aquesta energia amb el nombre de Kcal consumides per Km recorregut. Les diferències metabòliques entre els individus poden afectar l’energia requerida per dur a terme una determinada activitat. Per tant, no és aconsellable triar tres grups d’individus i a cada grup fer-li fer una de les tres activitats físiques: les diferències metabòliques entre els individus triats podrien afectar els resultats i amagar l’efecte real. Ens decidim per un disseny experimental en paral·lel: Seleccionam alguns individus i demanam a cadascun que corri, camini i recorri amb bicicleta una distància fixada en tres moments diferents, seleccionant l’ordre de les activitats de cada individu a l’atzar, i mesuram per a cada individu i cada activitat el consum de Kca/Km. Si a tots els individus els féssim fer les tres activitats en el mateix ordre, podria ser que qualque factor extern que no controlàssim influís en el resultat. Per exemple, si tots caminen al mateix temps, després corren al mateix temps i després pedalen al mateix temps, i hi ha grans diferències de temperatura ambient entre els tres moments, això podria influir en el resultat final. Si, en canvi, aleatoritzam l’ordre de les activitats, en principi aquestes diferències es compensen. Aquests són els resultats obtinguts per a 8 individus: \\[ \\begin{array}{c} \\hphantom{Individu}\\text{Activitat}\\\\ \\begin{array}{c|ccc} \\text{Individu} &amp;\\text{1 (corrent)} &amp;\\text{2 (caminant)}&amp;\\text{3 (pedalant)}\\\\ \\hline 1&amp;1.4&amp;1.1&amp;0.7\\\\ 2&amp;1.5&amp;1.2&amp;0.8\\\\ 3&amp;1.8&amp;1.3&amp;0.7\\\\ 4&amp;1.7&amp;1.3&amp;0.8\\\\ 5&amp;1.6&amp;0.7&amp;0.1\\\\ 6&amp;1.5&amp;1.2&amp;0.7\\\\ 7&amp;1.7&amp;1.1&amp;0.4\\\\ 8&amp;2.0&amp;1.3&amp;0.6\\\\ \\end{array} \\end{array} \\] En aquest estudi, fixau-vos que empram els nivells d’un factor (tipus de desplaçament) per classificar la població (els consums energètics) en tres subpoblacions, però ara les mostres que hem pres no són independents sinó aparellades: hem mesurat els consums energètics dels tres esports sobre els mateixos individus. Per tant no podem realitzar una ANOVA d’1 via per analitzar els resultats. L’ANOVA de blocs (complets aleatoris, però ometrem aquests adjectius perquè és l’únic que veurem) generalitza el contrast de 2 mitjanes amb mostres aparellades a \\(k\\) mitjanes amb mostres aparellades. La situació general és la següent. Tenim una variable aleatòria \\(X\\) i un factor de \\(k\\) nivells, o tractaments, que classifica la població en \\(k\\) subpoblacions (a les que, recordau, identificam amb els tractaments). Diguem \\(\\mu_i\\) a la mitjana de \\(X\\) en els individus del nivell \\(i\\)-èsim. Volem comparar aquestes mitjanes \\(\\mu_1\\),…,\\(\\mu_k\\) i en concret decidir si són totes iguals o no. És a dir, el contrast és \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{1} =\\mu_{2} =\\cdots =\\mu_{k} \\\\ H_1 : \\text{Hi ha } i,j \\text{ tals que } \\mu_{i} \\not=\\mu_{j} \\end{array} \\right. \\] En un experiment de disseny d’ANOVA de blocs: Escollim una mostra aleatòria de \\(b\\) blocs: conjunts de \\(k\\) subjectes aparellats (per exemple, escollim \\(b\\) subjectes i entenem cada bloc com a format per \\(k\\) còpies del mateix subjecte), on fixau-vos que \\(k\\) és el nombre de tractaments. Dins cada bloc, assignam aleatòriament a cada subjecte un tractament, de manera que cada tractament s’empri exactament un cop dins cada bloc. Així, el disseny de l’Exemple 9.11 és d’una ANOVA de blocs: La variable aleatòria és l’energia consumida (en Kcal) per una persona en recórrer un km Els tractaments són els tres tipus de desplaçament Prenem 8 persones de manera raonablement aleatòria i interpretam cada una com un bloc Assignam a cada persona el tres tractaments en un ordre escollit a l’atzar per a cada una d’elles La filosofia del contrast serà similar a la de l’ANOVA d’1 via, comparant variabilitats: si la variabilitat de les mitjanes de les mostres és molt més gran que la variabilitat dels “errors”, rebutjarem la igualtat de totes les mitjanes poblacionals. En una ANOVA de blocs, les dades se solen representar en forma d’una taula com la següent \\[ \\begin{array}{c} \\hphantom{Bloc}\\text{Tractament}\\\\ \\begin{array}{ccccc} \\text{Bloc} &amp;\\text{Tract. 1} &amp;\\text{Tract. 2}&amp;\\ldots &amp; \\text{Tract. $k$}\\\\ \\hline 1 &amp; X_{11} &amp; X_{21} &amp; \\ldots &amp; X_{k1} \\\\ 2 &amp; X_{12} &amp; X_{22} &amp; \\ldots &amp; X_{k2} \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\ddots &amp; \\vdots \\\\ b &amp; X_{1b} &amp; X_{2b} &amp; \\ldots &amp; X_{kb} \\\\ \\hline \\end{array} \\end{array} \\] on cada \\(X_{ij}\\) és el valor del tractament \\(i\\)-èsim en l’individu corresponent del bloc \\(j\\)-èsim. Com en les taules emprades en l’ANOVA d’1 via, observau que no és la notació usual de les taules de dades, sinó la transposada: a \\(X_{{i}{j}}\\), \\(i\\) hi indica la columna, el tractament, i \\(j\\) hi indica la filera, és a dir, el bloc. D’aquesta manera, cada filera \\((X_{1j},\\ldots,X_{kj})\\) representa un bloc. Exemple 9.12 Tornant al nostre Exemple 9.11 inicial, els blocs són els 8 individus (\\(b=8\\)) i els tractaments, les diferents activitats (\\(k=3\\)). Si \\(\\mu_{1}\\) representa el nombre mitjà de Kcal que es consumeixen corrent 1 km \\(\\mu_{2}\\) representa el nombre mitjà de Kcal que es consumeixen caminant 1 km \\(\\mu_{3}\\) representa el nombre mitjà de Kcal que es consumeixen pedalant 1 km el contrast que volem realitzar és \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{1} = \\mu_{2} = \\mu_{3} \\\\ H_1 : \\mu_{1} \\neq \\mu_{2}\\text{ o } \\mu_{1} \\neq \\mu_{3}\\text{ o } \\mu_{2} \\neq \\mu_{3} \\end{array} \\right. \\] Per que les conclusions d’una ANOVA de blocs tenguin sentit cal que: Les \\(k\\cdot b\\) observacions constitueixin mostres aleatòries, cadascuna de mida 1, de les \\(k\\cdot b\\) poblacions definides per les parelles (tractament,bloc) Aquestes \\(k\\cdot b\\) poblacions són totes normals, cada una amb mitjana \\(\\mu_{ij}\\), on \\(i\\) indica el tractament i \\(j\\) indica el bloc, i totes amb la mateixa variància \\(\\sigma^2\\) No hi ha interacció entre els blocs i els tractaments. Això significa que l’efecte dels blocs i els tractaments és additiu: la diferència entre les mitjanes poblacionals de cada parella concreta de tractaments és la mateixa a cada bloc \\[ \\mu_{i_1j_1}-\\mu_{i_2j_1}=\\mu_{i_1j_2}-\\mu_{i_2j_2} \\] Per exemple, que no hi hagi interacció entre els blocs i els tractaments a l’Exemple 9.11 significa que: La diferència entre el consum energètic mitjà en córrer i en caminar és la mateixa a cada individu de la mostra La diferència entre el consum energètic mitjà en córrer i en pedalar és la mateixa a cada individu de la mostra La diferència entre el consum energètic mitjà en caminar i en pedalar és la mateixa a cada individu de la mostra En canvi, hi hauria interacció si, per exemple, la diferència entre el consum energètic mitjà en córrer i en caminar depengués de l’individu: si en uns la diferència fos més gran que en d’altres. Amb un sol valor per cada parell (tractament,bloc), cap d’aquestes condicions necessàries per poder realitzar una ANOVA de blocs no es pot contrastar i per tant l’experimentador ha de decidir si se satisfan o no segons la seva experiència. Què significa això de la interacció entre dues variables? Imaginau que podem administrar dos analgèsics, A i B, a dones i homes, i mesuram el temps que triguen en fer efecte. Diguem \\(\\mu_{AD}\\): temps mitjà que triga en fer efecte l’analgèsic A sobre les dones \\(\\mu_{BD}\\): temps mitjà que triga en fer efecte l’analgèsic B sobre les dones \\(\\mu_{AH}\\): temps mitjà que triga en fer efecte l’analgèsic A sobre els homes \\(\\mu_{BH}\\): temps mitjà que triga en fer efecte l’analgèsic B sobre els homes Aleshores: No hi ha interacció entre els analgèsics i el sexe si la diferència en el temps mitjà en fer efecte A i B és la mateixa en les dones que en els homes: \\[ \\mu_{AD}-\\mu_{BD}= \\mu_{AH}-\\mu_{BH} \\] En canvi, sí que hi ha interacció entre els analgèsics i el sexe quan aquestes dues diferències són diferents, la qual cosa significaria que la diferència d’efectivitat entre els dos analgèsics no és la mateixa en els homes que en les dones: \\[ \\mu_{AD}-\\mu_{BD}\\neq \\mu_{AH}-\\mu_{BH} \\] Fixau-vos que això no és exactament equivalent al fet que un analgèsic sigui més efectiu en un sexe que en l’altre, per exemple més en les dones que en els homes: si l’altre analgèsic també és més efectiu en les dones que en els homes, pot ser que la diferència entre les mitjanes se mantengui i no hi hagi interacció. Recordarem algunes notacions, i n’introduïm algunes altres. Pel que fa a la població: Direm \\(\\mu_i\\) a la mitjana de la variable d’interès sobre la població definida pel tractament \\(i\\)-èsim Direm \\(\\mu\\) a la mitjana de la variable d’interès sobre el total de la població, sense distingir tractaments Direm \\(\\mu_{\\bullet j}\\) a la mitjana de la variable d’interès sobre el bloc \\(j\\)-èsim L’ANOVA de blocs se basa en el model següent: per a tots \\(i=1,\\ldots,k\\) i \\(j=1,\\ldots,b\\) \\[ X_{ij}=\\mu+ (\\mu_{i}-\\mu) +(\\mu_{\\bullet j}-\\mu) + E_{ij} \\] on: \\(X_{ij}\\) indica el valor de la variable \\(X\\) per al tractament \\(i\\)-èsim en el bloc \\(j\\)-èsim \\(\\mu_i-\\mu\\) representa la desviació de la mitjana de \\(X\\) en el nivell \\(i\\)-èsim respecte de la mitjana global \\(\\mu\\) (l’efecte del tractament \\(i\\)-èsim) \\(\\mu_{\\bullet j}-\\mu\\) representa la desviació de la mitjana de \\(X\\) en el bloc \\(j\\)-èsim respecte de la mitjana global \\(\\mu\\) (l’efecte del bloc \\(j\\)-èsim) \\(E_{ij}\\) representa la part de la diferència entre \\(X_{ij}\\) i \\(\\mu\\) que no expliquen ni el tractament ni el bloc; en diem l’error aleatori, o el residu. Aquest model diu bàsicament que el valor de \\(X\\) sobre un individu és la suma de quatre components: La mitjana global \\(\\mu\\) de \\(X\\) sobre tota la població L’efecte del tractament L’efecte del bloc L’error aleatori i per tant hi pressuposam que res més no influeix en el valor de \\(X\\), i en particular que l’efecte del bloc i el del tractament se sumen, sense que hi hagi interacció entre ells. Si això no és veritat, és a dir, si aquest valor pot dependre d’altres efectes que no tinguem en compte o si hi ha interacció entre els blocs i els tractaments, el model no és vàlid, i les conclusions de l’ANOVA tampoc. Pel que fa a la nostra mostra: \\(\\overline{X}_{i}\\) és la mitjana mostral de la mostra del tractament \\(i\\)-èsim \\[ \\overline{X}_{i}=\\dfrac{\\sum_{j=1}^b X_{ij}}{b} \\] \\(\\overline{X}_{\\bullet j}\\) és la mitjana mostral de les mesures preses sobre el bloc \\(j\\)-èsim \\[ \\overline{X}_{\\bullet j}=\\dfrac{\\sum_{i=1}^k X_{ij}}{k} \\] \\(\\overline{X}\\) és la mitjana mostral de tota la mostra \\[ \\overline{X}=\\dfrac{\\sum_{i=1}^k\\sum_{j=1}^b X_{ij}}{k\\cdot b} \\] Exemple 9.13 Tornem a l’Exemple 9.11. Recordem que les dades eren \\[ \\begin{array}{c} \\hphantom{Individu}\\text{Tractament}\\\\ \\begin{array}{c|ccc} \\text{Individu} &amp;\\text{1 (corrent)} &amp;\\text{2 (caminant)}&amp;\\text{3 (pedalant)}\\\\ \\hline 1&amp;1.4&amp;1.1&amp;0.7\\\\ 2&amp;1.5&amp;1.2&amp;0.8\\\\ 3&amp;1.8&amp;1.3&amp;0.7\\\\ 4&amp;1.7&amp;1.3&amp;0.8\\\\ 5&amp;1.6&amp;0.7&amp;0.1\\\\ 6&amp;1.5&amp;1.2&amp;0.7\\\\ 7&amp;1.7&amp;1.1&amp;0.4\\\\ 8&amp;2.0&amp;1.3&amp;0.6\\\\ \\end{array} \\end{array} \\] Per tant les mitjanes serien, amb aquestes notacions \\[ \\begin{array}{c} \\text{Tractament}\\\\ \\begin{array}{c|ccc|c} \\text{Individu} &amp;\\text{1 (corrent)} &amp;\\text{2 (caminant)}&amp;\\text{3 (pedalant)} &amp; \\text{Mitjanes}\\\\ \\hline 1&amp;1.4&amp;1.1&amp;0.7 &amp; \\overline{X}_{\\bullet1}\\\\ 2&amp;1.5&amp;1.2&amp;0.8 &amp; \\overline{X}_{\\bullet2}\\\\ 3&amp;1.8&amp;1.3&amp;0.7 &amp; \\overline{X}_{\\bullet3}\\\\ 4&amp;1.7&amp;1.3&amp;0.8 &amp; \\overline{X}_{\\bullet4}\\\\ 5&amp;1.6&amp;0.7&amp;0.1 &amp; \\overline{X}_{\\bullet5}\\\\ 6&amp;1.5&amp;1.2&amp;0.7 &amp; \\overline{X}_{\\bullet6}\\\\ 7&amp;1.7&amp;1.1&amp;0.4 &amp; \\overline{X}_{\\bullet7}\\\\ 8&amp;2.0&amp;1.3&amp;0.6 &amp; \\overline{X}_{\\bullet8}\\\\ \\hline \\text{Mitjanes} &amp; \\overline{X}_{1} &amp; \\overline{X}_{2} &amp; \\overline{X}_{3} &amp; \\overline{X} \\end{array} \\end{array} \\] Anem a calcular-les. Emmagatzemarem les dades en un dataframe Dades de tres variables: kilocal: les Kcal/Km consumides blocs: l’individu tracts: l’activitat Per poder després fer l’ANOVA, aquests dos darrers han de ser factors. Com que entrarem les dades de la taula per fileres: el factor tracts ha d’estar format per 8 còpies del vector (1,2,3), on 1 representa córrer, 2, caminar i 3, pedalar el factor blocs ha de tenir la forma (1,1,1,2,2,2,3,3,3,…) kilocal=c(1.4,1.1,0.7,1.5,1.2,0.8,1.8,1.3,0.7,1.7,1.3,0.8, 1.6,0.7,0.1,1.5,1.2,0.7,1.7,1.1,0.4,2.0,1.3,0.6) blocs=as.factor(rep(1:8,each=3)) blocs ## [1] 1 1 1 2 2 2 3 3 3 4 4 4 5 5 5 6 6 6 7 7 7 8 8 8 ## Levels: 1 2 3 4 5 6 7 8 tracts=as.factor(rep(1:3,times=8)) tracts ## [1] 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 1 2 3 ## Levels: 1 2 3 Dades=data.frame(kilocal,tracts,blocs) str(Dades) ## &#39;data.frame&#39;: 24 obs. of 3 variables: ## $ kilocal: num 1.4 1.1 0.7 1.5 1.2 0.8 1.8 1.3 0.7 1.7 ... ## $ tracts : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 2 3 1 2 3 1 2 3 1 ... ## $ blocs : Factor w/ 8 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 1 1 2 2 2 3 3 3 4 ... head(Dades) ## kilocal tracts blocs ## 1 1.4 1 1 ## 2 1.1 2 1 ## 3 0.7 3 1 ## 4 1.5 1 2 ## 5 1.2 2 2 ## 6 0.8 3 2 Calculem les mitjanes mostrals dels tractaments, \\(\\overline{X}_i\\): mean.tracts=aggregate(kilocal~tracts,data=Dades,mean) mean.tracts ## tracts kilocal ## 1 1 1.65 ## 2 2 1.15 ## 3 3 0.60 Calculem les mitjanes mostrals dels blocs, \\(\\overline{X}_{\\bullet j}\\): mean.blocs=aggregate(kilocal~blocs,data=Dades,mean) mean.blocs ## blocs kilocal ## 1 1 1.066667 ## 2 2 1.166667 ## 3 3 1.266667 ## 4 4 1.266667 ## 5 5 0.800000 ## 6 6 1.133333 ## 7 7 1.066667 ## 8 8 1.300000 Calculem la mitjana mostral global \\(\\overline{X}\\): mean.tot=mean(Dades$kilocal) mean.tot ## [1] 1.133333 A l’ANOVA de blocs s’hi té la identitat següent: Teorema 9.3 (Identitat de les sumes de quadrats) \\[ SS_{Total}=SS_{Tr}+SS_{Blocs}+SS_E \\] on \\(SS_{Total}=\\displaystyle\\sum\\limits_{i=1}^k\\sum\\limits_{j=1}^b (X_{ij}- \\overline{X})^2\\); és la Suma Total de Quadrats \\(SS_{Tr}=\\displaystyle b\\sum\\limits_{i=1}^k (\\overline{X}_{i}-\\overline{X})^2\\); és la Suma de Quadrats dels Tractaments \\(SS_{Blocs}=\\displaystyle k\\sum\\limits_{j=1}^b (\\overline{X}_{\\bullet j}-\\overline{X})^2\\); és la Suma de Quadrats dels Blocs \\(SS_E=\\displaystyle\\sum\\limits_{i=1}^k\\sum\\limits_{j=1}^b (X_{ij} - \\overline{X}_{i}- \\overline{X}_{\\bullet j}+\\overline{X})^2\\); és la Suma de Quadrats dels Residus o dels Errors En aquesta identitat \\(SS_{Total}\\) representa la variabilitat total de les dades: és el numerador de la variància de la mostra total \\(SS_{Tr}\\) representa la variabilitat de les mitjanes dels tractaments: és \\(b\\) vegades el numerador de la variància de \\((\\overline{X}_1,\\overline{X}_2,\\ldots,\\overline{X}_k)\\) \\(SS_{Tr}\\) representa la variabilitat de les mitjanes dels blocs: és \\(k\\) vegades el numerador de la variància de \\((\\overline{X}_{\\bullet 1},\\overline{X}_{\\bullet 2},\\ldots,\\overline{X}_{\\bullet b})\\) \\(SS_E\\) representa la “resta de la variabilitat” Per a que el model de l’ANOVA de blocs \\[ X_{ij}=\\mu+ (\\mu_{i}-\\mu) +(\\mu_{\\bullet j}-\\mu) + E_{ij} \\] ha de passar (aïllant) que \\[ E_{ij}=X_{ij}-\\mu_{i}-\\mu_{\\bullet j}+\\mu \\] i aleshores \\(SS_E\\) és la suma dels quadrats de les estimacions d’aquests errors aleatoris per als individus de la nostra mostra. Per tant \\[ SS_{Total}=SS_{Tr}+SS_{Blocs}+SS_E \\] bàsicament diu que en una ANOVA de blocs la variabilitat total descompon en la suma de la variabilitat de les mitjanes dels tractaments més la variabilitat de les mitjanes dels blocs més la variabilitat “residual”. Exemple 9.14 Tornem a l’Exemple 9.11 Recordem les dades que ja tenim str(Dades) ## &#39;data.frame&#39;: 24 obs. of 3 variables: ## $ kilocal: num 1.4 1.1 0.7 1.5 1.2 0.8 1.8 1.3 0.7 1.7 ... ## $ tracts : Factor w/ 3 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;: 1 2 3 1 2 3 1 2 3 1 ... ## $ blocs : Factor w/ 8 levels &quot;1&quot;,&quot;2&quot;,&quot;3&quot;,&quot;4&quot;,..: 1 1 1 2 2 2 3 3 3 4 ... k=3 #Nombre de tractaments b=8 #Nombre de blocs mean.tracts #Mitjanes de tractaments ## tracts kilocal ## 1 1 1.65 ## 2 2 1.15 ## 3 3 0.60 mean.blocs #Mitjanes de blocs ## blocs kilocal ## 1 1 1.066667 ## 2 2 1.166667 ## 3 3 1.266667 ## 4 4 1.266667 ## 5 5 0.800000 ## 6 6 1.133333 ## 7 7 1.066667 ## 8 8 1.300000 mean.tot # Mitjana global ## [1] 1.133333 Calculem la suma total de quadrats \\[ SS_{Total}=\\sum\\limits_{i=1}^k\\sum\\limits_{j=1}^b (X_{ij}- \\overline{X})^2 \\] SS.Tot=sum((kilocal-mean.tot)^2) SS.Tot ## [1] 5.353333 Calculem la suma de quadrats dels tractaments \\[ SS_{Tr}=b\\sum\\limits_{i=1}^k (\\overline{X}_{i}-\\overline{X})^2 \\] Fixau-vos que el vector \\((\\overline{X}_{1},\\overline{X}_{2},\\overline{X}_{3})\\) és la variable kilocal de mean.tracts. SS.Tr=b*sum((mean.tracts$kilocal-mean.tot)^2) SS.Tr ## [1] 4.413333 Calculem la suma de quadrats dels blocs \\[ SS_{Blocs}=k\\sum\\limits_{j=1}^b (\\overline{X}_{\\bullet j}-\\overline{X})^2 \\] Fixau-vos que el vector \\((\\overline{X}_{\\bullet 1},\\ldots,\\overline{X}_{\\bullet b})\\) és la variable kilocal de mean.blocs. SS.Bl=k*sum((mean.blocs$kilocal-mean.tot)^2) SS.Bl ## [1] 0.5533333 Calculem la suma de quadrats dels residus \\[ SS_E=\\sum\\limits_{i=1}^k\\sum\\limits_{j=1}^b (X_{ij} - \\overline{X}_{i}- \\overline{X}_{\\bullet j}+\\overline{X})^2 \\] Per calcular aquesta suma, actuarem com al càlcul de la \\(SS_E\\) de l’ANOVA d’1 via, tenint en compte que Les entrades de Dades$kilocal que difereixen en un múltiple de 3 són del mateix tractament: per exemple, la 1a, la 4a, la 7a etc. corresponen al tractament 1 (córrer). Si a Dades$kilocal li restam el vector de les mitjanes del tractaments, mean.tracts$kilocal, en realitat estam dient a R que li resti 8 còpies consecutives d’aquest vector, i per tant a cada entrada de Dades$kilocal li restam la mitjana del seu tractament. Cada grup de 3 entrades consecutives de Dades$kilocal corresponen a un bloc: les tres primeres al bloc 1, les tres següents al bloc 2 etc. Per tant, per restar a cada entrada de Dades$kilocal la mitjana del bloc corresponent, li hem de restar rep(mean.blocs$kilocal,each=3). SSE=sum((Dades$kilocal-mean.tracts$kilocal-rep(mean.blocs$kilocal,each=3)+mean.tot)^2) SSE ## [1] 0.3866667 Comprovem la identitat de les sumes de quadrats: SS.Tot ## [1] 5.353333 SS.Tr+SS.Bl+SSE ## [1] 5.353333 A partir d’aquí, tot funciona com a l’ANOVA d’1 via. Al contrast \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{1}=\\cdots =\\mu_{k} \\\\ H_1 : \\text{Hi ha } i,j=1,\\ldots ,k \\text{ tals que } \\mu_{i}\\neq \\mu_{j} \\end{array} \\right. \\] rebutjarem la hipòtesi nul·la si \\(SS_{Tr}\\) és prou més gran que \\(SS_{E}\\). Per mesurar-ho, emprarem els estadístics següents: Quadrat mitjà dels tractaments: \\[ MS_{Tr}=\\dfrac{SS_{Tr}}{k-1} \\] Quadrat mitjà dels errors: \\[ MS_E = \\dfrac{SS_E}{(b-1) (k-1)} \\] Fixau-vos que el denominador és diferent que al \\(MS_E\\) de l’ANOVA d’1 via A més, R calcula el Quadrat mitjà dels blocs, que nosaltres no farem servir però que donam per si de cas: \\[ MS_{Blocs}=\\dfrac{SS_{Blocs}}{b-1} \\] Si se satisfan les condicions necessàries que hem esmentat per que l’ANOVA es pugui realitzar, es té que \\[ \\begin{array}{l} E(MS_{Tr})=\\sigma^2 + \\dfrac{b}{k-1}\\sum\\limits_{i=1}^k (\\mu_{i}-\\mu)^2 \\\\ E(MS_E)=\\sigma^2 \\end{array} \\] I \\(MS_E\\) torna a estimar la variància comuna de totes les poblacions definides per les parelles (tractament,bloc). Aleshores, com a l’ANOVA d’1 via, si \\(H_0:\\mu_{1}=\\cdots =\\mu_{k}(=\\mu)\\) és certa, \\[ \\sum\\limits_{i=1}^k (\\mu_{i}-\\mu)^2 = 0, \\] i per tant \\(E(MS_{Tr})=E(MS_E)\\), mentre que si \\(H_0\\) no és certa \\[ \\sum\\limits_{i=1}^k (\\mu_{i}-\\mu)^2 &gt; 0 \\] cas en el qual \\(E(MS_{Tr})&gt;E(MS_E)\\). Aleshores prendrem com a estadístic de contrast el quocient \\[ F=\\frac{MS_{Tr}}{MS_E} \\] Si \\(H_0\\) és certa: La seva distribució és de tipus F de Fisher amb \\(k-1\\) i \\((k-1)(b-1)\\) graus de llibertat, \\(F_{k-1,(k-1)(b-1)}\\) En general, els graus de llibertat de l’estadístic F d’una ANOVA, sigui del tipus que sigui, són els denominadors emprats en les definicions dels quadrats mitjans del numerador i el denominador. El seu valor és proper a 1 I per tant rebutjarem la hipòtesi nul·la si el valor \\(F_0\\) de \\(F\\) sobre la nostra mostra és prou més gran que 1, la qual cosa decidirem comparant el p-valor \\(P(F_{k-1,(k-1)(b-1)}\\geqslant F_0)\\) amb el nivell de significació \\(\\alpha\\). En resum, per realitzar una ANOVA de blocs a partir d’una mostra: Calculam \\(SS_{Tr},SS_E\\) Calculam \\(MS_{Tr},MS_E\\) Calculam el valor \\(F_0\\) de l’estadístic de contrast \\[ F=\\frac{MS_{Tr}}{MS_E} \\] Calculam el p-valor \\[ P(F_{k-1,(k-1)(b-1)}\\geqslant F_0) \\] Si aquest p-valor és més petit que el nivell de significació \\(\\alpha\\), rebutjam \\(H_0\\) i concloem que no totes les mitjanes són iguals. En cas contrari, acceptam que totes les mitjanes són iguals. Totes aquestes dades se solen recollir en la taula ANOVA següent: \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; k-1 &amp; SS_{Tr}&amp; MS_{Tr} &amp; F &amp; \\text{p-valor} \\\\ \\text{Blocs} &amp; b-1 &amp; SS_{Blocs} &amp; MS_{Blocs} &amp; \\\\ \\text{Residus} &amp; (k-1)(b-1) &amp; SS_E &amp; MS_E &amp; \\\\\\hline \\end{array} \\] Exemple 9.15 Tornem al nostre Exemple 9.11. Ja hem calculat: \\[ \\begin{array}{cccccc} k &amp; b &amp; SS_{Total} &amp; SS_{Tr} &amp; SS_{Blocs} &amp; SS_E\\\\ \\hline 3 &amp; 8 &amp; 5.3533 &amp; 4.4133 &amp; 0.5533 &amp; 0.3867 \\end{array} \\] Aleshores: \\(MS_{Tr}=\\dfrac{SS_{Tr}}{k-1}=2.2066\\) \\(MS_{Blocs}=\\dfrac{SS_{Blocs}}{b-1}=0.079\\) \\(MS_E = \\dfrac{SS_E}{(b-1) (k-1)}=0.0276\\) \\(F=\\dfrac{MS_{Tr}}{MS_E}=79.949\\) p-valor: \\(P(F_{2,14}\\geqslant 79.949)=2\\cdot 10^{-8}\\) Conclusió: Hem obtingut evidència estadística que no és veritat que les tres activitats tenguin el mateix consum energètic mitjà per km (ANOVA de blocs, p-valor 2·10-8) La taula ANOVA d’aquest exemple és \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; 2 &amp; 4.4133&amp;2.2067&amp;79.949 &amp; 2\\cdot 10^{-8} \\\\ \\text{Blocs} &amp; 7 &amp; 0.5533&amp;0.079&amp; &amp; \\\\ \\text{Residus} &amp; 14 &amp; 0.3867&amp;0.0276&amp; &amp; \\\\\\hline \\end{array} \\] 9.3.2 Amb R L’ANOVA de blocs s’efectua amb R aplicant summary(aov( )) a la fórmula que separa la variable numèrica per la suma dels factors que representen els tractaments i els blocs. Així, l’ANOVA de blocs de l’Exemple 9.11 es fa amb summary(aov(Dades$kilocal~Dades$tracts+Dades$blocs)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## Dades$tracts 2 4.413 2.2067 79.897 2.2e-08 *** ## Dades$blocs 7 0.553 0.0790 2.862 0.0446 * ## Residuals 14 0.387 0.0276 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 o, equivalentment, amb summary(aov(kilocal~tracts+blocs, data=Dades)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## tracts 2 4.413 2.2067 79.897 2.2e-08 *** ## blocs 7 0.553 0.0790 2.862 0.0446 * ## Residuals 14 0.387 0.0276 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 Obtenim la taula d’abans (llevat d’una petita diferència en la \\(F\\) deguda a que als càlculs a mà anàvem arrodonint pel camí) amb dues entrades més: l’estadístic de contrast i el p-valor de la filera blocs, que corresponen al contrast sobre hi ha diferència o no entre les mitjanes dels blocs (en aquest exemple, els consums mitjans energètics per km dels individus de la mostra en desplaçar-se de qualsevol de les tres maneres). 9.3.3 Comparacions posteriors per parelles Com en el cas d’1 via, si rebutjam la hipòtesi nul·la, podem demanar-nos quins són els tractaments que tenen mitjanes diferents. Ho podem respondre fent un test t per a cada parella de tractaments emprant mostres aparellades i aplicant un ajust del p-valor (Bonferroni, Holm…). No donarem els detalls de les fórmules, simplement heu de saber que amb R es fa com a l’ANOVA d’1 via: amb la funció pairwise.t.test, però ara indicant-hi que paired=TRUE. Exemple 9.16 A l’experiment de l’Exemple 9.11 hem arribat a la conclusió que no totes les mitjanes són iguals. Emprem un contrast posterior per parelles amb l’ajust de Bonferroni per mirar quines són diferents. pairwise.t.test(Dades$kilocal, Dades$tracts, paired=TRUE, p.adjust.method=&quot;bonferroni&quot;) ## ## Pairwise comparisons using paired t tests ## ## data: Dades$kilocal and Dades$tracts ## ## 1 2 ## 2 0.00108 - ## 3 0.00011 1.1e-05 ## ## P value adjustment method: bonferroni Conclusió: Hem obtingut evidència estadísticament significativa que les tres activitats tenen diferent consum energètic mitjà per km (ANOVA de blocs, test posterior de Bonferroni, p-valors ajustats inferiors a 0.0011) 9.3.4 Contrast no paramètric Si en un experiment amb disseny d’ANOVA de blocs no podem aplicar l’ANOVA perquè sospitem que no se satisfan les condicions necessàries, cal emprar un test no paramètric. El més popular és el test de Friedman, que generalitza el test de Wilcoxon a més de 2 mostres. En R està implementat en la funció friedman.test que s’aplica a la mateixa fórmula que summary(aov( )) excepte que cal substituir-hi la suma “+” per una barra vertical “|”. Per exemple: friedman.test(kilocal~tracts|blocs,data=Dades) ## ## Friedman rank sum test ## ## data: kilocal and tracts and blocs ## Friedman chi-squared = 16, df = 2, p-value = 0.0003355 La conclusió és la mateixa que abans: No tots els consums energètics mitjans són iguals (test de Friedman, p-valor 0.0003). Si ara volem realitzar els tests posteriors per parelles, el més adient és emprar en tots ells el test de Wilcoxon, amb la funció pairwise.wilcox.test que ja empràvem a l’ANOVA d’1 via, però ara amb paired=TRUE: pairwise.wilcox.test(Dades$kilocal, Dades$tracts, paired =TRUE) ## ## Pairwise comparisons using Wilcoxon signed rank test with continuity correction ## ## data: Dades$kilocal and Dades$tracts ## ## 1 2 ## 2 0.042 - ## 3 0.042 0.042 ## ## P value adjustment method: holm Obtenim evidència estadísticament significativa que les tres activitats tenen consums energètics mitjans diferents (test de Friedman, test posterior per parelles de Wilcoxon amb ajust de Holm, p-valors ajustats 0.042). 9.4 ANOVA de 2 vies Amb l’ANOVA d’1 via comparàvem les mitjanes de més de 2 subpoblacions definides pels nivells d’un únic factor. Ara ens interessa el cas en què aquestes subpoblacions estan definides combinant els nivells de més d’un factor. Es diu en aquest cas que el disseny de l’experiment és d’ANOVA factorial. Nosaltres aquí considerarem només el cas més senzill, quan s’empren només 2 factors (2 vies). A més, per simplificar, només estudiarem el cas en què totes les mostres de cada combinació de nivells d’un factor i de l’altre tenen la mateixa mida. Per tant, en un experiment amb disseny d’ANOVA de 2 vies: Tenim una variable aleatòria \\(X\\) Classificam la població segons les combinacions dels nivells de dos factors Prenem una m.a.s. de cada combinació de nivells, independents i totes de la mateixa mida, i hi mesuram la variable \\(X\\) 9.4.1 Contrast bàsic Comencem amb un exemple. Exemple 9.17 S’havien observat diferències estacionals en el desenvolupament de les gònades d’una espècie de peixos que viuen als llacs africans, i es volia saber si això era conseqüència de la diferència entre estacions en hores de llum o en temperatura. Per decidir-ho, en un experiment s’intentà determinar l’efecte de la llum i la temperatura sobre l’índex gonadosomàtic o GSI (una mesura de creixement de l’ovari) d’aquesta espècie de peixos. S’hi van utilitzar dos fotoperíodes (l’estival, 14 hores de llum i 10 hores de foscor; i l’hivernal, 9 hores de llum-15 hores de foscor) i dues temperatures (l’estival, 27o C, i l’hivernal, 16o C). En concret, com diem, es volia determinar si el GSI mitjà depèn del fotoperíode, o de la temperatura, o de la combinació dels dos tractaments, i si a més hi ha interacció entre ells, en el sentit que en alguna combinació de nivells dels dos tractaments els dos efectes no s’acumulin, sinó que l’efecte final sigui més gran, o més petit, que la suma dels dos efectes per separat. L’experiment es va realitzar sobre 20 femelles. Es van dividir aleatòriament en 4 subgrups de 5 exemplars cadascun. Cada grup va rebre una combinació diferent de llum i temperatura. Als 3 mesos es mesuraren els seus GSI. Els resultats obtinguts varen ser: \\[ \\begin{array}{c} \\hphantom{(temperatura)}\\text{Factor A}\\\\ \\hphantom{(temperatura)}\\text{(hores de llum)}\\\\ \\begin{array}{c|cc} \\text{Factor B} &amp; \\text{9 hores}&amp; \\text{14 hores}\\\\ \\text{(temperatura)}&amp; &amp;\\\\\\hline 16^\\circ &amp;1.30&amp;1.01\\\\ &amp;2.88&amp;1.52\\\\ &amp;2.42&amp;1.02\\\\ &amp;2.66&amp;1.32\\\\ &amp;2.94&amp;1.63\\\\\\hline 27^\\circ &amp;0.90&amp;0.83\\\\ &amp;1.06&amp;0.67\\\\ &amp;0.98&amp;0.57\\\\ &amp;1.29&amp;0.47\\\\ &amp;1.12&amp;0.66\\\\ \\end{array} \\end{array} \\] El disseny experimental d’aquest estudi és d’ANOVA de 2 vies: La variable aleatòria d’interés \\(X\\) és el GSI d’un peix (femella) als 3 mesos Classificam la població (els peixos) segons les combinacions dels nivells de dos factors (A: el fotoperíode; B: la temperatura) Prenem una m.a.s. de cada combinació de nivells, independents i totes de la mateixa mida, i mesuram el GSI dels individus seleccionats La situació general en una ANOVA de 2 vies serà la següent: Tenim en compte dos factors, A i B. El factor A té \\(a\\) nivells (o tractaments, recordau) i el factor B, \\(b\\) nivells. En el nostre exemple, \\(a=b=2\\) Fem \\(n\\) observacions de cada combinació de tractaments, un de cada factor. El nombre total d’observacions serà per tant \\(N=n\\cdot a\\cdot b\\). En el nostre exemple, \\(n=5\\) i \\(N=20\\) Indicarem amb \\(X_{ijk}\\), \\(i=1,\\ldots,a\\), \\(j=1,\\ldots,b\\), \\(k=1,\\ldots,n\\), el valor de la variable \\(X\\) en el \\(k\\)-èsim subjecte de la mostra corresponent al nivell \\(i\\)-èsim del factor A i el nivell \\(j\\)-èsim del factor B Donarem les dades en una taula d’aquest estil: \\[ \\begin{array}{c} \\hphantom{Factor B}\\text{Factor A}\\\\ \\begin{array}{c|cccc} \\text{Factor B} &amp; 1&amp; 2 &amp; \\ldots &amp; a\\\\ \\hline 1&amp;X_{111}&amp;X_{211}&amp;\\cdots&amp;X_{a11}\\\\ &amp;X_{112}&amp;X_{212}&amp;\\cdots&amp;X_{a12}\\\\ &amp;\\cdots&amp;\\cdots&amp;\\cdots&amp;\\cdots\\\\ &amp;X_{11n}&amp;X_{21n}&amp;\\cdots&amp;X_{a1n}\\\\\\hline 2&amp;X_{121}&amp;X_{221}&amp;\\cdots&amp;X_{a21}\\\\ &amp;X_{122}&amp;X_{222}&amp;\\cdots&amp;X_{a22}\\\\ &amp;\\cdots&amp;\\cdots&amp;\\cdots&amp;\\cdots\\\\ &amp;X_{12n}&amp;X_{22n}&amp;\\cdots&amp;X_{a2n}\\\\\\hline \\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\ \\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots&amp;\\vdots\\\\\\hline b&amp;X_{1b1}&amp;X_{2b1}&amp;\\cdots&amp;X_{ab1}\\\\ &amp;X_{1b2}&amp;X_{2b2}&amp;\\cdots&amp;X_{ab2}\\\\ &amp;\\cdots&amp;\\cdots&amp;\\cdots&amp;\\cdots\\\\ &amp;X_{1bn}&amp;X_{2bn}&amp;\\cdots&amp;X_{abn}\\\\\\hline \\end{array} \\end{array} \\] Per que tengui sentit realitzar una ANOVA de 2 vies sobre aquestes dades, s’han de satisfer les condicions següents: Les observacions per a cada combinació de nivells constitueixen mostres aleatòries simples independents, totes de la mateixa mida \\(n\\) Cadascuna de les \\(a\\cdot b\\) subpoblacions definides per les combinacions de tractaments, un de cada factor, és normal Homocedasticitat: Totes aquestes subpoblacions tenen la mateixa variància, que indicarem amb \\(\\sigma^2\\) Els paràmetres que intervindran en el contrast són: \\(\\mu\\): la mitjana poblacional global \\(\\mu_{i\\bullet}\\): la mitjana poblacional del nivell \\(i\\)-èsim del factor A \\(\\mu_{\\bullet j}\\): mitjana poblacional del nivell \\(j\\)-èsim del factor B \\(\\mu_{ij}\\): mitjana poblacional de la combinació \\((i,j)\\) de nivells d’A i B L’ANOVA de 2 vies se basa en el model següent: per a tots \\(i=1,\\ldots,a\\) i \\(j=1,\\ldots,b\\) \\[ X_{ij}=\\mu+ \\alpha_i +\\beta_j + (\\alpha\\beta)_{ij}+E_{ij} \\] on: \\(X_{ij}\\) indica el valor de la variable \\(X\\) sobre un individu que pertany al nivell \\(i\\)-èsim del factor A i al nivell \\(j\\)-èsim del factor B \\(\\alpha_i=\\mu_{i\\bullet}-\\mu\\) representa la desviació de la mitjana de \\(X\\) en el nivell \\(i\\)-èsim del factor A respecte de la mitjana global \\(\\mu\\) (l’efecte del tractament \\(i\\)-èsim del factor A) \\(\\beta_j=\\mu_{\\bullet j}-\\mu\\) representa la desviació de la mitjana de \\(X\\) en el nivell \\(j\\)-èsim del factor B respecte de la mitjana global \\(\\mu\\) (l’efecte del tractament \\(j\\)-èsim del factor B) \\((\\alpha\\beta)_{ij}=\\mu_{ij}-\\mu_{i\\bullet}-\\mu_{\\bullet j}+\\mu\\) representa l’efecte de la interacció entre el nivell \\(i\\)-èsim del factor \\(A\\) i el nivell \\(j\\)-èsim del factor \\(B\\); si no hi hagués interacció, tendríem que \\[ \\mu_{ij}-\\mu=(\\mu_{i\\bullet}-\\mu)+(\\mu_{\\bullet j}-\\mu) \\] (l’efecte dels dos tractaments se sumaria; la demostració la donam en un bloc de corbes perilloses més a baix) i aquesta contribució de la interacció seria 0. \\(E_{ij}=X_{ij}-\\mu_{ij}\\) representa la part de la diferència entre \\(X_{ij}\\) i \\(\\mu\\) que no expliquen ni el tractament ni el bloc ni la interacció; en diem l’error aleatori, o el residu. Aquest model diu bàsicament que el valor de \\(X\\) sobre un individu és la suma de cinc components: La mitjana global \\(\\mu\\) de \\(X\\) sobre tota la població L’efecte del tractament A L’efecte del tractament B L’efecte de la interacció L’error aleatori Passem ara a la mostra amb la que volem realitzar el contrast. Siguin: \\(\\overline{X}_{ij}=\\dfrac{\\sum_{k=1}^n X_{ijk}}{n}\\): la mitjana mostral de la combinació \\((i,j)\\) de nivells d’A i B; estima \\(\\mu_{ij}\\) \\(\\overline{X}_{i\\bullet}=\\dfrac{\\sum_{j=1}^b\\sum_{k=1}^n X_{ijk}}{bn}\\): la mitjana mostral del nivell \\(i\\)-èsim del factor A; estima \\(\\mu_{i\\bullet}\\) \\(\\overline{X}_{\\bullet j}=\\dfrac{\\sum_{i=1}^a\\sum_{k=1}^n X_{ijk}}{an}\\): la mitjana mostral del nivell \\(j\\)-èsim del factor B estima \\(\\mu_{\\bullet j}\\) \\(\\overline{X}=\\dfrac{\\sum_{i=1}^{a}\\sum_{j=1}^b\\sum_{k=1}^n X_{ijk}}{a b n}\\): la mitjana mostral de tota la mostra; estima \\(\\mu\\) Exemple 9.18 Les mitjanes de la taula de l’Exemple 9.17 correspondrien a \\[ \\begin{array}{c} \\text{Factor A}\\\\ \\begin{array}{c|cc|cc|c} \\text{Factor B}&amp;\\text{9 hores} &amp; &amp;\\text{14 hores} &amp; &amp; \\\\ \\hline 16^\\circ &amp;1.30&amp; &amp; 1.01&amp; &amp;\\\\ &amp;2.88&amp; &amp; 1.52&amp; &amp;\\\\ &amp;2.42&amp; \\!\\!\\!\\!\\!\\!\\overline{X}_{11} &amp; 1.02&amp;\\!\\!\\!\\!\\!\\!\\! \\overline{X}_{21} &amp;\\overline{X}_{\\bullet1}\\\\ &amp;2.66&amp; &amp; 1.32&amp; &amp;\\\\ &amp;2.94&amp; &amp; 1.63&amp; &amp;\\\\\\hline 27^\\circ &amp;0.90&amp; &amp; 0.83&amp; &amp;\\\\ &amp;1.06&amp; &amp; 0.67&amp; &amp;\\\\ &amp;0.98&amp;\\!\\!\\!\\!\\!\\! \\overline{X}_{12} &amp; 0.57&amp;\\!\\!\\!\\!\\!\\!\\! \\overline{X}_{22} &amp;\\overline{X}_{\\bullet2}\\\\ &amp;1.29&amp; &amp; 0.47&amp; &amp;\\\\ &amp;1.12&amp; &amp; 0.66&amp; &amp;\\\\\\hline &amp; \\overline{X}_{1\\bullet} &amp; &amp; \\overline{X}_{2\\bullet} &amp; &amp; \\end{array} \\end{array} \\] Anem a calcular-les. Organitzarem les dades en un dataframe peixos amb 3 variables: GSI, quantitativa, contendrà el GSI de cada peix llum, un factor que contendrà el valor del nivell del factor A (fotoperíode) per a cada peix temp, un factor que contendrà el valor del nivell del factor B (temperatura) per a cada peix Com a tots els ANOVA, els factors que s’empren per classificar la població convé que siguin això, factors (o, almenys, vectors de paraules, no vectors numèrics), al dataframe si volem després emprar la funció aov per fer l’ANOVA. Entrarem les dades de la taula per fileres. Per tant el factor llum ha d’estar format per 10 còpies consecutives del vector (9,14) i el factor temp ha d’estar format per 10 còpies de “16” seguides de 10 còpies de “27”. GSI= c(1.30,1.01,2.88,1.52,2.42,1.02,2.66,1.32,2.94,1.63,0.90, 0.83,1.06,0.67,0.98,0.57,1.29,0.47,1.12,0.66) llum=as.factor(rep(c(9,14),10)) llum ## [1] 9 14 9 14 9 14 9 14 9 14 9 14 9 14 9 14 9 14 9 14 ## Levels: 9 14 temp=as.factor(rep(c(16,27),each=10)) temp ## [1] 16 16 16 16 16 16 16 16 16 16 27 27 27 27 27 27 27 27 27 27 ## Levels: 16 27 peixos=data.frame(GSI,llum,temp) str(peixos) ## &#39;data.frame&#39;: 20 obs. of 3 variables: ## $ GSI : num 1.3 1.01 2.88 1.52 2.42 1.02 2.66 1.32 2.94 1.63 ... ## $ llum: Factor w/ 2 levels &quot;9&quot;,&quot;14&quot;: 1 2 1 2 1 2 1 2 1 2 ... ## $ temp: Factor w/ 2 levels &quot;16&quot;,&quot;27&quot;: 1 1 1 1 1 1 1 1 1 1 ... head(peixos) ## GSI llum temp ## 1 1.30 9 16 ## 2 1.01 14 16 ## 3 2.88 9 16 ## 4 1.52 14 16 ## 5 2.42 9 16 ## 6 1.02 14 16 Calculem les mitjanes: Les \\(\\overline{X}_{ij}\\): Xb.i.j.bullet=aggregate(GSI~llum+temp, data=peixos,mean) Xb.i.j.bullet ## llum temp GSI ## 1 9 16 2.44 ## 2 14 16 1.30 ## 3 9 27 1.07 ## 4 14 27 0.64 Hem obtingut aquesta taula: \\[ \\begin{array}{c|cc} \\overline{X}_{ij} &amp; 9 &amp; 14\\\\ \\hline 16 &amp; 2.44 &amp; 1.30\\\\ 27 &amp; 1.07 &amp; 0.64 \\end{array} \\] Les \\(\\overline{X}_{i\\bullet}\\): Xb.A=aggregate(GSI~llum,data=peixos,mean) Xb.A ## llum GSI ## 1 9 1.755 ## 2 14 0.970 Les \\(\\overline{X}_{\\bullet j}\\): Xb.B=aggregate(GSI~temp,data=peixos,mean) Xb.B ## temp GSI ## 1 16 1.870 ## 2 27 0.855 La \\(\\overline{X}\\): mean(peixos$GSI) ## [1] 1.3625 Hem obtingut la taula següent: \\[ \\begin{array}{cc|cc|c} \\overline{X}_{1\\bullet} &amp; \\overline{X}_{2\\bullet} &amp; \\overline{X}_{\\bullet 1} &amp; \\overline{X}_{\\bullet 2} &amp; \\overline{X} \\\\ \\hline 1.755 &amp; 0.970 &amp; 1.870 &amp; 0.855 &amp; 1.3625 \\end{array} \\] En l’ANOVA de 2 vies hi tenim les identitats següents: Teorema 9.4 (Identitat de les sumes de quadrats) \\[ \\begin{array}{l} SS_{Total} = SS_{Tr}+SS_E\\\\[1ex] SS_{Tr} = SS_A+SS_B+SS_{AB} \\end{array} \\] on \\(SS_{Total}=\\displaystyle\\sum\\limits_{i=1}^a\\sum\\limits_{j=1}^b\\sum\\limits_{k=1}^n (X_{ijk}-\\overline{X})^2\\); és la Suma Total de Quadrats \\(SS_{Tr}=\\displaystyle n\\sum\\limits_{i=1}^a\\sum\\limits_{j=1}^b (\\overline{X}_{ij}-\\overline{X})^2\\); és la Suma de Quadrats dels Tractaments \\(SS_{A}=\\displaystyle b n\\sum\\limits_{i=1}^a (\\overline{X}_{i\\bullet}-\\overline{X})^2\\); és la Suma de Quadrats del Factor A \\(SS_{B}=\\displaystyle a n\\sum\\limits_{i=1}^b (\\overline{X}_{\\bullet j}-\\overline{X})^2\\); és la Suma de Quadrats del Factor B \\({SS_{AB}}=n \\sum\\limits_{i=1}^a\\sum\\limits_{j=1}^b (\\overline{X}_{ij}-\\overline{X}_{i\\bullet}-\\overline{X}_{\\bullet j}+\\overline{X})^2\\); és la Suma de Quadrats de la Interacció \\(SS_E=\\displaystyle\\sum\\limits_{i=1}^a\\sum\\limits_{j=1}^b\\sum\\limits_{k=1}^n (X_{ijk}-\\overline{X}_{ij})^2\\); és la Suma de Quadrats dels Residus o dels Errors Com als ANOVA anteriors, aquestes sumes de quadrats representen les diferents fonts de variabilitat de les dades: \\(SS_{Total}\\) representa la variabilitat total de les dades \\(SS_{Tr}\\) representa la variabilitat de les mitjanes de les combinacions de nivells \\(SS_{A}\\) representa la variabilitat de les mitjanes dels nivells del factor A \\(SS_{B}\\) representa la variabilitat de les mitjanes dels nivells del factor B \\(SS_E\\) representa la suma de les variabilitats dins cada combinació de nivells \\(SS_{AB}\\) representa la variabilitat deguda a la interacció Recordau que, si no hi hagués interacció, per a cada parella de nivells \\(j,j&#39;\\) de B, les diferències \\[ \\mu_{ij}-\\mu_{ij&#39;} \\] serien totes la mateixa, independentment del nivell \\(i\\) de \\(A\\). Diguem a aquesta diferència \\(\\delta_{jj&#39;}\\). Si ara calculam la mitjana per a tots els nivells \\(j&#39;\\) de B tenim \\[ \\mu_{ij}-\\mu_{i\\bullet}=\\mu_{ij}-\\frac{1}{b}\\sum_{j&#39;=1}^b \\mu_{ij&#39;}= \\frac{1}{b} \\sum_{j&#39;=1}^b(\\mu_{ij}-\\mu_{ij&#39;})= \\frac{1}{b}\\sum_{j&#39;=1}^b \\delta_{jj&#39;} \\] Aquest valor no depèn del nivell \\(i\\). Per tant, si ara calculam la mitjana per a tots els nivells \\(i\\) d’A \\[ \\mu_{\\bullet j}-\\mu=\\frac{1}{a}\\sum_{i=1}^a(\\mu_{ij}-\\mu_{i\\bullet})=\\frac{1}{b}\\sum_{j&#39;=1}^b \\delta_{jj&#39;} \\] En resum, si no hi hagués interacció entre els dos factors, tendríem que \\[ \\begin{array}{l} \\mu_{ij}-\\mu_{i\\bullet}-\\mu_{\\bullet j}+\\mu=(\\mu_{ij}-\\mu_{i\\bullet})-(\\mu_{\\bullet j}-\\mu)\\\\ \\qquad\\displaystyle =\\frac{1}{b}\\sum_{j&#39;=1}^b \\delta_{jj&#39;}-\\frac{1}{b}\\sum_{j&#39;=1}^b \\delta_{jj&#39;}=0 \\end{array} \\] i per tant, sobre la nostra mostra, esperaríem que \\[ \\overline{X}_{ij}-\\overline{X}_{i\\bullet}-\\overline{X}_{\\bullet j}+\\overline{X}=0 \\] Aleshores, \\(SS_{AB}\\) és la suma dels quadrats de les divergències, per a cada parell \\((i,j)\\), d’aquests valors a la nostra mostra respecte del que esperaríem si no hi hagués interacció. A més, de \\(\\mu_{ij}-\\mu_{i\\bullet}-\\mu_{\\bullet j}+\\mu=0\\) deduïm que \\[ \\mu_{ij}-\\mu=\\mu_{i\\bullet}+\\mu_{\\bullet j}-2\\mu=(\\mu_{i\\bullet}-\\mu)+(\\mu_{\\bullet j}-\\mu) \\] com afirmàvem en parlar del model de l’ANOVA de 2 vies. Observau que de \\[ \\begin{array}{l} SS_{Total} = SS_{Tr}+SS_E\\\\[1ex] SS_{Tr} = SS_A+SS_B+SS_{AB} \\end{array} \\] s’en dedueix que \\[ SS_{Total} = SS_A+SS_B+SS_{AB}+SS_E \\] La variabilitat total descompon en la suma de la variabilitat de les mitjanes del factor A més la variabilitat de les mitjanes del factor B més la variabilitat deguda a la interacció més la variabilitat de les dades dins cada combinació de tractaments, un de cada factor. Exemple 9.19 Comprovem aquestes identitats amb les dades de l’Exemple 9.17. Procurau entendre com calculam les sumes de quadrats; hem donat els raonaments detallats als altres dos tipus d’ANOVA, aquí ja no els donarem. n=5 a=2 b=2 X.barra=mean(peixos$GSI) La \\(SS_{Total}\\): SS.Tot=sum((peixos$GSI-X.barra)^2) SS.Tot ## [1] 11.13377 La \\(SS_{A}\\): SS.A=b*n*sum((Xb.A$GSI-X.barra)^2) SS.A ## [1] 3.081125 La \\(SS_{B}\\): SS.B=a*n*sum((Xb.B$GSI-X.barra)^2) SS.B ## [1] 5.151125 La \\(SS_{AB}\\): SS.AB=n*sum((Xb.i.j.bullet$GSI-Xb.A$GSI-rep(Xb.B$GSI,each=a)+X.barra)^2) SS.AB ## [1] 0.630125 La \\(SS_{Tr}\\): SS.Tr=n*sum((Xb.i.j.bullet$GSI-X.barra)^2) SS.Tr ## [1] 8.862375 La \\(SS_{E}\\): SS.E=sum((peixos$GSI-c(rep(Xb.i.j.bullet[1:2,3],n),rep(Xb.i.j.bullet[3:4,3],n)))^2) SS.E ## [1] 2.2714 Comprovem les igualtats de sumes de quadrats SS.Tr ## [1] 8.862375 SS.A+SS.B+SS.AB ## [1] 8.862375 SS.Tot ## [1] 11.13377 SS.Tr+SS.E ## [1] 11.13377 Com als altres ANOVA, compararem la variabilitat de les mitjanes amb la variabilitat dels errors. Per això, emprarem els quadrats mitjans següents: Quadrat mitjà del factor A: \\[ MS_A =\\dfrac{SS_A}{a-1} \\] Quadrat mitjà del factor B: \\[ MS_B =\\dfrac{SS_B}{b-1} \\] Quadrat mitjà de la interacció: \\[ MS_{AB}=\\dfrac{SS_{AB}}{(a-1)(b-1)} \\] Quadrat mitjà dels tractaments: \\[ MS_{Tr}=\\dfrac{SS_{Tr}}{ab-1} \\] Quadrat mitjà dels errors: \\[ MS_E=\\dfrac{SS_E}{ab (n-1)} \\] Fixau-vos que els denominadors són diferents dels dels quadrats mitjans homònims en les altres ANOVA. Exemple 9.20 Al nostre Exemple 9.17, on \\(n=5\\) i \\(a=b=2\\), hem obtingut les sumes de quadrats següents: \\[ \\begin{array}{cccccc} SS_{Total} &amp; SS_A &amp; SS_B &amp; SS_{AB} &amp;SS_{Tr} &amp; SS_E\\\\ \\hline 11.1338 &amp; 3.0811 &amp; 5.1511 &amp; 0.6301 &amp; 8.8624 &amp; 2.2714 \\end{array} \\] Per tant: \\[ \\begin{array}{ccccc} MS_A &amp; MS_B &amp; MS_{AB} &amp; MS_{Tr} &amp; MS_E\\\\ \\hline 3.0811 &amp; 5.1511 &amp; 0.6301 &amp; 2.9541 &amp; 0.142 \\end{array} \\] En una ANOVA de 2 vies, ens poden interessar els quatre contrastos següents: Contrast de mitjanes del factor A: Contrastam si hi ha diferències entre les mitjanes dels tractaments del factor A: \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{1\\bullet}=\\mu_{2\\bullet}=\\cdots =\\mu_{a\\bullet} \\\\ H_1 : \\text{Hi ha } i,i&#39;\\text{ tals que } \\mu_{i\\bullet} \\not = \\mu_{i&#39;\\bullet} \\end{array} \\right. \\] L’estadístic de contrast és \\[ F_A=\\frac{MS_A}{MS_E}, \\] el qual, si \\(H_0\\) és certa, té distribució \\(F\\) de Fisher amb \\(a-1\\) i \\(ab(n-1)\\) graus de llibertat i valor proper a 1 Contrast de mitjanes del factor B: Contrastam si hi ha diferències entre les mitjanes dels tractaments del factor B: \\[ \\left\\{ \\begin{array}{l} H_0 : \\mu_{\\bullet 1}=\\mu_{\\bullet 2}=\\cdots =\\mu_{ \\bullet b} \\\\ H_1 : \\text{Hi ha } j,j&#39;\\text{ tals que } \\mu_{\\bullet j} \\not = \\mu_{\\bullet j&#39;} \\end{array} \\right. \\] L’estadístic de contrast és \\[ F_B=\\frac{MS_B}{MS_E}, \\] el qual, si \\(H_0\\) és certa, té distribució \\(F\\) de Fisher amb \\(b-1\\) i \\(ab(n-1)\\) graus de llibertat i valor proper a 1 Contrast dels tractaments: Contrastam si hi ha diferències entre les mitjanes de les parelles (nivell de A, nivell de B): \\[ \\left\\{ \\begin{array}{l} H_0 : \\text{Per a tots }i,j,i&#39;,j&#39;,\\ \\mu_{ij}=\\mu_{i&#39;j&#39;} \\\\ H_1 : \\text{Hi ha } i,j,i&#39;,j&#39;\\text{ tals que } \\mu_{ij}\\neq \\mu_{i&#39;j&#39;} \\end{array} \\right. \\] L’estadístic de contrast és \\[ F_{Tr}=\\frac{MS_{Tr}}{MS_E}, \\] el qual, si \\(H_0\\) és certa, té distribució \\(F\\) de Fisher amb \\(ab-1\\) i \\(ab(n-1)\\) graus de llibertat i valor proper a 1 Contrast de no interacció: Contrastam si hi ha interacció entre els factors A i B: \\[ \\left\\{ \\begin{array}{l} H_0 : \\text{No hi ha interacció entre els nivells d&#39;$A$ i $B$} \\\\ H_1 : \\text{Hi ha interacció entre alguns nivells d&#39;$A$ i $B$} \\end{array} \\right. \\] L’estadístic de contrast és \\[ F_{AB} = \\frac{MS_{AB}}{MS_E}, \\] el qual, si \\(H_0\\) és certa, té distribució \\(F\\) de Fisher amb \\((a-1)(b-1)\\) i \\(ab(n-1)\\) graus de llibertat i valor proper a 1 En els quatre contrastos, el p-valor és \\[ P(F_{x,y}\\geqslant\\text{valor de l&#39;estadístic sobre la mostra}) \\] on \\(F_{x,y}\\) representa la distribució \\(F\\) de Fisher amb els graus de llibertat que pertoquin al contrast. Com fins ara, els graus de llibertat de cada estadístic de contrast F són els denominadors emprats en les definicions dels quadrats mitjans del numerador i el denominados. Tota aquesta informació se recull en la taula ANOVA següent: \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp; ab-1 &amp; SS_{Tr}&amp; MS_{Tr} &amp; F_{Tr} &amp; \\text{p-valor}_{Tr} \\\\ \\text{Factor A} &amp; a-1 &amp; SS_{A}&amp; MS_{A} &amp; F_A &amp; \\text{p-valor}_A \\\\ \\text{Factor B} &amp; b-1 &amp; SS_{B}&amp; MS_{B} &amp; F_B &amp; \\text{p-valor}_B \\\\ \\text{Interacció AB} &amp; (a-1)(b-1) &amp; SS_{AB}&amp; MS_{AB} &amp; F_{AB} &amp; \\text{p-valor}_{AB} \\\\ \\text{Residus} &amp; ab(n-1) &amp; SS_E &amp; MS_E &amp; \\\\\\hline \\end{array} \\] Exemple 9.21 Tornant a l’Exemple 9.17, tenim que \\(n=5\\), \\(a=b=2\\) i ja hem calculat els quadrats mitjans següents: \\[ \\begin{array}{ccccc} MS_A &amp; MS_B &amp; MS_{AB} &amp; MS_{Tr} &amp; MS_E\\\\ \\hline 3.0811 &amp; 5.1511 &amp; 0.6301 &amp; 2.9541 &amp; 0.142 \\end{array} \\] Realitzem els quatre contrastos: Hi ha diferència en la mitjana del GSI segons el fotoperíode? \\[ \\begin{array}{l} F_A=\\dfrac{MS_{A}}{MS_E}=21.7\\\\ \\text{p-valor}_A=P(F_{1,16}\\geqslant 21.7)=\\texttt{1-pf(21.7,1,16)}=0.0003 \\end{array} \\] Conclusió: Hem trobat evidència estadística que el GSI mitjà és diferent segons el fotoperíode (ANOVA de blocs, p-valor 0.0003) Hi ha diferència en la mitjana del GSI segons la temperatura? \\[ \\begin{array}{l} F_B=\\dfrac{MS_{B}}{MS_E}=36.3\\\\ \\text{p-valor}_B=P(F_{1,16}\\geqslant 36.3)=\\texttt{1-pf(36.3,1,16)}=2\\cdot 10^{-5} \\end{array} \\] Conclusió: Hem trobat evidència estadística que el GSI mitjà és diferent segons la temperatura (ANOVA de blocs, p-valor 2·10-5) Hi ha diferència en la mitjana del GSI segons les combinacions de fotoperíode i temperatura? \\[ \\begin{array}{l} F_{Tr}=\\dfrac{MS_{Tr}}{MS_E}=20.8\\\\ \\text{p-valor}_{Tr}=P(F_{3,16}\\geqslant 20.8)=\\texttt{1-pf(20.8,3,16)}=9\\cdot 10^{-6} \\end{array} \\] Conclusió: Hem trobat evidència estadística que no tots els GSI mitjans per a les combinacions de fotoperíode i temperatura són iguals (ANOVA de blocs, p-valor 9·10-6) Hi ha interacció entre el fotoperíode i la temperatura? \\[ \\begin{array}{l} F_{AB}=\\dfrac{MS_{AB}}{MS_E}=4.437\\\\ \\text{p-valor}_{AB}=P(F_{1,16}\\geqslant 4.437)=\\texttt{1-pf(4.437,1,16)}=0.051 \\end{array} \\] Conclusió: No hem trobat evidència estadística que hi hagi interacció entre el fotoperíode i la temperatura (ANOVA de blocs, p-valor 0.051) La taula ANOVA és \\[ \\begin{array}{llllll} \\hline \\text{Origen de la}&amp;\\text{Graus de}&amp;\\text{Sumes de}&amp;\\text{Quadrats} &amp; \\text{Estadístic de}&amp;\\text{p-valor}\\\\[-0.5ex] \\text{variabilitat}&amp;\\text{llibertat}&amp;\\text{quadrats}&amp;\\text{mitjans}&amp;\\text{contrast} &amp; \\\\\\hline \\text{Tractaments} &amp;3&amp;8.862&amp;2.954&amp;20.8 &amp; 9\\cdot 10^{-6} \\\\ \\text{Factor A} &amp;1&amp;3.081&amp;3.081&amp;21.7 &amp; 0.0003 \\\\ \\text{Factor B} &amp; 1&amp;5.151&amp;5.151&amp;36.3 &amp; 2\\cdot 10^{-5} \\\\ \\text{Interacció AB} &amp; 1&amp;0.630&amp;0.630&amp;4.44 &amp; 0.051 \\\\ \\text{Residus} &amp; 19&amp;11.134&amp;&amp; &amp; \\\\\\hline \\end{array} \\] Hem fet quatre contrastos. No hauríem d’ajustar els p-valors? No, perquè estam emprant les mateixes dades als quatre contrastos, no són contrastos independents. És a dir, o la mostra ens ha sortit representativa i totes les conclusions són més o menys fiables, o la mostra ens ha sortit rareta i totes les conclusions són poc fiables. 9.4.2 Amb R A l’ANOVA de 2 vies: Els contrastos de les mitjanes de cada un dels factors i de no interacció s’efectuen aplicant summary(aov( )) a la fórmula que separa la variable numèrica pel producte dels dos factors, indicat amb un asterisc *. El contrast dels tractaments, és a dir, de les mitjanes de les subpoblacions definides per les combinacions de nivells, un de cada factor, s’efectua aplicant summary(aov( )) a la fórmula que separa la variable numèrica per la combinació dels dos factors, indicada amb dos punts :. Així, l’ANOVA de blocs de l’Exemple 9.11 es fa amb summary(aov(GSI~llum*temp,data=peixos)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## llum 1 3.081 3.081 21.704 0.000262 *** ## temp 1 5.151 5.151 36.285 1.77e-05 *** ## llum:temp 1 0.630 0.630 4.439 0.051268 . ## Residuals 16 2.271 0.142 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 summary(aov(GSI~llum:temp,data=peixos)) ## Df Sum Sq Mean Sq F value Pr(&gt;F) ## llum:temp 3 8.862 2.954 20.81 9.06e-06 *** ## Residuals 16 2.271 0.142 ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 La primera funció calcula les fileres “Factor A”, “Factor B”, “Interacció AB” i “Residus” de la taula ANOVA, i de la segona funció us heu de quedar amb la primera filera, que us dóna la filera “Tractaments” de la taula ANOVA. No confongueu les fileres llum:temp de la primera taula, que és la de les Interaccions, amb la de la segona, que és la dels Tractaments. "]
]
