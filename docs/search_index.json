[
["index.html", "Matemàtiques II Presentació", " Matemàtiques II 2020-03-05 Presentació Això és una edició en línea dels apunts de Matemàtiques II dels graus de Biologia i Bioquímica de la UIB. Aquests apunts no són autocontinguts pel que fa al R: suposam que l’estudiant va llegint les lliçons de R corresponents a cada tema a la 2a part del manual AprendeR, que trobareu per ara a https://aprender-uib.github.io/AprendeR2/. Aquests apunts estan en construcció. A la llista següent hi anirem anunciant les actualitzacions. 02-03-2020: Afegits dos exemples a la Secció ?? 24-02-2020: Pujat tema 4 i corregits alguns errors irrellevants als temes anteriors 17-02-2020: Pujats temes 1, 2 i 3 Significats d’algunes capses: Material molt important. Alerta! Exercici. Detalls matemàtics que us poden interessar, però que no cal saber. Comentari que volem emfatitzar. Comentari que volem que recordeu. Acabam de matar un moixet. El llibre està escrit en R Markdown, emprant RStudio com a editor de textos i el paquet bookdown per convertir els fitxers markdown en un llibre Aquest treball se publica sota llicència Atribució-No Comercial-SenseDerivats 4.0 "],
["contrastos-dhipotesis-generalitats.html", "Tema 1 Contrastos d’hipòtesis: Generalitats 1.1 Hipòtesis nul·la i alternativa 1.2 Un exemple 1.3 El p-valor 1.4 Tipus d’errors 1.5 Exemple: El test t 1.6 Recapitulació", " Tema 1 Contrastos d’hipòtesis: Generalitats En moltes situacions, s’ha de prendre a partir d’una mostra una decisió sobre si es pot acceptar o rebutjar una hipòtesi relativa al valor d’un paràmetre d’una població o diverses poblacions. Per exemple: Volem saber si una moneda està trucada a favor de cara. Per decidir-ho, la llençam en l’aire una sèrie de vegades, i comptam quantes cares surten. Volem decidir si un tractament nou A és més efectiu que el tractament vell B en la curació d’una malaltia X. Per decidir-ho, portam a terme un assaig clínic, tractant amb A un grup de malalts i amb B un altre grup de malalts, i comparam la taxa de curació dels tractaments sobre aquests dos grups. El mètode estadístic que s’empra per acceptar o rebutjar una hipòtesi rep el nom de contrast d’hipòtesis. 1.1 Hipòtesis nul·la i alternativa En un contrast d’hipòtesis, es comparen sempre dues hipòtesis alternatives: la hipòtesi nul·la \\(H_{0}\\) i la hipòtesi alternativa \\(H_{1}\\). Se sol plantejar formalment \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{hipòtesi nul·la}\\\\ H_{1}:\\text{hipòtesi alternativa} \\end{array} \\right. \\] En un contrast d’hipòtesis: Típicament, la hipòtesi nul·la \\(H_{0}\\) és “no hi ha diferència”, “no passa res”, “no hi ha res d’estrany” o l’equivalent en el context del contrast: La moneda és honrada (50% de probabilitat de cara) Els tractaments A i B són igual d’efectius en la curació de la malaltia X La hipòtesi alternativa \\(H_{1}\\) planteja la diferència de la qual cercam evidència: La moneda està trucada a favor de cara (més del 50% de probabilitat de cara) A és més efectiu que B en la curació de la malaltia X Per defecte, estam disposats a acceptar \\(H_0\\): que no hi ha diferència, no passa res. Per defecte, estam disposats a acceptar que la moneda és honrada (la majoria ho són, no?) Per defecte, estam disposats a acceptar que els dos tractaments són igual d’efectius Si obtenim evidència suficient que \\(H_0\\) és falsa, rebutjarem \\(H_0\\) en favor de \\(H_1\\) i conclourem que \\(H_1\\) és vertadera. Què vol dir “obtenir evidència suficient que \\(H_0\\) és falsa”? Doncs que les proves obtingudes fan que \\(H_0\\) sigui inversemblant (mala de creure) per comparació amb \\(H_1\\): Tendrem evidència que la moneda està trucada a favor de cara si a la nostra sèrie de llençaments la proporció de cares és tan i tan gran que fa molt difícil creure que la probabilitat de cara sigui del 50% Tendrem evidència que el tractament A és més efectiu que B en la curació de la malaltia X si en el nostre assaig la taxa de curació de la malaltia X amb el tractament A és tan i tan més gran que la de B que fa molt difícil creure que els dos tractaments siguin iguals d’efectius Si no obtenim evidència suficient que \\(H_0\\) és falsa, és a dir, si les nostres dades són compatibles amb \\(H_0\\), no podrem rebutjar-la: acceptarem la hipòtesi nul·la. Acceptarem que la moneda no està trucada a favor de cara si a la nostra sèrie de llençaments la proporció de cares no és prou gran com per fer molt difícil creure que sigui honrada Acceptarem que el tractament A és igual d’efectiu que B en la curació de la malaltia X si en el nostre assaig la taxa de curació de la malaltia X amb el tractament A no és prou més gran que la de B com per fer molt difícil creure que els dos tractaments siguin iguals d’efectius Si rebutjam \\(H_0\\) en favor de \\(H_1\\) no serà perquè hàgim demostrat que \\(H_0\\) sigui impossible, ni tan sols que sigui improbable: tan sols haurem observat que és mala de creure vists els resultats del nostre experiment Per exemple, si en una seqüència de 30 llençaments d’una moneda obtenim totes les vegades cara, segurament ho considerarem evidència que la moneda està trucada, però no demostra que la moneda estigui trucada. Sí, fa mal de creure que sigui honrada, però no és impossible: la moneda podria ser honrada i per pur atzar nosaltres haver tengut aquesta ratxa de cares. I tampoc podem dir que sigui improbable que sigui honrada, ja que nosaltres sabem calcular \\[ P(\\text{30 cares en 30 llençaments}|\\text{La moneda és honrada})=0.5^{30} \\] però no sabem calcular \\[ P(\\text{La moneda és honrada}|\\text{30 cares en 30 llençaments}). \\] Si acceptam la hipòtesi nul·la és perquè no trobam motius per dubtar d’ella, però no haurem trobat evidència que sigui vertadera ni haurem demostrat que sigui probable (i possible en principi ho és sempre). Per exemple, si en una seqüència de 4 llençaments d’una moneda obtenim 2 cares, haurem d’acceptar que la moneda és honrada. Però podria ser que estigués lleugerament escorada cap a cara i no haver-se notat en una seqüència tan curta de llençaments. Exemple 1.1 En un judici (on l’acusat és innocent si no es demostra el contrari, i per tant estam disposats a acceptar per defecte que és innocent), se cerca evidència que l’acusat és culpable, per tant aquesta és la hipòtesi alternativa: El contrast és \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;acusat és innocent}\\\\ H_{1}:\\text{L&#39;acusat és culpable} \\end{array} \\right. \\] S’aporten proves Si el jurat troba prou incriminatòries les proves, “més enllà de tot dubte raonable”, declara culpable l’acusat (rebutja \\(H_0\\) en favor de \\(H_1\\)) Si el jurat no les troba prou incriminatòries, el considera no culpable (no rebutja \\(H_{0}\\)) Observau que considerar no culpable no és el mateix que demostrar que és innocent: simplement, es considera que l’acusat no és culpable si no s’ha trobat prou evidència que sigui culpable. Exemple 1.2 Un examen és un contrast d’hipòtesis. En aquest cas, “no passa res” significa que l’estudiant és com si no hagués anat al curs, no ha après res, i per tant aquesta és la hipòtesi nul·la; amb l’examen cercam evidència que l’estudiant ha après la matèria, per tant aquesta serà la hipòtesi alternativa: Contrast: \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;estudiant no sap la matèria}\\\\ H_{1}:\\text{L&#39;estudiant sap la matèria} \\end{array} \\right. \\] Prenem una mostra del coneixement de l’estudiant (l’estudiant fa l’examen) Si hi ha prou evidència en favor de \\(H_1\\) (si l’examen li surt prou bé), rebutjam \\(H_0\\): decidim que l’estudiant sap la matèria, aprova l’assignatura Si no hi ha prou evidència en favor de \\(H_1\\) (si l’examen no li surt prou bé), ens quedam amb \\(H_0\\): concloem que l’estudiant no ha après la matèria, suspèn l’assignatura Exemple 1.3 Ens trobam amb la notícia següent al diari, i ens demanam si les dones practiquen realment menys esport que els homes. Aquesta pregunta la podem plantejar de moltes maneres: Totes les dones fan cada dia menys hores d’esport que tots els homes? Si prenc una dona i un home a l’atzar, hi ha més d’un 50% de probabilitat que ella practiqui menys esport que ell? La majoria de les dones fan cada dia menys hores d’esport que la majoria dels homes? La proporció de practicants d’esport entre les dones és més petita que entre els homes? La mitjana setmanal de vegades que les dones practiquen esport és més petita que la dels homes? La mitjana setmanal d’hores que les dones practiquen esport és més petita que la dels homes? … Cada una d’aquestes preguntes es traduiria en un contrast d’hipòtesis diferent i possiblement mostres de tipus de dades diferents per realitzar-los. Com que aquí estam tractant contrastos sobre paràmetres poblacionals (mitjanes, proporcions, etc.), podríem plantejar algun dels tres darrers. Anem a centrar-nos en la darrera qüestió, sobre mitjanes setmanals d’hores d’esport. Aquí, les variables poblacionals d’interés són: \\(X_d\\): “Prenc una dona i calcul el seu nombre mitjà d’hores setmanals d’esport”, amb mitjana \\(\\mu_d\\): la mitjana d’hores setmanals d’esport de les dones (la mitjana de les mitjanes d’hores setmanals d’esport de totes les dones és la mitjana d’hores setmanals d’esport de les dones). \\(X_h\\): “Prenc un home i calcul el seu nombre mitjà d’hores setmanals d’esport”, amb mitjana \\(\\mu_h\\): la mitjana d’hores setmanals d’esport dels homes El contrast que volem realitzar és Hipòtesi nul·la: no hi ha diferència entre les mitjanes d’hores setmanals d’esport d’homes i dones Hipòtesi alternativa: la mitjana d’hores setmanals d’esport de les dones és més petita que la dels homes És a dir \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&lt;\\mu_h \\end{array} \\right. \\] El procediment per realitzar-lo serà: Prenem mostres aleatòries de dones i d’homes i els demanam pels seus hàbits de pràctica d’esport Calculam la mitjana mostral \\(\\overline{X}_d\\) d’hores setmanals d’esport de les dones de la mostra Calculam la mitjana mostral \\(\\overline{X}_h\\) d’hores setmanals d’esport dels homes de la mostra Si \\(\\overline{X}_d\\) és molt més petita que \\(\\overline{X}_h\\), ho prendrem com a evidència que \\(\\mu_d&lt;\\mu_h\\) Si \\(\\overline{X}_d\\) no és molt més petita que \\(\\overline{X}_h\\), no podrem rebutjar que \\(\\mu_d=\\mu_h\\) Què significa “\\(\\overline{X}_d\\) molt més petita que \\(\\overline{X}_h\\)”? Una opció, que podríem importar del tema anterior, seria calcular un interval de confiança del 95% per a \\(\\mu_d-\\mu_h\\) a partir de la mostra: Si està totalment a l’esquerra del 0, amb un 95% de confiança podem concloure que \\(\\mu_d&lt;\\mu_h\\) En cas contrari (si conté el 0 o si està totalment a la dreta del 0), amb un 95% de confiança no podem concloure que \\(\\mu_d&lt;\\mu_h\\) Com que aquí voldrem filar més prim que això del “nivell de confiança”, el procediment serà una mica més complicat (bàsicament, emprarem diferents fórmules per calcular els intervals de confiança segons la forma que tengui la hipòtesi alternativa). Abans de tancar aquesta secció, volem emfatitzar algunes advertències. Les hipòtesis dels contrastos són sobre paràmetres de les poblacions, NO sobre estadístics de les mostres. Aquí les hipòtesis del contrast comparaven les mitjanes poblacionals d’hores setmanals d’esport de les dones i els homes, no les mitjanes mostrals d’hores setmanals d’esport de les dones i els homes de la nostra mostra. Per comparar les mitjanes mostrals no ens fa falta un contrast d’hipòtesis: les calculam i punt. En canvi, com que no podem calcular les mitjanes d’hores setmanals d’esport de totes les dones i de tots els homes, ens veiem obligats a fer un contrast d’hipòtesis. La falta d’evidència a favor de \\(H_1\\) no és evidència a favor de \\(H_0\\) Si no podem assegurar que les dones practiquin menys esport que els homes (perquè no hàgim trobat evidència a favor d’aquesta hipòtesi), això no significarà que hàgim trobat evidència que els homes i les dones practiquin la mateixa quantitat d’esport o que les dones en practiquin més. Simplement, significarà que l’evidència a favor de \\(H_1\\) no ha estat prou forta com per poder afirmar que és vertadera i per tant acceptam que tothom practica la mateixa quantitat d’esport. En general, mai no podrem trobar evidència de la hipòtesi nul·la. Si per exemple al nostre estudi haguéssim trobat que \\(\\overline{X}_d=\\overline{X}_h\\), això seria compatible amb la hipòtesi nul·la \\(\\mu_d=\\mu_h\\), i per això no la podríem rebutjar, però no aporta evidència que \\(\\mu_d=\\mu_h\\), ja que segurament també seria compatible, per exemple, amb \\(\\mu_d=\\mu_h+0.0007\\) (les dones fan, de mitjana, un minut més d’esport a la setmana que els homes). La pregunta (el contrast) us la plantejau a priori a partir d’hipòtesis o suposicions prèvies. No val canviar de contrast a la vista de les dades. La pregunta la plantejam abans d’obtenir la mostra. Si estam interessats en el contrast \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&lt;\\mu_h \\end{array} \\right. \\] i obtenim que \\(\\overline{X}_d\\) és molt més gran que \\(\\overline{X}_h\\) en la nostra mostra, concloem que no tenim evidència que \\(\\mu_d&lt;\\mu_h\\) i punt. És fer trampes dir: “No hem trobat evidència que les dones practiquin menys esport que els homes, però si amb aquestes mateixes dades realitzam el contrast \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&gt;\\mu_h \\end{array} \\right. \\] sí que obtenim evidència que elles practiquen més esport que ells.” D’això s’en diu “anar a pescar” o també “torturar les dades”: obtenir unes dades i cercar de què donen evidència. És mala praxis científica. Qualsevol conjunt de dades, si el torturam prou, acaba donant evidència de qualque cosa. Triau la hipòtesi alternativa en funció d’allò que cercau evidència. No confongueu \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&lt;\\mu_h \\end{array} \\right. \\] amb \\[ \\left\\{\\begin{array}{ll} H_{0}: \\mu_d=\\mu_h\\\\ H_{1}:\\mu_d\\neq \\mu_h \\end{array} \\right. \\] que tradueix la pregunta &quot;Els homes i les dones, de mitjana, practiquen esport un nombre diferent d’hores a la setmana?’’ Regles per triar \\(H_0\\) i \\(H_1\\) en aquest curs: \\(H_0\\) sempre ha de significar “no hi ha diferència” i s’ha de definir formalment mitjançant una igualtat \\(H_1\\) és la hipòtesi de la que cercam evidència, i s’ha de definir formalment mitjançant alguna cosa “estricta”: Hipòtesi unilateral (one-sided; també d’una cua, one-tailed): definida amb &lt; o amb &gt; Hipòtesi bilateral (two-sided; també de dues cues, two-tailed): definida amb \\(\\neq\\) Els contrastos prenen el nom del tipus d’hipòtesi alternativa: contrast unilateral, de dues cues, etc. 1.2 Un exemple Tenc una moneda, i crec que està trucada a favor de cara. Vull contrastar-ho. Aquí la variable aleatòria \\(X\\) que ens interessa és “Llenç la moneda en l’aire i mir si surt cara”, que és Bernoulli amb probabilitat d’èxit (és a dir, probabilitat de treure cara amb la meva moneda) \\(p_{\\mathit{Cara}}\\). La hipòtesi nul·la serà que la moneda no està trucada (no li passa res a la meva moneda), i l’alternativa (de la que cerc evidència) que la moneda està trucada a favor de cara. En termes de \\(p_{\\mathit{Cara}}\\), el contrast és \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Exemple 1.4 Suposem que llenç la moneda en l’aire 3 vegades i obtenc 3 cares. És evidència suficient que està trucada? Diguem \\(S_3\\) a la variable aleatòria “Nombre de cares en 3 llençaments d’aquesta moneda.” Si la moneda no està trucada, \\(S_3\\) és binomial, \\(S_3\\sim B(3,0.5)\\), i per tant \\[ P(S_3=3)=0.5^{3}=0.125 \\] El resultat obtingut no és molt improbable amb una moneda honrada: passaria en 1 de cada 8 seqüències de 3 llençaments. Per tant, no és evidència suficient que estigui trucada. D’aquest tipus de procediment, emprant la distribució binomial del nombre d’èxits en una mostra aleatòria simple per contrastar un valor de la probabilitat poblacional d’èxit, en direm un test binomial. Exemple 1.5 Suposem que ara llenç la moneda en l’aire 10 vegades i obtenc 10 cares. És evidència suficient que està trucada? Diguem ara \\(S_{10}\\) a la variable aleatòria “Nombre de cares en 10 llençaments.” Si la moneda no està trucada, \\(S_{10}\\sim B(10,0.5)\\) i per tant \\[ P(S_{10}=10)=0.5^{10}=0.001 \\] El resultat obtingut és molt improbable si la moneda no està trucada: si la moneda fos honrada, només en 1 de cada 1000 seqüències de 10 llençaments obtendríem 10 cares. És a dir: El resultat del nostre experiment seria molt estrany si la moneda fos honrada, per tant és inversemblant que sigui honrada. Ho consideram evidència que està trucada. Fixau-vos en el procediment: Hem plantejat el contrast: \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Hem recollit una mostra aleatòria: la seqüència de llençaments Hem triat un estadístic de contrast amb distribució mostral coneguda quan \\(H_0\\) és vertadera: al nostre cas, el nombre de cares Hem calculat el valor d’aquest estadístic sobre la nostra mostra Hem calculat la probabilitat que l’estadístic prengui el valor observat si \\(H_0\\) és vertadera Si aquesta probabilitat és molt petita, ho consideram evidència que \\(H_1\\) és vertadera Si no és prou petita, no tenim evidència que \\(H_0\\) sigui falsa Bé, això és el que hem fet, però no és del tot correcte. Als punts (5) i (6) diem que: “Calculam la probabilitat que l’estadístic prengui el valor observat si \\(H_0\\) és vertadera i si és molt petita, ho consideram evidència que \\(H_1\\) és vertadera.” Segur?? Suposem que, al contrast anterior, llençam la moneda en l’aire 10 vegades i ara obtenim 10 creus. És evidència suficient que està trucada a favor de cara? Òbviament no ho pot ser, però la probabilitat és la mateixa que abans: \\[ P(S_{10}=0)=0.5^{10}=0.001 \\] En molts casos, la probabilitat d’obtenir exactament el que hem obtingut pot ser molt petita, independentment del que hàgim obtingut. Per exemple, suposem que llençam la moneda en l’aire 10000 vegades i obtenim 5000 cares. Si la moneda és honrada, el nombre de cares seguirà una distribució binomial \\(B(10000,0.5)\\) i la probabilitat d’obtenir 5000 cares serà dbinom(5000,10000,0.5)=0.008, ben petita, però clarament si la meitat de llençaments donen cara, no podem tenir mai evidència que la moneda estigui trucada. O, encara més exagerat, si l’estadístic de contrast té distribució contínua, recordau que la probabilitat que una variable aleatòria contínua prengui un valor concret és 0. Més petit impossible, però no sempre rebutjarem la hipòtesi nu·la. En realitat, a (5) es calcula la probabilitat que, si \\(H_0\\) és vertadera, l’estadístic prengui un valor tan extrem o més (en el sentit de \\(H_1\\)) que l’obtingut. A aquesta probabiitat li diem el p-valor. Al nostre exemple de la moneda, com que la hipòtesi nul·la és \\(p_{\\mathit{Cara}}= 0.5\\) i la hipòtesi alternativa és \\(p_{\\mathit{Cara}}&gt; 0.5\\), el p-valor és la probabilitat que, si \\(p_{\\mathit{Cara}}= 0.5\\), el nombre de cares sigui tan o més gran que l’obtingut a la nostra mostra. En els dos exemples anteriors concrets, on obteníem 3 cares en 3 llençaments i 10 cares en 10 llençaments, és el mateix demanar que el nombre de cares sigui igual a l’obtingut i demanar que el nombre de cares sigui més gran o igual que l’obtingut, perquè en els dos experiments hem obtingut el nombre màxim possible de cares; per exemple, treure 3 o més cares en 3 llençaments és exactament el mateix que treure 3 cares en 3 llençaments. Però en general no serà el cas. Exemple 1.6 Tornem al nostre contrast \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}&gt; 0.5 \\end{array} \\right. \\] Suposem que llenç la moneda en l’aire 10 vegades i obtenc 7 cares. És evidència suficient que està trucada? Seguim dient \\(S_{10}\\) a la variable aleatòria “Nombre de cares en 10 llençaments”. Si la moneda no està trucada, \\(S_{10}\\sim B(10,0.5)\\). Com que la hipòtesi alternativa és \\(p_{\\mathit{Cara}}&gt; 0.5\\), “obtenir un nombre de cares tan extrem o més que el que hem obtingut en el sentit de la hipòtesi alternativa” és treure tantes cares com les que hem obtingut o més, és a dir treure 7 o més cares. Per tant \\[ \\text{p-valor}=P(S_{10}\\geqslant 7)=\\texttt{1-pbinom(6,10,0.5)}=0.172 \\] Un resultat tan extrem o més que l’obtingut no és molt improbable si la moneda no està trucada: passaria 1 de cada 6 vegades. Per tant, com que és bastant compatible amb el fet que la moneda sigui honrada, no ho podem considerar evidència que estigui trucada a favor de cara. Exemple 1.7 Tenc una moneda, i ara crec que està trucada a favor de creu. Vull contrastar-ho. Plantejat en termes de \\(p_{\\mathit{Cara}}\\), el contrast que vull realitzar és \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}: p_{\\mathit{Cara}}&lt; 0.5 \\end{array} \\right. \\] Suposem que llenç la moneda en l’aire 10 vegades i obtenc 1 cara. És evidència suficient que \\(p_{\\mathit{Cara}}&lt; 0.5\\)? Seguim dient \\(S_{10}\\) a la variable aleatòria “Nombre de cares en 10 llençaments d’aquesta moneda.” Si la moneda no està trucada, \\(S_{10}\\sim B(10,0.5)\\). Ara, com que \\(H_{1}\\) és \\(p_{\\mathit{Cara}}&lt; 0.5\\), “obtenir un nombre de cares tan extrem o més que el que hem obtingut en el sentit de la hipòtesi alternativa” és treure tantes cares com les que hem obtingut o menys, és a dir treure 1 cara o cap. Per tant \\[ \\text{p-valor}=P(S_{10}\\leqslant 1)=\\texttt{pbinom(1,10,0.5)}=0.01 \\] Un resultat tan extrem o més que l’obtingut és molt improbable si \\(p_{\\mathit{Cara}}= 0.5\\): passaria en 1 de cada 100 seqüències de 10 llençaments. Ho podem considerar evidència que la moneda està trucada a favor de creu. 1.3 El p-valor El p-valor d’un contrast és la probabilitat que, si la hipòtesi nul·la és vertadera, l’estadístic de contrast prengui en una mostra aleatòria simple de la mateixa mida que la nostra un valor tan o més extrem, en el sentit de la hipòtesi alternativa, que l’obtingut amb la mostra emprada per realitzar el contrast. Ho tornarem a repetir, posant èmfasi en els components fonamentals de la definició. El p-valor és: La probabilitat que, si la hipòtesi nul·la és vertadera, l’estadístic de contrast prengui en una mostra aleatòria simple de la mateixa mida que la nostra un valor tan o més extrem, en el sentit de la hipòtesi alternativa, que l’obtingut amb la nostra mostra. Exemple 1.8 Suposem que al contrast de les mitjanes d’hores setmanals d’esport d’homes i dones de l’Exemple 1.3 empram com a estadístic de contrast la diferència entre les mitjanes mostrals \\(\\overline{X}_d-\\overline{X}_h\\) (que no serà el cas: només és un exemple!) i que hem pres mostres de 50 dones i de 50 homes. Aleshores, el p-valor del contrast és La probabilitat que, si la hipòtesi nul·la és vertadera, si \\(\\mu_d=\\mu_h\\), és a dir, si els homes i les dones practiquen de mitjana el mateix nombre d’hores d’esport a la setmana, l’estadístic de contrast prengui en una mostra aleatòria simple de la mateixa mida que la nostra el valor de \\(\\overline{X}_d-\\overline{X}_h\\), és a dir, de la mitjana mostral d’hores setmanals d’esport en les dones menys la mitjana mostral d’hores setmanals d’esport en els homes, d’una mostra aleatòria formada per 50 dones i 50 homes un valor tan o més extrem, en el sentit de la hipòtesi alternativa, sigui més petit o igual (perquè la hipòtesi alternativa és \\(\\mu_d&lt;\\mu_h\\), és a dir \\(\\mu_d-\\mu_h&lt;0\\)) que l’obtingut amb la nostra mostra. que el de la nostra mostra En resum, el p-valor seria en aquest cas La probabilitat, suposant que \\(\\mu_d=\\mu_h\\), que, si prenem una mostra aleatòria de 50 dones i 50 homes, el valor de \\(\\overline{X}_d-\\overline{X}_h\\) que obtinguem sigui més petit o igual que el de la nostra mostra. Si aquesta probabilitat és molt petita, la mostra obtinguda és poc consistent amb la hipòtesi nul·la i per tant conclourem que la hipòtesi alternativa és vertadera. Si, en canvi, aquesta probabilitat no és molt petita, la mostra obtinguda és consistent amb la hipòtesi nul·la i per tant no podrem rebutjar que \\(H_0\\) sigui vertadera. El p-valor no és: La probabilitat que \\(H_0\\) sigui vertadera condicionada al nostre resultat La probabilitat que \\(H_1\\) sigui falsa condicionada al nostre resultat És a l’inrevés: El p-valor és la probabilitat del nostre resultat (o quelcom més extrem) condicionada al fet que \\(H_0\\) sigui vertadera. Per tant, el p-valor és una evidencia indirecta inversa de \\(H_1\\): Com més petit sigui el p-valor, més rar seria el que hem obtingut si \\(H_0\\) fos vertadera i \\(H_1\\) falsa, i per tant més evidència tenim que \\(H_0\\) no pot ser vertadera i que la vertadera és \\(H_1\\). Per exemple, que el p-valor d’un contrast doni 0.03 Significa que, si \\(H_0\\) és vertadera, la probabilitat que l’estadístic de contrast prengui sobre una mostra un valor tan extrem o més que el que hem obtingut és 0.03 El trobau petit? Ho preneu com a evidència que \\(H_0\\) és falsa i \\(H_1\\) vertadera No el trobau petit? No teniu evidència per rebutjar que \\(H_0\\) és vertadera No significa que: La probabilitat que \\(H_0\\) sigui vertadera és 0.03 \\(H_0\\) és vertadera un 3% de les vegades En un contrast d’hipòtesis no obtenim cap informació directa sobre la probabilitat de \\(H_0\\) o de \\(H_1\\). Exemple 1.9 Tenc una moneda i crec que està trucada; a favor de cara o a favor de creu, no ho sé, només sospit que està trucada. Vull contrastar-ho. Plantejat en termes de la probabilitat de treure cara \\(p_{\\mathit{Cara}}\\), el contrast que vull realitzar ara és \\[ \\left\\{\\begin{array}{ll} H_{0}:p_{\\mathit{Cara}}= 0.5\\\\ H_{1}:p_{\\mathit{Cara}}\\neq 0.5 \\end{array} \\right. \\] Suposem que la llenç en l’aire 10 vegades i obtenc 8 cares. És evidència suficient que està trucada? Com a la secció anterior, diguem \\(S_{10}\\) a la variable “Nombre de cares en 10 llençaments”. Si \\(p_{\\mathit{Cara}}= 0.5\\), \\(S_{10}\\sim B(10,0.5)\\). Si la hipòtesi nul·la fos vertadera, esperaríem treure 5 cares i 5 creus. Com que la hipòtesi alternativa és \\(H_{1}:p_{\\mathit{Cara}}\\neq 0.5\\), ara “obtenir un resultat tan o més extrem, en el sentit de la hipòtesi alternativa, que l’obtingut” és treure un resultat tant o més diferent de 5 cares i 5 creus que l’obtingut: és a dir, treure almenys 8 cares o almenys 8 creus, o el que és el mateix, treure o bé 8 o més cares, o bé 2 o menys cares. Per tant, el p-valor és \\[ \\begin{array}{l} P(S_{10}\\geqslant 8\\text{ o }S_{10}\\leqslant 2) =P(S_{10}\\geqslant 8) + P(S_{10}\\leqslant 2)\\\\ \\qquad =1-P(S_{10}\\leqslant 7) + P(S_{10}\\leqslant 2)\\\\ \\qquad =\\texttt{1-pbinom(7,10,0.5)+pbinom(2,10,0.5)}\\\\ \\qquad =0.11 \\end{array} \\] Per tant, si la moneda no està trucada, un resultat com l’obtingut o més llunyà de “meitat cares, meitat creus” és improbable, però no gaire (1 de cada 9 vegades passaria). És evidència suficient que estigui trucada? 1.4 Tipus d’errors Al darrer exemple ens ha sorgit la qüestió de quin p-valor marca el llindar entre obtenir evidència o no. És 0.11 prou petit? La resposta és que depèn de quant estiguem disposats a equivocar-nos. La comparació entre la realitat i la decisió resultant d’un contrast dóna lloc a quatre situacions possibles, resumides en la taula següent: \\(H_0\\) és la vertadera a la realitat i nosaltres decidim que \\(H_1\\) és vertadera. La conclusió del contrast és errònia. En diem error de tipus I o positiu fals. Indicarem amb \\(\\alpha\\) la probabilitat de cometre un error de tipus I, és a dir, de rebutjar \\(H_0\\) si és vertadera, i en direm el nivell de significació: \\[ \\alpha=P(\\text{Rebutjar } H_0| H_0\\text{ vertadera}). \\] \\(H_1\\) és vertadera a la realitat i nosaltres acceptam \\(H_0\\). La conclusió del contrast és errònia. En diem error de tipus II o negatiu fals. Indicarem amb \\(\\beta\\) la probabilitat de cometre un error de tipus II, és a dir, d’acceptar \\(H_0\\) si \\(H_1\\) és vertadera,: \\[ \\beta=P(\\text{Acceptar } H_0| H_1\\text{ vertadera}). \\] \\(H_1\\) és vertadera a la realitat i nosaltres decidim que \\(H_1\\) és vertadera. La conclusió del contrast és correcta. En diem un positiu vertader. La probabilitat d’encertar amb un positiu vertader és \\(1-\\beta\\) i en direm la potència: \\[ 1-\\beta=P(\\text{Rebutjar } H_0| H_1\\text{ vertadera}). \\] \\(H_0\\) és la vertadera a la realitat i nosaltres l’acceptam. La conclusió del contrast és correcta. En diem un negatiu vertader. La probabilitat d’encertar amb un negatiu vertader és \\(1-\\alpha\\) i en direm el nivell de confiança: \\[ 1-\\alpha=P(\\text{Acceptar } H_0| H_0\\text{ vertadera}). \\] En el context d’un contrast d’hipòtesis, un resultat positiu és rebutjar la hipòtesi nul·la i decidir que l’alternativa és la vertadera (hem trobat qualque cosa) un resultat negatiu és acceptar la hipòtesi nul·la (no hem trobat res i ens hem de conformar amb la hipòtesi nul·la) Ho tornam a repetir: el nivell de significació d’un contrast és la probabilitat que, si la hipótesi nul·la és vertadera, nosaltres ens equivoquem i la rebutjem en favor de l’alternativa: \\[ \\alpha=P(\\text{Rebutjar } H_0| H_0\\text{ vertadera}). \\] la potència d’un contrast és la probabilitat que, si la hipótesi alternativa és vertadera, nosaltres ho detectem i rebutjem la hipòtesi nul·la en favor de l’alternativa: \\[ 1-\\beta=P(\\text{Rebutjar } H_0| H_1\\text{ vertadera}). \\] Exemple 1.10 En un test d’embaraç, el contrast que es realitza és: \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{No estàs embaraçada}\\\\ H_{1}:\\text{Estàs embaraçada} \\end{array} \\right. \\] Exemple 1.11 En un judici, on s’ha de declarar un acusat innocent o culpable, el contrast era \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;acusat és innocent}\\\\ H_{1}:\\text{L&#39;acusat és culpable} \\end{array} \\right. \\] Es poden cometre dos errors: Error de tipus I: Declarar culpable un innocent Error de tipus II: Declarar no culpable un culpable És pitjor l’error de tipus I, convé minimitzar-lo. Per això només es declara qualcú culpable quan les proves ho demostren més enllà de qualsevol dubte raonable Exemple 1.12 En un examen, el contrast era \\[ \\left\\{\\begin{array}{ll} H_{0}:\\text{L&#39;estudiant no sap la matèria}\\\\ H_{1}:\\text{L&#39;estudiant sap la matèria} \\end{array} \\right. \\] Es poden donar dos errors: Que l’estudiant aprovi sense saber la matèria Que l’estudiant suspengui sabent la matèria Quin és el de tipus I i quin el de tipus II? Quin creieu que és pitjor? Normalment, es considera pitjor cometre un error de tipus I que cometre un error de tipus II. Per tant, l’objectiu primari en un contrast és trobar una regla de rebuig de \\(H_{0}\\) que tengui poca probabilitat \\(\\alpha\\) d’error de tipus I. Però també voldríem minimitzar la probabilitat \\(\\beta\\) d’error de tipus II. El problema és que quan fem disminuir \\(\\alpha\\), sol augmentar \\(\\beta\\). Què se sol fer? Donar una regla de decisió per a un \\(\\alpha\\) màxim fixat Després, augmentar la mida \\(n\\) de la mostra per arribar a la \\(\\beta\\) desitjada Abans d’acabar amb els errors, fixau-vos que si efectuam \\(M\\) contrastos (independents) emprant una regla de decisió que garanteixi un nivell de significació \\(\\alpha\\) fixat, i a tots aquests contrastos la \\(H_0\\) és vertadera, el nombre de contrastos d’aquests on ens equivocarem i rebutjarem \\(H_0\\) té distribució binomial \\(B(M,\\alpha)\\). En particular, esperam equivocar-nos en \\(\\alpha M\\) d’aquests \\(M\\) contrastos on l’hipòtesi nul·la sigui vertadera. Si efectuam molts contrastos, augmenta la probabilitat de “trobar qualque cosa” encara que no hi hagi res que trobar, i acabar dient que les gominoles verdes curen l’acné: Figura 1.1: “Significant” (https://xkcd.com/882/ (CC-BY-NC 2.5)) 1.5 Exemple: El test t Ens demanam si els homes joves amb diabetis tenen una concentració de calci en plasma superior a la dels homes joves sans. Ho traduirem en un contrast d’hipòtesis sobre la concentració mitjana de calci en plasma en els homes joves amb diabetis, diguem-li \\(\\mu\\): La hipòtesi nul·la serà que no hi ha diferència entre \\(\\mu\\) i la concentració mitjana de calci en plasma en els homes joves sans, és a dir, que són iguals La hipòtesi alternativa és d’allò que cercam evidència: que \\(\\mu\\) és més gran que la concentració mitjana de calci en plasma en els homes joves sans. Se sap que la concentració de calci en plasma en homes sans segueix una llei aproximadament normal. El seu valor mitjà en homes sans de 22 a 44 anys s’estima en 2.5 mmol/l. Per tant, el contrast que volem realitzar és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=2.5\\\\ H_{1}:\\mu &gt;2.5 \\end{array} \\right. \\] En una mostra de 20 diabètics d’aquesta franja d’edat, es va obtenir una concentració mitjana de calci \\(\\overline{x}=3.2\\) mmol/l amb una desviació típica mostral \\(\\widetilde{s}=1.5\\). Suposem que aquesta mostra de diabètics joves és representativa i raonablement aleatòria. Volem decidir el contrast a partir d’aquesta mostra. Diguem \\(X\\) a la variable aleatòria “Prenem un home diabètic de 22 a 44 anys i li mesuram la concentració de calci en plasma en mmol/l”. Aquesta variable \\(X\\) també segueix una llei normal, però ara no sabem la seva mitjana \\(\\mu\\) i volem contrastar si és més gran que 2.5 o no. La nostra situació, doncs, és un cas particular del cas general següent. Tenim una variable aleatòria poblacional \\(X\\sim N(\\mu,\\sigma)\\) i plantejam el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt;\\mu_0 \\end{array} \\right. \\] per a un valor concret \\(\\mu_0\\). Volem prendre una decisió a partir d’una mostra aleatòria simple. En aquesta situació, si \\(H_0\\) és vertadera, és a dir, si la mitjana de \\(X\\) és \\(\\mu_0\\), sabem que \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\sim t_{n-1} \\] La idea que guiarà el procediment per prendre una decisió en aquest contrast serà: Rebutjarem \\(H_0\\) en favor de \\(H_1\\) si aquest estadístic de contrast \\(T\\) pren un valor “molt gran” sobre la mostra, és a dir, si \\(\\overline{X}\\) és “molts errors típics” més gran que \\(\\mu_0\\). La definició precisa de “molt gran” dependrà del valor d’\\(\\alpha\\) que volguem prendre, és a dir, de la probabilitat de cometre un error de tipus I que estiguem disposats a assumir. En Biologia i Bioquímica usualment es pren \\(\\alpha=0.05\\): una mica menys que la probabilitat de treure 4 cares seguides amb una moneda honrada. Aquí ara prendrem aquest mateix nivell de significació \\(\\alpha=0.05\\). És a dir, acceptarem que la probabilitat d’equivocar-nos rebutjant \\(H_0\\) en favor de \\(H_1\\) és 0.05, o el que és el mateix, ens permetrem cometre un error de tipus I una vegada de cada 20 que la hipòtesi nul·la sigui vertadera. Sigui \\(T_0\\) el valor que pren l’estadístic de contrast \\(T\\) en la nostra mostra. Rebutjarem \\(H_{0}\\) si \\(T_0\\) és més gran que un cert llindar \\(L_0\\), que determinam a partir de \\(\\alpha\\): \\[ \\begin{array}{l} \\alpha = P(\\text{Rebutjar } H_{0}| H_{0} \\text{ certa})=P(T&gt; L_0)\\\\ \\qquad\\quad \\Longrightarrow 1-\\alpha= P(T\\leqslant L_0)\\Longrightarrow L_0= t_{n-1,1-\\alpha} \\end{array} \\] Per tant, a fi que el nivell de significació del contrast sigui \\(\\alpha\\), Rebutjarem \\(H_0\\) si \\(T_0&gt;t_{n-1,1-\\alpha}\\) En direm una regla de rebuig per aquest tipus de contrast. Tornem al nostre exemple dels diabètics \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=2.5\\\\ H_{1}:\\mu &gt; 2.5 \\end{array} \\right. \\] Si \\(\\alpha=0.05\\) i \\(n=20\\), el llindar a partir del qual rebutjam \\(H_0\\) és \\(t_{n-1,1-\\alpha}=t_{19,0.95}=\\texttt{qt(0.95,19)}=1.73\\). A la nostra mostra hi tenim que \\(\\overline{x}=3.2\\), \\(\\widetilde{s}=1.5\\) i \\(n=20\\), per tant l’estadístic de contrast val \\[ T_0=\\frac{3.2-2.5}{1.5/\\sqrt{20}}=2.09 \\] Com que \\(2.09&gt;1.73\\), concloem amb un nivell de significació de 0.05 que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els joves sans. Anem a veure com entra en joc el p-valor. Recordem que rebutjarem \\(H_0\\) quan \\(T_0&gt;t_{n-1,1-\\alpha}\\): \\[ \\begin{array}{l} \\text{Rebutjarem $H_0$} \\Longleftrightarrow T_0&gt; t_{n-1,1-\\alpha}\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt; P(T\\geqslant t_{n-1,1-\\alpha})\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt; 1-P(T\\leqslant t_{n-1,1-\\alpha})=1-(1-\\alpha)=\\alpha\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant T_0)&lt;\\alpha \\end{array} \\] I ara observau que \\(P(T\\geqslant T_0)\\) és la probabilitat que, si \\(H_0\\) és vertadera, l’estadístic de contrast \\(T\\) prengui un valor tan extrem o més, en el sentit de \\(H_1: \\mu&gt;2.5\\), que l’obtingut en la nostra mostra, \\(T_0\\): és el p-valor del contrast. Per tant, tenim una altra regla de rebuig (equivalent a l’anterior): Rebutjarem \\(H_0\\) quan el p-valor sigui més petit que \\(\\alpha\\) En el nostre exemple, ja hem calculat \\(T_0=2.09\\). Llavors, \\[ \\text{p-valor} =P(T\\geqslant 2.09)=\\texttt{1-pt(2.09,19)} =0.025 \\] Com que el p-valor és més petit que 0.05, concloem amb un nivell de significació de 0.05 que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els sans. D’aquest tipus de procediment, emprant la distribució t de Student de \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\sim t_{n-1} \\] per comparar la \\(\\mu\\) d’una variable amb el valor \\(\\mu_0\\) en direm un test t. Fixau-vos que la nostra conclusió ha estat que “concloem amb un nivell de significació de 0.05 que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els joves sans.” Per tant, reconeixem una probabilitat d’equivocar-nos del 5%: Si en realitat el nivell mitjà de calci en sang en els joves diabètics és el mateix que en els sans, la probabilitat que teníem d’equivocar-nos i concloure que el nivell mitjà de calci en sang en els joves diabètics és més gran que en els sans és del 5%. Anem a estudiar aquesta taxa d’encerts per mitjà d’una simulació. Primer suposarem que el nivell mitjà real és 2.5, i simularem la probabilitat d’error de tipus I. Com que estam fent el contrast amb nivell de significació 0.05, esperam al voltant d’un 5% d’errors de tipus I. Per fixar idees, modelarem la població de joves diabètics per mitjà d’una variable aleatòria \\(N(2.5,0.5)\\). La \\(\\sigma=0.5\\) ens l’hem inventada. Aprofitam per fixar la llavor d’aleatorietat. set.seed(42) mu0=2.5 sigma0=0.5 El llindar \\(L_0\\) per \\(n=20\\) i \\(\\alpha=0.05\\) és L0=qt(0.95,19) La funció estadístic següent pren una mostra aleatòria de mida \\(n\\) d’una variable \\(N(\\mu, \\sigma)\\) i en calcula l’estadístic de contrast \\(T\\): estadístic=function(n,mu,sigma){ mostra=rnorm(n,mu,sigma) (mean(mostra)-mu0)/(sd(mostra)/sqrt(n)) } Ara, repetim 200 vegades el procés de prendre una mostra aleatòria de mida 20 de la nostra població i calcular la \\(T\\) corresponent. Després miram la proporció de vegades que això ha donat més gran que el llindar, és a dir, la proporció de vegades que rebutjam la hipòtesi nul·la \\(\\mu=2.5\\) i que per tant cometem un error de tipus I. Tes=replicate(200,estadístic(20,mu0,sigma0)) p.error.Tipus.I=length(which((Tes&gt;L0)==TRUE))/200 p.error.Tipus.I ## [1] 0.05 Hem comès exactament un 5% d’errors de tipus I! Ara suposarem que el nivell mitjà real és estrictament més gran que 2.5, i anam a simular els errors de tipus II, per veure amb quina freqüència els cometem. Per començar, generam de manera uniforme un vector de 100 \\(\\mu\\)’s entre 2.6 i 3. mus=runif(100,2.6,3) I ara el que farem serà el següent. Per a cada \\(\\mu_i\\) d’aquest vector, prendrem com a “població de diabètics” una variable \\(N(\\mu_i,0.5)\\). A continuació, per a cada una d’aquestes poblacions, repetim 200 vegades el procés de prendre una mostra aleatòria simple de mida 20 d’aquesta població i calcular la \\(T\\) corresponent. Després, per a cada població, miram la proporció de vegades que això ha donat més petit o igual que el llindar, és a dir, la proporció de vegades que acceptam la hipòtesi nul·la \\(\\mu=2.5\\) i que per tant cometem un error de tipus II. Organitzam totes aquestes proporcions en un vector p.error.Tipus.II. p.error.Tipus.II=rep(1,100) for (j in 1:100){ Tes=replicate(200,estadístic(20,mus[j],sigma0)) p.error.Tipus.II[j]=round(length(which((Tes&lt;=L0)==TRUE))/200,2) } p.error.Tipus.II ## [1] 0.24 0.36 0.52 0.53 0.31 0.04 0.08 0.09 0.78 0.68 0.62 0.00 0.10 0.12 ## [15] 0.65 0.01 0.04 0.62 0.57 0.10 0.58 0.25 0.30 0.00 0.29 0.48 0.26 0.00 ## [29] 0.08 0.66 0.07 0.08 0.79 0.03 0.02 0.00 0.00 0.56 0.52 0.24 0.72 0.04 ## [43] 0.70 0.77 0.74 0.70 0.06 0.15 0.06 0.48 0.00 0.04 0.10 0.01 0.02 0.00 ## [57] 0.35 0.60 0.58 0.64 0.08 0.38 0.09 0.40 0.78 0.02 0.02 0.66 0.46 0.27 ## [71] 0.18 0.05 0.59 0.01 0.04 0.44 0.33 0.34 0.66 0.01 0.10 0.68 0.73 0.74 ## [85] 0.21 0.07 0.18 0.68 0.02 0.32 0.06 0.64 0.66 0.27 0.08 0.49 0.20 0.02 ## [99] 0.10 0.42 La proporció mitjana d’errors de tipus II ha estat: mean(p.error.Tipus.II) ## [1] 0.3091 Si prenem mostres més grans, la probabilitat d’error de tipus II disminueix. Comprovem-ho repetint aquest segon experiment amb mostres de mida 200. p.error.Tipus.II.200=rep(1,100) for (j in 1:100){ Tes=replicate(200,estadístic(200,mus[j],sigma0)) p.error.Tipus.II.200[j]=round(length(which((Tes&lt;=L0)==TRUE))/200,2) } mean(p.error.Tipus.II.200) ## [1] 0.0074 Hem baixat d’una taxa d’errors de tipus II del 30.91% al 0.74%. Recordau que la potència d’un contrast és la probabilitat de no cometre un error de tipus II. Hem vist que prenent mostres més grans, la proporció d’errors de tipus II ha disminuït. Això és general: si augmentam la mida de la mostra i mantenim el nivell de significació, la potència augmenta. Si fixam el nivell de significació, com més grans són les mostres, més gran és la potència del contrast. Tornem a la situació general en la que tenim una variable aleatòria \\(X\\sim N(\\mu,\\sigma)\\) i volem contrastar \\(\\mu\\) amb un cert valor \\(\\mu_0\\) i suposem que ara cercam evidència que \\(\\mu&lt;\\mu_0\\), de manera que el contrast és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &lt; \\mu_0 \\end{array} \\right. \\] En aquest cas, el p-valor és \\(P(T\\leqslant T_0)\\) i, raonant exactament igual com abans, obtenim les dues regles de rebuig equivalents següents: Rebutjarem \\(H_0\\) si \\(T_0&lt; t_{n-1,\\alpha}\\) Rebutjarem \\(H_0\\) si el p-valor és més petit que \\(\\alpha\\) I què passa si ara cercam evidència que \\(\\mu\\) és diferent de \\(\\mu_0\\), és a dir, si tenim el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu\\ \\neq \\mu_0 \\end{array} \\right. \\] Aleshores rebutjarem \\(H_{0}\\) quan \\(\\overline{X}\\) és prou diferent de \\(\\mu_0\\), per damunt o per davall de \\(\\mu_0\\), i això ho traduïm en que rebutjarem \\(H_{0}\\) quan \\(|T_0|\\) (el valor absolut de \\(T_0\\)) sigui més gran que un cert llindar \\(L_0\\), que determinam a partir de \\(\\alpha\\) com abans: \\[ \\begin{array}{l} \\alpha = P(\\text{Rebutjar } H_{0}| H_{0} \\text{ certa})=P(|T|&gt; L_0)\\\\ \\hphantom{\\alpha} = P(T&lt; -L_0\\text{ o } T&gt;L_0)= P(T&lt; -L_0)+P(T&gt;L_0)\\\\ \\hphantom{\\alpha} =2P(T&gt;L_0) \\text{ (per la simetria de $t_{n-1}$)}\\\\ \\Longrightarrow \\alpha/2=P(T&gt;L_0)= 1-P(T\\leqslant L_0) \\\\ \\Longrightarrow P(T\\leqslant L_0)=1-\\alpha/2\\Longrightarrow L_0= t_{n-1,1-\\alpha/2} \\end{array} \\] Per tant, en un contrast bilateral amb nivell de significació \\(\\alpha\\), tenim la regla de rebuig següent: Rebutjarem \\(H_0\\) si \\(|T_0|&gt;t_{n-1,1-\\alpha/2}\\) En aquest cas, el p-valor serà la probabilitat que \\(T\\) prengui un valor tant o més extrem que \\(T_0\\), en el sentit de la hipòtesi alternativa: és a dir, més enfora de 0 que \\(T_0\\): més gran que \\(|T_0|\\) o més petit que \\(-|T_0|\\): \\[ \\text{p-valor} =P(T\\leqslant-|T_0|)+P(T\\geqslant|T_0|)=2 P(T\\geqslant|T_0|) \\] Per tant, \\[ \\begin{array}{l} \\text{Rebutjam $H_0$} \\Longleftrightarrow |T_0|&gt;t_{n-1,1-\\alpha/2}\\\\ \\qquad \\Longleftrightarrow P(T\\geqslant|T_0|)&lt;{\\alpha}/{2}\\\\ \\qquad\\Longleftrightarrow 2 P(T\\geqslant|T_0|)&lt;\\alpha\\\\ \\qquad \\Longleftrightarrow \\text{p-valor} &lt; \\alpha \\end{array} \\] Per tant, en un contrast bilateral amb nivell de significació \\(\\alpha\\) també tenim la regla de rebuig: Rebutjarem \\(H_0\\) si el p-valor és més petit que \\(\\alpha\\) Exemple 1.13 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&gt;20 \\end{array} \\right. \\] amb un nivell de significació de 0.05. Prenem una m.a.s. de \\(n=25\\) observacions i obtenim \\(\\overline{x}=20.7\\) i \\(\\widetilde{s}=1.8\\). Què decidim? Estadístic de contrast: \\(T=\\dfrac{\\overline{X}-\\mu_0}{\\widetilde{S}_X/\\sqrt{n}}\\) Pren el valor \\[ T_0=\\dfrac{20.7-20}{{1.8}/{\\sqrt{25}}}=1.944 \\] p-valor \\[ P(T\\geqslant 1.944)=\\texttt{1-pt(1.944,24)}=0.032 \\] Decisió: Com que el p-valor és més petit que 0.05, rebutjam \\(H_0\\) i concloem (amb \\(\\alpha=0.05\\)) que \\(\\mu&gt;20\\). Exemple 1.14 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu&gt;20 \\end{array} \\right. \\] amb un nivell de significació de 0.01. Amb la mateixa m.a.s. de l’exemple anterior. Què decidim? El p-valor és el mateix que abans, 0.032, perquè el contrast i la mostra són els mateixos. Com que aquest p-valor ara és més gran que 0.01, no podem rebutjar \\(H_0\\) amb \\(\\alpha=0.01\\) i hem d’acceptar que \\(\\mu=20\\). Fixau-vos que per reduir la probabilitat d’equivocar-nos rebutjant \\(H_0\\) si és vertadera, fem més fàcil acceptar-la “per si de cas”. Exemple 1.15 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu\\neq 20 \\end{array} \\right. \\] amb un nivell de significació de 0.05. Amb la mateixa m.a.s. dels exemples anteriors. Què decidim? Recordem que \\(n=25\\), \\(\\overline{x}=20.7\\) i \\(\\widetilde{s}=1.8\\). L’estadístic de contrast prenia el valor \\(T_0=1.944\\). Ara el p-valor és \\[ 2\\cdot P(T\\geqslant 1.944)=\\texttt{2*(1-pt(1.944,24))}=0.064 \\] Com que el p-valor és més gran que \\(\\alpha\\), no podem rebutjar \\(H_0\\): no podem afirmar amb \\(\\alpha=0.05\\) que \\(\\mu\\neq 20\\). Com pot ser que amb la mateixa mostra i mateix nivell de significació poguem concloure que \\(\\mu&gt; 20\\) però no poguem concloure que \\(\\mu\\neq 20\\)? O és que \\(\\mu&gt; 20\\) no implica que \\(\\mu\\neq 20\\)? Vegem, si haguéssim demostrat que segur que \\(\\mu&gt; 20\\), està clar que això implicaria que \\(\\mu\\neq 20\\). Però hem arribat a la conclusió \\(\\mu&gt; 20\\) assumint un cert marge d’equivocar-nos, una probabilitat d’error de tipus I de 0.05. En aquesta situació les regles de la lògica aristotèlica ja no funcionen. Fixau-vos que, en realitat, el que passa és que trobarem evidència que \\(\\mu\\neq 20\\) si \\(T\\) és molt gran o molt petit, i per tant al contrast bilateral hi tenim dues fonts d’error de tipus I: que per pur atzar \\(T\\) ens surti molt gran o que ens surti molt petit. En canvi, només trobarem evidència que \\(\\mu&gt; 20\\) si \\(T\\) és molt gran, i per tant hi tenim una sola font d’error de tipus I. Aleshores, per garantir una mateixa probabilitat d’error de tipus I, hem de ser molt més exigents al contrast bilateral, on ens podem equivocar de dues maneres diferents, que a l’unilateral. Exemple 1.16 Sigui \\(X\\) una població normal. Volem fer el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=20\\\\ H_{1}:\\mu\\neq 20 \\end{array} \\right. \\] amb un nivell de significació de 0.05. Prenem una m.a.s. de \\(n=25\\) observacions i obtenim \\(\\overline{x}=19\\) i \\(\\widetilde{s}=1.8\\). Què decidim? Estadístic de contrast: \\(T=\\dfrac{\\overline{X}-\\mu_0}{\\widetilde{S}_X/\\sqrt{n}}\\) Pren el valor \\[ T_0=\\dfrac{19-20}{{1.8}/{\\sqrt{25}}}=-2.778 \\] p-valor \\[ 2P(T\\geqslant-2.778)=\\texttt{2*(1-pt(-2.778,24))}=1.99 \\] Decisió: com que el p-valor és més gran que \\(\\alpha\\), no podem rebutjar \\(H_0\\). El p-valor és una probabiitat. Com voleu que doni 1.99? NO! El p-valor és \\(2\\cdot P(T\\geqslant|T_0|)\\), no \\(2\\cdot P(T\\geqslant T_0)\\). Per tant, el p-valor és \\[ 2\\cdot P(T\\geqslant 2.778)=\\texttt{2*(1-pt(2.778,24))}=0.01 \\] i com que p-valor és més petit que \\(\\alpha\\), podem rebutjar \\(H_0\\) i concloure, amb nivell de significació 0.05, que \\(\\mu\\neq 20\\). 1.6 Recapitulació Repassem els conceptes introduïts fins ara, i posem nom a alguns altres: Nivell de significació, \\(\\alpha\\): probabilitat de rebutjar \\(H_0\\) si aquesta és vertadera (probabilitat d’error de tipus I, de positiu fals) Nivell de confiança, \\(1-\\alpha\\): probabilitat d’acceptar \\(H_0\\) si aquesta és vertadera (probabilitat de negatiu vertader) Potència, \\(1-\\beta\\): probabilitat de rebutjar \\(H_0\\) si \\(H_1\\) és vertadera (probabilitat de positiu vertader) Estadístic de contrast: el que calculam sobre una mostra aleatòria simple i ens permet definir una regla de rebuig de \\(H_{0}\\) Regió crítica o de rebuig: el rang de valors de l’estadístic de contrast per als quals rebutjam \\(H_{0}\\) amb un nivell de significació \\(\\alpha\\) donat Regió d’acceptació: el complementari de la regió de rebuig, és a dir, el rang de valors de l’estadístic de contrast per als quals acceptam \\(H_{0}\\) amb un nivell de significació \\(\\alpha\\) donat p-valor: La probabilitat que, si \\(H_0\\) és vertadera, l’estadístic de contrast prengui sobre una mostra aleatòria simple de la mateixa mida que la nostra un valor tan o més extrem (en el sentit de \\(H_1\\)) que l’obtingut sobre la nostra mostra Exemple 1.17 Si realitzam un test t per efectuar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt; \\mu_0 \\end{array} \\right. \\] rebutjam \\(H_0\\) amb nivell de significació \\(\\alpha\\) (o amb nivell de confiança \\(1-\\alpha\\)) quan \\[ T=\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}&gt;t_{n-1,1-\\alpha} \\] Per tant: Estadístic de contrast: Aquest \\(T\\) Regió crítica per aquest \\(\\alpha\\): l’interval \\((t_{n-1,1-\\alpha},\\infty)\\) Regió d’acceptació per aquest \\(\\alpha\\): l’interval \\((-\\infty,t_{n-1,1-\\alpha}]\\) p-valor: \\(P(T\\geqslant T_0)\\), on \\(T_0\\) indica el valor de \\(T\\) sobe la nostra mostra Si en canvi el contrast que volem efectuar és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &lt; \\mu_0 \\end{array} \\right. \\] rebutjam \\(H_0\\) amb nivell de significació \\(\\alpha\\) (o amb nivell de confiança \\(1-\\alpha\\)) quan \\[ T=\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}&lt;t_{n-1,\\alpha} \\] Per tant: Estadístic de contrast: El mateix \\(T\\) que abans Regió crítica per aquest \\(\\alpha\\): l’interval \\((-\\infty,t_{n-1,\\alpha})\\) Regió d’acceptació per aquest \\(\\alpha\\): l’interval \\([t_{n-1,\\alpha},\\infty)\\) p-valor: \\(P(T\\leqslant T_0)\\) Finalment, si el contrast que volem realitzar és \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq \\mu_0 \\end{array} \\right. \\] rebutjam \\(H_0\\) amb nivell de significació \\(\\alpha\\) (o amb nivell de confiança \\(1-\\alpha\\)) quan \\[ |T|=\\left|\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\right|&gt;t_{n-1,1-\\alpha/2} \\] Per tant: Estadístic de contrast: El mateix \\(T\\) que abans Regió crítica per aquest \\(\\alpha\\): la unió d’intervals \\((-\\infty,-t_{n-1,1-\\alpha/2})\\cup (t_{n-1,1-\\alpha/2},\\infty)\\) Regió d’acceptació per aquest \\(\\alpha\\): l’interval \\([-t_{n-1,1-\\alpha/2},t_{n-1,1-\\alpha/2}]\\) p-valor: \\(2P(T\\geqslant|T_0|)\\) Interval de confiança d’un contrast L’interval de confiança de nivell de confiança \\(1-\\alpha\\) d’un contrast és un interval on el paràmetre poblacional que contrastam té probabilitat \\(1-\\alpha\\) de pertànyer-hi (en el sentit dels intervals de confiança del tema anterior: calculat amb una fórmula que un \\((1-\\alpha)\\cdot 100\\%\\) de les vegades que l’aplicam a una mostra aleatòria simple dóna un interval que conté el paràmetre d’interès). Aquest interval de confiança s’obté imposant que l’estadístic de contrast pertanyi a la regió d’acceptació per al nivell de significació \\(\\alpha\\) i aïllant el paràmetre poblacional. Quan \\(H_1\\) és bilateral, coincideix amb l’interval de confiança donat en el tema anterior Quan \\(H_1\\) és unilateral, dóna un interval infinit al costat definit per la hipòtesi alternativa. Per exemple, considerem el cas de un test t per efectuar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu &gt; \\mu_0 \\end{array} \\right. \\] Acceptam \\(H_0\\) amb nivell de significació \\(\\alpha\\) quan \\[ \\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\leqslant t_{n-1,1-\\alpha} \\] Aïllant \\(\\mu_0\\), obtenim \\[ \\overline{X}- t_{n-1,1-\\alpha}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu_0 \\] Per tant, l’interval de confiança de nivell de confiança \\(1-\\alpha\\) per a aquest contrast és \\[ \\Bigg[\\overline{X}- t_{n-1,1-\\alpha}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}},\\infty\\Bigg) \\] En l’exemple dels diabètics de la Secció 1.5, dóna l’interval \\[ \\Bigg[3.2- 1.73\\cdot \\dfrac{1.5}{\\sqrt{20}},\\infty\\Bigg)=[2.62,\\infty) \\] Obtenim que, amb un nivell de confiança del 95%, la concentració mitjana de calci en sang en els joves diabètics és com a mínim 2.62, i que per tant, amb aquest nivell de confiança, no pot ser 2.5, encara que per poc. Si efectuam un contrast bilateral amb un test t \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu\\neq \\mu_0 \\end{array} \\right. \\] acceptam \\(H_0\\) amb nivell de significació \\(\\alpha\\) quan \\[ -t_{n-1,1-\\alpha/2}\\leqslant\\dfrac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}}\\leqslant t_{n-1,1-\\alpha/2} \\] Aïllant \\(\\mu_0\\), obtenim: \\[ \\overline{X}- t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\leqslant\\mu_0 \\leqslant\\overline{X}+ t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}} \\] Per tant, l’interval de confiança de nivell de confiança \\(1-\\alpha\\) per a aquest contrast és \\[ \\Bigg[\\overline{X}- t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}},\\overline{X}+ t_{n-1,1-\\alpha/2}\\cdot \\dfrac{\\widetilde{S}_X}{\\sqrt{n}}\\Bigg] \\] Us sona? Fent \\(q=1-\\alpha\\), és el del tema anterior. Donat un contrast d’hipòtesis, podem decidir si rebutjam \\(H_0\\) en favor de \\(H_1\\) amb nivell de significació \\(\\alpha\\) emprant: La regió crítica: Si l’estadístic de contrast cau dins la regió crítica per al nivell de significació \\(\\alpha\\), rebutjam \\(H_0\\) El p-valor: Si el p-valor és més petit que el nivell de significació \\(\\alpha\\), rebutjam \\(H_0\\) L’interval de confiança: Si el valor que contrastam del paràmetre poblacional no pertany a l’interval de confiança de nivell de confiança \\(1-\\alpha\\), rebutjam \\(H_0\\) Els tres mètodes són equivalents. El més adequat és donar el p-valor i l’interval de confiança: el p-valor perquè el lector el pugui comparar amb el nivell de significació que consideri oportú i l’interval de confiança perquè mostra el marge amb el qual hem acceptat o rebutjat la hipòtesi nul·la amb el nostre nivell de significació. Si no establim un nivell de significació \\(\\alpha\\), el que és habitual en Biologia i Bioquímica és: Acceptam \\(H_0\\) si el p-valor és més gran que 0.1: es diu que el p-valor no és estadísticament significatiu Rebutjam \\(H_0\\) si el p-valor és més petit que 0.05: es diu que el p-valor és estadísticament significatiu Si el p-valor està entre 0.05 i 0.1 i no s’ha fixat nivell de significació, el millor que podeu fer és no concloure res Quan el p-valor és més petit que 0.05, se solen distingir tres franges: Significatiu si està entre 0.01 i 0.05 Fortament significatiu si està entre 0.001 i 0.01 Molt significatiu si és més petit que 0.001 R marca aquestes franges amb un codi d’asteriscs Signif. codes: 0 ‘***’ 0.001 ‘**’ 0.01 ‘*’ 0.05 ‘.’ 0.1 ‘ ’ 1 Figura 1.2: Emoticones per representar els nivells de significació estadística (BMJ 2018; 363, doi: https://doi.org/10.1136/bmj.k5033) Atès que rebutjam \\(H_0\\) si, i només si, el p-valor és \\(&lt;\\alpha\\), el p-valor d’un contrast és el nivell de significació més petit per al qual rebutjaríem la hipòtesi nul·la. És a dir: El p-valor obtingut en un contrast és la probabilitat mínima que tenim d’equivocar-nos rebutjant la hipòtesi nul·la si és vertadera. Per tant, per favor, acostumau-vos a donar el p-valor, i no la franja de significació on cau. La potència Recordau que la potència \\(1-\\beta\\) és la probabilitat de rebutjar \\(H_0\\) quan \\(H_1\\) és vertadera. Per exemple, en l’exemple del calci en diabètics de la Secció 1.5, la regla de rebuig era \\[ T=\\frac{\\overline{X}-2.5}{\\widetilde{S}_X/\\sqrt{n}}&gt;1.73, \\] per tant la potència era \\[ 1-\\beta=P(\\text{Rebutjar } H_0| H_1\\text{ vertadera})=P(T&gt;1.73| \\mu&gt;2.5). \\] Aquesta probabilitat és impossible de calcular, però hi ha paquets de R que la saben estimar. Per a cada tipus de contrast es té una relació numèrica entre: La potència \\(1-\\beta\\) La mida de la mostra \\(n\\): la potència creix amb \\(n\\) El nivell de significació \\(\\alpha\\): la potència decreix amb \\(\\alpha\\) La mida de l’efecte, un valor que quantifica la diferència entre el paràmetre mostral i el valor contrastat: la potència creix amb el valor absolut de la mida de l’efecte Aquesta relació permet calcular qualsevol dels quatre valors a partir dels altres tres; amb R, el paquet pwr permet fer-ho amb els contrastos més usuals. A l’hora de planejar un experiment per realitzar un contrast, el que s’ha de fer és: Fixar el nivell de significació desitjat Fixar la potència desitjada Estimar la mida de l’efecte esperat (a partir de la nostra teoria, de la nostra experiència, dels resultats d’altres estudis…) o que volguem detectar (per rebutjar la hipòtesi nul·la ens bastarà una mida de l’efecte petita o la requerirem grossa?) i emprar la relació anterior per calcular la mida de la mostra necessària per assolir la potència desitjada. Desconfiau dels treballs on això no es faci. Podria ser que la potència fos molt baixa i hi hagués un biaix de infrapotència (underpower): es necessitava un efecte molt gran per poder rebutjar la hipòtesi nul·la i publicar l’article. El risc de positiu fals El paquet statcheck de R permet revisar de manera automàtica tots els càlculs d’un article escrit en un format concret en psicologia i comprovar-ne els p-valors. Els autors van analitzar 30,000 articles i varen concloure que (Behavior research methods 48 (2016), 1205-1226): “Hem trobat que la meitat dels articles contenen almenys un p-valor erroni. I un de cada vuit articles conté un p-valor molt inconsistent que afecta la conclusió estadística.” Per tant, Qualsevol article pot donar un p-valor petit que estigui equivocat No us en refieu. A més, teniu present que: Qualsevol estudi mal dissenyat o mal realitzat pot donar un p-valor petit… que no signifiqui absolutament res Qualsevol estudi perfectament dissenyat i realitzat pot donar per pur atzar un p-valor petit… que impliqui un positiu fals El risc de positiu fals, FPR, en un contrast és \\[ P(H_0\\text{ vertadera}|H_0\\text{ rebutjada}). \\] Pel teorema de Bayes (notau que entenem \\(H_1= \\text{no }H_0\\)) \\[ \\begin{array}{rl} FPR&amp;=\\dfrac{P(H_0)\\cdot P(H_0\\text{ reb.}|H_0)}{P(H_0)\\cdot P(H_0\\text{ reb.}|H_0)+P(H_1)\\cdot P(H_0\\text{ reb.}|H_1)}\\\\ &amp; =\\dfrac{P(H_0)\\cdot \\alpha}{P(H_0)\\cdot \\alpha+(1-P(H_0))\\cdot (1-\\beta)}\\\\ &amp; =\\dfrac{(1-P(H_1))\\cdot \\alpha}{(1-P(H_1))\\cdot \\alpha+ P(H_1)\\cdot (1-\\beta)} \\end{array} \\] Per calcular-lo, hem de saber el nivell de significació i la potència i hem de decidir a priori quina probabilitat assignam al fet que \\(H_1\\) sigui vertadera. Exemple 1.18 En un estudi (publicat a Psychological Science 22 (2011), pp. 1011-1018) es repartiren 66 participants en dos grups de 33, als que direm grup Bandera i grup Control, i els mostraren les mateixes 4 fotos d’edificis. En les del grup Bandera, dues mostraven una bandera dels EUA, i en les del grup Control, aquestes banderes havien estat eliminades digitalment. Per emmascarar l’estudi, se’ls demanà que endevinassin l’hora del dia en què varen ser preses les fotos. Després de mirar les fotos, els participants emplenaren un qüestionari sobre idees polítiques, a partir del qual es pot calcular un cert “índex de republicanisme” (en el sentit nordamericà del terme) \\(M\\) del que l’ha contestat. Resulta que \\(M\\) va ser significativament més gran en el grup Bandera que en el grup Control, i amb un nivell de significació \\(\\alpha=0.05\\) els autors de l’estudi conclogueren que mirar fotos amb banderes estatals et “dretitza” (almenys a curt termini) les idees polítiques. Vaig a estimar el risc que aquest positiu sigui fals. Com que a priori, trob molt improbable que la conclusió sigui certa, li assignaré \\(P(H_1)=0.1\\) i gràcies. Emprarem \\(\\alpha=0.05\\), i si es calcula la potència del contrast publicat, dóna 0.5. Llavors \\[ FPR =\\dfrac{0.9\\cdot 0.05}{0.9\\cdot 0.05+0.1\\cdot 0.5}=0.47 \\] Per tant, a posteriori, crec que hi ha un 47% de probabilitats que \\(H_1\\) sigui falsa i un 53% de probabilitats que \\(H_1\\) sigui vertadera. "],
["contrastos-dhipotesis-dun-i-dos-parametres.html", "Tema 2 Contrastos d’hipòtesis d’un i dos paràmetres 2.1 Contrastos de mitjanes 2.2 Contrastos de variàncies 2.3 Contrastos per a proporcions", " Tema 2 Contrastos d’hipòtesis d’un i dos paràmetres Per adquirir un poc de disciplina en la realització de contrastos d’hipòtesis, procurau, almenys per ara, dividir-los en els apartats següents: Variables aleatòries d’interès i els paràmetres poblacionals involucrats en el contrast Contrast \\[ \\left\\{\\begin{array}{l} H_{0}: ...\\\\ H_{1}: ... \\end{array} \\right. \\] I a partir d’aquí, si el feu “a mà”: Estadístic de contrast i distribució si la hipòtesi nul·la és vertadera Valor de l’estadístic sobre la mostra p-valor i si pot ser interval de confiança del nivell de significació demanat (0.05 per defecte) Conclusió I si el feu amb R: L’efectuau amb R Conclusió Per a la conclusió, emprau la plantilla següent Hem obtingut evidència estadísticament significativa que passa tal cosa (test realitzat, p-valor …, IC 95% …). No hem obtingut evidència estadísticament significativa que passa tal cosa (test realitzat, p-valor …, IC 95% …). 2.1 Contrastos de mitjanes 2.1.1 Test t per a una mitjana Si estam en una de les dues situacions següents: \\(X\\) una variable aleatòria normal amb mitjana \\(\\mu\\) i en prenem una mostra aleatòria simple de mida \\(n\\) qualsevol \\(X\\) una variable aleatòria qualsevol amb mitjana \\(\\mu\\) i en prenem una mostra aleatòria simple de mida \\(n\\) gran (diguem que de mida com a mínim 30) i volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq\\mu_0\\text{ o }\\mu &gt;\\mu_0\\text{ o }\\mu&lt;\\mu_0 \\end{array} \\right. \\] podem emprar el test t que ja hem explicat a la Secció 1.5, basat en l’estadístic de contrast \\[ T= \\frac{\\overline{X}-\\mu_{0}}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] que, en les condicions donades i si \\(\\mu=\\mu_0\\), té una distribució (aproximadament, si \\(X\\) no és normal però \\(n\\) és gran) \\(t_{n-1}\\). Exemple 2.1 Una organització ecologista afirma que el pes mitjà dels individus adults d’una espècie ha disminuït dràsticament. Se sap per les dades històriques que el pes mitjà poblacional era de 460 g. Una mostra aleatòria de 50 individus d’aquesta espècie ha donat una mitjana mostral de 428 g i una desviació típica mostral de 119 g. Amb aquestes dades, podem afirmar amb un nivell de significació del 5% que el pes mitjà és inferior a 460 g? Variable aleatòria d’interès: \\(X\\): “Prenem un animaló d’aquests i mesuram el seu pes, en grams”, amb mitjana \\(\\mu\\) Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=460\\\\ H_{1}:\\mu&lt;460 \\end{array} \\right. \\] Prenem nivell de significació \\(\\alpha=0.05\\). Estadístic de contrast: Com que \\(n=50\\) és gran, podem usar \\[ T=\\frac{\\overline{X}-\\mu_0}{{\\widetilde{S}_X}/{\\sqrt{n}}} \\] que sí \\(H_0\\) és vertadera serà (aproximadament) t de Student amb \\(n-1=49\\) graus de llibertat Valor de l’estadístic: \\[ \\dfrac{428-460}{{119}/{\\sqrt{50}}}=-1.9 \\] p-valor: \\[ P(T\\leqslant-1.9)=\\texttt{pt(-1.9,49)}=0.032 \\] Interval de confiança del 95%: \\[ \\left(-\\infty, \\overline{X}+t_{n-1,1-\\alpha}\\cdot \\frac{\\widetilde{S}_X}{\\sqrt{n}}\\right]=(-\\infty, 456.2] \\] Conclusió: Com que el p-valor és més petit que 0.05, concloem (amb \\(\\alpha=0.05\\)) que el pes mitjà actual és més petit que 460 g. De fet, amb un 95% de confiança podem afirmar que el pes mitjà actual és inferior a 456.2 g, que està per davall dels 460 g. Amb la plantilla que us hem donat: Hem obtingut evidència estadísticament significativa que el pes mitjà actual és menor que 460 g (test t, p-valor 0.03, IC 95% de \\(-\\infty\\) a 456.2) i que per tant ha minvat en els darrers anys. 2.1.2 Test t per a dues mitjanes Si estam en una de les situacions següents: \\(X_1,X_2\\) dues variables aleatòries normals de mitjanes \\(\\mu_1\\), \\(\\mu_2\\) i en prenem mostres aleatòries simples de mides \\(n_1\\), \\(n_2\\) qualssevol \\(X_1,X_2\\) dues variables aleatòries qualssevol de mitjanes \\(\\mu_1\\), \\(\\mu_2\\) i en prenem mostres aleatòries simples de mides \\(n_1\\), \\(n_2\\) grans (diguem que cadascuna de mida com a mínim 30) i volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1=\\mu_2\\\\ H_{1}:\\mu_1 \\neq\\mu_2\\text{ o }\\mu_1 &gt;\\mu_2\\text{ o }\\mu_1&lt;\\mu_2 \\end{array} \\right. \\] podem usar un test t, basat en un estadístic de contrast \\(T\\) adequat que segueix una llei t de Student. L’estadístic de contrast concret i els graus de llibertat de la seva distribució t de Student depenen: De si les dues mostres són independents (hem mesurat \\(X_1\\) i \\(X_2\\) sobre dues mostres obtingudes de manera independent una de l’altra) o aparellades (hem mesurat \\(X_1\\) i \\(X_2\\) sobre els subjectes d’una mateixa mostra o hi ha un aparellament natural entre els subjectes de les dues mostres) Quan les mostres són independents, també depenen de si \\(X_1\\) i \\(X_2\\) tenen la mateixa variància o no (la qual cosa es pot decidir amb un altre contrast: vegeu la Secció 2.2); per a mostres de la mateixa mida de variables normals, la conclusió sol ser la mateixa Quan les mostres són aparellades, podem entendre que tenim una sola mostra, formada per les diferències dels valors de \\(X_1\\) i \\(X_2\\) sobre les parelles. En aquest cas, traduïm \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1=\\mu_2\\\\ H_{1}:\\mu_1 \\neq\\mu_2\\text{ o }\\mu_1 &gt;\\mu_2\\text{ o }\\mu_1&lt;\\mu_2 \\end{array} \\right. \\] en \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_1-\\mu_2=0\\\\ H_{1}:\\mu_1-\\mu_2 \\neq0\\text{ o }\\mu_1-\\mu_2 &gt;0\\text{ o }\\mu_1-\\mu_2&lt;0 \\end{array} \\right. \\] on \\(\\mu_1-\\mu_2\\) és la mitjana de \\(X_1-X_2\\), i el consideram un contrast d’una sola mitjana, emprant com a mostra les diferències \\(X_1-X_2\\) a les parelles. Per tant, quan les mostres són aparellades, si diem \\(\\overline{D}\\) a la mitjana mostral de \\(X_1-X_2\\) i \\(\\widetilde{S}_D\\) a la desviació típica mostral de \\(X_1-X_2\\) sobre la mostra de parelles i diem \\(n\\) a la mida de la mostra de parelles, l’estadístic de contrast és \\[ T=\\frac{\\overline{D}}{\\widetilde{S}_D/\\sqrt{n}} \\] que, quan \\(\\mu_1-\\mu_2=0\\), té (aproximadament, en el cas que \\(X_1,X_2\\) no siguin normals però la \\(n\\) sigui gran) distribució \\(t_{n-1}\\). Quan les mostres són independents, siguin \\(\\overline{X}_1\\) i \\(\\widetilde{S}^2_1\\) la mitjana mostral i la variància mostral de la mostra de \\(X_1\\) i \\(\\overline{X}_2\\) i \\(\\widetilde{S}^2_2\\) la mitjana mostral i la variància mostral de la mostra de \\(X_2\\). Diguem, a més, \\(\\sigma_1^2\\) i \\(\\sigma_2^2\\) a les variàncies (poblacionals) de \\(X_1\\) i \\(X_2\\). Aleshores: Si \\(\\sigma_1^2=\\sigma_2^2\\), l’estadístic de contrast és \\[ T=\\frac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{(\\frac{1}{n_1}+\\frac{1}{n_2})\\cdot \\frac{(n_1-1)\\widetilde{S}_1^2+(n_2-1)\\widetilde{S}_2^2}{n_1+n_2-2}}} \\] que, quan \\(\\mu_1=\\mu_2\\), té distribució (aproximadament, en el cas que \\(X_1,X_2\\) no siguin normals però \\(n_1\\) i \\(n_2\\) siguin grans) \\(t_{n_1+n_2-2}\\) Si \\(\\sigma_1^2\\neq \\sigma_2^2\\), l’estadístic de contrast és \\[ T=\\frac{\\overline{X}_1-\\overline{X}_2}{\\sqrt{\\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}}} \\] que, quan \\(\\mu_1=\\mu_2\\), té distribució (aproximadament, en el cas que \\(X_1,X_2\\) no siguin normals però \\(n_1\\) i \\(n_2\\) siguin grans) \\(t_{\\nu}\\) amb \\[ \\nu=\\frac{\\displaystyle \\left( \\frac{\\widetilde{S}_1^2}{n_1}+\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2} {\\displaystyle \\frac{1}{n_1-1}\\left(\\frac{\\widetilde{S}_1^2}{n_1}\\right)^2+\\frac{1}{n_2-1}\\left(\\frac{\\widetilde{S}_2^2}{n_2}\\right)^2} \\] No cal que sapigueu aquestes fórmules per a mostres independents, només que l’estadístic de contrast i la seva distribució depenen de si les variàncies poblacionals són iguals o diferents. El nombre de graus de llibertat de la distribució t de Student usada en un contrast sobre dues mostres de mida \\(n\\): Si les mostres són aparellades, és \\(n-1\\) Si les mostres són independents, és aproximadament \\(2(n-1)\\) Això fa que la probabilitat d’error de Tipus I del contrast amb mostres aparellades (a igualtat de la resta de valors) sigui més petita. Per exemple, suposem que volem realitzar el contrast \\[ \\left\\{ \\begin{array}{l} H_0: \\mu_1=\\mu_2\\\\ H_1: \\mu_1&gt;\\mu_2 \\end{array} \\right. \\] i que l’estadístic de contrast \\(T\\) sobre dues mostres de mides \\(n_1=n_2=20\\) dóna 1.7. Aleshores Si les mostres són independents, \\[ \\text{p-valor}=P(T&gt;1.7)\\approx \\texttt{1-pt(1.7,38)}=0.0487 \\] Si les mostres són aparellades, \\[ \\text{p-valor}=P(T&gt;1.7)=\\texttt{1-pt(1.7,19)}=0.0527 \\] Per tant, amb nivell de significació \\(\\alpha=0.05\\), rebutjaríem la hipòtesi nul·la amb les mostres independents i l’acceptaríem amb les mostres aparellades. 2.1.3 Tests t amb R Tots aquests tests t estan implementats en la funció de R t.test(x, y, mu=..., alternative=..., paired=..., var.equal=..., conf.level=...) on: Entram com a x una mostra i a mu el valor amb el qual volem contrastar \\(\\mu\\), o entram com a x i y les mostres de \\(X_1\\) i de \\(X_2\\) A alternative hi hem d’indicar el tipus de contrast segons la hipòtesi alternativa: alternative=&quot;two.sided&quot; (\\(\\neq\\), el valor per defecte) alternative=&quot;less&quot; (\\(&lt;\\)) alternative=&quot;greater&quot; (\\(&gt;\\)) En el cas d’un contrast de dues mitjanes, a paired hi hem d’indicar si les mostres són independents, amb paired=FALSE (el valor per defecte), o aparellades, amb paired=TRUE En el cas d’un contrast de dues mitjanes amb mostres independents, a var.equal hi hem d’indicar si les variàncies són iguals, amb var.equal=TRUE, o diferents, amb var.equal=FALSE (el valor per defecte) A conf.level hi hem d’especificar el nivell de confiança \\(1-\\alpha\\): el seu valor per defecte és 0.95, que correspon al nivell de significació \\(\\alpha=0.05\\) usual 2.1.4 Exemples Exemple 2.2 La temperatura mitjana del cos humà, és el valor usualment acceptat de 98.6o F (37o C)? Per contrastar-ho, emprarem la taula de dades Body_Temperature.txt, construïda per P.A. Mackowiak, S. S. Wasserman i M.M. Levine en 1992 precisament per realitzar aquest contrast i que trobareu a l’Aula Digital. Variable aleatòria d’interès: \\(X\\): “Prenem una persona i li miram la temperatura, en graus F”, amb mitjana \\(\\mu\\) Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=98.6\\\\ H_{1}:\\mu \\neq 98.6 \\end{array} \\right. \\] Realitzarem aquest contrast amb R. Carregam la taula de temperatures, que prèviament hem guardat en el directori de treball de R, en un dataframe que anomenarem BT. BT=read.table(&quot;Body_Temperature.txt&quot;) head(BT) ## Gender HeartRate Temperature ## 1 M 69 97.0 ## 2 M 72 98.8 ## 3 M 68 96.2 ## 4 F 75 97.8 ## 5 F 68 98.8 ## 6 M 79 101.3 str(BT) ## &#39;data.frame&#39;: 230 obs. of 3 variables: ## $ Gender : Factor w/ 2 levels &quot;F&quot;,&quot;M&quot;: 2 2 2 1 1 2 1 1 1 2 ... ## $ HeartRate : int 69 72 68 75 68 79 71 73 77 81 ... ## $ Temperature: num 97 98.8 96.2 97.8 98.8 ... Veiem que la taula BT consta de 230 individus i 3 variables mesurades sobre cadascun d’ells: el sexe (variable Gender, amb nivells F per a dona i M per a home), les pulsacions per minut (variable HeartRate) i la temperatura en graus F (variable Temperature). Com que la mostra és gran, \\(n=230\\), podem emprar un test t. Emprarem la funció t.test, aplicant-la al vector de temperatures i al valor que contrastam, 98.6, entrat amb el parametre mu. El paràmetre alternative=&quot;two.sided&quot; indica que el test serà bilateral. t.test(BT$Temperature, mu=98.6, alternative=&quot;two.sided&quot;) ## ## One Sample t-test ## ## data: BT$Temperature ## t = -5.7205, df = 229, p-value = 3.301e-08 ## alternative hypothesis: true mean is not equal to 98.6 ## 95 percent confidence interval: ## 98.17563 98.39307 ## sample estimates: ## mean of x ## 98.28435 Del resultat cal destacar: El p-valor, p-value, en el nostre cas \\(3.301\\times 10^{-8}\\) (R l’ha escrit en notació científica: 3.301e-08). L’IC 95%, 95 percent confidence interval, per al valor que contrastam (aquí, la temperatura mitjana poblacional), en el nostre cas [98.17563, 98.39307]. La mitjana mostral de la mostra, sample of x, en el nostre cas 98.28435. Per tant: El p-valor és \\(3\\times 10^{-8}\\), per la qual cosa amb les dades d’aquesta taula obtenim evidència estadísticament significativa que la temperatura mitjana del cos humà no és de 98.6o F (37o C) A més, com que l’IC 95% per a la temperatura mitjana del cos humà que hem obtingut va de 98.2 a 98.4 (36.78 a 36.89o C), hem trobat evidència amb aquest nivell de confiança que aquesta temperatura mitjana és (lleugerament) inferior 98.6o F Conclusió: Hem obtingut evidència estadísticament significativa que la temperatura mitjana del cos humà no és de 98.6o F (test t, p-valor 3·10-8, IC 95% de 98.2 a 98.4). Exemple 2.3 La temperatura dels homes, és més alta que la de les dones? Per resoldre aquesta qüestió, emprarem la mateixa taula de dades que abans. Variables aleatòries d’interès: \\(X_d\\): “Prenem una dona i li miram la temperatura, en graus F”, amb mitjana \\(\\mu_d\\) \\(X_h\\): “Prenem un home i li miram la temperatura, en graus F”, amb mitjana \\(\\mu_h\\) Contrast: Plantejarem el contrast en termes de temperatures mitjanes: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_d=\\mu_h\\\\ H_{1}:\\mu_d&lt; \\mu_h \\end{array} \\right. \\] Per poder emprar un t test, primer ens cal saber si hi ha nombres suficientment grans d’homes i dones a la nostra mostra per emprar-lo. Per això calcularem la taula de freqüències dels sexes, aplicant la funció table al vector BT$Gender dels sexes: table(BT$Gender) ## ## F M ## 116 114 Són prou grans. Anam a crear uns vectors amb les temperatures d’homes i de dones. Recordau que per extreure d’un dataframe el vector de valors d’una variable V1 per als individus que prenen un valor concret X en una altra variable V2 s’empra la construcció dataframe[V2==X,V1]. Així, les temperatures dels homes (individus on la variable Gender és igual a M) són BT$Temperature[BT$Gender==&quot;M&quot;] ## [1] 97.0 98.8 96.2 101.3 99.2 97.5 97.3 98.6 99.0 98.0 97.0 ## [12] 97.6 99.0 97.1 98.9 98.6 98.9 97.2 98.0 99.4 98.8 98.5 ## [23] 99.6 97.3 96.5 97.8 98.3 98.1 98.8 97.7 98.3 97.7 99.1 ## [34] 98.8 97.4 96.9 98.0 98.4 100.3 97.0 99.0 100.6 98.0 98.5 ## [45] 97.0 97.0 98.6 97.8 97.3 96.3 96.7 96.9 97.0 97.1 97.1 ## [56] 97.1 97.2 97.3 97.4 97.4 97.4 97.4 97.5 97.5 97.6 97.6 ## [67] 97.6 97.7 97.8 97.8 97.8 97.8 97.9 97.9 98.0 98.0 98.0 ## [78] 98.0 98.0 98.0 98.1 98.1 98.2 98.2 98.2 98.2 98.3 98.3 ## [89] 98.4 98.4 98.4 98.4 98.5 98.5 98.6 98.6 98.6 98.6 98.6 ## [100] 98.6 98.7 98.7 98.8 98.8 98.8 98.9 99.0 99.0 99.0 99.1 ## [111] 99.2 99.3 99.4 99.5 Bé, cream els vectors \\(X_d\\) (dones) i \\(X_h\\) (homes) X_d=BT[BT$Gender==&quot;F&quot;,&quot;Temperature&quot;] #temperatures de dones X_h=BT[BT$Gender==&quot;M&quot;,&quot;Temperature&quot;] #temperatures d&#39;homes Per portar a terme un test t per comparar dues mitjanes, aplicam la funció t.test als vectors X_di X_h amb paràmetre alternative=&quot;less&quot; per indicar que el test és unilateral: la hipòtesi alternativa és que la mitjana de la primera població (dones) és més petita que la de la segona (homes). En aquest exemple, a més, especificarem que les mostres són independents amb paired=FALSE (no caldria, ja que és el valor per defecte) i a més hem d’especificar si les variàncies poblacionals són iguals (var.equal=TRUE) o diferents (var.equal=FALSE). El que farem aquí serà provar els dos casos: amb les variàncies iguals i amb les variàncies diferents. Si les dues conclusions són la mateixa, aquesta serà la conclusió que prendrem. Si dóna diferent, haurem de realitzar un contrast previ per decidir si podem suposar que les variàncies són iguals o diferents. t.test(X_d, X_h, alternative=&quot;less&quot;,paired=FALSE, var.equal=TRUE) ## ## Two Sample t-test ## ## data: X_d and X_h ## t = 2.5379, df = 228, p-value = 0.9941 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf 0.4569566 ## sample estimates: ## mean of x mean of y ## 98.42155 98.14474 t.test(X_d, X_h, alternative=&quot;less&quot;,paired=FALSE, var.equal=FALSE) ## ## Welch Two Sample t-test ## ## data: X_d and X_h ## t = 2.5358, df = 225.32, p-value = 0.9941 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf 0.4571095 ## sample estimates: ## mean of x mean of y ## 98.42155 98.14474 En tots dos casos obtenim un p-valor (p-value) gran. L’IC 95 % (95 percent confidence interval) que ens dóna és per a la diferència de les mitjanes. Com que conté el 0, no podem descartar que les dues mitjanes siguin iguals. Conclusió: No hem obtingut evidència estadísticament significativa que la temperatura mitjana de les dones sigui més baixa que la dels homes (test t, p-valor 0.99, IC 95% per a la diferència de les mitjanes de \\(-\\infty\\) a 0.46). Vegem, si \\(\\overline{X_d}=98.42\\) i \\(\\overline{X_h}=98.14\\), com volíeu que obtinguéssim evidència que \\(\\mu_d&lt;\\mu_h\\)? Mirau sempre les dades primer! Si haguéssim dibuixat abans del contrast un diagrama de caixes de les temperatures separades per sexe, hauríem vist que era impossible obtenir evidència que les dones tenen temperatura mitjana inferior als homes, i no hauria fet falta continuar. boxplot(Temperature~Gender,data=BT,names=c(&quot;Dones&quot;,&quot;Homes&quot;),xlab=&quot;&quot;,ylab=&quot;Temperatura&quot;) Exercici: Emprant les mateixes dades, trobau evidència que \\(\\mu_h&lt;\\mu_d\\)? I que \\(\\mu_h\\neq \\mu_d\\)? Spoiler: Exemple 2.4 Desdijunar segó de civada (oat bran) en lloc de flocs de blat de moro (corn flakes), ajuda a reduir el nivell de colesterol? Per resoldre aquesta qüestió, emprarem la taula de dades oatbran.txt, que trobareu a l’Aula Digital. Aquestes dades es recolliren en un assaig creuat sobre 14 individus. A cada un d’ells se li assignà un dels dos desdijunis de manera aleatòria i el prengueren durant 15 dies. Al final d’aquest període, se’ls mesurà el nivell de colesterol en sang. Passat un mes de descans, cada participant va desdijunar durant 15 dies l’altre producte, i al final se’ls tornà a mesurar el nivell de colesterol en sang. Variables aleatòries d’interès: \\(X_{ob}\\): “Prenem una persona que desdijuna oat bran i li mesuram el nivell de colesterol”, amb mitjana \\(\\mu_{ob}\\) \\(X_{cf}\\): “Prenem una persona que desdijuna corn flakes i li mesuram el nivell de colesterol”, amb mitjana \\(\\mu_{cf}\\) Contrast: El plantejarem en termes de nivells mitjans de colesterol: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{ob}=\\mu_{cf}\\\\ H_{1}:\\mu_{ob}&lt; \\mu_{cf} \\end{array} \\right. \\] Carregam la taula de dades, que prèviament hem guardat en el directori de treball de R, en un dataframe al que anomenam OBR i consultam la seva estructura: OBR=read.table(&quot;oatbran.txt&quot;,header=TRUE) head(OBR) ## CORNFLK OATBRAN ## 1 4.61 3.94 ## 2 6.42 5.57 ## 3 5.40 5.85 ## 4 4.54 4.80 ## 5 3.98 3.68 ## 6 3.82 2.96 str(OBR) ## &#39;data.frame&#39;: 14 obs. of 2 variables: ## $ CORNFLK: num 4.61 6.42 5.4 4.54 3.98 3.82 5.01 4.34 3.8 4.56 ... ## $ OATBRAN: num 3.94 5.57 5.85 4.8 3.68 2.96 4.41 3.72 3.49 3.94 ... N’extraiem les dues variables en forma de vectors: OAT=OBR$OATBRAN CFL=OBR$CORNFLK Com que 14 dades són poques, si volem aplicar un test t necessitam que provinguin d’una distribució normal. Per decidir si és veritat o no, més endavant explicarem contrastos de bondat d’ajust, amb hipòtesi nul·la “Aquesta mostra prové d’una variable aleatòria amb tal distribució” i hipòtesi alternativa “No és veritat que aquesta mostra provengui d’una variable aleatòria amb tal distribució”. Per ara ens conformarem amb decidir-ho a partir d’un gràfic. A Matemàtiques I us explicàvem que podeu dibuixar un histograma d’una mostra afegint-hi la densitat estimada, a partir de la mostra, de la variable poblacional i la densitat d’una distribució normal amb mitjana i desviació típica les de la mostra, i mirar si sembla que les dades segueixen aquesta distribució normal. Però amb poques dades això és mal de veure: hist(OAT,freq=FALSE, breaks=4,col=&quot;light blue&quot;,xlab=&quot;Colesterol&quot;, ylab=&quot;Densitat&quot;, main=&quot;Histograma de OATBRAN&quot;,ylim=c(0,max(density(OAT)$y))) lines(density(OAT),lty=2,lwd=2) curve(dnorm(x,mean(OAT),sd(OAT)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;), col=c(&quot;black&quot;,&quot;red&quot;),lty=c(2,1),cex=0.75) # hist(CFL,freq=FALSE, breaks=4,col=&quot;light blue&quot;,xlab=&quot;Colesterol&quot;, ylab=&quot;Densitat&quot;, main=&quot;Histograma de CORNFLK&quot;,,ylim=c(0,max(density(CFL)$y))) curve(dnorm(x,mean(CFL),sd(CFL)),col=&quot;red&quot;,lwd=2,add=TRUE) lines(density(CFL),lty=2,lwd=2) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;), col=c(&quot;black&quot;,&quot;red&quot;),lty=c(2,1),cex=0.75) En aquest cas, una opció millor és dibuixar un q-q-plot. Un q-q-plot d’una mostra i una distribució teòrica és el gràfic dels q-q-punts: els punts de la forma (q-quantil de la distribució, q-quantil de la mostra), per a tots els valors de q que tengui sentit donada la mida de la mostra. Quan la distribució amb la que comparam la mostra és una normal, se’n diu un normal-plot. Si la mostra prové de la distribució emprada en el q-q-plot, és d’esperar que el q-quantil de la mostra sigui aproximadament igual al q-quantil de la distribució i per tant que aquests q-q-punts estiguin prop de la diagonal principal \\(y=x\\). La funció qqPlot del paquet car produeix uns q-q-plots que contenen una regió de confiança del 95% que especifica què vol dir això que “els q-q-punts estiguin prop de la diagonal principal \\(y=x\\)”, amb el significat usual de nivell de confiança. L’explicam amb detall a la lliçó de R sobre contrastos de bondat d’ajust. library(car) qqPlot(OAT, distribution=&quot;norm&quot;, mean=mean(OAT), sd=sd(OAT), ylab=&quot;Quantils de OATBRAN&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) qqPlot(CFL, distribution=&quot;norm&quot;, mean=mean(CFL),sd=sd(CFL), ylab=&quot;Quantils de CORNFLK&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) Aceptarem per tant que les nostres dades provenen de dues distribucions normals: podem fer servir la funció t.test. En aquest cas, el test t és de mostres aparellades (hem mesurat les dues variable aleatòries sobre els mateixos individus), per la qual cosa hem d’especificar paired=TRUE i no hem d’especificar el paràmetre var.equal. Emprarem el paràmetre alternative=&quot;less&quot; per indicar que el test és unilateral: la mitjana de la primera població és més petita que la de la segona. t.test(OAT,CFL,alternative=&quot;less&quot;, paired=TRUE) ## ## Paired t-test ## ## data: OAT and CFL ## t = -3.3195, df = 13, p-value = 0.002768 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.1626132 ## sample estimates: ## mean of the differences ## -0.3485714 Com abans, el resultat inclou el p-valor, l’IC 95% per a la mitjana de les diferències (que és igual a la diferència de les mitjanes: recordau que \\(E(X-Y)=E(X)-E(Y)\\)) i ara, com a novetat, la mitjana de les diferències (mean of the differences) en comptes de les dues mitjanes. Conclusió: Hem obtingut evidència estadísticament significativa que desdijunar oatbran redueix el nivell mitjà de colesterol respecte de desdijunar corn flakes (test t, p-valor 0.003, IC 95% per a la diferència de les mitjanes de \\(-\\infty\\) a -0.163). Exemple 2.5 Volem contrastar si el nivell de triglicèrids als nadons de 2 setmanes és més alt que el del seu cordó umbilical. Per fer-ho, emprarem les dades d’una mostra de 25 nadons als quals els mesuraren els nivells de triglicèrids en plasma a la sang del seu cordó umbilical i en la seva sang al cap de 2 setmanes de néixer. Tenim les dades a la taula trignadons.txt que trobareu a l’Aula Digital. Les seves variables són CU, les mesures del cordó umbilical, DS, les mesures al cap de dues setmanes, i Nin, que identifica el nadó. Variables aleatòries d’interès: \\(X_{cu}\\): “Prenem un recent nat i mesuram el nivell de triglicèrids en plasma a la sang del seu cordó umbilical”, amb mitjana \\(\\mu_{cu}\\) \\(X_{ds}\\): “Prenem un nadó de 2 setmanes i mesuram el seu nivell de triglicèrids en plasma”, amb mitjana \\(\\mu_{cf}\\) Contrast: Plantejarem el contrast en termes dels nivells mitjans de triglicèrids: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{cu}=\\mu_{ds}\\\\ H_{1}:\\mu_{cu}&lt; \\mu_{ds} \\end{array} \\right. \\] Carregam la taula de dades, que prèviament hem guardat en el directori de treball de R, en un dataframe al que anomenam TGN i consultam la seva estructura: TGN=read.table(&quot;trignadons.txt&quot;,header=TRUE) head(TGN) ## Nin CU DS ## 1 1 45 80 ## 2 2 30 68 ## 3 3 30 83 ## 4 4 30 78 ## 5 5 31 79 ## 6 6 27 78 str(TGN) ## &#39;data.frame&#39;: 25 obs. of 3 variables: ## $ Nin: int 1 2 3 4 5 6 7 8 9 10 ... ## $ CU : int 45 30 30 30 31 27 27 30 33 32 ... ## $ DS : int 80 68 83 78 79 78 89 78 72 75 ... Com que 25 dades són poques, miram si segueixen distribucions normals amb els seus normal-plots: qqPlot(TGN$CU, distribution=&quot;norm&quot;, mean=mean(TGN$CU), sd=sd(TGN$CU), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) qqPlot(TGN$DS, distribution=&quot;norm&quot;, mean=mean(TGN$DS), sd=sd(TGN$DS), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, pch=20,id=FALSE) Vaja, no sembla que segueixin una distribució normal. Vegem els seus histogrames hist(TGN$CU, freq=FALSE, main=&quot;Histograma de TGN$CU&quot;, xlab=&quot;&quot;,ylab=&quot;&quot;,col=&quot;light blue&quot;) lines(density(TGN$CU),lty=2,lwd=2) curve(dnorm(x,mean(TGN$CU),sd(TGN$CU)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;),col=c(&quot;black&quot;,&quot;red&quot;), lty=c(2,1),cex=0.5) # hist(TGN$DS, freq=FALSE, main=&quot;Histograma de TGN$DS&quot;, xlab=&quot;&quot;,ylab=&quot;&quot;,col=&quot;light blue&quot;) lines(density(TGN$DS),lty=2,lwd=2) curve(dnorm(x,mean(TGN$DS),sd(TGN$DS)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;),col=c(&quot;black&quot;,&quot;red&quot;), lty=c(2,1),cex=0.5) Les dues mostres presenten una cua a la dreta, com podem veure als diagrames de caixa: boxplot(TGN$CU,TGN$DS,names=c(&quot;CU&quot;,&quot;DS&quot;),xlab=&quot;&quot;,ylab=&quot;Nivell triglicèrids&quot;) En casos així, de vegades els logaritmes seguexen aproximadament una distribució normal. Vegem si hi ha sort. LogCU=log(TGN$CU) qqPlot(LogCU, distribution=&quot;norm&quot;, mean=mean(LogCU), sd=sd(LogCU), ylab=&quot;Quantils dels logaritmes&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) # LogDS=log(TGN$DS) qqPlot(LogDS, distribution=&quot;norm&quot;, mean=mean(LogDS), sd=sd(LogCU), ylab=&quot;Quantils dels logaritmes&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) Aquests logaritmes ja poden passar per normals. Per tant, el que farem serà, en lloc de comparar les mitjanes dels nivells de triglicèrids, comparar les mitjanes dels seus logaritmes. Aquest tipus de transformació és molt usual en Bioestadística. No són contrastos equivalents, perquè el logaritme de la mitjana no és la mitjana del logaritme. Però en realitat la pregunta que originava aquesta investigació era si el nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons, i ho plantejàvem en termes de si és veritat que el nivell mitjà de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons. Ara, demanar-nos si “el nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons” sí que és equivalent a demanar-nos si “el logaritme del nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons”. I el que fem és plantejar aquesta pregunta en termes de si és veritat que el valor mitjà del logaritme del nivell de triglicèrids augmenta en les dues primeres setmanes de vida dels nadons Noves variables aleatòries d’interès: \\(\\log(X_{cu})\\): “Prenem un recent nat i calculam el logaritme del nivell de triglicèrids en plasma a la sang del seu cordó umbilical”, amb mitjana \\(\\mu_{logcu}\\) \\(\\log(X_{ds})\\): “Prenem un nadó de 2 setmanes i calculam el logaritme del seu nivell de triglicèrids en plasma”, amb mitjana \\(\\mu_{logcf}\\) Nou contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{logcu}=\\mu_{logds}\\\\ H_{1}:\\mu_{logcu}&lt; \\mu_{logds} \\end{array} \\right. \\] Prenem com a mostres de \\(\\log(X_{cu})\\) i \\(\\log(X_{ds})\\) els vectors de logaritmes LogCU i LogDS de la nostra mostra original, que podem acceptar que provenen de distribucions normals, i els aplicam la funció t.test amb paired=TRUE, perquè són mostres aparellades, i alternative=&quot;less&quot;. t.test(LogCU, LogDS, paired=TRUE, alternative=&quot;less&quot;) ## ## Paired t-test ## ## data: LogCU and LogDS ## t = -26.112, df = 24, p-value &lt; 2.2e-16 ## alternative hypothesis: true difference in means is less than 0 ## 95 percent confidence interval: ## -Inf -0.8353074 ## sample estimates: ## mean of the differences ## -0.8938758 Conclusió: Hem obtingut evidència estadísticament significativa que el valor mitjà del logaritme del nivell de triglicèrids a la sang del cordó umbilical d’un nadó és més petit que el valor mitjà del logaritme del nivell de triglicèrids a la sang d’un nadó de 2 setmanes (test t, p-valor&lt;10-16, IC 95% per a la diferència de les mitjanes de \\(-\\infty\\) a -0.84). Concloem, per tant, que tenim evidència estadísticament significativa que el nivell de triglicèrids als nadons de 2 setmanes és més alt que el del seu cordó umbilical. 2.1.5 Tests no paramètrics Si les variables aleatòries d’interès no són (aproximadament) normals i alguna mostra és petita, no podem usar un test t per comparar mitjanes. En aquest cas, una possibilitat és provar de transformar les dades com a l’Exemple 2.5 per veure si la transformació esdevé normal, i si és el cas, plantejar el contrast en termes de mitjanes de logaritmes. Una altra possibilitat és emprar un test no paramètric, que no necessiti que les variables aleatòries siguin normals per que la conclusió sigui vàlida. La majoria de tests no paramètrics per comparar mitjanes en realitat comparen medianes, però normalment cometem l’abús de llenguatge de dir que són per contrastar mitjanes. A més, si les variables aleatòries són simètriques, les mitjanes coincideixen amb les medianes. Els més populars són: Test de Wilcoxon per a una mitjana o dues mitjanes usant mostres aparellades Test de Mann-Whitney per a dues mitjanes usant mostres independents Tots tres es calculen amb R amb la funció wilcox.test(x, y, mu=..., alternative=..., paired=..., conf.level=...) amb sintaxi idèntica a la de t.test (excepte que no s’hi empra el var.equal). Els millors tests no paramètrics solen tenir potència inferior als millors tests paramètrics. A més, els tests no paramètrics no solen produir intervals de confiança fiables. Però, per exemple, emprar un test t quan no és adequat pot portar a conclusions equivocades. Emprau tests paramètrics sempre que pogueu, però només quan pogueu. Com a exemple, vegem com funciona (una versió simplificada) del test de Wilcoxon d’una mitjana. Sigui \\(X\\) una variable aleatòria contínua simètrica al voltant de la seva mitjana \\(\\mu\\) desconeguda. Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=\\mu_0\\\\ H_{1}:\\mu \\neq \\mu_0 \\text{ o }\\mu &gt;\\mu_0\\text{ o }\\mu&lt;\\mu_0 \\end{array} \\right. \\] Prenem una mostra aleatòria simple \\(x_1,\\ldots, x_n\\) de \\(X\\). El procediment d’aquest test es basa aleshores en els següents passos, que després il·lustram a l’Exemple 2.6: Per a cada \\(i=1,\\ldots,n\\), sigui \\(d_i=x_i-\\mu_0\\); s’eliminen els valors 0 Enumeram els valors \\(d_i\\) de menor a major valor absolut; en cas d’empats, a cada un li assignam la mitjana de les posicions que ocuparien. A l’índex assignat d’aquesta manera a cada \\(d_i\\) li diem el seu rang. Per exemple, a l’Exemple 2.6 hi ha quatre \\(i\\) amb valors \\(d_i=\\pm 1\\), i els tocarien les posicions 1, 2, 3 i 4: aleshores el rang de cada un d’aquests quatre \\(d_i\\) és 2.5. Diem \\(T_+\\) a la suma dels rangs dels \\(d_i&gt;0\\) i \\(T_{-}\\) a la suma dels rangs dels \\(d_i&lt;0\\) Si \\(H_0\\) vertadera, és a dir, si \\(\\mu=\\mu_0\\), per la simetria de \\(X\\) al voltant de \\(\\mu\\) esperam que \\(T_+\\approx T_-\\). Per tant: Si \\(T_+\\) és molt petit, és evidència que \\(\\mu &lt;\\mu_0\\) En efecte, si \\(T_+\\) és molt més petit que \\(T_-\\), bàsicament significa que hi ha més valors a l’esquerra de \\(\\mu_0\\) que a la dreta, i per tant la mediana (és a dir, el valor que deixa la meitat dels valors a l’esquerra i l’altra meitat a la dreta) ha d’estar a l’esquerra de \\(\\mu_0\\). Si \\(T_+\\) és molt gran, és evidència que \\(\\mu &gt;\\mu_0\\) En efecte, si \\(T_+\\) és molt més gran que \\(T_-\\), bàsicament significa que hi ha més valors a la dreta de \\(\\mu_0\\) que a l’esquerra, i per tant la mediana ha d’estar a la dreta de \\(\\mu_0\\). Si \\(T_+\\) és molt petit o gran, és evidència que \\(\\mu\\neq \\mu_0\\) I resulta que, quan \\(X\\) és simètrica i \\(H_0\\) vertadera, la distribució de \\(T_+\\), per a cada \\(n\\), és coneguda, i es pot emprar per calcular el p-valor, que és el que fa la funció wilcox.test. Exemple 2.6 Alimentàrem amb una dieta especial 13 ratolins des del naixement fins a la setmana 12. Els augments de pes (en grams) varen ser els del vector següent pesos=c(69,61,69,65,70,68,69,68,72,67,74,69,76) Podem conclure que l’augment mitjà de pes en aquestes condicions és de menys de 70 g? Variable aleatòria d’interès: \\(X\\): “Prenem un ratolí alimentat amb aquesta dieta especial i mesuram el seu augment de pes durant les seves primeres 12 setmanes de vida”, amb mitjana \\(\\mu\\). Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu=70\\\\ H_{1}:\\mu &lt;70 \\end{array} \\right. \\] Si miram la mostra, veurem que no té pinta de venir d’una distribució normal però sí simètrica: qqPlot(pesos, distribution=&quot;norm&quot;, mean=mean(pesos), sd=sd(pesos), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) boxplot(pesos) Per tant, emprarem un test de Wilcoxon. Vegem com aniria a mà. Calculam els \\(d_i=x_i-70\\) \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\hline \\end{array} \\] Assignam índexos als \\(d_i\\neq 0\\) en ordre creixent al seu valor absolut. En cas d’empat, per ara els assignam els índexos ordenats d’esquerra a dreta. \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\textrm{Rang fals} &amp; 1 &amp; 12 &amp; 2 &amp; 10 &amp; &amp; 5 &amp; 3 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 4 &amp; 11 \\\\ \\hline \\end{array} \\] A continuació, assignam com a “rang vertader” de cada \\(d_i\\) la mitjana de tots els “rangs falsos” dels \\(d_i\\) amb el seu mateix valor absolut. Així, el rang de tots els \\(d_i=-1\\) és \\((1+2+3+4)/4=2.5\\) i el rang dels \\(d_i=-2\\) o 2 és \\((5+6+7)/3=6\\). \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\textrm{Rang fals} &amp; 1 &amp; 12 &amp; 2 &amp; 10 &amp; &amp; 5 &amp; 3 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 4 &amp; 11 \\\\ \\textrm{Rang} &amp; 2.5 &amp; 12 &amp; 2.5 &amp; 10 &amp; &amp; 6 &amp; 2.5 &amp; 6 &amp; 6 &amp; 8 &amp; 9 &amp; 2.5 &amp; 11 \\\\ \\hline \\end{array} \\] Anotam quins \\(d_i\\) són positius i quins negatius: \\[ \\begin{array}{l|cccccccccccccc} \\hline x_i &amp; 69 &amp; 61 &amp; 69 &amp; 65 &amp; 70 &amp; 68 &amp; 69 &amp; 68 &amp; 72 &amp; 67 &amp; 74 &amp; 69 &amp; 76\\\\ d_i &amp; -1 &amp; -9 &amp; -1 &amp; -5 &amp; 0 &amp; -2 &amp; -1 &amp; -2 &amp; 2 &amp; -3 &amp; 4 &amp; -1 &amp; 6\\\\ \\textrm{Rang fals} &amp; 1 &amp; 12 &amp; 2 &amp; 10 &amp; &amp; 5 &amp; 3 &amp; 6 &amp; 7 &amp; 8 &amp; 9 &amp; 4 &amp; 11 \\\\ \\textrm{Rang} &amp; 2.5 &amp; 12 &amp; 2.5 &amp; 10 &amp; &amp; 6 &amp; 2.5 &amp; 6 &amp; 6 &amp; 8 &amp; 9 &amp; 2.5 &amp; 11 \\\\ \\textrm{Signe} &amp; - &amp; - &amp; - &amp; - &amp; &amp; - &amp; - &amp; - &amp; + &amp; - &amp; + &amp; - &amp; +\\\\ \\hline \\end{array} \\] Sumam, d’una banda, els rangs dels \\(d_i\\) positius i de l’altra, els dels negatius: \\[ \\begin{array}{l} T_+=6+9+11=26\\\\ T_-=2.5+ 12 + 2.5 + 10 + 6 + 2.5 + 6 + 8 + 2.5=52 \\end{array} \\] I ara miraríem si \\(T_+\\) és prou més petit que \\(T_-\\) per que sigui evidència estadísticament significativa de que \\(\\mu &lt;\\mu_0\\). Això ja no ho podem fer a mà. Amb R, simplement entraríem wilcox.test(pesos,mu=70,alternative=&quot;less&quot;) ## ## Wilcoxon signed rank test with continuity correction ## ## data: pesos ## V = 26, p-value = 0.1621 ## alternative hypothesis: true location is less than 70 Conclusió: No hem obtingut evidència estadísticament significativa que l’augment mitjà de pes en aquestes condicions sigui més petit que 70 g (test de Wilcoxon, p-valor 0.16). El test de Wilcoxon per a dues mitjanes emprant mostres aparellades és bàsicament el test anterior aplicat a la diferència dels valors de les dues variables a les parelles. Exemple 2.7 Una alternativa a la transformació logarítmica portada a terme a l’Exemple 2.5 hagués estat emprar el test de Wilcoxon per a mostres aparellades. El contrast ara seria \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{cu}-\\mu_{ds}=0\\\\ H_{1}:\\mu_{cu}- \\mu_{ds}&lt;0 \\end{array} \\right. \\] que clarament correspon al contrast original \\[ \\left\\{\\begin{array}{l} H_{0}:\\mu_{cu}=\\mu_{ds}\\\\ H_{1}:\\mu_{cu}&lt; \\mu_{ds} \\end{array} \\right. \\] però hem de tenir present que la hipòtesi nul·la en realitat significa que la mediana de les diferències dels nivells de triglicèrids en el cordó umbilical menys els nivells de triglicèrids al cap de dues setmanes és 0, és a dir Si restam del nivell de triglicèrids en la sang del cordó umbilical d’un nadó el seu nivell de triglicèrids en sang al cap de dues setmanes, la meitat de les vegades obtenim un valor \\(\\geqslant 0\\) i l’altra meitat de les vegades un valor \\(\\leqslant 0\\), o, equivalentment, La meitat dels nadons tenen el nivell de triglicèrids en la sang del cordó umbilical més alt o igual que el seu nivell de triglicèrids en sang al cap de dues setmanes, i l’altra meitat tenen el nivell de triglicèrids en la sang del cordó umbilical més petit o igual que el seu nivell de triglicèrids en sang al cap de dues setmanes. La hipòtesi alternativa que aquesta mediana és negativa. És a dir, la hipòtesi alternativa és Si restam el nivell de triglicèrids en la sang del cordó umbilical d’un nadó menys el nivell de triglicèrids en sang al cap de dues setmanes, més de la meitat de les vegades obtendríem un valor \\(&lt;0\\) o, equivalentment, Més de la meitat dels nadons tenen el nivell de triglicèrids en la sang del cordó umbilical més petit que el seu nivell de triglicèrids en sang al cap de dues setmanes. wilcox.test(TGN$CU,TGN$DS,alternative=&quot;less&quot;,paired=TRUE) ## ## Wilcoxon signed rank test with continuity correction ## ## data: TGN$CU and TGN$DS ## V = 0, p-value = 6.384e-06 ## alternative hypothesis: true location shift is less than 0 Com que el p-valor és de l’ordre de 10-6, rebutjam la hipòtesi nul·la en favor de la alternativa, i cometem l’abús de llenguatge d’expressar-ho en termes de mitjanes: Conclusió: Hem obtingut evidència estadísticament significativa que el nivell mitjà de triglicèrids a la sang del cordó umbilical dels nadons és més petit que al cap de dues setmanes (test de Wilcoxon, p-valor 6.4·10-6). 2.2 Contrastos de variàncies 2.2.1 Test \\(\\chi^2\\) d’una variància Siguin \\(X\\) una variable aleatòria \\(N(\\mu,\\sigma)\\) i \\(X_1,\\ldots,X_n\\) una mostra aleatòria simple de \\(X\\) de mida \\(n\\) qualsevol. Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma=\\sigma_0\\\\ H_{1}:\\sigma \\neq\\sigma_0\\text{ o }\\sigma &gt;\\sigma_0\\text{ o }\\sigma&lt;\\sigma_0 \\end{array} \\right. \\] o equivalentment \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma^2=\\sigma_0^2\\\\ H_{1}:\\sigma^2 \\neq\\sigma_0^2\\text{ o }\\sigma^2 &gt;\\sigma_0^2\\text{ o }\\sigma^2&lt;\\sigma_0^2 \\end{array} \\right. \\] Si \\(H_0\\) és vertadera, sabem que l’estadístic de contrast \\[ \\chi^2=\\frac{(n-1) \\widetilde{S}_X^2}{\\sigma_{0}^2} \\] té distribució \\(\\chi_{n-1}^2\\), i aleshores ho podem emprar per calcular p-valors, regions crítiques etc. En concret, si el valor d’aquest estadístic de contrast sobre la mostra és \\(\\chi_0^2\\), aleshores: Si \\(H_{1}:\\sigma&gt;\\sigma_{0}\\), el p-valor és \\(P(\\chi^2\\geqslant\\chi_0^2)\\) Si \\(H_{1}:\\sigma&lt;\\sigma_{0}\\), el p-valor és \\(P(\\chi^2\\leqslant\\chi^2_0)\\) Si \\(H_{1}:\\sigma\\neq \\sigma_{0}\\), el p-valor es pren, per conveni, igual a \\(2\\text{min}\\big\\{P(\\chi^2\\geqslant\\chi^2_0), P(\\chi^2\\leqslant\\chi^2_0)\\big\\}\\) Alerta amb els p-valors dels contrastos bilaterals relacionats amb variàncies, ja que per motius històrics no es calculen com “la probabilitat d’obtenir un valor de \\(\\chi^2\\) tant o més extrem que \\(\\chi_0^2\\) en el sentit de la hipòtesi alternativa”, sinó per mitjà de la fórmula que us hem donat. Exemple 2.8 Suposem que tenim una mostra aleatòria simple de \\(X\\) normal de mida 25, i ha donat \\(\\widetilde{S}_X^2=1.25\\). Volem realitzar alguns contrastos amb hipòtesi nul·la \\(\\sigma_X^2=0.8\\), i per tant tendrem \\[ \\chi_0^2=\\frac{(25-1)\\cdot 1.25}{0.8}=37.5 \\] Si volem realitzar el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_X^2=0.8 \\\\ H_{1}:\\sigma_X^2&gt; 0.8 \\end{array} \\right. \\] el p-valor és \\[ P(\\chi^2_{24} \\geqslant 37.5)=\\texttt{1-pchisq(37.5,24)}=0.039 \\] Amb nivell de confiança \\(\\alpha=0.05\\) rebutjam \\(H_0\\) en favor de \\(H_1\\) Si volem realitzar el contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_X^2=0.8 \\\\ H_{1}:\\sigma_X^2\\neq 0.8 \\end{array} \\right. \\] El p-valor és \\[ \\begin{array}{l} 2\\min\\big\\{P(\\chi^2_{24}\\geqslant 37.5),P(\\chi^2_{24}\\leqslant 37.5)\\big\\}\\\\ \\qquad=2\\min\\{\\texttt{1-pchisq(37.5,24)},\\texttt{pchisq(37.5,24)}\\}\\\\ \\qquad=2\\min\\{0.039,0.961\\}= 0.078 \\end{array} \\] Amb nivell de confiança \\(\\alpha=0.05\\), no podem rebutjar \\(H_0\\). En resum: amb la nostra mostra trobam evidència estadísticament significativa que \\(\\sigma&gt;\\sigma_0\\), però no trobam evidència estadísticament significativa que \\(\\sigma\\neq \\sigma_0\\). No us ha de venir de nou, ja ens hi hem trobat en altres ocasions (recordau els Exemples 1.13 i 1.15): per rebutjar la hipòtesi nul·la en un contrast bilateral cal més evidència que en un contrast unilateral, perquè al contrast bilateral tenim dues fonts d’error de tipus I i al contrast unilateral només una. Exemple 2.9 S’ha analitzat el líquid amniòtic d’una mostra aleatòria de 15 embarassades de 3er trimestre, i s’han obtingut les mesures següents de proteïnes totals (en grams per 100 ml): amnio=c(0.69,1.04,0.39,0.37,0.64,0.73,0.69,1.04,0.83,1.01, 0.19,0.61,0.42,0.25,0.79) Podem concloure a partir d’aquestes dades, amb un nivell de significació del 5%, que la desviació típica poblacional (és a dir, la desviació típica de la quantitat de proteïna total en el líquid amniòtic de les embarassades de 3er trimestre expressada en grams per 100 ml) és diferent de 0.25? Variable aleatòria d’interès: \\(X\\): “Prenem una embarassada i li mesuram la uantitat de proteïna total en …” de desviació típica \\(\\sigma\\). Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma=0.25 \\\\ H_{1}:\\sigma\\neq 0.25 \\end{array} \\right. \\] amb \\(\\alpha=0.05\\) Per poder aplicar el test \\(\\chi^2\\), cal que \\(X\\) sigui normal. Vegem-ho qqPlot(amnio, distribution=&quot;norm&quot;, mean=mean(amnio), sd=sd(amnio), ylab=&quot;Quantils de la mostra&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) Acceptarem que \\(X\\) és normal. Estadístic de contrast: \\[ \\chi^2=\\frac{(n-1) \\widetilde{S}_X^2}{\\sigma_{0}^2} \\] que segueix una llei \\(\\chi^2_{n-1}\\) si \\(H_0\\) és certa. Valor de l’estadístic de contrast, \\(\\chi^2_0\\): n=length(amnio) n ## [1] 15 var(amnio) ## [1] 0.07624 khi0=(n-1)*var(amnio)/0.25^2 round(khi0,2) ## [1] 17.08 p-valor: \\[ \\begin{array}{l} 2\\min\\big\\{P(\\chi_{n-1}^2\\geqslant\\chi^2_0), P(\\chi_{n-1}^2\\leqslant\\chi^2_0)\\big\\}\\\\ \\qquad=2\\min\\{\\texttt{1-pchisq(17.08,14)},\\texttt{pchisq(17.08,14)}\\}\\\\ \\qquad=2\\min\\{0.252,0.748\\}= 0.504 \\end{array} \\] En aquest exemple, com que el contrast és bilateral, l’IC 95% seria el del tema anterior (amb \\(q=1-\\alpha=0.95\\)). El de la variància seria \\[ \\begin{array}{l} \\displaystyle \\left[ \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,0.975}^2}, \\frac{(n-1)\\widetilde{S}_{X}^2}{\\chi_{n-1,0.025}^2} \\right]\\\\ \\qquad\\displaystyle=\\left[ \\frac{14\\cdot 0.0762}{26.1189}, \\frac{14\\cdot 0.0762}{5.6287}\\right]=[0.0408, 0.1895] \\end{array} \\] L’interval de confiança del 95% per a la desviació típica serà aleshores \\[ [\\sqrt{0.0408}, \\sqrt{0.1895}]= [0.202,0.435] \\] i conté el valor 0.25 que contrastàvem. Conclusió: No hem obtingut evidència estadísticament significativa que la desviació típica (de la quantitat de proteïna total …) sigui diferent de 0.25 (test \\(\\chi^2\\), p-valor 0.504, IC 95% de 0.202 a 0.435). Aquest test \\(\\chi^2\\) d’una variància està implementat en la funció sigma.test del paquet TeachingDemos. La seva sintaxi és similar a la de t.test. Per exemple, per realitzar aquest darrer contrast, simplement entraríem library(TeachingDemos) sigma.test(amnio,sigma=0.25,alternative=&quot;two.sided&quot;) ## ## One sample Chi-squared test for variance ## ## data: amnio ## X-squared = 17.078, df = 14, p-value = 0.5041 ## alternative hypothesis: true variance is not equal to 0.0625 ## 95 percent confidence interval: ## 0.04086535 0.18962728 ## sample estimates: ## var of amnio ## 0.07624 Ups, què ha passat amb l’interval de confiança? No res: fixau-vos que és el de la variància. L’interval de confiança que dóna la funció sigma.test és el de la variància, tant si contrastam la desviació típica (amb el paràmetre sigma) com si contrastam la variància (amb el paràmetre sigmasq). 2.2.2 Test F per a dues variàncies Siguin \\(X_1,X_2\\) dues variables aleatòries normals de desviacions típiques \\(\\sigma_1\\) i \\(\\sigma_2\\), respectivament. En prenem dues mostres aleatòries simples independents de mides \\(n_1\\) i \\(n_2\\) i variàncies mostrals \\(\\widetilde{S}^2_1\\) i \\(\\widetilde{S}^2_2\\). Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_1^2=\\sigma_2^2\\\\[1ex] H_{1}:\\sigma_1^2\\neq \\sigma_2^2\\text{ o }\\sigma_1^2&gt; \\sigma_2^2\\text{ o }\\sigma_1^2&lt; \\sigma_2^2 \\end{array} \\right. \\] L’interpretarem \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_1^2/\\sigma_2^2=1\\\\[1ex] H_{1}:\\sigma_1^2/\\sigma_2^2\\neq 1\\text{ o }\\sigma_1^2/\\sigma_2^2&gt;1 \\text{ o }\\sigma_1^2/\\sigma_2^2&lt; 1 \\end{array} \\right. \\] Per realitzar-lo, s’empra l’estadístic de contrast \\[ F={\\widetilde{S}_1^2}/{\\widetilde{S}_2^2} \\] que, si les dues poblacions són normals i \\[ H_0: \\sigma_1=\\sigma_2 \\] és vertadera, té distribució coneguda: la F de Fisher-Snedecor \\(F_{n_1-1,n_2-1}\\) amb \\(n_1-1\\) i \\(n_2-1\\) graus de llibertat. Per aquest motiu a aquest contrast se li diu un test F. De la distribució \\(F_{n,m}\\), on \\(n,m\\) són els seus graus de llibertat, heu de saber que: Els graus de llibertat \\(n,m\\) són els paràmetres dels quals depèn la funció de distribució, i l’ordre és important: si \\(n\\neq m\\), la distribució \\(F_{n,m}\\) i la distribució \\(F_{m,n}\\) són diferents. Amb R és f No és simètrica, té cua a la dreta i per tant els p-valors dels contrastos bilaterals es calculen com al test \\(\\chi^2\\) d’una variància. El gràfic següent mostra les gràfiques de les densitats de les distribucions \\(F_{n,m}\\) per a \\(n=3,4\\) i \\(m=3,4,5\\). Es pot observar a cada una d’elles una cua a la dreta ben marcada, i també hi podeu observar que les distribucions \\(F_{3,4}\\) i \\(F_{4,3}\\) tenen densitats diferents. Per tant, si diem \\(F_0\\) al valor que pren l’estadístic \\(F\\) sobre la nostra mostra Si \\(H_{1}:\\sigma_1^2&gt;\\sigma_2^2\\), el p-valor del constrast és \\(P(F\\geqslant F_0)\\) Si \\(H_{1}:\\sigma_1^2&lt;\\sigma_2^2\\), el p-valor del constrast és \\(P(F\\leqslant F_0)\\) Si \\(H_{1}:\\sigma_1^2\\neq \\sigma_2^2\\), el p-valor es pren, per conveni, igual a \\(2\\text{min}\\big\\{P(F\\geqslant F_0), P(F\\leqslant F_0)\\big\\}\\) El test F està implementat en la funció var.test de R: s’aplica a les dues mostres, amb sintaxi similar a la de t.test. Exemple 2.10 Les variables \\(X_d\\) i \\(X_h\\) de l’Exemple 2.3, tenen la mateixa variància? Suposarem que totes dues són normals (les temperatures ho solen ser) i diguem \\(\\sigma_d^2\\) i \\(\\sigma_h^2\\) a les seves variàncies. Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:\\sigma_d^2=\\sigma_h^2\\\\ H_{1}:\\sigma_d^2\\neq \\sigma_h^2 \\end{array} \\right. \\] Estadístic de contrast: \\[ F=\\widetilde{S}_d^2/\\widetilde{S}_h^2 \\] Valor de l’estadístic de contrast a la nostra mostra, \\(F_0\\): F0=var(X_d)/var(X_h) round(F0,4) ## [1] 0.8322 Recordem que les mides de les nostres mostres eren \\(n_d=116\\) i \\(n_h=114\\) p-valor: \\[ \\begin{array}{l} 2\\min\\big\\{P(F_{n_d-1,n_h-1} \\geqslant F0), P(F_{n_d-1,n_h-1}\\leqslant F_0)\\big\\}\\\\ \\qquad =2\\min\\big\\{P(F_{115,113} \\geqslant 0.8322), P(F_{115,113} \\leqslant 0.8322)\\big\\}\\\\ \\qquad =2\\min\\{\\texttt{1-pf(0.8322,115,113)},\\texttt{pf(0.8322,115,113)}\\} \\\\ \\qquad =2\\min\\{0.836,0.164\\}= 0.328 \\end{array} \\] Conclusió: No hem trobat evidència estadísticament significativa que les variables \\(X_h\\) i \\(X_d\\) tenguin variància diferent (test F, p-valor 0.33). Acceptarem que tenen la mateixa variància. Amb R entraríem: var.test(X_d, X_h) ## ## F test to compare two variances ## ## data: X_d and X_h ## F = 0.8322, num df = 115, denom df = 113, p-value = 0.3278 ## alternative hypothesis: true ratio of variances is not equal to 1 ## 95 percent confidence interval: ## 0.575234 1.203224 ## sample estimates: ## ratio of variances ## 0.8321984 Obtenim el mateix p-valor que abans. L’interval de confiança que dóna aquesta funció és per al quocient de les variàncies. Aleshores, com que l’IC 95% conté l’1, no podem rebutjar amb un nivell de significació del 5% que \\(\\sigma_d^2/\\sigma_h^2=1\\), és a dir, que \\(\\sigma_d^2=\\sigma_h^2\\). És a dir: Conclusió: No hem trobat evidència estadísticament significativa que les variables \\(X_h\\) i \\(X_d\\) tenguin variància diferent (test F, p-valor 0.33, IC 95% per al quocient de les variàncies de 0.83 a 1.74). Acceptarem que tenen la mateixa variància. Per tant, si els tests t amb var.equal=TRUE i var.equal=FALSE de l’Exemple 2.3 haguessin donat conclusions diferents, prendríem la corresponent a variàncies iguals. Hem emprat un test F per comparar aquestes variàncies, i per que la conclusió sigui fiable, cal que les variables poblacionals siguin normals, no és suficient que les mostres siguin grans; de fet, la seva validesa no depèn per res de la mida de les mostres. Podem suposar que efectivament les variables \\(X_d\\) i \\(X_h\\) són normals? Vegem els histogrames: hist(X_d,freq=FALSE, breaks=4,col=&quot;light blue&quot;,xlab=&quot;Temperatures&quot;, ylab=&quot;Densitat&quot;,main=&quot;Histograma de temperatures de dones&quot;) lines(density(X_d),lty=2,lwd=2) curve(dnorm(x,mean(X_d),sd(X_d)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;), col=c(&quot;black&quot;,&quot;red&quot;),lty=c(2,1),cex=0.5) # hist(X_h,freq=FALSE, breaks=4,col=&quot;light blue&quot;,xlab=&quot;Temperatures&quot;, ylab=&quot;Densitat&quot;,main=&quot;Histograma de temperatures d&#39;homes&quot;) lines(density(X_h),lty=2,lwd=2) curve(dnorm(x,mean(X_h),sd(X_h)),col=&quot;red&quot;,lwd=2,add=TRUE) legend(&quot;topright&quot;,legend=c(&quot;Densitat estimada&quot;,&quot;Normal&quot;), col=c(&quot;black&quot;,&quot;red&quot;),lty=c(2,1),cex=0.5) i els normal-plot: qqPlot(X_d, distribution=&quot;norm&quot;, mean=mean(X_d), sd=sd(X_d), ylab=&quot;Quantils de la mostra de dones&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) qqPlot(X_h, distribution=&quot;norm&quot;, mean=mean(X_h), sd=sd(X_h), ylab=&quot;Quantils de la mostra d&#39;homes&quot;, xlab=&quot;Quantils de normal&quot;, pch=20, id=FALSE) Seria millor haver emprat un test no paramètric, per més seguretat. 2.2.3 Tests no paramètrics Quan alguna de les variables poblacionals involucrades en un test de dues variàncies no és normal, no es pot fer servir el test F. En aquest cas, us recomanam emprar el test de Fligner-Killeen, implementat en R en la funció fligner.test, que en la pràctica ha mostrat ser més exacte per a variables aleatòries molt diferents de normals. Aquest test només serveix per a contrastos bilaterals, que en realitat són els únics interessants, i està implementat en la funció fligner.test de R. S’aplica a una list formada per les dues mostres o a una fórmula que separi una variable numèrica en dos grups. Per exemple, per emprar-lo en el contrast bilateral de variàncies de l’exemple anterior, entraríem: fligner.test(list(X_h,X_d)) ## ## Fligner-Killeen test of homogeneity of variances ## ## data: list(X_h, X_d) ## Fligner-Killeen:med chi-squared = 1.7736, df = 1, p-value = 0.1829 Seguim acceptant que \\(X_h\\) i \\(X_d\\) tenen la mateixa variància. 2.3 Contrastos per a proporcions 2.3.1 Contrastos per a una proporció Suposem que la variable poblacional \\(X\\) és Bernoulli de probabilitat d’èxit \\(p\\) i que volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:p=p_{0}\\\\ H_{1}:p\\neq p_{0}\\text{ o } p&gt;p_0 \\text{ o } p&lt;p_0 \\end{array} \\right. \\] Tenim dues opcions: Realitzar un test binomial exacte, que és el que explicàvem a la Secció 1.2 Realitzar un test aproximat basat en l’aproximació d’una distribució binomial per una normal, i que per tant només podem emprar si la mostra és gran Test binomial exacte Suposem que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) qualsevol i que hi obtenim \\(S_0\\) èxits, de manera que \\(\\widehat{p}_X=S_0/n\\). Si \\(H_0\\) és vertadera, el nombre d’èxits \\(S\\) en una mostra aleatòria simple segueix una distribució \\(B(n,p_0)\\). Ho podem usar per calcular p-valors de la manera usual: Si \\(H_{1}:p&gt;p_{0}\\), el p-valor és \\(P(S\\geqslant S_0)\\) Si \\(H_{1}:p&lt;p_{0}\\), el p-valor és \\(P(S\\leqslant S_0)\\) Si \\(H_{1}:p\\neq p_{0}\\), el p-valor és la probabilitat que \\(S\\) estigui tan o més allunyada que \\(S_0\\) del nombre d’èxits qe esperaríem si \\(H_0\\) fos vertadera, que és \\(p_0\\cdot n\\). Per tant, és \\[ \\text{p-valor}=P(S\\leqslant p_0\\cdot n-|p_0\\cdot n-S_0|)+P(S\\geqslant p_0\\cdot n+|p_0\\cdot n-S_0|) \\] Aquesta probabilitat també es pot calcular com la probabilitat que \\(S\\) prengui un valor de probabilitat més petita o igual que la de \\(S_0\\): \\[ \\text{p-valor}=\\sum_{k\\atop P(S=k)\\leqslant P(S=S_0)} P(S=k) \\] Una distribució binomial \\(B(n,p_0)\\) només és simètrica quan \\(p_0= 0.5\\). Aquest test binomial exacte està implementat en R en la funció binom.test binom.test(x, n, p=..., alternative=..., conf.level=...) on x indica al nombre d’èxits, n la mida de la mostra, p la probablitat que es contrasta, i els altres dos paràmetres signifiquen el mateix que a les altres funcions explicades fins ara. L’interval de confiança que dóna en els contrastos bilaterals és el de Clopper-Pearson. Exemple 2.11 Ens demanam si la proporció d’estudiants esquerrans a la UIB, és diferent de la de l’estat espanyol, que és del 10%. Prenem un mostra de 30 estudiants de la UIB més o menys a l’atzar i hi trobam 1 esquerrà. Variable aleatòria d’interès: \\(X\\): “Prenem un estudiant de la UIB i miram si és esquerrà”, de probabilitat d’èxit \\(p\\) Contrast: \\[ \\left\\{\\begin{array}{l} H_{0}:p=0.1\\\\ H_{1}:p\\neq 0.1 \\end{array} \\right. \\] Emprarem el test binomial exacte Estadístic de contrast: Nombre d’èxits \\(S\\), que si \\(H_0\\) és vertadera, té distribució \\(B(n,0.1)\\) Valor de l’estadístic de contrast: 1 p-valor: Si la hipòtesi nul·la \\(p=0.1\\) fos vertadera, en una mostra aleatòria de 30 estudiants esperaríem 3 esquerrans, i n’hem trobat 1. Per tant el p-valor és la probabilitat que \\(S\\) sigui més petit o igual que 1 o més gran o igual que 5: \\[ P(S\\leqslant 1)+P(S\\geqslant 5)=\\texttt{pbinom(1,30,0.1)+1-pbinom(4,30,0.1)}=0.359 \\] Conclusió: No hem obtingut evidència estadísticament significativa que el percentatge d’esquerrans a la UIB sigui diferent del 10% (test binomial, p-valor 0.36). Amb R, entraríem: binom.test(1, 30, p=0.1, alternative=&quot;two.sided&quot;) ## ## Exact binomial test ## ## data: 1 and 30 ## number of successes = 1, number of trials = 30, p-value = 0.3592 ## alternative hypothesis: true probability of success is not equal to 0.1 ## 95 percent confidence interval: ## 0.0008435709 0.1721694556 ## sample estimates: ## probability of success ## 0.03333333 i a més obtenim l’IC 95% de Clopper-Pearson per a \\(p\\), per tant podem refinar la nostra conclusió: Conclusió: No hem obtingut evidència estadísticament significativa que el percentatge d’esquerrans a la UIB sigui diferent del 10% (test binomial, p-valor 0.37, IC 95% de 0.001 a 0.172). Test aproximat Suposem que prenem una mostra aleatòria simple de \\(X\\) de mida \\(n\\) gran, posem de 40 subjectes o més, i que hi obtenim una proporció mostral d’èxits \\(\\widehat{p}_X\\). En aquest cas, si \\(H_{0}:p=p_{0}\\) és vertadera, pel Teorema Central del Límit, la distribució de \\[ Z=\\frac{\\widehat{p}_X-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\] és aproximadament la d’una variable \\(N(0,1)\\). Ho podem emprar per calcular p-valors i intervals de confiança. Si \\(Z\\) pren el valor \\(z_0\\), Quan \\(H_{1}:p&gt;p_{0}\\), el p-valor és \\(P(Z\\geqslant z_0)\\) Quan \\(H_{1}:p&lt;p_{0}\\), el p-valor és \\(P(Z\\leqslant z_0)\\) Quan \\(H_{1}:p\\neq p_{0}\\), el p-valor és \\(2P(Z\\geqslant|z_0|)\\) (recordau que \\(Z\\) és simètrica) Amb R, està implementat en la funció prop.test(x, n, p=...,alternative=..., conf.level=..., correct=...) on els paràmetres tenen el mateix significat que a binom.test excepte correct, que serveix per especificar si volem que s’apliqui una correcció de continuïtat (que és recomanable quan s’aproxima una variable discreta per una contínua però que nosaltres no aplicarem en realitzar contrastos “a mà” per no complicar-los) que millora els resultats. El seu valor per defecte és TRUE, i és el que us recomanan que empreu; el que hem explicat aquí correspon a correct=FALSE. L’interval de confiança que dóna aquesta funció en un contrast bilateral és el de Wilson (amb o sense correcció de continuïtat, segons el que valgui correct). Exemple 2.12 Continuant amb l’Exemple 2.11, ara hi emprarem el test aproximat, tot i que no és lo seu. Estadístic de contrast: \\[ Z=\\frac{\\widehat{p}_X-p_0}{\\sqrt{\\frac{p_0(1-p_0)}{n}}} \\] que, si \\(H_0\\) és vertadera, seguiria una distribució (aproximadament) normal estándard. Valor sobre la nostra mostra: \\[ z_0=\\frac{\\frac{1}{30}-0.1}{\\sqrt{\\frac{0.1(1-0.1)}{30}}}=-1.22 \\] p-valor: \\(2P(Z\\geqslant|-1.22|)=\\texttt{2*(1-pnorm(1.22))}=0.222\\) Conclusió: Un altre cop, no obtenim evidència estadísticament significativa que el percentatge d’esquerrans a la UIB sigui diferent del 10% (prop-test, p-valor 0.22). Amb R, entraríem: prop.test(1, 30, p=0.1, alternative=&quot;two.sided&quot;) ## Warning in prop.test(1, 30, p = 0.1, alternative = &quot;two.sided&quot;): Chi- ## squared approximation may be incorrect ## ## 1-sample proportions test with continuity correction ## ## data: 1 out of 30, null probability 0.1 ## X-squared = 0.83333, df = 1, p-value = 0.3613 ## alternative hypothesis: true p is not equal to 0.1 ## 95 percent confidence interval: ## 0.001742467 0.190530216 ## sample estimates: ## p ## 0.03333333 No dóna el mateix p-valor que abans, perquè, com hem explicat, el nostre test correspon a correct=FALSE: prop.test(1, 30, p=0.1, alternative=&quot;two.sided&quot;, correct=FALSE) ## Warning in prop.test(1, 30, p = 0.1, alternative = &quot;two.sided&quot;, correct = ## FALSE): Chi-squared approximation may be incorrect ## ## 1-sample proportions test without continuity correction ## ## data: 1 out of 30, null probability 0.1 ## X-squared = 1.4815, df = 1, p-value = 0.2235 ## alternative hypothesis: true p is not equal to 0.1 ## 95 percent confidence interval: ## 0.00590859 0.16670391 ## sample estimates: ## p ## 0.03333333 Si llegiu amb cura la sortida del prop.test, veureu que no empra un estadístic de contrast que té una distribució normal, sinó un que té distribució \\(\\chi^2\\) amb 1 grau de llibertat: X-squared=..., df=1. El que passa és que R no empra l’estadístic \\(Z\\) que hem explicat, sinó el seu quadrat, \\(Z^2\\), que té distribució \\(\\chi_1^2\\) perquè \\(Z\\) és normal estàndard. El missatge d’advertència que ens ha donat R en aquestes dues execucions de la funció prop.test ens diu que no se satisfan les condicions necessàries per que el resultat d’aquest contrast sigui vàlid. Exemple 2.13 Quina és la potència del contrast realitzat a l’exemple anterior? Emprarem les funcions del paquet pwr per calcular-la. Primer calculam la mida de l’efecte observat amb la funció ES.h aplicada a la proporció poblacional contrastada i a la proporció mostral: library(pwr) ES.h(0.1,0.03) ## [1] 0.2953351 I ara aplicam la funció pwr.p.test a la mida de l’efecte observat, h, la mida de la mostra, n, el nivell de significació, sig.level, i el tipus de contrast, alternative, i ens donarà la potència: pwr.p.test(h=0.3, n=30, sig.level=0.05, alternative=&quot;two.sided&quot;) ## ## proportion power calculation for binomial distribution (arcsine transformation) ## ## h = 0.3 ## n = 30 ## sig.level = 0.05 ## power = 0.3758563 ## alternative = two.sided Què hagués passat si, en lloc d’1 esquerrà en una mostra de 30, haguéssim trobat 5 esquerrans en una mostra (aleatòria simple) de 150 estudiants, de manera que la proporció mostral fos la mateixa? prop.test(5, 150, p=0.1) ## ## 1-sample proportions test with continuity correction ## ## data: 5 out of 150, null probability 0.1 ## X-squared = 6.6852, df = 1, p-value = 0.009722 ## alternative hypothesis: true p is not equal to 0.1 ## 95 percent confidence interval: ## 0.01233588 0.08010876 ## sample estimates: ## p ## 0.03333333 Ara podríem rebutjar amb un nivell de significació del 5% que la proporció d’esquerrans a la UIB és del 10%. Quina ha estat la potència d’aquest test? pwr.p.test(h=0.3, n=150, sig.level=0.05, alternative=&quot;two.sided&quot;) ## ## proportion power calculation for binomial distribution (arcsine transformation) ## ## h = 0.3 ## n = 150 ## sig.level = 0.05 ## power = 0.9567605 ## alternative = two.sided Amb una mostra més gran, la potència és més gran, és més fàcil detectar que la hipòtesi alternativa sigui vertadera. Exemple 2.14 De quina mida hauríem d’haver pres la mostra per obtenir una potència del 90% amb \\(\\alpha=0.05\\) i esperant un efecte petit? Per determinar el valor d’un “efecte petit” entram cohen.ES(test=&quot;p&quot;,size=&quot;small&quot;) ## ## Conventional effect size from Cohen (1982) ## ## test = p ## size = small ## effect.size = 0.2 i ara, a l’argument pwr.p.test, en lloc d’entrar-hi la mida de la mostra n, hi entram la potència desitjada i ens donarà la mida necessària per assolir-la: pwr.p.test(h=0.2, power=0.9, sig.level=0.05, alternative=&quot;two.sided&quot;) ## ## proportion power calculation for binomial distribution (arcsine transformation) ## ## h = 0.2 ## n = 262.6855 ## sig.level = 0.05 ## power = 0.9 ## alternative = two.sided Ens caldria una mostra aleatòria simple de 263 estudiants. Com que en un contrast d’una proporció sempre hi podem emprar el test binomial exacte, no hi ha necessitat d’emprar-hi tests no paramètrics. 2.3.2 Contrastos per a 2 proporcions emprant mostres independents Siguin \\(X_1\\) i \\(X_2\\) dues variables aleatòries Bernoulli de paràmetres poblacionals d’èxit \\(p_1\\) i \\(p_2\\). Volem realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2\\text{ o }p_1&gt; p_2\\text{ o }p_1&lt; p_2 \\end{array} \\right. \\] Suposem que, per realitzar aquest contrast, prenem una mostra aleatòria simple de cada variable, independents una de l’altra. Obtenim la taula de freqüències següent \\[ \\begin{array}{r|cc|c } &amp; X_1 &amp; X_2 &amp; \\textrm{Total} \\\\\\hline \\textrm{Èxits} &amp; n_{11} &amp; n_{12} &amp; E \\\\ \\textrm{Fracassos} &amp; n_{21} &amp; n_{22} &amp; F \\\\\\hline \\textrm{Total} &amp; n_{1} &amp; n_{2} \\end{array} \\] Aleshores tenim dues opcions: Realitzar un test \\(\\chi^2\\), que es basa en una aproximació a una normal i requereix algunes condicions sobre les dues mostres Realitzar un test de Fisher, que es pot emprar sempre però no dóna la informació exactament com la voldríem Test \\(\\chi^2\\) Suposem que les dues mostres són grans, per fixar idees \\(n_1,n_2\\geqslant 50\\), i que els nombres d’èxits i de fracasos a cada mostra no són molt petits, per fixar idees tots dos més grans o iguals que 5. Siguin \\(\\widehat{p}_1\\) i \\(\\widehat{p}_2\\) les proporcions mostrals d’èxits a les dues mostres. En aquestes condicions, si la hipòtesi nul·la \\(H_0: p_1=p_2\\) és vertadera, l’estadístic de contrast \\[ Z=\\frac{\\widehat{p}_1 -\\widehat{p}_2}{ \\sqrt{\\frac{E}{n_1 +n_2}\\cdot \\Big(1-\\frac{E}{n_1 +n_2}\\Big)\\cdot \\Big(\\frac{1}{n_1}+\\frac{1}{n_2} \\Big)}} \\] (\\(E=n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2\\) és el nombre total d’èxits a les dues mostres) té distribució aproximadament normal estàndard, la qual cosa es pot emprar com sempre per calcular p-valors i intervals de confiança. Aquest test està implementat en la funció de R prop.test(c(x1,x2), c(n1,n2) ,alternative=..., conf.level=..., correct=...) on x1 i x2 són els nombres d’èxits a les dues mostres i n1, n2 les seves mides. Com al cas d’una proporció, la versió que hem explicat correspon a correct=FALSE, però és més recomanable emprar el valor per defecte de correct, que és TRUE i fa que s’hi apliqui una correcció de continuïtat. Aquest test s’anomena prop-test, o també test \\(\\chi^2\\) perquè és un cas particular d’un test \\(\\chi^2\\) que veurem al proper tema. Det fet, en la seva implementació en R no s’hi empra \\(Z\\) sinó \\(Z^2\\), que té distribució aproximadament \\(\\chi^2_1\\). Exemple 2.15 En un estudi es volgué saber si un determinat al·lel d’un gen és present o no amb la mateixa proporció entre els mallorquins i els menorquins. Es prengueren una mostra d’ADN de 100 individus amb almenys tres generacions familiars a l’illa de Mallorca, i una altra de 50 individus amb almenys tres generacions familiars a l’illa de Menorca: les mostres es prengueren de manera independent. A la mostra mallorquina, 20 individus tengueren l’al·lel, i a la mostra menorquina, 12. La taula de freqüències és, doncs \\[ \\begin{array}{r|cc } &amp; \\textrm{Mallorca} &amp; \\textrm{Menorca} \\\\\\hline \\textrm{Present} &amp; 20 &amp; 12 \\\\ \\textrm{Absent} &amp; 80 &amp; 38 \\\\\\hline \\textrm{Total} &amp; 100 &amp; 50 \\end{array} \\] Variables d’interés: \\(X_1\\): “Prenem un mallorquí amb 3 generacions familiars a l’illa i miram si té aquest al·lel” \\(X_2\\): “Prenem un menorquí amb 3 generacions familiars a l’illa i miram si té aquest al·lel” Totes dues són Bernoulli, de proporcions poblacionals d’èxit \\(p_1\\) i \\(p_2\\), respectivament. Contrast: \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1\\neq p_2 \\end{array}\\right. \\] Estam les condicions de poder emprar el test \\(\\chi^2\\), perquè les dues mostres i els seus nombres d’èxits (individus amb l’al·lel) i fracassos (individus sense l’al·lel) són prou grans. Estadístic de contrast: \\[ Z=\\frac{\\widehat{p}_1 -\\widehat{p}_2}{ \\sqrt{\\frac{n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2}{n_1 +n_2}\\cdot \\Big(1-\\frac{n_1 \\widehat{p}_1 +n_2 \\widehat{p}_2}{n_1 +n_2}\\Big)\\cdot\\Big(\\frac{1}{n_1}+\\frac{1}{n_2} \\Big)}} \\] que és aproximadament \\(N(0,1)\\) si \\(H_0\\) és vertadera. Valor de l’estadístic: Teim que \\(\\widehat{p}_1=0.2\\), \\(\\widehat{p}_2=0.24\\), \\(n_1=100\\), \\(n_2=50\\), \\(E=32\\) i per tant \\[ z_0=\\frac{0.2 -0.24}{ \\sqrt{\\frac{32}{150}\\Big(1-\\frac{32}{150}\\Big)\\Big(\\frac{1}{100}+\\frac{1}{50} \\Big)}} =-0.5637 \\] p-valor: \\(2\\cdot P(Z\\geqslant|-0.5637|)=0.573\\) Conclusió: No hem trobat evidència estadísticament significativa que les proporcions de mallorquins i menorquins amb aquest al·lel siguin diferents (test \\(\\chi^2\\), p-valor 0.57). Amb R, entraríem prop.test(c(20,12), c(100,50), alternative=&quot;two.sided&quot;) ## ## 2-sample test for equality of proportions with continuity ## correction ## ## data: c(20, 12) out of c(100, 50) ## X-squared = 0.12414, df = 1, p-value = 0.7246 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.1969858 0.1169858 ## sample estimates: ## prop 1 prop 2 ## 0.20 0.24 Bé, no exactament: com hem explicat, nosaltres hem fet la versió correct=FALSE. prop.test(c(20,12), c(100,50), alternative=&quot;two.sided&quot;, correct=FALSE) ## ## 2-sample test for equality of proportions without continuity ## correction ## ## data: c(20, 12) out of c(100, 50) ## X-squared = 0.3178, df = 1, p-value = 0.5729 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.1819858 0.1019858 ## sample estimates: ## prop 1 prop 2 ## 0.20 0.24 L’interval de confiança que dóna la funció prop.test en un contrast de dues proporcions és per a la diferència de les proporcions, \\(p_1-p_2\\). Test exacte de Fisher Si no se satisfan les condicions pel test \\(\\chi^2\\), sempre es pot aplicar el test exacte de Fisher, que es basa en la idea següent. Tenim la taula de freqüències \\[ \\begin{array}{r|cc|c } &amp; X_1 &amp; X_2 &amp; \\textrm{Total} \\\\\\hline \\textrm{Èxits} &amp; n_{11} &amp; n_{12} &amp; E \\\\ \\textrm{Fracassos} &amp; n_{21} &amp; n_{22} &amp; F \\\\\\hline \\textrm{Total} &amp; n_{1} &amp; n_{2} \\end{array} \\] Si \\(p_1=p_2\\), les dues variables \\(X_1\\) i \\(X_2\\) tenen la mateixa probabilitat d’èxit, i per tant les dues mostres podrien considerar-se com a dues mostres independents de la mateixa variable \\(X_1\\). Llavors, la probabilitat d’obtenir \\(n_{11}\\) èxits dins la mostra de \\(X_1\\) és la de: Si en una bossa hi tenim \\(E\\) bolles “Èxit” i \\(F\\) bolles “Fracàs”, la probabilitat d’obtenir \\(n_{11}\\) bolles “Èxit” si en triam \\(n_{1}\\) de cop. Per tant, la distribució de \\(n_{11}\\) és hipergeomètrica \\(H(E,F,n_{1})\\). Podem emprar \\(n_{11}\\) com a estadístic de contrast i la distribució hipergeomètrica per calcular p-valors. Exemple 2.16 Per determinar si la Síndrome de Mort Sobtada del Nadó (SIDS) té component genètic, es consideren els casos de SIDS en parelles de bessons monozigòtics i dizigòtics. Diguem: \\(p_1\\): proporció de parelles de bessons monozigòtics amb algun cas de SIDS on només un germà la sofrí \\(p_2\\): proporció de parelles de bessons dizigòtics amb algun cas de SIDS on només un germà la sofrí Si la SIDS té component genètic, hauria de passar que \\(p_1&lt;p_2\\). En efecte, si aquesta síndrome té component genètic i en una parella de bessons un d’ells mor per SIDS, és més probable que l’altre bessó també la sofreixi si els bessons són monozigòtics que si són dizigòtics, ja que els genomes dels monozigòtics són pràcticament idèntics i els dels dizigòtics no. És a dir, és més probable que l’altre bessó també mori per SIDS si els bessons són monozigòtics que si són dizigòtics, o el que és el mateix, és MENYS probable que l’altre bessó NO mori per SIDS si els bessons són monozigòtics que si són dizigòtics. Per tant el contrast que volem realitzar és \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1&lt; p_2 \\end{array}\\right. \\] En un estudi s’obtingueren les dades següents: \\[ \\begin{array}{c} \\hphantom{Monozigotic} \\textbf{Tipus de bessons} \\\\ \\begin{array}{lr|cc|c} &amp; &amp; \\textrm{Monozigòtics} &amp; \\textrm{Dizigòtics} &amp; \\textrm{Total} \\\\ \\hline \\textbf{Casos} &amp; \\textrm{Un} &amp; 23 &amp; 35 &amp; 58\\\\ \\textbf{de SIDS} &amp; \\textrm{Dos} &amp; 1 &amp; 2 &amp; 3\\\\\\hline &amp; \\textrm{Total} &amp; 24 &amp; 37 &amp; \\end{array} \\end{array} \\] Emprarem el test de Fisher, ja que ni les mostres ni els nombres de “fracassos” no són prou grans per poder emprar el test \\(\\chi^2\\). p-valor: \\[ P(H(58,3,24)\\leqslant 23) =\\texttt{phyper(23,58,3,24)}=0.7841 \\] Conclusió: No hem obtingut evidència estadísticament significativa que la SIDS tengui un component genètic (test de Fisher, p-valor 0.78). Amb R el test de Fisher està implementat en la funció fisher.test(M,alternative=...,conf.level=...) on M és la matriu de freqüències de la mostra tal i com l’hem donada: fileres Èxits i Fracassos (en aquest ordre) i columnes \\(X_1\\) i \\(X_2\\). En el nostre exemple, entraríem M=matrix(c(23,35,1,2), nrow=2, byrow=TRUE) fisher.test(M,alternative=&quot;less&quot;) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: M ## p-value = 0.7841 ## alternative hypothesis: true odds ratio is less than 1 ## 95 percent confidence interval: ## 0.00000 39.73954 ## sample estimates: ## odds ratio ## 1.308589 Obtenim el mateix p-valor, i un interval de confiança del 95% que va de 0 a 39.7. Ja us podeu imaginar que aquest interval de confiança no pot ser per a \\(p_1-p_2\\). En realitat, la funció fisher.test no compara \\(p_1\\) i \\(p_2\\), sinó les seves odds (oportunitats; en castellà, també momios) \\[ \\frac{p_1}{1-p_1}\\text{ i }\\frac{p_2}{1-p_2}. \\] L’interval de confiança que dóna és per al quocient d’aquestes odds: la seva odds ratio (OR, raó d’oportunitats; en castellà, també razón de momios). Fem un incís sobre les odds. Les odds d’un esdeveniment \\(A\\) són \\[ \\text{Odds}(A)=\\frac{P(A)}{P(A^c)}=\\frac{P(A)}{1-P(A)} \\] i indiquen quantes vegades és més probable \\(A\\) que “no \\(A\\)”. Per exemple: Si \\(P(A)=0.3\\), \\(\\text{Odds}(A)=0.3/0.7=0.43\\) Si \\(P(A)=0\\), \\(\\text{Odds}(A)=0\\) Si \\(P(A)=0.5\\), \\(\\text{Odds}(A)=1\\) Si \\(P(A)=1\\), \\(\\text{Odds}(A)=\\infty\\) Les odds d’\\(A\\) se solen interpretar en termes d’apostes. Per desgràcia, si no estau acostumats a apostar, per exemple, a les carreres de trotons, aquesta interpretació no us aclarirà gaire. Però ho intentarem. Suposem que \\(\\text{Odds}(A)=m\\), és a dir, que \\(P(A)=m\\cdot P(A^c)\\), i suposem que: Per cada euro que jugueu a \\(A^c\\), la casa d’apostes us en paga 1 si passa \\(A^c\\) i 0 si passa \\(A\\) Per cada euro que jugueu a \\(A\\), la casa d’apostes us en paga \\(R\\) si passa \\(A\\) i 0 si passa \\(A^c\\) Això se sol abreviar dient que les apostes a favor d’\\(A\\) es paguen \\(R\\) a 1: per cada euro que es paga si “guanya” \\(A^c\\), es paguen \\(R\\) euros si “guanya” \\(A\\). Què ha de valer \\(R\\) per que si jugau 1 euro a \\(A\\), el que esperau guanyar sigui el mateix que si jugau 1 euro a \\(A^c\\)? (Es diu en aquest cas que les apostes estan equilibrades.) Vegem. Si jugau 1 euro a \\(A\\), esperau guanyar \\(R\\cdot P(A)=R\\cdot m\\cdot P(A^c)\\), i jugau 1 euro a \\(A^c\\) esperau guanyar \\(1\\cdot P(A^c)\\). Per tant, si aquests guanys esperats han de ser iguals, ha de passar \\(R\\cdot m=1\\), és a dir \\(R=1/m\\). Així, per exemple, si \\(\\text{Odds}(A)=2\\) (la probabilitat que passi \\(A\\) és 2 vegades la de que passi \\(A^c\\)), per que les apostes estiguin equilibrades s’han de pagar 0.5 a 1 a favor d’\\(A\\): per cada euro que es paga si guanya \\(A^c\\), s’ha de pagar mig euro si guanya \\(A\\). Fixau-vos que si coneixeu \\(\\text{Odds}(A)\\), podeu aïllar \\(P(A)\\). Per exemple si \\(\\text{Odds}(A)=0.6\\) \\[ \\begin{array}{l} 0.6=\\dfrac{P(A)}{1-P(A)}\\Rightarrow 0.6-0.6P(A)=P(A)\\\\ \\qquad \\Rightarrow 0.6=1.6P(A)\\Rightarrow P(A)=\\dfrac{0.6}{1.6}=0.375 \\end{array} \\] En general \\[ P(A)=\\dfrac{\\text{Odds}(A)}{1+\\text{Odds}(A)} \\] D’aquí podeu deduir fàcilment que \\[ \\begin{array}{c} \\text{Odds}(A)&lt;\\text{Odds}(B)\\Longleftrightarrow P(A)&lt;P(B)\\\\ \\text{Odds}(A)&gt;\\text{Odds}(B)\\Longleftrightarrow P(A)&gt;P(B)\\\\ \\text{Odds}(A)=\\text{Odds}(B)\\Longleftrightarrow P(A)=P(B) \\end{array} \\] i per tant comparant les probabilitats o les odds de dos esdeveniments obteniu la mateixa informació sobre quin és més probable. La odds ratio de \\(A\\) i \\(B\\) és \\[ \\text{OR}(A,B)=\\frac{\\text{Odds}(A)}{\\text{Odds}(B)} \\] Aquest quocient sol ser mal d’interpretar, i per això precisament sempre que poguem evitarem el test exacte de Fisher. En tot cas, fixau-vos que si \\(\\text{OR}(A,B)=r\\), és a dir, \\(\\text{Odds}(A)=r\\cdot \\text{Odds}(B)\\), i les apostes a favor de \\(A\\) es paguen \\(R_A\\) a 1 i les de \\(B\\) es paguen \\(R_B\\) a 1 i les dues estan equilibrades, aleshores \\[ \\frac{1}{R_A}=r\\cdot \\frac{1}{R_B}\\Longrightarrow R_B=r\\cdot R_A \\] Per tant, si \\(\\text{OR}(A,B)=r\\) i les apostes a favor de \\(B\\) es paguen \\(R_B\\) a 1, les apostes a favor d’\\(A\\) s’han de pagar \\(rR_B\\) a 1. \\(\\text{OR}(A,B)=1\\) si, i només si, \\(\\text{Odds}(A)=\\text{Odds}(B)\\) i per tant, pel que acabam de dir, si, i només si, \\(P(A)=P(B)\\). Per tant, si l’interval de confiança per a la odds ratio que dóna la funció fisher.test conté l’1, no podem rebutjar que les dues proporcions poblacionals d’èxit siguin iguals. Exemple 2.17 Si, per exemple, la odds ratio de \\(A\\) i \\(B\\) és \\[ \\text{OR}(A,B)=\\frac{\\text{Odds}(A)}{\\text{Odds}(B)}=1.5 \\] i per tant \\(\\text{Odds}(A)=1.5\\cdot \\text{Odds}(B)\\): Com que en particular \\(\\text{Odds}(A)&gt; \\text{Odds}(B)\\), podeu concloure que \\(P(A)&gt;P(B)\\) Però el fet que \\(\\text{Odds}(A)=1.5\\cdot \\text{Odds}(B)\\) no implica que \\(P(A)=1.5P(B)\\). De fet, d’aquest de \\(OR(A,B)\\) no podeu deduir el valor de \\(P(A)/P(B)\\). Intentau-ho si no ens creieu. Exemple 2.18 Si realitzam el contrast de l’Exemple 2.15 amb el test \\(\\chi^2\\), obtenim prop.test(c(20,12),c(100,50),alternative=&quot;two.sided&quot;,correct=FALSE) ## ## 2-sample test for equality of proportions without continuity ## correction ## ## data: c(20, 12) out of c(100, 50) ## X-squared = 0.3178, df = 1, p-value = 0.5729 ## alternative hypothesis: two.sided ## 95 percent confidence interval: ## -0.1819858 0.1019858 ## sample estimates: ## prop 1 prop 2 ## 0.20 0.24 El p-valor 0.5729 no ens permet rebutjar que les proporcions de mallorquins i menorquins amb l’al·lel objecte d’estudi siguin iguals L’IC 95% per a la diferència de proporcions va de -0.18 a 0.1: com que conté el 0, no podem rebutjar amb aquest nivell de confiança que les proporcions siguin iguals La diferència de proporcions mostrals \\(p_1-p_2\\) ha estat \\(0.2-0.24=-0.04\\): la proporció de menorquins amb l’al·lel a la nostra mostra ha estat 4 punts percentuals més gran que la dels mallorquins Si ara l’efectuam amb el test de Fisher: M.A=matrix(c(20,12,80,38), nrow=2, byrow=TRUE) fisher.test(M.A,alternative=&quot;two.sided&quot;) ## ## Fisher&#39;s Exact Test for Count Data ## ## data: M.A ## p-value = 0.673 ## alternative hypothesis: true odds ratio is not equal to 1 ## 95 percent confidence interval: ## 0.3287521 1.9742955 ## sample estimates: ## odds ratio ## 0.7929466 El p-valor 0.673 no ens permet rebutjar que les odds de tenir aquest al·lel entre els mallorquins i els menorquins siguin iguals; com que igualtat d’odds és equivalent a igualtat de probabilitats, no podem rebutjar que els mallorquins i menorquins tenguin la mateixa probabilitat de tenir l’al·lel objecte d’estudi L’IC 95% per a la odds ratio (per al quocient de les odds) va de 0.33 a 1.97: com que conté l’1, no podem rebutjar amb aquest nivell de confiança que la odds ratio sigui 1; és a dir, no podem rebutjar que les odds siguin iguals; és a dir, no podem rebutjar que les proporcions siguin iguals El quocient d’odds mostrals (la odds ratio mostral) ha estat 0.79: a la nostra mostra, les odds que un mallorquí tengués l’al·lel han estat 0.79 vegades (un 21% més petites que) les d’un menorquí; però això no ens dóna cap relació numèrica entre les proporcions mostrals de mallorquins i menorquins amb l’al·lel. 2.3.3 Contrastos per a 2 proporcions emprant mostres aparellades Siguin una altra vegada \\(X_1\\) i \\(X_2\\) dues variables aleatòries Bernoulli de paràmetres poblacionals \\(p_1\\) i \\(p_2\\). Seguim volent realitzar un contrast \\[ \\left\\{\\begin{array}{l} H_{0}:p_1=p_2\\\\ H_{1}:p_1\\neq p_2\\text{ o }p_1&gt; p_2\\text{ o }p_1&lt; p_2 \\end{array} \\right. \\] però ara les mesuram sobre els subjectes d’una mateixa mostra, o sobre els subjectes de dues mostres aparellades, de mida \\(n\\). Suposem que tenim els resultats en una taula \\[ \\begin{array}{c} \\hphantom{Variablesssss} \\text{Variable $X_2$}\\\\ \\begin{array}{r|cc} \\text{Variable $X_1$} &amp;\\text{Èxit} &amp; \\text{Fracàs} \\\\ \\hline \\text{Èxit} &amp; a &amp; b \\\\ \\text{Fracàs} &amp; c &amp; d\\\\ \\end{array} \\end{array} \\] on cada entrada representa el nombre de subjectes (o parelles) que satisfan les condicions de la filera i la columna. En aquest cas tenim dues opcions: Realitzar un test de McNemar, que només serveix per a contrastos bilaterals i a més requereix algunes condicions sobre les dues mostres Realitzar un test binomial, que es pot emprar sempre però no dóna la informació exactament com la voldríem Test de McNemar Quan el test és bilateral, si \\(n\\) és prou gran (posem, a partir de 100) i si el nombre de casos discordants (\\(b+c\\) en la taula anterior) és grandet (posem, més gran o igual que 20), es pot emprar el test de McNemar, que empra l’estadístic de contrast \\[ Z^2=\\frac{(b-c)^2}{b+c} \\] el qual, si se satisfan les condicions esmentades, segueix aproximadament una distribució \\(\\chi^2_1\\) si \\(H_0\\) és vertadera. En aquest test se rebutja la hipòtesi nul·la si \\(b\\) i \\(c\\) són prou diferents i per tant, malgrat ser un contrast bilateral, es pren com a p-valor \\(P(Z^2\\geqslant Z_0^2)\\), on \\(Z_0^2\\) és el valor de l’estadístic a la nostra mostra i \\(Z^2\\) té distribució \\(\\chi_1^2\\). Aquest test està implementat en R en la funció mcnemar.test, que s’aplica a la taula de freqüències absolutes de la mostra tal i com l’hem donada. Exemple 2.19 En un assaig clínic es volgué comparar l’efectivitat d’un fàrmac nou contra la migranya amb la d’un placebo. Es prengué una mostra de 500 persones afectades per migranya. A cada una, a l’atzar, se li administrà el fàrmac o el placebo. Se’ls demanà si havien notat alleujament en el dolor. Al cap d’un temps, als mateixos individus se’ls subministrà l’altre tractament (fàrmac als que havien rebut placebo, placebo als que havien rebut fàrmac) i se’ls tornà a demanar si havien notat o no millora. Els resultats varen ser: \\[ \\begin{array}{c} \\hphantom{Variables} \\text{Placebo}\\\\ \\begin{array}{r|cc} \\text{Fàrmac} &amp;\\text{Sí} &amp; \\text{No} \\\\ \\hline \\text{Sí} &amp; 150 &amp; 41 \\\\ \\text{No} &amp; 19 &amp; 285\\\\ \\end{array} \\end{array} \\] on “Sí” indica que el malalt va dir que sí que havia notat alleujament en el dolor. Variables d’interès: \\(X_1\\): “Prenem un malalt, li administram el fàrmac i li demanam si nota millora del dolor”. És Bernoulli de proporció poblacional \\(p_1\\) \\(X_2\\): “Prenem un malalt, li administram el placebo i li demanam si nota millora del dolor”. És Bernoulli de proporció poblacional \\(p_2\\) Contrast: Com que la mostra i el nombre de casos discordants són prou grans, podem emprar el test de McNemar, però aleshores el contrast ha de ser bilateral \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1\\neq p_2 \\end{array}\\right. \\] Estadístic de contrast: \\[ Z^2=\\frac{(b-c)^2}{b+c} \\] que segueix una distribució aproximadament \\(\\chi_1^2\\) si \\(p_1=p_2\\). Valor sobre la nostra mostra: \\(Z_0^2=(41-19)^2/(41+19)=8.067\\) p-valor: \\(P(Z^2\\geqslant 8.067)=\\texttt{1-pchisq(8.067,1)}=0.0045\\) Conclusió: Hem obtingut evidència estadísticament significativa que la taxa d’efectivitat del placebo i del fàrmac són diferents (test de McNemar, p-valor 0.0045). I ara, com que la taxa d’efectivitat del fàrmac ha estat superior a la del placebo (191/500 contra 169/500), faríem la petita trampa de concloure que la diferència entre aquestes taxes d’efectivitat és perquè el fàrmac es més efectiu. Amb R, entraríem Dades.M=matrix(c(150,41,19,285), nrow=2, byrow=TRUE) mcnemar.test(Dades.M) ## ## McNemar&#39;s Chi-squared test with continuity correction ## ## data: Dades.M ## McNemar&#39;s chi-squared = 7.35, df = 1, p-value = 0.006706 Ups! No ha donat el mateix estadístic ni el mateix p-valor. Això passa perquè R també aplica per defecte una correcció de continuïtat al test de McNemar. El que nosaltres hem explicat correspon a mcnemar.test(Dades.M,correct=FALSE) ## ## McNemar&#39;s Chi-squared test ## ## data: Dades.M ## McNemar&#39;s chi-squared = 8.0667, df = 1, p-value = 0.004509 Test binomial exacte Si no podeu emprar el test de McNemar, sempre podeu emprar el test binomial exacte següent. Considerau la taula de probabilitats poblacionals \\[ \\begin{array}{c} \\hphantom{Variablesssss} \\text{Variable $X_2$}\\\\ \\begin{array}{r|cc} \\text{Variable $X_1$} &amp;\\text{Èxit} &amp; \\text{Fracàs} \\\\ \\hline \\text{Èxit} &amp; p_{11} &amp; p_{10} \\\\ \\text{Fracàs} &amp; p_{01} &amp; p_{00} \\end{array} \\end{array} \\] Llavors \\[ p_1=p_{11}+p_{10},\\ p_2=p_{11}+p_{01} \\] i per tant \\[ \\begin{array}{l} p_1=p_2\\Longleftrightarrow p_{10}=p_{01}\\\\ p_1\\neq p_2\\Longleftrightarrow p_{10}\\neq p_{01}\\\\ p_1&lt; p_2\\Longleftrightarrow p_{10}&lt; p_{01}\\\\ p_1&gt; p_2\\Longleftrightarrow p_{10}&gt; p_{01} \\end{array} \\] Això permet traduir un contrast sobre \\(p_1\\) i \\(p_2\\) en el mateix contrast sobre \\(p_{01}\\) i \\(p_{10}\\), i al final en un contrast d’una proporció. Per exemple: \\[ \\left\\{\\begin{array}{l} H_0: p_1=p_2\\\\ H_1: p_1&lt; p_2 \\end{array}\\right. \\] és equivalent a \\[ \\left\\{\\begin{array}{l} H_0: p_{10}=p_{01}\\\\ H_1: p_{10}&lt;p_{01} \\end{array}\\right. \\] i això és equivalent a \\[ \\left\\{\\begin{array}{l} H_0: \\dfrac{p_{10}}{p_{10}+p_{01}}=0.5\\\\ H_1: \\dfrac{p_{10}}{p_{10}+p_{01}}&lt;0.5 \\end{array}\\right. \\] Ara fixau-vos que \\[ \\frac{p_{10}}{p_{10}+p_{01}} \\] és la proporció poblacional de parelles (Èxit,Fracàs) dins la població de casos discordants. En general, el contrast \\[ \\left\\{\\begin{array}{l} H_0: p_1=p_2\\\\ H_1: p_1&lt; p_2\\text{ o }p_1&gt; p_2\\text{ o }p_1\\neq p_2 \\end{array}\\right. \\] es tradueix en el contrast \\[ \\left\\{\\begin{array}{l} H_0: \\dfrac{p_{10}}{p_{10}+p_{01}}=0.5\\\\ H_1: \\dfrac{p_{10}}{p_{10}+p_{01}}&lt;0.5\\text{ o }\\dfrac{p_{10}}{p_{10}+p_{01}}&gt;0.5\\text{ o }\\dfrac{p_{10}}{p_{10}+p_{01}}\\neq 0.5 \\end{array}\\right. \\] i el podem efectuar amb un test binomial exacte prenent: Com a mostra, els casos discordants, de mida \\(b+c\\) Com a èxits, tenir Èxit a \\(X_1\\) i Fracàs a \\(X_2\\): a la mostra n’hi ha \\(b\\) Com a proporció a contrastar: \\(p=0.5\\) L’inconvenient d’aquest test és que l’interval de confiança que donarà és per a \\(p_{10}/(p_{10}+p_{01})\\), i no té res a veure amb \\(p_1-p_2\\) o \\(p_1/p_2\\). Per tant només ens hi podem fixar en el p-valor. Exemple 2.20 Tornem a la situació de l’Exemple 2.19. Ara volem fer el contrast que realment ens interessa, que és si la taxa d’efectivitat del fàrmac és més gran que la del placebo: \\[ \\left\\{\\begin{array}{l} H_0:p_1=p_2\\\\ H_1:p_1&gt;p_2 \\end{array}\\right. \\] Dient \\(p=p_{10}/(p_{10}+p_{01})\\), el traduïm en \\[ \\left\\{\\begin{array}{l} H_0:p=0.5\\\\ H_1:p&gt; 0.5 \\end{array}\\right. \\] Les dades eren \\[ \\begin{array}{c} \\hphantom{Variables} \\text{Placebo}\\\\ \\begin{array}{r|cc} \\text{Fàrmac} &amp;\\text{Sí} &amp; \\text{No} \\\\ \\hline \\text{Sí} &amp; 150 &amp; 41 \\\\ \\text{No} &amp; 19 &amp; 285 \\end{array} \\end{array} \\] I per tant al contrast sobre \\(p\\) emprarem la mostra de 60 casos discordants on 41 són Èxits. Ho fen directament amb R: binom.test(41, 60, p=0.5, alternative=&quot;greater&quot;) ## ## Exact binomial test ## ## data: 41 and 60 ## number of successes = 41, number of trials = 60, p-value = ## 0.003109 ## alternative hypothesis: true probability of success is greater than 0.5 ## 95 percent confidence interval: ## 0.5708296 1.0000000 ## sample estimates: ## probability of success ## 0.6833333 Conclusió: Hem obtingut evidència estadísticament significativa que la taxa d’efectivitat del placebo i del fàrmac són diferents (test binomial, p-valor 0.003). "]
]
